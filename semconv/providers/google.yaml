# Google AI (Gemini) Provider Fingerprinting
# API Documentation: https://ai.google.dev/api

provider: google
display_name: "Google AI (Gemini)"
base_urls:
  - https://generativelanguage.googleapis.com
  - https://aiplatform.googleapis.com  # Vertex AI

# === Authentication ===
auth:
  methods:
    api_key:
      type: api_key
      query_param: "key"
      description: "Google AI Studio API key"
    oauth:
      type: oauth2
      header: "Authorization"
      format: "Bearer {token}"
      description: "Google Cloud OAuth for Vertex AI"
    service_account:
      type: service_account
      header: "Authorization"
      format: "Bearer {token}"
      description: "GCP service account for Vertex AI"

# === Endpoints ===
endpoints:
  # Google AI Studio (generativelanguage.googleapis.com)
  generate_content:
    path: "/v1beta/models/{model}:generateContent"
    method: POST
    request_type: chat
    request_extraction:
      model: "{model}"  # From URL path
      contents: "$.contents"
      system_instruction: "$.systemInstruction"
      tools: "$.tools"
      generation_config:
        temperature: "$.generationConfig.temperature"
        max_output_tokens: "$.generationConfig.maxOutputTokens"
        top_p: "$.generationConfig.topP"
        top_k: "$.generationConfig.topK"
    response_extraction:
      candidates: "$.candidates"
      usage:
        prompt_tokens: "$.usageMetadata.promptTokenCount"
        completion_tokens: "$.usageMetadata.candidatesTokenCount"
        total_tokens: "$.usageMetadata.totalTokenCount"
      finish_reason: "$.candidates[0].finishReason"
        
  stream_generate_content:
    path: "/v1beta/models/{model}:streamGenerateContent"
    method: POST
    request_type: chat
    streaming: true
    query_params:
      alt: "sse"
      
  embed_content:
    path: "/v1beta/models/{model}:embedContent"
    method: POST
    request_type: embedding
    
  batch_embed_contents:
    path: "/v1beta/models/{model}:batchEmbedContents"
    method: POST
    request_type: embedding
    
  count_tokens:
    path: "/v1beta/models/{model}:countTokens"
    method: POST
    request_type: utility

  # Vertex AI (aiplatform.googleapis.com)
  vertex_generate_content:
    path: "/v1/projects/{project}/locations/{location}/publishers/google/models/{model}:generateContent"
    method: POST
    request_type: chat
    
  vertex_stream_generate_content:
    path: "/v1/projects/{project}/locations/{location}/publishers/google/models/{model}:streamGenerateContent"
    method: POST
    request_type: chat
    streaming: true

# === Models ===
# Model data is auto-generated from LiteLLM. See:
#   semconv/providers/_generated/models.yaml
#   semconv/providers/_generated/models.json
#
# To update model data, run:
#   python scripts/sync-models.py
#
# Model families for grouping (manually maintained):
model_families:
  gemini-2.0:
    pattern: "^gemini-2\\.0"
    display_name: "Gemini 2.0"
    
  gemini-1.5:
    pattern: "^gemini-1\\.5"
    display_name: "Gemini 1.5"
    
  gemini-1.0:
    pattern: "^gemini-1\\.0|^gemini-pro"
    display_name: "Gemini 1.0"
    deprecated: true
    
  embedding:
    pattern: "^text-embedding|^embedding"
    display_name: "Embeddings"

# === Special Features ===
features:
  grounding:
    description: "Ground responses with Google Search"
    enabled_via:
      tool_type: "google_search_retrieval"
    models: [gemini-2.0-flash, gemini-1.5-pro, gemini-1.5-flash]
    
  code_execution:
    description: "Execute Python code in sandbox"
    enabled_via:
      tool_type: "code_execution"
    models: [gemini-2.0-flash, gemini-1.5-pro, gemini-1.5-flash]
    
  context_caching:
    description: "Cache large contexts for reuse"
    api_path: "/v1beta/cachedContents"

# === Fingerprinting Signals ===
fingerprints:
  high_confidence:
    - domain: "generativelanguage.googleapis.com"
      path_contains: ":generateContent"
      
    - domain: "generativelanguage.googleapis.com"
      path_contains: ":streamGenerateContent"
      
    - domain: "aiplatform.googleapis.com"
      path_contains: "/publishers/google/models/"
      
  medium_confidence:
    - domain: "generativelanguage.googleapis.com"
      path_prefix: "/v1beta/models/"
      
  response_signals:
    - body_field: "$.candidates"
      is_array: true
    - body_field: "$.usageMetadata.promptTokenCount"
    - body_field: "$.candidates[0].finishReason"
      values: ["STOP", "MAX_TOKENS", "SAFETY", "RECITATION"]

