# OISP Provider Registry
# 
# Master list of AI providers with fingerprinting metadata.
#
# Model capabilities are AUTO-GENERATED from LiteLLM. See:
#   _generated/models.yaml  - Human-readable
#   _generated/models.json  - Machine-readable
#   _generated/models.ts    - TypeScript types
#
# To update model data, run:
#   python scripts/sync-models.py
#
# Source: https://github.com/BerriAI/litellm

version: "0.1"
last_updated: "2025-12-22"

# Reference to generated model data
models_source:
  type: "generated"
  path: "./_generated/models.json"
  script: "scripts/sync-models.py"
  upstream: "https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"

providers:
  # === Major Cloud Providers ===
  
  openai:
    display_name: "OpenAI"
    type: cloud
    domains:
      - api.openai.com
    config_file: openai.yaml
    litellm_provider: openai
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
      key_prefixes:
        - "sk-"           # Legacy keys
        - "sk-proj-"      # Project keys
        - "sk-svcacct-"   # Service account keys
    features:
      - chat
      - completion
      - embedding
      - image_generation
      - audio_transcription
      - audio_speech
      - moderation

  anthropic:
    display_name: "Anthropic"
    type: cloud
    domains:
      - api.anthropic.com
    config_file: anthropic.yaml
    litellm_provider: anthropic
    auth:
      type: api_key
      header: "x-api-key"
      key_prefixes:
        - "sk-ant-"
    features:
      - chat
      - vision
      - tool_use
      - computer_use

  google:
    display_name: "Google AI (Gemini)"
    type: cloud
    domains:
      - generativelanguage.googleapis.com
      - aiplatform.googleapis.com
    config_file: google.yaml
    litellm_provider: gemini
    auth:
      type: api_key
      query_param: "key"
    features:
      - chat
      - embedding
      - vision
      - function_calling

  azure_openai:
    display_name: "Azure OpenAI Service"
    type: cloud
    domains:
      - "*.openai.azure.com"
    config_file: azure-openai.yaml
    litellm_provider: azure
    auth:
      type: api_key
      header: "api-key"
    features:
      - chat
      - completion
      - embedding
      - image_generation

  aws_bedrock:
    display_name: "AWS Bedrock"
    type: cloud
    domains:
      - "bedrock-runtime.*.amazonaws.com"
      - "bedrock.*.amazonaws.com"
    config_file: aws-bedrock.yaml
    litellm_provider: bedrock
    auth:
      type: aws_sig_v4
    features:
      - chat
      - embedding
      - image_generation

  # === Other Cloud Providers ===

  cohere:
    display_name: "Cohere"
    type: cloud
    domains:
      - api.cohere.ai
      - api.cohere.com
    config_file: cohere.yaml
    litellm_provider: cohere
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - embedding
      - rerank

  mistral:
    display_name: "Mistral AI"
    type: cloud
    domains:
      - api.mistral.ai
    config_file: mistral.yaml
    litellm_provider: mistral
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - embedding
      - function_calling

  groq:
    display_name: "Groq"
    type: cloud
    domains:
      - api.groq.com
    config_file: groq.yaml
    litellm_provider: groq
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - vision

  together:
    display_name: "Together AI"
    type: cloud
    domains:
      - api.together.xyz
    config_file: together.yaml
    litellm_provider: together_ai
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - embedding
      - image_generation

  fireworks:
    display_name: "Fireworks AI"
    type: cloud
    domains:
      - api.fireworks.ai
    config_file: fireworks.yaml
    litellm_provider: fireworks_ai
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - embedding

  replicate:
    display_name: "Replicate"
    type: cloud
    domains:
      - api.replicate.com
    litellm_provider: replicate
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Token "
    features:
      - chat
      - image_generation

  huggingface:
    display_name: "Hugging Face"
    type: cloud
    domains:
      - api-inference.huggingface.co
    litellm_provider: huggingface
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - embedding

  perplexity:
    display_name: "Perplexity"
    type: cloud
    domains:
      - api.perplexity.ai
    litellm_provider: perplexity
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - web_search

  deepseek:
    display_name: "DeepSeek"
    type: cloud
    domains:
      - api.deepseek.com
    litellm_provider: deepseek
    auth:
      type: api_key
      header: "Authorization"
      prefix: "Bearer "
    features:
      - chat
      - reasoning

  # === Local/Self-Hosted ===

  ollama:
    display_name: "Ollama"
    type: local
    domains:
      - localhost:11434
      - "127.0.0.1:11434"
      - "*.local:11434"
    config_file: ollama.yaml
    litellm_provider: ollama
    auth:
      type: none
    features:
      - chat
      - embedding
    notes: "Local LLM runner. Default port 11434."

  lmstudio:
    display_name: "LM Studio"
    type: local
    domains:
      - localhost:1234
      - "127.0.0.1:1234"
    litellm_provider: lm_studio
    auth:
      type: none
    features:
      - chat
    notes: "Local LLM GUI. Default port 1234. OpenAI-compatible API."

  vllm:
    display_name: "vLLM"
    type: self_hosted
    domains: []  # User-configured
    litellm_provider: vllm
    auth:
      type: api_key  # Optional
    features:
      - chat
      - completion
    notes: "Self-hosted inference server. OpenAI-compatible API."

  text_generation_inference:
    display_name: "Text Generation Inference (TGI)"
    type: self_hosted
    domains: []
    litellm_provider: huggingface
    auth:
      type: none
    features:
      - chat
      - completion
    notes: "Hugging Face TGI server."

# === Domain to Provider Mapping (for quick lookup) ===

domain_lookup:
  "api.openai.com": openai
  "api.anthropic.com": anthropic
  "generativelanguage.googleapis.com": google
  "aiplatform.googleapis.com": google
  "api.cohere.ai": cohere
  "api.cohere.com": cohere
  "api.mistral.ai": mistral
  "api.groq.com": groq
  "api.together.xyz": together
  "api.fireworks.ai": fireworks
  "api.replicate.com": replicate
  "api-inference.huggingface.co": huggingface
  "api.perplexity.ai": perplexity
  "api.deepseek.com": deepseek

# Patterns for wildcard matching
domain_patterns:
  - pattern: "*.openai.azure.com"
    provider: azure_openai
  - pattern: "bedrock-runtime.*.amazonaws.com"
    provider: aws_bedrock
  - pattern: "bedrock.*.amazonaws.com"
    provider: aws_bedrock
  - pattern: "localhost:11434"
    provider: ollama
  - pattern: "127.0.0.1:11434"
    provider: ollama
  - pattern: "localhost:1234"
    provider: lmstudio
  - pattern: "127.0.0.1:1234"
    provider: lmstudio

