# Anthropic Provider Fingerprinting
# API Documentation: https://docs.anthropic.com/en/api

provider: anthropic
display_name: "Anthropic"
base_urls:
  - https://api.anthropic.com

# === Authentication ===
auth:
  type: api_key
  header: "x-api-key"
  key_patterns:
    - pattern: "^sk-ant-[a-zA-Z0-9-]+"
      description: "Anthropic API key"
  version_header: "anthropic-version"
  beta_header: "anthropic-beta"

# === Endpoints ===
endpoints:
  messages:
    path: "/v1/messages"
    method: POST
    request_type: chat
    streaming:
      indicator:
        body_field: "stream"
        value: true
      content_type: "text/event-stream"
    request_extraction:
      model: "$.model"
      messages: "$.messages"
      system: "$.system"
      max_tokens: "$.max_tokens"
      temperature: "$.temperature"
      tools: "$.tools"
      tool_choice: "$.tool_choice"
      stream: "$.stream"
    response_extraction:
      model: "$.model"
      request_id:
        header: "request-id"
      content: "$.content"
      stop_reason: "$.stop_reason"
      usage:
        input_tokens: "$.usage.input_tokens"
        output_tokens: "$.usage.output_tokens"
        cache_creation_input_tokens: "$.usage.cache_creation_input_tokens"
        cache_read_input_tokens: "$.usage.cache_read_input_tokens"

  messages_count_tokens:
    path: "/v1/messages/count_tokens"
    method: POST
    request_type: utility
    
  completions:
    path: "/v1/complete"
    method: POST
    request_type: completion
    deprecated: true
    note: "Legacy Text Completions API"

# === Response Headers ===
response_headers:
  request_id: "request-id"
  ratelimit_requests_limit: "anthropic-ratelimit-requests-limit"
  ratelimit_requests_remaining: "anthropic-ratelimit-requests-remaining"
  ratelimit_tokens_limit: "anthropic-ratelimit-tokens-limit"
  ratelimit_tokens_remaining: "anthropic-ratelimit-tokens-remaining"

# === Models ===
# Model data is auto-generated from LiteLLM. See:
#   semconv/providers/_generated/models.yaml
#   semconv/providers/_generated/models.json
#
# To update model data, run:
#   python scripts/sync-models.py
#
# Model families for grouping (manually maintained):
model_families:
  claude-3.5:
    pattern: "^claude-3-5"
    display_name: "Claude 3.5"
    
  claude-3:
    pattern: "^claude-3(?!-5)"
    display_name: "Claude 3"
    
  claude-2:
    pattern: "^claude-2"
    display_name: "Claude 2"
    deprecated: true

# === Special Features ===
features:
  prompt_caching:
    description: "Cache long contexts for repeated use"
    enabled_via: "anthropic-beta: prompt-caching-2024-07-31"
    usage_fields:
      cache_creation_input_tokens: "$.usage.cache_creation_input_tokens"
      cache_read_input_tokens: "$.usage.cache_read_input_tokens"
      
  computer_use:
    description: "Allow Claude to control computer interfaces"
    enabled_via: "anthropic-beta: computer-use-2024-10-22"
    models: [claude-3-5-sonnet-20241022]
    tool_types: [computer_20241022, text_editor_20241022, bash_20241022]
    
  extended_thinking:
    description: "Extended reasoning capabilities"
    enabled_via: "anthropic-beta: extended-thinking-2025-01-24"

# === Fingerprinting Signals ===
fingerprints:
  high_confidence:
    - domain: "api.anthropic.com"
      path_prefix: "/v1/"
      has_model_field: true
      model_pattern: "^claude-"
      
  medium_confidence:
    - domain: "api.anthropic.com"
      path_prefix: "/v1/"
      
  response_signals:
    - header: "anthropic-ratelimit-requests-limit"
    - body_field: "$.type"
      values: ["message", "message_start", "content_block_delta"]
    - body_field: "$.model"
      pattern: "^claude-"
    - body_field: "$.stop_reason"
      values: ["end_turn", "max_tokens", "stop_sequence", "tool_use"]

