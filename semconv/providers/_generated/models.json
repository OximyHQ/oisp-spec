{
  "version": "0.1",
  "generated_at": "2025-12-23T00:25:02.581276+00:00",
  "source": "litellm",
  "source_url": "https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json",
  "stats": {
    "total_models": 2248,
    "providers": 94
  },
  "providers": {
    "ai21": {
      "model_count": 12,
      "models": [
        "j2-light",
        "j2-mid",
        "j2-ultra",
        "jamba-1.5",
        "jamba-1.5-large",
        "jamba-1.5-large@001",
        "jamba-1.5-mini",
        "jamba-1.5-mini@001",
        "jamba-large-1.6",
        "jamba-large-1.7",
        "jamba-mini-1.6",
        "jamba-mini-1.7"
      ]
    },
    "aiml": {
      "model_count": 10,
      "models": [
        "dall-e-2",
        "dall-e-3",
        "flux-pro",
        "flux-pro/v1.1",
        "flux-pro/v1.1-ultra",
        "flux-realism",
        "flux/dev",
        "flux/kontext-max/text-to-image",
        "flux/kontext-pro/text-to-image",
        "flux/schnell"
      ]
    },
    "aleph_alpha": {
      "model_count": 6,
      "models": [
        "luminous-base",
        "luminous-base-control",
        "luminous-extended",
        "luminous-extended-control",
        "luminous-supreme",
        "luminous-supreme-control"
      ]
    },
    "amazon_nova": {
      "model_count": 4,
      "models": [
        "amazon-nova/nova-lite-v1",
        "amazon-nova/nova-micro-v1",
        "amazon-nova/nova-premier-v1",
        "amazon-nova/nova-pro-v1"
      ]
    },
    "anthropic": {
      "model_count": 22,
      "models": [
        "claude-3-5-haiku-20241022",
        "claude-3-5-haiku-latest",
        "claude-3-5-sonnet-20240620",
        "claude-3-5-sonnet-20241022",
        "claude-3-5-sonnet-latest",
        "claude-3-7-sonnet-20250219",
        "claude-3-7-sonnet-latest",
        "claude-3-haiku-20240307",
        "claude-3-opus-20240229",
        "claude-3-opus-latest",
        "claude-4-opus-20250514",
        "claude-4-sonnet-20250514",
        "claude-haiku-4-5",
        "claude-haiku-4-5-20251001",
        "claude-opus-4-1",
        "claude-opus-4-1-20250805",
        "claude-opus-4-20250514",
        "claude-opus-4-5",
        "claude-opus-4-5-20251101",
        "claude-sonnet-4-20250514",
        "claude-sonnet-4-5",
        "claude-sonnet-4-5-20250929"
      ]
    },
    "anyscale": {
      "model_count": 12,
      "models": [
        "HuggingFaceH4/zephyr-7b-beta",
        "codellama/CodeLlama-34b-Instruct-hf",
        "codellama/CodeLlama-70b-Instruct-hf",
        "google/gemma-7b-it",
        "meta-llama/Llama-2-13b-chat-hf",
        "meta-llama/Llama-2-70b-chat-hf",
        "meta-llama/Llama-2-7b-chat-hf",
        "meta-llama/Meta-Llama-3-70B-Instruct",
        "meta-llama/Meta-Llama-3-8B-Instruct",
        "mistralai/Mistral-7B-Instruct-v0.1",
        "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "mistralai/Mixtral-8x7B-Instruct-v0.1"
      ]
    },
    "assemblyai": {
      "model_count": 2,
      "models": [
        "best",
        "nano"
      ]
    },
    "aws_bedrock": {
      "model_count": 192,
      "models": [
        "*/1-month-commitment/cohere.command-light-text-v14",
        "*/1-month-commitment/cohere.command-text-v14",
        "*/6-month-commitment/cohere.command-light-text-v14",
        "*/6-month-commitment/cohere.command-text-v14",
        "ai21.j2-mid-v1",
        "ai21.j2-ultra-v1",
        "ai21.jamba-1-5-large-v1:0",
        "ai21.jamba-1-5-mini-v1:0",
        "ai21.jamba-instruct-v1:0",
        "amazon.nova-canvas-v1:0",
        "amazon.rerank-v1:0",
        "amazon.titan-embed-image-v1",
        "amazon.titan-embed-text-v1",
        "amazon.titan-embed-text-v2:0",
        "amazon.titan-image-generator-v1",
        "amazon.titan-image-generator-v2",
        "amazon.titan-image-generator-v2:0",
        "amazon.titan-text-express-v1",
        "amazon.titan-text-lite-v1",
        "amazon.titan-text-premier-v1:0",
        "anthropic.claude-3-5-haiku-20241022-v1:0",
        "anthropic.claude-3-5-sonnet-20240620-v1:0",
        "anthropic.claude-3-5-sonnet-20241022-v2:0",
        "anthropic.claude-3-7-sonnet-20240620-v1:0",
        "anthropic.claude-3-haiku-20240307-v1:0",
        "anthropic.claude-3-opus-20240229-v1:0",
        "anthropic.claude-3-sonnet-20240229-v1:0",
        "anthropic.claude-instant-v1",
        "anthropic.claude-v1",
        "anthropic.claude-v2:1",
        "ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
        "ap-northeast-1/1-month-commitment/anthropic.claude-v1",
        "ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
        "ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
        "ap-northeast-1/6-month-commitment/anthropic.claude-v1",
        "ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
        "ap-northeast-1/anthropic.claude-instant-v1",
        "ap-northeast-1/anthropic.claude-v1",
        "ap-northeast-1/anthropic.claude-v2:1",
        "ap-south-1/meta.llama3-70b-instruct-v1:0",
        "ap-south-1/meta.llama3-8b-instruct-v1:0",
        "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
        "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "apac.anthropic.claude-3-haiku-20240307-v1:0",
        "apac.anthropic.claude-3-sonnet-20240229-v1:0",
        "ca-central-1/meta.llama3-70b-instruct-v1:0",
        "ca-central-1/meta.llama3-8b-instruct-v1:0",
        "claude-sonnet-4-5-20250929-v1:0",
        "cohere.command-light-text-v14",
        "cohere.command-r-plus-v1:0",
        "cohere.command-r-v1:0",
        "cohere.command-text-v14",
        "cohere.embed-english-v3",
        "cohere.embed-multilingual-v3",
        "cohere.embed-v4:0",
        "cohere.rerank-v3-5:0",
        "eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
        "eu-central-1/1-month-commitment/anthropic.claude-v1",
        "eu-central-1/1-month-commitment/anthropic.claude-v2:1",
        "eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
        "eu-central-1/6-month-commitment/anthropic.claude-v1",
        "eu-central-1/6-month-commitment/anthropic.claude-v2:1",
        "eu-central-1/anthropic.claude-instant-v1",
        "eu-central-1/anthropic.claude-v1",
        "eu-central-1/anthropic.claude-v2:1",
        "eu-west-1/meta.llama3-70b-instruct-v1:0",
        "eu-west-1/meta.llama3-8b-instruct-v1:0",
        "eu-west-2/meta.llama3-70b-instruct-v1:0",
        "eu-west-2/meta.llama3-8b-instruct-v1:0",
        "eu-west-3/mistral.mistral-7b-instruct-v0:2",
        "eu-west-3/mistral.mistral-large-2402-v1:0",
        "eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
        "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
        "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
        "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
        "eu.anthropic.claude-3-haiku-20240307-v1:0",
        "eu.anthropic.claude-3-opus-20240229-v1:0",
        "eu.anthropic.claude-3-sonnet-20240229-v1:0",
        "eu.meta.llama3-2-1b-instruct-v1:0",
        "eu.meta.llama3-2-3b-instruct-v1:0",
        "eu.twelvelabs.marengo-embed-2-7-v1:0",
        "eu.twelvelabs.pegasus-1-2-v1:0",
        "invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
        "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
        "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
        "meta.llama2-13b-chat-v1",
        "meta.llama2-70b-chat-v1",
        "meta.llama3-1-405b-instruct-v1:0",
        "meta.llama3-1-70b-instruct-v1:0",
        "meta.llama3-1-8b-instruct-v1:0",
        "meta.llama3-2-11b-instruct-v1:0",
        "meta.llama3-2-1b-instruct-v1:0",
        "meta.llama3-2-3b-instruct-v1:0",
        "meta.llama3-2-90b-instruct-v1:0",
        "meta.llama3-70b-instruct-v1:0",
        "meta.llama3-8b-instruct-v1:0",
        "mistral.mistral-7b-instruct-v0:2",
        "mistral.mistral-large-2402-v1:0",
        "mistral.mistral-large-2407-v1:0",
        "mistral.mistral-small-2402-v1:0",
        "mistral.mixtral-8x7b-instruct-v0:1",
        "sa-east-1/meta.llama3-70b-instruct-v1:0",
        "sa-east-1/meta.llama3-8b-instruct-v1:0",
        "stability.sd3-5-large-v1:0",
        "stability.sd3-large-v1:0",
        "stability.stable-conservative-upscale-v1:0",
        "stability.stable-creative-upscale-v1:0",
        "stability.stable-fast-upscale-v1:0",
        "stability.stable-image-control-sketch-v1:0",
        "stability.stable-image-control-structure-v1:0",
        "stability.stable-image-core-v1:0",
        "stability.stable-image-core-v1:1",
        "stability.stable-image-erase-object-v1:0",
        "stability.stable-image-inpaint-v1:0",
        "stability.stable-image-remove-background-v1:0",
        "stability.stable-image-search-recolor-v1:0",
        "stability.stable-image-search-replace-v1:0",
        "stability.stable-image-style-guide-v1:0",
        "stability.stable-image-ultra-v1:0",
        "stability.stable-image-ultra-v1:1",
        "stability.stable-outpaint-v1:0",
        "stability.stable-style-transfer-v1:0",
        "twelvelabs.marengo-embed-2-7-v1:0",
        "twelvelabs.pegasus-1-2-v1:0",
        "us-east-1/1-month-commitment/anthropic.claude-instant-v1",
        "us-east-1/1-month-commitment/anthropic.claude-v1",
        "us-east-1/1-month-commitment/anthropic.claude-v2:1",
        "us-east-1/6-month-commitment/anthropic.claude-instant-v1",
        "us-east-1/6-month-commitment/anthropic.claude-v1",
        "us-east-1/6-month-commitment/anthropic.claude-v2:1",
        "us-east-1/anthropic.claude-instant-v1",
        "us-east-1/anthropic.claude-v1",
        "us-east-1/anthropic.claude-v2:1",
        "us-east-1/meta.llama3-70b-instruct-v1:0",
        "us-east-1/meta.llama3-8b-instruct-v1:0",
        "us-east-1/mistral.mistral-7b-instruct-v0:2",
        "us-east-1/mistral.mistral-large-2402-v1:0",
        "us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
        "us-gov-east-1/amazon.nova-pro-v1:0",
        "us-gov-east-1/amazon.titan-embed-text-v1",
        "us-gov-east-1/amazon.titan-embed-text-v2:0",
        "us-gov-east-1/amazon.titan-text-express-v1",
        "us-gov-east-1/amazon.titan-text-lite-v1",
        "us-gov-east-1/amazon.titan-text-premier-v1:0",
        "us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
        "us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0",
        "us-gov-east-1/claude-sonnet-4-5-20250929-v1:0",
        "us-gov-east-1/meta.llama3-70b-instruct-v1:0",
        "us-gov-east-1/meta.llama3-8b-instruct-v1:0",
        "us-gov-west-1/amazon.nova-pro-v1:0",
        "us-gov-west-1/amazon.titan-embed-text-v1",
        "us-gov-west-1/amazon.titan-embed-text-v2:0",
        "us-gov-west-1/amazon.titan-text-express-v1",
        "us-gov-west-1/amazon.titan-text-lite-v1",
        "us-gov-west-1/amazon.titan-text-premier-v1:0",
        "us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
        "us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0",
        "us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0",
        "us-gov-west-1/claude-sonnet-4-5-20250929-v1:0",
        "us-gov-west-1/meta.llama3-70b-instruct-v1:0",
        "us-gov-west-1/meta.llama3-8b-instruct-v1:0",
        "us-west-1/meta.llama3-70b-instruct-v1:0",
        "us-west-1/meta.llama3-8b-instruct-v1:0",
        "us-west-2/1-month-commitment/anthropic.claude-instant-v1",
        "us-west-2/1-month-commitment/anthropic.claude-v1",
        "us-west-2/1-month-commitment/anthropic.claude-v2:1",
        "us-west-2/6-month-commitment/anthropic.claude-instant-v1",
        "us-west-2/6-month-commitment/anthropic.claude-v1",
        "us-west-2/6-month-commitment/anthropic.claude-v2:1",
        "us-west-2/anthropic.claude-instant-v1",
        "us-west-2/anthropic.claude-v1",
        "us-west-2/anthropic.claude-v2:1",
        "us-west-2/mistral.mistral-7b-instruct-v0:2",
        "us-west-2/mistral.mistral-large-2402-v1:0",
        "us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
        "us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
        "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "us.anthropic.claude-3-haiku-20240307-v1:0",
        "us.anthropic.claude-3-opus-20240229-v1:0",
        "us.anthropic.claude-3-sonnet-20240229-v1:0",
        "us.meta.llama3-1-405b-instruct-v1:0",
        "us.meta.llama3-1-70b-instruct-v1:0",
        "us.meta.llama3-1-8b-instruct-v1:0",
        "us.meta.llama3-2-11b-instruct-v1:0",
        "us.meta.llama3-2-1b-instruct-v1:0",
        "us.meta.llama3-2-3b-instruct-v1:0",
        "us.meta.llama3-2-90b-instruct-v1:0",
        "us.twelvelabs.marengo-embed-2-7-v1:0",
        "us.twelvelabs.pegasus-1-2-v1:0"
      ]
    },
    "aws_polly": {
      "model_count": 4,
      "models": [
        "generative",
        "long-form",
        "neural",
        "standard"
      ]
    },
    "aws_sagemaker": {
      "model_count": 6,
      "models": [
        "meta-textgeneration-llama-2-13b",
        "meta-textgeneration-llama-2-13b-f",
        "meta-textgeneration-llama-2-70b",
        "meta-textgeneration-llama-2-70b-b-f",
        "meta-textgeneration-llama-2-7b",
        "meta-textgeneration-llama-2-7b-f"
      ]
    },
    "azure_openai": {
      "model_count": 242,
      "models": [
        "Cohere-embed-v3-english",
        "Cohere-embed-v3-multilingual",
        "FLUX-1.1-pro",
        "FLUX.1-Kontext-pro",
        "Llama-3.2-11B-Vision-Instruct",
        "Llama-3.2-90B-Vision-Instruct",
        "Llama-3.3-70B-Instruct",
        "Llama-4-Maverick-17B-128E-Instruct-FP8",
        "Llama-4-Scout-17B-16E-Instruct",
        "MAI-DS-R1",
        "Meta-Llama-3-70B-Instruct",
        "Meta-Llama-3.1-405B-Instruct",
        "Meta-Llama-3.1-70B-Instruct",
        "Meta-Llama-3.1-8B-Instruct",
        "Phi-3-medium-128k-instruct",
        "Phi-3-medium-4k-instruct",
        "Phi-3-mini-128k-instruct",
        "Phi-3-mini-4k-instruct",
        "Phi-3-small-128k-instruct",
        "Phi-3-small-8k-instruct",
        "Phi-3.5-MoE-instruct",
        "Phi-3.5-mini-instruct",
        "Phi-3.5-vision-instruct",
        "Phi-4",
        "Phi-4-mini-instruct",
        "Phi-4-mini-reasoning",
        "Phi-4-multimodal-instruct",
        "Phi-4-reasoning",
        "ada",
        "claude-haiku-4-5",
        "claude-opus-4-1",
        "claude-sonnet-4-5",
        "codex-mini",
        "cohere-rerank-v3-english",
        "cohere-rerank-v3-multilingual",
        "cohere-rerank-v3.5",
        "cohere-rerank-v4.0-fast",
        "cohere-rerank-v4.0-pro",
        "command-r-plus",
        "computer-use-preview",
        "computer-use-preview",
        "container",
        "deepseek-r1",
        "deepseek-v3",
        "deepseek-v3-0324",
        "deepseek-v3.2",
        "deepseek-v3.2-speciale",
        "doc-intelligence/prebuilt-document",
        "doc-intelligence/prebuilt-layout",
        "doc-intelligence/prebuilt-read",
        "embed-v-4-0",
        "eu/gpt-4o-2024-08-06",
        "eu/gpt-4o-2024-11-20",
        "eu/gpt-4o-mini-2024-07-18",
        "eu/gpt-4o-mini-realtime-preview-2024-12-17",
        "eu/gpt-4o-realtime-preview-2024-10-01",
        "eu/gpt-4o-realtime-preview-2024-12-17",
        "eu/gpt-5-2025-08-07",
        "eu/gpt-5-mini-2025-08-07",
        "eu/gpt-5-nano-2025-08-07",
        "eu/gpt-5.1",
        "eu/gpt-5.1-chat",
        "eu/gpt-5.1-codex",
        "eu/gpt-5.1-codex-mini",
        "eu/o1-2024-12-17",
        "eu/o1-mini-2024-09-12",
        "eu/o1-preview-2024-09-12",
        "eu/o3-mini-2025-01-31",
        "global-standard/gpt-4o-2024-08-06",
        "global-standard/gpt-4o-2024-11-20",
        "global-standard/gpt-4o-mini",
        "global/gpt-4o-2024-08-06",
        "global/gpt-4o-2024-11-20",
        "global/gpt-5.1",
        "global/gpt-5.1-chat",
        "global/gpt-5.1-codex",
        "global/gpt-5.1-codex-mini",
        "global/grok-3",
        "global/grok-3-mini",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-0125",
        "gpt-35-turbo",
        "gpt-35-turbo-0125",
        "gpt-35-turbo-0301",
        "gpt-35-turbo-0613",
        "gpt-35-turbo-1106",
        "gpt-35-turbo-16k",
        "gpt-35-turbo-16k-0613",
        "gpt-4",
        "gpt-4-0125-preview",
        "gpt-4-0613",
        "gpt-4-1106-preview",
        "gpt-4-32k",
        "gpt-4-32k-0613",
        "gpt-4-turbo",
        "gpt-4-turbo-2024-04-09",
        "gpt-4-turbo-vision-preview",
        "gpt-4.1",
        "gpt-4.1-2025-04-14",
        "gpt-4.1-mini",
        "gpt-4.1-mini-2025-04-14",
        "gpt-4.1-nano",
        "gpt-4.1-nano-2025-04-14",
        "gpt-4.5-preview",
        "gpt-4o",
        "gpt-4o-2024-05-13",
        "gpt-4o-2024-08-06",
        "gpt-4o-2024-11-20",
        "gpt-4o-audio-preview-2024-12-17",
        "gpt-4o-mini",
        "gpt-4o-mini-2024-07-18",
        "gpt-4o-mini-audio-preview-2024-12-17",
        "gpt-4o-mini-realtime-preview-2024-12-17",
        "gpt-4o-mini-transcribe",
        "gpt-4o-mini-tts",
        "gpt-4o-realtime-preview-2024-10-01",
        "gpt-4o-realtime-preview-2024-12-17",
        "gpt-4o-transcribe",
        "gpt-4o-transcribe-diarize",
        "gpt-5",
        "gpt-5-2025-08-07",
        "gpt-5-chat",
        "gpt-5-chat-latest",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-mini-2025-08-07",
        "gpt-5-nano",
        "gpt-5-nano-2025-08-07",
        "gpt-5-pro",
        "gpt-5.1",
        "gpt-5.1-2025-11-13",
        "gpt-5.1-chat",
        "gpt-5.1-chat-2025-11-13",
        "gpt-5.1-codex",
        "gpt-5.1-codex-2025-11-13",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.1-codex-mini-2025-11-13",
        "gpt-5.2",
        "gpt-5.2-2025-12-11",
        "gpt-5.2-chat-2025-12-11",
        "gpt-5.2-pro",
        "gpt-5.2-pro-2025-12-11",
        "gpt-audio-2025-08-28",
        "gpt-audio-mini-2025-10-06",
        "gpt-image-1",
        "gpt-image-1-mini",
        "gpt-realtime-2025-08-28",
        "gpt-realtime-mini-2025-10-06",
        "grok-3",
        "grok-3-mini",
        "grok-4",
        "grok-4-fast-non-reasoning",
        "grok-4-fast-reasoning",
        "grok-code-fast-1",
        "hd/1024-x-1024/dall-e-3",
        "hd/1024-x-1792/dall-e-3",
        "hd/1792-x-1024/dall-e-3",
        "high/1024-x-1024/gpt-image-1",
        "high/1024-x-1024/gpt-image-1-mini",
        "high/1024-x-1536/gpt-image-1",
        "high/1024-x-1536/gpt-image-1-mini",
        "high/1536-x-1024/gpt-image-1",
        "high/1536-x-1024/gpt-image-1-mini",
        "jais-30b-chat",
        "jamba-instruct",
        "low/1024-x-1024/gpt-image-1",
        "low/1024-x-1024/gpt-image-1-mini",
        "low/1024-x-1536/gpt-image-1",
        "low/1024-x-1536/gpt-image-1-mini",
        "low/1536-x-1024/gpt-image-1",
        "low/1536-x-1024/gpt-image-1-mini",
        "medium/1024-x-1024/gpt-image-1",
        "medium/1024-x-1024/gpt-image-1-mini",
        "medium/1024-x-1536/gpt-image-1",
        "medium/1024-x-1536/gpt-image-1-mini",
        "medium/1536-x-1024/gpt-image-1",
        "medium/1536-x-1024/gpt-image-1-mini",
        "ministral-3b",
        "mistral-document-ai-2505",
        "mistral-large",
        "mistral-large-2402",
        "mistral-large-2407",
        "mistral-large-3",
        "mistral-large-latest",
        "mistral-large-latest",
        "mistral-medium-2505",
        "mistral-nemo",
        "mistral-small",
        "mistral-small-2503",
        "o1",
        "o1-2024-12-17",
        "o1-mini",
        "o1-mini-2024-09-12",
        "o1-preview",
        "o1-preview-2024-09-12",
        "o3",
        "o3-2025-04-16",
        "o3-deep-research",
        "o3-mini",
        "o3-mini-2025-01-31",
        "o3-pro",
        "o3-pro-2025-06-10",
        "o4-mini",
        "o4-mini-2025-04-16",
        "sora-2",
        "sora-2-pro",
        "sora-2-pro-high-res",
        "speech/azure-tts",
        "speech/azure-tts-hd",
        "standard/1024-x-1024/dall-e-2",
        "standard/1024-x-1024/dall-e-3",
        "standard/1024-x-1792/dall-e-3",
        "standard/1792-x-1024/dall-e-3",
        "text-embedding-3-large",
        "text-embedding-3-small",
        "text-embedding-ada-002",
        "tts-1",
        "tts-1-hd",
        "us/gpt-4.1-2025-04-14",
        "us/gpt-4.1-mini-2025-04-14",
        "us/gpt-4.1-nano-2025-04-14",
        "us/gpt-4o-2024-08-06",
        "us/gpt-4o-2024-11-20",
        "us/gpt-4o-mini-2024-07-18",
        "us/gpt-4o-mini-realtime-preview-2024-12-17",
        "us/gpt-4o-realtime-preview-2024-10-01",
        "us/gpt-4o-realtime-preview-2024-12-17",
        "us/gpt-5-2025-08-07",
        "us/gpt-5-mini-2025-08-07",
        "us/gpt-5-nano-2025-08-07",
        "us/gpt-5.1",
        "us/gpt-5.1-chat",
        "us/gpt-5.1-codex",
        "us/gpt-5.1-codex-mini",
        "us/o1-2024-12-17",
        "us/o1-mini-2024-09-12",
        "us/o1-preview-2024-09-12",
        "us/o3-2025-04-16",
        "us/o3-mini-2025-01-31",
        "us/o4-mini-2025-04-16",
        "whisper-1"
      ]
    },
    "azure_text": {
      "model_count": 3,
      "models": [
        "azure/gpt-3.5-turbo-instruct-0914",
        "azure/gpt-35-turbo-instruct",
        "azure/gpt-35-turbo-instruct-0914"
      ]
    },
    "bedrock_converse": {
      "model_count": 87,
      "models": [
        "amazon.nova-2-lite-v1:0",
        "amazon.nova-lite-v1:0",
        "amazon.nova-micro-v1:0",
        "amazon.nova-pro-v1:0",
        "anthropic.claude-3-7-sonnet-20250219-v1:0",
        "anthropic.claude-haiku-4-5-20251001-v1:0",
        "anthropic.claude-haiku-4-5@20251001",
        "anthropic.claude-opus-4-1-20250805-v1:0",
        "anthropic.claude-opus-4-20250514-v1:0",
        "anthropic.claude-opus-4-5-20251101-v1:0",
        "anthropic.claude-sonnet-4-20250514-v1:0",
        "anthropic.claude-sonnet-4-5-20250929-v1:0",
        "apac.amazon.nova-2-lite-v1:0",
        "apac.amazon.nova-lite-v1:0",
        "apac.amazon.nova-micro-v1:0",
        "apac.amazon.nova-pro-v1:0",
        "apac.anthropic.claude-haiku-4-5-20251001-v1:0",
        "apac.anthropic.claude-sonnet-4-20250514-v1:0",
        "au.anthropic.claude-haiku-4-5-20251001-v1:0",
        "au.anthropic.claude-sonnet-4-5-20250929-v1:0",
        "deepseek.v3-v1:0",
        "eu.amazon.nova-2-lite-v1:0",
        "eu.amazon.nova-lite-v1:0",
        "eu.amazon.nova-micro-v1:0",
        "eu.amazon.nova-pro-v1:0",
        "eu.anthropic.claude-haiku-4-5-20251001-v1:0",
        "eu.anthropic.claude-opus-4-1-20250805-v1:0",
        "eu.anthropic.claude-opus-4-20250514-v1:0",
        "eu.anthropic.claude-opus-4-5-20251101-v1:0",
        "eu.anthropic.claude-sonnet-4-20250514-v1:0",
        "eu.anthropic.claude-sonnet-4-5-20250929-v1:0",
        "eu.mistral.pixtral-large-2502-v1:0",
        "global.amazon.nova-2-lite-v1:0",
        "global.anthropic.claude-haiku-4-5-20251001-v1:0",
        "global.anthropic.claude-opus-4-5-20251101-v1:0",
        "global.anthropic.claude-sonnet-4-20250514-v1:0",
        "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
        "google.gemma-3-12b-it",
        "google.gemma-3-27b-it",
        "google.gemma-3-4b-it",
        "jp.anthropic.claude-haiku-4-5-20251001-v1:0",
        "jp.anthropic.claude-sonnet-4-5-20250929-v1:0",
        "meta.llama3-3-70b-instruct-v1:0",
        "meta.llama4-maverick-17b-instruct-v1:0",
        "meta.llama4-scout-17b-instruct-v1:0",
        "minimax.minimax-m2",
        "mistral.magistral-small-2509",
        "mistral.ministral-3-14b-instruct",
        "mistral.ministral-3-3b-instruct",
        "mistral.ministral-3-8b-instruct",
        "mistral.mistral-large-3-675b-instruct",
        "mistral.voxtral-mini-3b-2507",
        "mistral.voxtral-small-24b-2507",
        "moonshot.kimi-k2-thinking",
        "nvidia.nemotron-nano-12b-v2",
        "nvidia.nemotron-nano-9b-v2",
        "openai.gpt-oss-120b-1:0",
        "openai.gpt-oss-20b-1:0",
        "openai.gpt-oss-safeguard-120b",
        "openai.gpt-oss-safeguard-20b",
        "qwen.qwen3-235b-a22b-2507-v1:0",
        "qwen.qwen3-32b-v1:0",
        "qwen.qwen3-coder-30b-a3b-v1:0",
        "qwen.qwen3-coder-480b-a35b-v1:0",
        "qwen.qwen3-next-80b-a3b",
        "qwen.qwen3-vl-235b-a22b",
        "us.amazon.nova-2-lite-v1:0",
        "us.amazon.nova-lite-v1:0",
        "us.amazon.nova-micro-v1:0",
        "us.amazon.nova-premier-v1:0",
        "us.amazon.nova-pro-v1:0",
        "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
        "us.anthropic.claude-haiku-4-5-20251001-v1:0",
        "us.anthropic.claude-opus-4-1-20250805-v1:0",
        "us.anthropic.claude-opus-4-20250514-v1:0",
        "us.anthropic.claude-opus-4-5-20251101-v1:0",
        "us.anthropic.claude-sonnet-4-20250514-v1:0",
        "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
        "us.deepseek.r1-v1:0",
        "us.meta.llama3-3-70b-instruct-v1:0",
        "us.meta.llama4-maverick-17b-instruct-v1:0",
        "us.meta.llama4-scout-17b-instruct-v1:0",
        "us.mistral.pixtral-large-2502-v1:0",
        "us.writer.palmyra-x4-v1:0",
        "us.writer.palmyra-x5-v1:0",
        "writer.palmyra-x4-v1:0",
        "writer.palmyra-x5-v1:0"
      ]
    },
    "cerebras": {
      "model_count": 6,
      "models": [
        "gpt-oss-120b",
        "llama-3.3-70b",
        "llama3.1-70b",
        "llama3.1-8b",
        "qwen-3-32b",
        "zai-glm-4.6"
      ]
    },
    "cloudflare": {
      "model_count": 4,
      "models": [
        "@cf/meta/llama-2-7b-chat-fp16",
        "@cf/meta/llama-2-7b-chat-int8",
        "@cf/mistral/mistral-7b-instruct-v0.1",
        "@hf/thebloke/codellama-7b-instruct-awq"
      ]
    },
    "codestral": {
      "model_count": 2,
      "models": [
        "codestral-2405",
        "codestral-latest"
      ]
    },
    "cohere": {
      "model_count": 22,
      "models": [
        "command",
        "command-a-03-2025",
        "command-light",
        "command-nightly",
        "command-r",
        "command-r-08-2024",
        "command-r-plus",
        "command-r-plus-08-2024",
        "command-r7b-12-2024",
        "embed-english-light-v2.0",
        "embed-english-light-v3.0",
        "embed-english-v2.0",
        "embed-english-v3.0",
        "embed-multilingual-light-v3.0",
        "embed-multilingual-v2.0",
        "embed-multilingual-v3.0",
        "embed-v4.0",
        "rerank-english-v2.0",
        "rerank-english-v3.0",
        "rerank-multilingual-v2.0",
        "rerank-multilingual-v3.0",
        "rerank-v3.5"
      ]
    },
    "dashscope": {
      "model_count": 22,
      "models": [
        "qwen-coder",
        "qwen-flash",
        "qwen-flash-2025-07-28",
        "qwen-max",
        "qwen-plus",
        "qwen-plus-2025-01-25",
        "qwen-plus-2025-04-28",
        "qwen-plus-2025-07-14",
        "qwen-plus-2025-07-28",
        "qwen-plus-2025-09-11",
        "qwen-plus-latest",
        "qwen-turbo",
        "qwen-turbo-2024-11-01",
        "qwen-turbo-2025-04-28",
        "qwen-turbo-latest",
        "qwen3-30b-a3b",
        "qwen3-coder-flash",
        "qwen3-coder-flash-2025-07-28",
        "qwen3-coder-plus",
        "qwen3-coder-plus-2025-07-22",
        "qwen3-max-preview",
        "qwq-plus"
      ]
    },
    "databricks": {
      "model_count": 28,
      "models": [
        "databricks-bge-large-en",
        "databricks-claude-3-7-sonnet",
        "databricks-claude-haiku-4-5",
        "databricks-claude-opus-4",
        "databricks-claude-opus-4-1",
        "databricks-claude-opus-4-5",
        "databricks-claude-sonnet-4",
        "databricks-claude-sonnet-4-1",
        "databricks-claude-sonnet-4-5",
        "databricks-gemini-2-5-flash",
        "databricks-gemini-2-5-pro",
        "databricks-gemma-3-12b",
        "databricks-gpt-5",
        "databricks-gpt-5-1",
        "databricks-gpt-5-mini",
        "databricks-gpt-5-nano",
        "databricks-gpt-oss-120b",
        "databricks-gpt-oss-20b",
        "databricks-gte-large-en",
        "databricks-llama-2-70b-chat",
        "databricks-llama-4-maverick",
        "databricks-meta-llama-3-1-405b-instruct",
        "databricks-meta-llama-3-1-8b-instruct",
        "databricks-meta-llama-3-3-70b-instruct",
        "databricks-meta-llama-3-70b-instruct",
        "databricks-mixtral-8x7b-instruct",
        "databricks-mpt-30b-instruct",
        "databricks-mpt-7b-instruct"
      ]
    },
    "dataforseo": {
      "model_count": 1,
      "models": [
        "search"
      ]
    },
    "deepgram": {
      "model_count": 36,
      "models": [
        "base",
        "base-conversationalai",
        "base-finance",
        "base-general",
        "base-meeting",
        "base-phonecall",
        "base-video",
        "base-voicemail",
        "enhanced",
        "enhanced-finance",
        "enhanced-general",
        "enhanced-meeting",
        "enhanced-phonecall",
        "nova",
        "nova-2",
        "nova-2-atc",
        "nova-2-automotive",
        "nova-2-conversationalai",
        "nova-2-drivethru",
        "nova-2-finance",
        "nova-2-general",
        "nova-2-meeting",
        "nova-2-phonecall",
        "nova-2-video",
        "nova-2-voicemail",
        "nova-3",
        "nova-3-general",
        "nova-3-medical",
        "nova-general",
        "nova-phonecall",
        "whisper",
        "whisper-base",
        "whisper-large",
        "whisper-medium",
        "whisper-small",
        "whisper-tiny"
      ]
    },
    "deepinfra": {
      "model_count": 67,
      "models": [
        "Gryphe/MythoMax-L2-13b",
        "NousResearch/Hermes-3-Llama-3.1-405B",
        "NousResearch/Hermes-3-Llama-3.1-70B",
        "Qwen/QwQ-32B",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2.5-7B-Instruct",
        "Qwen/Qwen2.5-VL-32B-Instruct",
        "Qwen/Qwen3-14B",
        "Qwen/Qwen3-235B-A22B",
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-32B",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Thinking",
        "Sao10K/L3-8B-Lunaris-v1-Turbo",
        "Sao10K/L3.1-70B-Euryale-v2.2",
        "Sao10K/L3.3-70B-Euryale-v2.3",
        "allenai/olmOCR-7B-0725-FP8",
        "anthropic/claude-3-7-sonnet-latest",
        "anthropic/claude-4-opus",
        "anthropic/claude-4-sonnet",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/DeepSeek-R1-0528-Turbo",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "deepseek-ai/DeepSeek-R1-Turbo",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3-0324",
        "deepseek-ai/DeepSeek-V3.1",
        "deepseek-ai/DeepSeek-V3.1-Terminus",
        "google/gemini-2.0-flash-001",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-pro",
        "google/gemma-3-12b-it",
        "google/gemma-3-27b-it",
        "google/gemma-3-4b-it",
        "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "meta-llama/Llama-3.2-3B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "meta-llama/Llama-Guard-3-8B",
        "meta-llama/Llama-Guard-4-12B",
        "meta-llama/Meta-Llama-3-8B-Instruct",
        "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "microsoft/WizardLM-2-8x22B",
        "microsoft/phi-4",
        "mistralai/Mistral-Nemo-Instruct-2407",
        "mistralai/Mistral-Small-24B-Instruct-2501",
        "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Instruct-0905",
        "nvidia/Llama-3.1-Nemotron-70B-Instruct",
        "nvidia/Llama-3.3-Nemotron-Super-49B-v1.5",
        "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "zai-org/GLM-4.5"
      ]
    },
    "deepseek": {
      "model_count": 8,
      "models": [
        "deepseek-chat",
        "deepseek-chat",
        "deepseek-coder",
        "deepseek-r1",
        "deepseek-reasoner",
        "deepseek-reasoner",
        "deepseek-v3",
        "deepseek-v3.2"
      ]
    },
    "elevenlabs": {
      "model_count": 2,
      "models": [
        "scribe_v1",
        "scribe_v1_experimental"
      ]
    },
    "exa_ai": {
      "model_count": 1,
      "models": [
        "search"
      ]
    },
    "fal_ai": {
      "model_count": 12,
      "models": [
        "bria/text-to-image/3.2",
        "fal-ai/bytedance/dreamina/v3.1/text-to-image",
        "fal-ai/bytedance/seedream/v3/text-to-image",
        "fal-ai/flux-pro/v1.1",
        "fal-ai/flux-pro/v1.1-ultra",
        "fal-ai/flux/schnell",
        "fal-ai/ideogram/v3",
        "fal-ai/imagen4/preview",
        "fal-ai/imagen4/preview/fast",
        "fal-ai/imagen4/preview/ultra",
        "fal-ai/recraft/v3/text-to-image",
        "fal-ai/stable-diffusion-v35-medium"
      ]
    },
    "featherless_ai": {
      "model_count": 2,
      "models": [
        "featherless-ai/Qwerky-72B",
        "featherless-ai/Qwerky-QwQ-32B"
      ]
    },
    "firecrawl": {
      "model_count": 1,
      "models": [
        "search"
      ]
    },
    "fireworks": {
      "model_count": 263,
      "models": [
        "accounts/fireworks/models/",
        "accounts/fireworks/models/SSD-1B",
        "accounts/fireworks/models/chronos-hermes-13b-v2",
        "accounts/fireworks/models/code-llama-13b",
        "accounts/fireworks/models/code-llama-13b-instruct",
        "accounts/fireworks/models/code-llama-13b-python",
        "accounts/fireworks/models/code-llama-34b",
        "accounts/fireworks/models/code-llama-34b-instruct",
        "accounts/fireworks/models/code-llama-34b-python",
        "accounts/fireworks/models/code-llama-70b",
        "accounts/fireworks/models/code-llama-70b-instruct",
        "accounts/fireworks/models/code-llama-70b-python",
        "accounts/fireworks/models/code-llama-7b",
        "accounts/fireworks/models/code-llama-7b-instruct",
        "accounts/fireworks/models/code-llama-7b-python",
        "accounts/fireworks/models/code-qwen-1p5-7b",
        "accounts/fireworks/models/codegemma-2b",
        "accounts/fireworks/models/codegemma-7b",
        "accounts/fireworks/models/cogito-671b-v2-p1",
        "accounts/fireworks/models/cogito-v1-preview-llama-3b",
        "accounts/fireworks/models/cogito-v1-preview-llama-70b",
        "accounts/fireworks/models/cogito-v1-preview-llama-8b",
        "accounts/fireworks/models/cogito-v1-preview-qwen-14b",
        "accounts/fireworks/models/cogito-v1-preview-qwen-32b",
        "accounts/fireworks/models/dbrx-instruct",
        "accounts/fireworks/models/deepseek-coder-1b-base",
        "accounts/fireworks/models/deepseek-coder-33b-instruct",
        "accounts/fireworks/models/deepseek-coder-7b-base",
        "accounts/fireworks/models/deepseek-coder-7b-base-v1p5",
        "accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5",
        "accounts/fireworks/models/deepseek-coder-v2-instruct",
        "accounts/fireworks/models/deepseek-coder-v2-lite-base",
        "accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
        "accounts/fireworks/models/deepseek-prover-v2",
        "accounts/fireworks/models/deepseek-r1",
        "accounts/fireworks/models/deepseek-r1-0528",
        "accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b",
        "accounts/fireworks/models/deepseek-r1-basic",
        "accounts/fireworks/models/deepseek-r1-distill-llama-70b",
        "accounts/fireworks/models/deepseek-r1-distill-llama-8b",
        "accounts/fireworks/models/deepseek-r1-distill-qwen-14b",
        "accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b",
        "accounts/fireworks/models/deepseek-r1-distill-qwen-32b",
        "accounts/fireworks/models/deepseek-r1-distill-qwen-7b",
        "accounts/fireworks/models/deepseek-v2-lite-chat",
        "accounts/fireworks/models/deepseek-v2p5",
        "accounts/fireworks/models/deepseek-v3",
        "accounts/fireworks/models/deepseek-v3-0324",
        "accounts/fireworks/models/deepseek-v3p1",
        "accounts/fireworks/models/deepseek-v3p1-terminus",
        "accounts/fireworks/models/deepseek-v3p2",
        "accounts/fireworks/models/devstral-small-2505",
        "accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b",
        "accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new",
        "accounts/fireworks/models/dolphin-2-9-2-qwen2-72b",
        "accounts/fireworks/models/dolphin-2p6-mixtral-8x7b",
        "accounts/fireworks/models/ernie-4p5-21b-a3b-pt",
        "accounts/fireworks/models/ernie-4p5-300b-a47b-pt",
        "accounts/fireworks/models/fare-20b",
        "accounts/fireworks/models/firefunction-v1",
        "accounts/fireworks/models/firefunction-v2",
        "accounts/fireworks/models/firellava-13b",
        "accounts/fireworks/models/firesearch-ocr-v6",
        "accounts/fireworks/models/fireworks-asr-large",
        "accounts/fireworks/models/fireworks-asr-v2",
        "accounts/fireworks/models/flux-1-dev",
        "accounts/fireworks/models/flux-1-dev-controlnet-union",
        "accounts/fireworks/models/flux-1-dev-fp8",
        "accounts/fireworks/models/flux-1-schnell",
        "accounts/fireworks/models/flux-1-schnell-fp8",
        "accounts/fireworks/models/flux-kontext-max",
        "accounts/fireworks/models/flux-kontext-pro",
        "accounts/fireworks/models/gemma-2b-it",
        "accounts/fireworks/models/gemma-3-27b-it",
        "accounts/fireworks/models/gemma-7b",
        "accounts/fireworks/models/gemma-7b-it",
        "accounts/fireworks/models/gemma2-9b-it",
        "accounts/fireworks/models/glm-4p5",
        "accounts/fireworks/models/glm-4p5-air",
        "accounts/fireworks/models/glm-4p5v",
        "accounts/fireworks/models/glm-4p6",
        "accounts/fireworks/models/gpt-oss-120b",
        "accounts/fireworks/models/gpt-oss-20b",
        "accounts/fireworks/models/gpt-oss-safeguard-120b",
        "accounts/fireworks/models/gpt-oss-safeguard-20b",
        "accounts/fireworks/models/hermes-2-pro-mistral-7b",
        "accounts/fireworks/models/internvl3-38b",
        "accounts/fireworks/models/internvl3-78b",
        "accounts/fireworks/models/internvl3-8b",
        "accounts/fireworks/models/japanese-stable-diffusion-xl",
        "accounts/fireworks/models/kat-coder",
        "accounts/fireworks/models/kat-dev-32b",
        "accounts/fireworks/models/kat-dev-72b-exp",
        "accounts/fireworks/models/kimi-k2-instruct",
        "accounts/fireworks/models/kimi-k2-instruct-0905",
        "accounts/fireworks/models/kimi-k2-thinking",
        "accounts/fireworks/models/llama-guard-2-8b",
        "accounts/fireworks/models/llama-guard-3-1b",
        "accounts/fireworks/models/llama-guard-3-8b",
        "accounts/fireworks/models/llama-v2-13b",
        "accounts/fireworks/models/llama-v2-13b-chat",
        "accounts/fireworks/models/llama-v2-70b",
        "accounts/fireworks/models/llama-v2-70b-chat",
        "accounts/fireworks/models/llama-v2-7b",
        "accounts/fireworks/models/llama-v2-7b-chat",
        "accounts/fireworks/models/llama-v3-70b-instruct",
        "accounts/fireworks/models/llama-v3-70b-instruct-hf",
        "accounts/fireworks/models/llama-v3-8b",
        "accounts/fireworks/models/llama-v3-8b-instruct-hf",
        "accounts/fireworks/models/llama-v3p1-405b-instruct",
        "accounts/fireworks/models/llama-v3p1-405b-instruct-long",
        "accounts/fireworks/models/llama-v3p1-70b-instruct",
        "accounts/fireworks/models/llama-v3p1-70b-instruct-1b",
        "accounts/fireworks/models/llama-v3p1-8b-instruct",
        "accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct",
        "accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
        "accounts/fireworks/models/llama-v3p2-1b",
        "accounts/fireworks/models/llama-v3p2-1b-instruct",
        "accounts/fireworks/models/llama-v3p2-3b",
        "accounts/fireworks/models/llama-v3p2-3b-instruct",
        "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
        "accounts/fireworks/models/llama-v3p3-70b-instruct",
        "accounts/fireworks/models/llama4-maverick-instruct-basic",
        "accounts/fireworks/models/llama4-scout-instruct-basic",
        "accounts/fireworks/models/llamaguard-7b",
        "accounts/fireworks/models/llava-yi-34b",
        "accounts/fireworks/models/minimax-m1-80k",
        "accounts/fireworks/models/minimax-m2",
        "accounts/fireworks/models/ministral-3-14b-instruct-2512",
        "accounts/fireworks/models/ministral-3-3b-instruct-2512",
        "accounts/fireworks/models/ministral-3-8b-instruct-2512",
        "accounts/fireworks/models/mistral-7b",
        "accounts/fireworks/models/mistral-7b-instruct-4k",
        "accounts/fireworks/models/mistral-7b-instruct-v0p2",
        "accounts/fireworks/models/mistral-7b-instruct-v3",
        "accounts/fireworks/models/mistral-7b-v0p2",
        "accounts/fireworks/models/mistral-large-3-fp8",
        "accounts/fireworks/models/mistral-nemo-base-2407",
        "accounts/fireworks/models/mistral-nemo-instruct-2407",
        "accounts/fireworks/models/mistral-small-24b-instruct-2501",
        "accounts/fireworks/models/mixtral-8x22b",
        "accounts/fireworks/models/mixtral-8x22b-instruct",
        "accounts/fireworks/models/mixtral-8x22b-instruct-hf",
        "accounts/fireworks/models/mixtral-8x7b",
        "accounts/fireworks/models/mixtral-8x7b-instruct",
        "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
        "accounts/fireworks/models/mythomax-l2-13b",
        "accounts/fireworks/models/nemotron-nano-v2-12b-vl",
        "accounts/fireworks/models/nous-capybara-7b-v1p9",
        "accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo",
        "accounts/fireworks/models/nous-hermes-2-yi-34b",
        "accounts/fireworks/models/nous-hermes-llama2-13b",
        "accounts/fireworks/models/nous-hermes-llama2-70b",
        "accounts/fireworks/models/nous-hermes-llama2-7b",
        "accounts/fireworks/models/nvidia-nemotron-nano-12b-v2",
        "accounts/fireworks/models/nvidia-nemotron-nano-9b-v2",
        "accounts/fireworks/models/openchat-3p5-0106-7b",
        "accounts/fireworks/models/openhermes-2-mistral-7b",
        "accounts/fireworks/models/openhermes-2p5-mistral-7b",
        "accounts/fireworks/models/openorca-7b",
        "accounts/fireworks/models/phi-2-3b",
        "accounts/fireworks/models/phi-3-mini-128k-instruct",
        "accounts/fireworks/models/phi-3-vision-128k-instruct",
        "accounts/fireworks/models/phind-code-llama-34b-python-v1",
        "accounts/fireworks/models/phind-code-llama-34b-v1",
        "accounts/fireworks/models/phind-code-llama-34b-v2",
        "accounts/fireworks/models/playground-v2-1024px-aesthetic",
        "accounts/fireworks/models/playground-v2-5-1024px-aesthetic",
        "accounts/fireworks/models/pythia-12b",
        "accounts/fireworks/models/qwen-qwq-32b-preview",
        "accounts/fireworks/models/qwen-v2p5-14b-instruct",
        "accounts/fireworks/models/qwen-v2p5-7b",
        "accounts/fireworks/models/qwen1p5-72b-chat",
        "accounts/fireworks/models/qwen2-72b-instruct",
        "accounts/fireworks/models/qwen2-7b-instruct",
        "accounts/fireworks/models/qwen2-vl-2b-instruct",
        "accounts/fireworks/models/qwen2-vl-72b-instruct",
        "accounts/fireworks/models/qwen2-vl-7b-instruct",
        "accounts/fireworks/models/qwen2p5-0p5b-instruct",
        "accounts/fireworks/models/qwen2p5-14b",
        "accounts/fireworks/models/qwen2p5-1p5b-instruct",
        "accounts/fireworks/models/qwen2p5-32b",
        "accounts/fireworks/models/qwen2p5-32b-instruct",
        "accounts/fireworks/models/qwen2p5-72b",
        "accounts/fireworks/models/qwen2p5-72b-instruct",
        "accounts/fireworks/models/qwen2p5-7b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-0p5b",
        "accounts/fireworks/models/qwen2p5-coder-0p5b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-14b",
        "accounts/fireworks/models/qwen2p5-coder-14b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-1p5b",
        "accounts/fireworks/models/qwen2p5-coder-1p5b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-32b",
        "accounts/fireworks/models/qwen2p5-coder-32b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k",
        "accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope",
        "accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k",
        "accounts/fireworks/models/qwen2p5-coder-3b",
        "accounts/fireworks/models/qwen2p5-coder-3b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-7b",
        "accounts/fireworks/models/qwen2p5-coder-7b-instruct",
        "accounts/fireworks/models/qwen2p5-math-72b-instruct",
        "accounts/fireworks/models/qwen2p5-vl-32b-instruct",
        "accounts/fireworks/models/qwen2p5-vl-3b-instruct",
        "accounts/fireworks/models/qwen2p5-vl-72b-instruct",
        "accounts/fireworks/models/qwen2p5-vl-7b-instruct",
        "accounts/fireworks/models/qwen3-0p6b",
        "accounts/fireworks/models/qwen3-14b",
        "accounts/fireworks/models/qwen3-1p7b",
        "accounts/fireworks/models/qwen3-1p7b-fp8-draft",
        "accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072",
        "accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960",
        "accounts/fireworks/models/qwen3-235b-a22b",
        "accounts/fireworks/models/qwen3-235b-a22b-instruct-2507",
        "accounts/fireworks/models/qwen3-235b-a22b-thinking-2507",
        "accounts/fireworks/models/qwen3-30b-a3b",
        "accounts/fireworks/models/qwen3-30b-a3b-instruct-2507",
        "accounts/fireworks/models/qwen3-30b-a3b-thinking-2507",
        "accounts/fireworks/models/qwen3-32b",
        "accounts/fireworks/models/qwen3-4b",
        "accounts/fireworks/models/qwen3-4b-instruct-2507",
        "accounts/fireworks/models/qwen3-8b",
        "accounts/fireworks/models/qwen3-coder-30b-a3b-instruct",
        "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
        "accounts/fireworks/models/qwen3-coder-480b-instruct-bf16",
        "accounts/fireworks/models/qwen3-embedding-0p6b",
        "accounts/fireworks/models/qwen3-embedding-4b",
        "accounts/fireworks/models/qwen3-next-80b-a3b-instruct",
        "accounts/fireworks/models/qwen3-next-80b-a3b-thinking",
        "accounts/fireworks/models/qwen3-reranker-0p6b",
        "accounts/fireworks/models/qwen3-reranker-4b",
        "accounts/fireworks/models/qwen3-reranker-8b",
        "accounts/fireworks/models/qwen3-vl-235b-a22b-instruct",
        "accounts/fireworks/models/qwen3-vl-235b-a22b-thinking",
        "accounts/fireworks/models/qwen3-vl-30b-a3b-instruct",
        "accounts/fireworks/models/qwen3-vl-30b-a3b-thinking",
        "accounts/fireworks/models/qwen3-vl-32b-instruct",
        "accounts/fireworks/models/qwen3-vl-8b-instruct",
        "accounts/fireworks/models/qwq-32b",
        "accounts/fireworks/models/rolm-ocr",
        "accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo",
        "accounts/fireworks/models/stable-diffusion-xl-1024-v1-0",
        "accounts/fireworks/models/stablecode-3b",
        "accounts/fireworks/models/starcoder-16b",
        "accounts/fireworks/models/starcoder-7b",
        "accounts/fireworks/models/starcoder2-15b",
        "accounts/fireworks/models/starcoder2-3b",
        "accounts/fireworks/models/starcoder2-7b",
        "accounts/fireworks/models/toppy-m-7b",
        "accounts/fireworks/models/whisper-v3",
        "accounts/fireworks/models/whisper-v3-turbo",
        "accounts/fireworks/models/yi-34b",
        "accounts/fireworks/models/yi-34b-200k-capybara",
        "accounts/fireworks/models/yi-34b-chat",
        "accounts/fireworks/models/yi-6b",
        "accounts/fireworks/models/yi-large",
        "accounts/fireworks/models/zephyr-7b-beta",
        "fireworks-ai-4.1b-to-16b",
        "fireworks-ai-56b-to-176b",
        "fireworks-ai-above-16b",
        "fireworks-ai-default",
        "fireworks-ai-moe-up-to-56b",
        "fireworks-ai-up-to-4b"
      ]
    },
    "fireworks_ai-embedding-models": {
      "model_count": 7,
      "models": [
        "fireworks-ai-embedding-150m-to-350m",
        "fireworks-ai-embedding-up-to-150m",
        "fireworks_ai/WhereIsAI/UAE-Large-V1",
        "fireworks_ai/nomic-ai/nomic-embed-text-v1",
        "fireworks_ai/nomic-ai/nomic-embed-text-v1.5",
        "fireworks_ai/thenlper/gte-base",
        "fireworks_ai/thenlper/gte-large"
      ]
    },
    "friendliai": {
      "model_count": 2,
      "models": [
        "meta-llama-3.1-70b-instruct",
        "meta-llama-3.1-8b-instruct"
      ]
    },
    "github_copilot": {
      "model_count": 29,
      "models": [
        "claude-haiku-4.5",
        "claude-opus-4.5",
        "claude-opus-41",
        "claude-sonnet-4",
        "claude-sonnet-4.5",
        "gemini-2.5-pro",
        "gemini-3-pro-preview",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-0613",
        "gpt-4",
        "gpt-4-0613",
        "gpt-4-o-preview",
        "gpt-4.1",
        "gpt-4.1-2025-04-14",
        "gpt-41-copilot",
        "gpt-4o",
        "gpt-4o-2024-05-13",
        "gpt-4o-2024-08-06",
        "gpt-4o-2024-11-20",
        "gpt-4o-mini",
        "gpt-4o-mini-2024-07-18",
        "gpt-5",
        "gpt-5-mini",
        "gpt-5.1",
        "gpt-5.1-codex-max",
        "gpt-5.2",
        "text-embedding-3-small",
        "text-embedding-3-small-inference",
        "text-embedding-ada-002"
      ]
    },
    "google": {
      "model_count": 127,
      "models": [
        "chirp",
        "deepseek-ai/deepseek-ocr-maas",
        "gemini-1.0-pro",
        "gemini-1.0-pro-001",
        "gemini-1.0-pro-002",
        "gemini-1.0-ultra",
        "gemini-1.0-ultra-001",
        "gemini-1.5-flash",
        "gemini-1.5-flash",
        "gemini-1.5-flash-001",
        "gemini-1.5-flash-001",
        "gemini-1.5-flash-002",
        "gemini-1.5-flash-002",
        "gemini-1.5-flash-8b",
        "gemini-1.5-flash-8b-exp-0827",
        "gemini-1.5-flash-8b-exp-0924",
        "gemini-1.5-flash-exp-0827",
        "gemini-1.5-flash-exp-0827",
        "gemini-1.5-flash-latest",
        "gemini-1.5-flash-preview-0514",
        "gemini-1.5-pro",
        "gemini-1.5-pro",
        "gemini-1.5-pro-001",
        "gemini-1.5-pro-001",
        "gemini-1.5-pro-002",
        "gemini-1.5-pro-002",
        "gemini-1.5-pro-exp-0801",
        "gemini-1.5-pro-exp-0827",
        "gemini-1.5-pro-latest",
        "gemini-1.5-pro-preview-0215",
        "gemini-1.5-pro-preview-0409",
        "gemini-1.5-pro-preview-0514",
        "gemini-2.0-flash",
        "gemini-2.0-flash",
        "gemini-2.0-flash-001",
        "gemini-2.0-flash-001",
        "gemini-2.0-flash-exp",
        "gemini-2.0-flash-exp",
        "gemini-2.0-flash-lite",
        "gemini-2.0-flash-lite",
        "gemini-2.0-flash-lite-001",
        "gemini-2.0-flash-lite-preview-02-05",
        "gemini-2.0-flash-live-001",
        "gemini-2.0-flash-live-preview-04-09",
        "gemini-2.0-flash-preview-image-generation",
        "gemini-2.0-flash-preview-image-generation",
        "gemini-2.0-flash-thinking-exp",
        "gemini-2.0-flash-thinking-exp",
        "gemini-2.0-flash-thinking-exp-01-21",
        "gemini-2.0-flash-thinking-exp-01-21",
        "gemini-2.0-pro-exp-02-05",
        "gemini-2.0-pro-exp-02-05",
        "gemini-2.5-computer-use-preview-10-2025",
        "gemini-2.5-flash",
        "gemini-2.5-flash",
        "gemini-2.5-flash-image",
        "gemini-2.5-flash-image-preview",
        "gemini-2.5-flash-image-preview",
        "gemini-2.5-flash-lite",
        "gemini-2.5-flash-lite",
        "gemini-2.5-flash-lite-preview-06-17",
        "gemini-2.5-flash-lite-preview-06-17",
        "gemini-2.5-flash-lite-preview-09-2025",
        "gemini-2.5-flash-lite-preview-09-2025",
        "gemini-2.5-flash-preview-04-17",
        "gemini-2.5-flash-preview-04-17",
        "gemini-2.5-flash-preview-05-20",
        "gemini-2.5-flash-preview-05-20",
        "gemini-2.5-flash-preview-09-2025",
        "gemini-2.5-flash-preview-09-2025",
        "gemini-2.5-flash-preview-tts",
        "gemini-2.5-pro",
        "gemini-2.5-pro",
        "gemini-2.5-pro-exp-03-25",
        "gemini-2.5-pro-exp-03-25",
        "gemini-2.5-pro-preview-03-25",
        "gemini-2.5-pro-preview-03-25",
        "gemini-2.5-pro-preview-05-06",
        "gemini-2.5-pro-preview-05-06",
        "gemini-2.5-pro-preview-06-05",
        "gemini-2.5-pro-preview-06-05",
        "gemini-2.5-pro-preview-tts",
        "gemini-2.5-pro-preview-tts",
        "gemini-3-flash-preview",
        "gemini-3-flash-preview",
        "gemini-3-flash-preview",
        "gemini-3-pro-image-preview",
        "gemini-3-pro-image-preview",
        "gemini-3-pro-preview",
        "gemini-3-pro-preview",
        "gemini-3-pro-preview",
        "gemini-embedding-001",
        "gemini-exp-1114",
        "gemini-exp-1206",
        "gemini-flash-experimental",
        "gemini-flash-latest",
        "gemini-flash-lite-latest",
        "gemini-gemma-2-27b-it",
        "gemini-gemma-2-9b-it",
        "gemini-live-2.5-flash-preview-native-audio-09-2025",
        "gemini-live-2.5-flash-preview-native-audio-09-2025",
        "gemini-pro",
        "gemini-pro",
        "gemini-pro-experimental",
        "gemini-pro-vision",
        "gemini/gemini-2.5-flash-image",
        "gemma-3-27b-it",
        "imagen-3.0-fast-generate-001",
        "imagen-3.0-generate-001",
        "imagen-3.0-generate-002",
        "imagen-4.0-fast-generate-001",
        "imagen-4.0-generate-001",
        "imagen-4.0-ultra-generate-001",
        "learnlm-1.5-pro-experimental",
        "medlm-large",
        "medlm-medium",
        "mistral-ocr-2505",
        "search_api",
        "veo-2.0-generate-001",
        "veo-3.0-fast-generate-preview",
        "veo-3.0-generate-preview",
        "veo-3.1-fast-generate-001",
        "veo-3.1-fast-generate-preview",
        "veo-3.1-generate-001",
        "veo-3.1-generate-preview",
        "vertex_ai/gemini-2.5-flash-image",
        "vertex_ai/gemini-3-pro-image-preview"
      ]
    },
    "google_pse": {
      "model_count": 1,
      "models": [
        "search"
      ]
    },
    "gradient_ai": {
      "model_count": 13,
      "models": [
        "alibaba-qwen3-32b",
        "anthropic-claude-3-opus",
        "anthropic-claude-3.5-haiku",
        "anthropic-claude-3.5-sonnet",
        "anthropic-claude-3.7-sonnet",
        "deepseek-r1-distill-llama-70b",
        "llama3-8b-instruct",
        "llama3.3-70b-instruct",
        "mistral-nemo-instruct-2407",
        "openai-gpt-4o",
        "openai-gpt-4o-mini",
        "openai-o3",
        "openai-o3-mini"
      ]
    },
    "groq": {
      "model_count": 31,
      "models": [
        "deepseek-r1-distill-llama-70b",
        "distil-whisper-large-v3-en",
        "gemma-7b-it",
        "gemma2-9b-it",
        "llama-3.1-405b-reasoning",
        "llama-3.1-70b-versatile",
        "llama-3.1-8b-instant",
        "llama-3.2-11b-text-preview",
        "llama-3.2-11b-vision-preview",
        "llama-3.2-1b-preview",
        "llama-3.2-3b-preview",
        "llama-3.2-90b-text-preview",
        "llama-3.2-90b-vision-preview",
        "llama-3.3-70b-specdec",
        "llama-3.3-70b-versatile",
        "llama-guard-3-8b",
        "llama2-70b-4096",
        "llama3-groq-70b-8192-tool-use-preview",
        "llama3-groq-8b-8192-tool-use-preview",
        "meta-llama/llama-4-maverick-17b-128e-instruct",
        "meta-llama/llama-4-scout-17b-16e-instruct",
        "mistral-saba-24b",
        "mixtral-8x7b-32768",
        "moonshotai/kimi-k2-instruct",
        "moonshotai/kimi-k2-instruct-0905",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "playai-tts",
        "qwen/qwen3-32b",
        "whisper-large-v3",
        "whisper-large-v3-turbo"
      ]
    },
    "heroku": {
      "model_count": 4,
      "models": [
        "claude-3-5-haiku",
        "claude-3-5-sonnet-latest",
        "claude-3-7-sonnet",
        "claude-4-sonnet"
      ]
    },
    "hyperbolic": {
      "model_count": 16,
      "models": [
        "NousResearch/Hermes-3-Llama-3.1-70B",
        "Qwen/QwQ-32B",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/Qwen3-235B-A22B",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3-0324",
        "meta-llama/Llama-3.2-3B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Meta-Llama-3-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-405B-Instruct",
        "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "moonshotai/Kimi-K2-Instruct"
      ]
    },
    "jina_ai": {
      "model_count": 1,
      "models": [
        "jina-reranker-v2-base-multilingual"
      ]
    },
    "lambda_ai": {
      "model_count": 20,
      "models": [
        "deepseek-llama3.3-70b",
        "deepseek-r1-0528",
        "deepseek-r1-671b",
        "deepseek-v3-0324",
        "hermes3-405b",
        "hermes3-70b",
        "hermes3-8b",
        "lfm-40b",
        "lfm-7b",
        "llama-4-maverick-17b-128e-instruct-fp8",
        "llama-4-scout-17b-16e-instruct",
        "llama3.1-405b-instruct-fp8",
        "llama3.1-70b-instruct-fp8",
        "llama3.1-8b-instruct",
        "llama3.1-nemotron-70b-instruct-fp8",
        "llama3.2-11b-vision-instruct",
        "llama3.2-3b-instruct",
        "llama3.3-70b-instruct-fp8",
        "qwen25-coder-32b-instruct",
        "qwen3-32b-fp8"
      ]
    },
    "lemonade": {
      "model_count": 5,
      "models": [
        "Gemma-3-4b-it-GGUF",
        "Qwen3-4B-Instruct-2507-GGUF",
        "Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "gpt-oss-120b-mxfp-GGUF",
        "gpt-oss-20b-mxfp4-GGUF"
      ]
    },
    "linkup": {
      "model_count": 2,
      "models": [
        "search",
        "search-deep"
      ]
    },
    "meta_llama": {
      "model_count": 4,
      "models": [
        "Llama-3.3-70B-Instruct",
        "Llama-3.3-8B-Instruct",
        "Llama-4-Maverick-17B-128E-Instruct-FP8",
        "Llama-4-Scout-17B-16E-Instruct-FP8"
      ]
    },
    "mistral": {
      "model_count": 40,
      "models": [
        "codestral-2405",
        "codestral-2508",
        "codestral-embed",
        "codestral-embed-2505",
        "codestral-latest",
        "codestral-mamba-latest",
        "devstral-2512",
        "devstral-medium-2507",
        "devstral-small-2505",
        "devstral-small-2507",
        "labs-devstral-small-2512",
        "magistral-medium-2506",
        "magistral-medium-2509",
        "magistral-medium-latest",
        "magistral-small-2506",
        "magistral-small-latest",
        "mistral-embed",
        "mistral-large-2402",
        "mistral-large-2407",
        "mistral-large-2411",
        "mistral-large-3",
        "mistral-large-latest",
        "mistral-medium",
        "mistral-medium-2312",
        "mistral-medium-2505",
        "mistral-medium-latest",
        "mistral-ocr-2505-completion",
        "mistral-ocr-latest",
        "mistral-small",
        "mistral-small-latest",
        "mistral-tiny",
        "open-codestral-mamba",
        "open-mistral-7b",
        "open-mistral-nemo",
        "open-mistral-nemo-2407",
        "open-mixtral-8x22b",
        "open-mixtral-8x7b",
        "pixtral-12b-2409",
        "pixtral-large-2411",
        "pixtral-large-latest"
      ]
    },
    "moonshot": {
      "model_count": 20,
      "models": [
        "kimi-k2-0711-preview",
        "kimi-k2-0905-preview",
        "kimi-k2-thinking",
        "kimi-k2-thinking-turbo",
        "kimi-k2-turbo-preview",
        "kimi-latest",
        "kimi-latest-128k",
        "kimi-latest-32k",
        "kimi-latest-8k",
        "kimi-thinking-preview",
        "moonshot-v1-128k",
        "moonshot-v1-128k-0430",
        "moonshot-v1-128k-vision-preview",
        "moonshot-v1-32k",
        "moonshot-v1-32k-0430",
        "moonshot-v1-32k-vision-preview",
        "moonshot-v1-8k",
        "moonshot-v1-8k-0430",
        "moonshot-v1-8k-vision-preview",
        "moonshot-v1-auto"
      ]
    },
    "morph": {
      "model_count": 2,
      "models": [
        "morph-v3-fast",
        "morph-v3-large"
      ]
    },
    "nlp_cloud": {
      "model_count": 2,
      "models": [
        "chatdolphin",
        "dolphin"
      ]
    },
    "nscale": {
      "model_count": 16,
      "models": [
        "Qwen/QwQ-32B",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/Qwen2.5-Coder-3B-Instruct",
        "Qwen/Qwen2.5-Coder-7B-Instruct",
        "black-forest-labs/FLUX.1-schnell",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "meta-llama/Llama-3.1-8B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "mistralai/mixtral-8x22b-instruct-v0.1",
        "stabilityai/stable-diffusion-xl-base-1.0"
      ]
    },
    "nvidia_nim": {
      "model_count": 3,
      "models": [
        "nvidia/llama-3_2-nv-rerankqa-1b-v2",
        "nvidia/nv-rerankqa-mistral-4b-v3",
        "ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2"
      ]
    },
    "oci": {
      "model_count": 13,
      "models": [
        "cohere.command-a-03-2025",
        "cohere.command-latest",
        "cohere.command-plus-latest",
        "meta.llama-3.1-405b-instruct",
        "meta.llama-3.2-90b-vision-instruct",
        "meta.llama-3.3-70b-instruct",
        "meta.llama-4-maverick-17b-128e-instruct-fp8",
        "meta.llama-4-scout-17b-16e-instruct",
        "xai.grok-3",
        "xai.grok-3-fast",
        "xai.grok-3-mini",
        "xai.grok-3-mini-fast",
        "xai.grok-4"
      ]
    },
    "ollama": {
      "model_count": 29,
      "models": [
        "codegeex4",
        "codegemma",
        "codellama",
        "deepseek-coder-v2-base",
        "deepseek-coder-v2-instruct",
        "deepseek-coder-v2-lite-base",
        "deepseek-coder-v2-lite-instruct",
        "deepseek-v3.1:671b-cloud",
        "gpt-oss:120b-cloud",
        "gpt-oss:20b-cloud",
        "internlm2_5-20b-chat",
        "llama2",
        "llama2-uncensored",
        "llama2:13b",
        "llama2:70b",
        "llama2:7b",
        "llama3",
        "llama3.1",
        "llama3:70b",
        "llama3:8b",
        "mistral",
        "mistral-7B-Instruct-v0.1",
        "mistral-7B-Instruct-v0.2",
        "mistral-large-instruct-2407",
        "mixtral-8x22B-Instruct-v0.1",
        "mixtral-8x7B-Instruct-v0.1",
        "orca-mini",
        "qwen3-coder:480b-cloud",
        "vicuna"
      ]
    },
    "openai": {
      "model_count": 154,
      "models": [
        "chatgpt-4o-latest",
        "codex-mini-latest",
        "container",
        "ft:gpt-3.5-turbo",
        "ft:gpt-3.5-turbo-0125",
        "ft:gpt-3.5-turbo-0613",
        "ft:gpt-3.5-turbo-1106",
        "ft:gpt-4-0613",
        "ft:gpt-4.1-2025-04-14",
        "ft:gpt-4.1-mini-2025-04-14",
        "ft:gpt-4.1-nano-2025-04-14",
        "ft:gpt-4o-2024-08-06",
        "ft:gpt-4o-2024-11-20",
        "ft:gpt-4o-mini-2024-07-18",
        "ft:o4-mini-2025-04-16",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-0125",
        "gpt-3.5-turbo-0301",
        "gpt-3.5-turbo-0613",
        "gpt-3.5-turbo-1106",
        "gpt-3.5-turbo-16k",
        "gpt-3.5-turbo-16k-0613",
        "gpt-4",
        "gpt-4-0125-preview",
        "gpt-4-0314",
        "gpt-4-0613",
        "gpt-4-1106-preview",
        "gpt-4-1106-vision-preview",
        "gpt-4-32k",
        "gpt-4-32k-0314",
        "gpt-4-32k-0613",
        "gpt-4-turbo",
        "gpt-4-turbo-2024-04-09",
        "gpt-4-turbo-preview",
        "gpt-4-vision-preview",
        "gpt-4.1",
        "gpt-4.1-2025-04-14",
        "gpt-4.1-mini",
        "gpt-4.1-mini-2025-04-14",
        "gpt-4.1-nano",
        "gpt-4.1-nano-2025-04-14",
        "gpt-4.5-preview",
        "gpt-4.5-preview-2025-02-27",
        "gpt-4o",
        "gpt-4o-2024-05-13",
        "gpt-4o-2024-08-06",
        "gpt-4o-2024-11-20",
        "gpt-4o-audio-preview",
        "gpt-4o-audio-preview-2024-10-01",
        "gpt-4o-audio-preview-2024-12-17",
        "gpt-4o-audio-preview-2025-06-03",
        "gpt-4o-mini",
        "gpt-4o-mini-2024-07-18",
        "gpt-4o-mini-audio-preview",
        "gpt-4o-mini-audio-preview-2024-12-17",
        "gpt-4o-mini-realtime-preview",
        "gpt-4o-mini-realtime-preview-2024-12-17",
        "gpt-4o-mini-search-preview",
        "gpt-4o-mini-search-preview-2025-03-11",
        "gpt-4o-mini-transcribe",
        "gpt-4o-mini-tts",
        "gpt-4o-realtime-preview",
        "gpt-4o-realtime-preview-2024-10-01",
        "gpt-4o-realtime-preview-2024-12-17",
        "gpt-4o-realtime-preview-2025-06-03",
        "gpt-4o-search-preview",
        "gpt-4o-search-preview-2025-03-11",
        "gpt-4o-transcribe",
        "gpt-4o-transcribe-diarize",
        "gpt-5",
        "gpt-5-2025-08-07",
        "gpt-5-chat",
        "gpt-5-chat-latest",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-mini-2025-08-07",
        "gpt-5-nano",
        "gpt-5-nano-2025-08-07",
        "gpt-5-pro",
        "gpt-5-pro-2025-10-06",
        "gpt-5.1",
        "gpt-5.1-2025-11-13",
        "gpt-5.1-chat-latest",
        "gpt-5.1-codex",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.2",
        "gpt-5.2-2025-12-11",
        "gpt-5.2-chat-latest",
        "gpt-5.2-pro",
        "gpt-5.2-pro-2025-12-11",
        "gpt-image-1",
        "gpt-image-1-mini",
        "gpt-image-1.5",
        "gpt-image-1.5-2025-12-16",
        "gpt-realtime",
        "gpt-realtime-2025-08-28",
        "gpt-realtime-mini",
        "hd/1024-x-1024/dall-e-3",
        "hd/1024-x-1792/dall-e-3",
        "hd/1792-x-1024/dall-e-3",
        "high/1024-x-1024/gpt-image-1",
        "high/1024-x-1536/gpt-image-1",
        "high/1536-x-1024/gpt-image-1",
        "low/1024-x-1024/gpt-image-1",
        "low/1024-x-1024/gpt-image-1-mini",
        "low/1024-x-1536/gpt-image-1",
        "low/1024-x-1536/gpt-image-1-mini",
        "low/1536-x-1024/gpt-image-1",
        "low/1536-x-1024/gpt-image-1-mini",
        "medium/1024-x-1024/gpt-image-1",
        "medium/1024-x-1024/gpt-image-1-mini",
        "medium/1024-x-1536/gpt-image-1",
        "medium/1024-x-1536/gpt-image-1-mini",
        "medium/1536-x-1024/gpt-image-1",
        "medium/1536-x-1024/gpt-image-1-mini",
        "o1",
        "o1-2024-12-17",
        "o1-mini",
        "o1-mini-2024-09-12",
        "o1-preview",
        "o1-preview-2024-09-12",
        "o1-pro",
        "o1-pro-2025-03-19",
        "o3",
        "o3-2025-04-16",
        "o3-deep-research",
        "o3-deep-research-2025-06-26",
        "o3-mini",
        "o3-mini-2025-01-31",
        "o3-pro",
        "o3-pro-2025-06-10",
        "o4-mini",
        "o4-mini-2025-04-16",
        "o4-mini-deep-research",
        "o4-mini-deep-research-2025-06-26",
        "omni-moderation-2024-09-26",
        "omni-moderation-latest",
        "omni-moderation-latest-intents",
        "sora-2",
        "sora-2-pro",
        "standard/1024-x-1024/dall-e-3",
        "standard/1024-x-1792/dall-e-3",
        "standard/1792-x-1024/dall-e-3",
        "text-embedding-3-large",
        "text-embedding-3-small",
        "text-embedding-ada-002",
        "text-embedding-ada-002-v2",
        "text-moderation-007",
        "text-moderation-latest",
        "text-moderation-stable",
        "tts-1",
        "tts-1-hd",
        "whisper-1"
      ]
    },
    "openrouter": {
      "model_count": 103,
      "models": [
        "anthropic/claude-2",
        "anthropic/claude-3-5-haiku",
        "anthropic/claude-3-5-haiku-20241022",
        "anthropic/claude-3-haiku",
        "anthropic/claude-3-haiku-20240307",
        "anthropic/claude-3-opus",
        "anthropic/claude-3-sonnet",
        "anthropic/claude-3.5-sonnet",
        "anthropic/claude-3.5-sonnet:beta",
        "anthropic/claude-3.7-sonnet",
        "anthropic/claude-3.7-sonnet:beta",
        "anthropic/claude-haiku-4.5",
        "anthropic/claude-instant-v1",
        "anthropic/claude-opus-4",
        "anthropic/claude-opus-4.1",
        "anthropic/claude-opus-4.5",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-sonnet-4.5",
        "bytedance/ui-tars-1.5-7b",
        "cognitivecomputations/dolphin-mixtral-8x7b",
        "cohere/command-r-plus",
        "databricks/dbrx-instruct",
        "deepseek/deepseek-chat",
        "deepseek/deepseek-chat-v3-0324",
        "deepseek/deepseek-chat-v3.1",
        "deepseek/deepseek-coder",
        "deepseek/deepseek-r1",
        "deepseek/deepseek-r1-0528",
        "deepseek/deepseek-v3.2",
        "deepseek/deepseek-v3.2-exp",
        "fireworks/firellava-13b",
        "google/gemini-2.0-flash-001",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-pro",
        "google/gemini-3-pro-preview",
        "google/gemini-pro-1.5",
        "google/gemini-pro-vision",
        "google/palm-2-chat-bison",
        "google/palm-2-codechat-bison",
        "gryphe/mythomax-l2-13b",
        "jondurbin/airoboros-l2-70b-2.1",
        "mancer/weaver",
        "meta-llama/codellama-34b-instruct",
        "meta-llama/llama-2-13b-chat",
        "meta-llama/llama-2-70b-chat",
        "meta-llama/llama-3-70b-instruct",
        "meta-llama/llama-3-70b-instruct:nitro",
        "meta-llama/llama-3-8b-instruct:extended",
        "meta-llama/llama-3-8b-instruct:free",
        "microsoft/wizardlm-2-8x22b:nitro",
        "minimax/minimax-m2",
        "mistralai/devstral-2512",
        "mistralai/devstral-2512:free",
        "mistralai/ministral-14b-2512",
        "mistralai/ministral-3b-2512",
        "mistralai/ministral-8b-2512",
        "mistralai/mistral-7b-instruct",
        "mistralai/mistral-7b-instruct:free",
        "mistralai/mistral-large",
        "mistralai/mistral-large-2512",
        "mistralai/mistral-small-3.1-24b-instruct",
        "mistralai/mistral-small-3.2-24b-instruct",
        "mistralai/mixtral-8x22b-instruct",
        "nousresearch/nous-hermes-llama2-13b",
        "openai/gpt-3.5-turbo",
        "openai/gpt-3.5-turbo-16k",
        "openai/gpt-4",
        "openai/gpt-4-vision-preview",
        "openai/gpt-4.1",
        "openai/gpt-4.1-2025-04-14",
        "openai/gpt-4.1-mini",
        "openai/gpt-4.1-mini-2025-04-14",
        "openai/gpt-4.1-nano",
        "openai/gpt-4.1-nano-2025-04-14",
        "openai/gpt-4o",
        "openai/gpt-4o-2024-05-13",
        "openai/gpt-5",
        "openai/gpt-5-chat",
        "openai/gpt-5-codex",
        "openai/gpt-5-mini",
        "openai/gpt-5-nano",
        "openai/gpt-5.2",
        "openai/gpt-5.2-chat",
        "openai/gpt-5.2-pro",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "openai/o1",
        "openai/o1-mini",
        "openai/o1-mini-2024-09-12",
        "openai/o1-preview",
        "openai/o1-preview-2024-09-12",
        "openai/o3-mini",
        "openai/o3-mini-high",
        "pygmalionai/mythalion-13b",
        "qwen/qwen-2.5-coder-32b-instruct",
        "qwen/qwen-vl-plus",
        "qwen/qwen3-coder",
        "switchpoint/router",
        "undi95/remm-slerp-l2-13b",
        "x-ai/grok-4",
        "x-ai/grok-4-fast:free",
        "z-ai/glm-4.6",
        "z-ai/glm-4.6:exacto"
      ]
    },
    "ovhcloud": {
      "model_count": 15,
      "models": [
        "DeepSeek-R1-Distill-Llama-70B",
        "Llama-3.1-8B-Instruct",
        "Meta-Llama-3_1-70B-Instruct",
        "Meta-Llama-3_3-70B-Instruct",
        "Mistral-7B-Instruct-v0.3",
        "Mistral-Nemo-Instruct-2407",
        "Mistral-Small-3.2-24B-Instruct-2506",
        "Mixtral-8x7B-Instruct-v0.1",
        "Qwen2.5-Coder-32B-Instruct",
        "Qwen2.5-VL-72B-Instruct",
        "Qwen3-32B",
        "gpt-oss-120b",
        "gpt-oss-20b",
        "llava-v1.6-mistral-7b-hf",
        "mamba-codestral-7B-v0.1"
      ]
    },
    "palm": {
      "model_count": 6,
      "models": [
        "chat-bison",
        "chat-bison-001",
        "text-bison",
        "text-bison-001",
        "text-bison-safety-off",
        "text-bison-safety-recitation-off"
      ]
    },
    "parallel_ai": {
      "model_count": 2,
      "models": [
        "search",
        "search-pro"
      ]
    },
    "perplexity": {
      "model_count": 26,
      "models": [
        "codellama-34b-instruct",
        "codellama-70b-instruct",
        "llama-2-70b-chat",
        "llama-3.1-70b-instruct",
        "llama-3.1-8b-instruct",
        "llama-3.1-sonar-huge-128k-online",
        "llama-3.1-sonar-large-128k-chat",
        "llama-3.1-sonar-large-128k-online",
        "llama-3.1-sonar-small-128k-chat",
        "llama-3.1-sonar-small-128k-online",
        "mistral-7b-instruct",
        "mixtral-8x7b-instruct",
        "pplx-70b-chat",
        "pplx-70b-online",
        "pplx-7b-chat",
        "pplx-7b-online",
        "search",
        "sonar",
        "sonar-deep-research",
        "sonar-medium-chat",
        "sonar-medium-online",
        "sonar-pro",
        "sonar-reasoning",
        "sonar-reasoning-pro",
        "sonar-small-chat",
        "sonar-small-online"
      ]
    },
    "publicai": {
      "model_count": 9,
      "models": [
        "BSC-LT/ALIA-40b-instruct_Q8_0",
        "BSC-LT/salamandra-7b-instruct-tools-16k",
        "aisingapore/Gemma-SEA-LION-v4-27B-IT",
        "aisingapore/Qwen-SEA-LION-v4-32B-IT",
        "allenai/Olmo-3-32B-Think",
        "allenai/Olmo-3-7B-Instruct",
        "allenai/Olmo-3-7B-Think",
        "swiss-ai/apertus-70b-instruct",
        "swiss-ai/apertus-8b-instruct"
      ]
    },
    "recraft": {
      "model_count": 2,
      "models": [
        "recraftv2",
        "recraftv3"
      ]
    },
    "replicate": {
      "model_count": 13,
      "models": [
        "meta/llama-2-13b",
        "meta/llama-2-13b-chat",
        "meta/llama-2-70b",
        "meta/llama-2-70b-chat",
        "meta/llama-2-7b",
        "meta/llama-2-7b-chat",
        "meta/llama-3-70b",
        "meta/llama-3-70b-instruct",
        "meta/llama-3-8b",
        "meta/llama-3-8b-instruct",
        "mistralai/mistral-7b-instruct-v0.2",
        "mistralai/mistral-7b-v0.1",
        "mistralai/mixtral-8x7b-instruct-v0.1"
      ]
    },
    "runwayml": {
      "model_count": 6,
      "models": [
        "eleven_multilingual_v2",
        "gen3a_turbo",
        "gen4_aleph",
        "gen4_image",
        "gen4_image_turbo",
        "gen4_turbo"
      ]
    },
    "sambanova": {
      "model_count": 16,
      "models": [
        "DeepSeek-R1",
        "DeepSeek-R1-Distill-Llama-70B",
        "DeepSeek-V3-0324",
        "DeepSeek-V3.1",
        "Llama-4-Maverick-17B-128E-Instruct",
        "Llama-4-Scout-17B-16E-Instruct",
        "Meta-Llama-3.1-405B-Instruct",
        "Meta-Llama-3.1-8B-Instruct",
        "Meta-Llama-3.2-1B-Instruct",
        "Meta-Llama-3.2-3B-Instruct",
        "Meta-Llama-3.3-70B-Instruct",
        "Meta-Llama-Guard-3-8B",
        "QwQ-32B",
        "Qwen2-Audio-7B-Instruct",
        "Qwen3-32B",
        "gpt-oss-120b"
      ]
    },
    "searxng": {
      "model_count": 1,
      "models": [
        "search"
      ]
    },
    "snowflake": {
      "model_count": 24,
      "models": [
        "claude-3-5-sonnet",
        "deepseek-r1",
        "gemma-7b",
        "jamba-1.5-large",
        "jamba-1.5-mini",
        "jamba-instruct",
        "llama2-70b-chat",
        "llama3-70b",
        "llama3-8b",
        "llama3.1-405b",
        "llama3.1-70b",
        "llama3.1-8b",
        "llama3.2-1b",
        "llama3.2-3b",
        "llama3.3-70b",
        "mistral-7b",
        "mistral-large",
        "mistral-large2",
        "mixtral-8x7b",
        "reka-core",
        "reka-flash",
        "snowflake-arctic",
        "snowflake-llama-3.1-405b",
        "snowflake-llama-3.3-70b"
      ]
    },
    "stability": {
      "model_count": 23,
      "models": [
        "conservative",
        "creative",
        "erase",
        "fast",
        "inpaint",
        "outpaint",
        "remove-background",
        "replace-background-and-relight",
        "sd3",
        "sd3-large",
        "sd3-large-turbo",
        "sd3-medium",
        "sd3.5-large",
        "sd3.5-large-turbo",
        "sd3.5-medium",
        "search-and-recolor",
        "search-and-replace",
        "sketch",
        "stable-image-core",
        "stable-image-ultra",
        "structure",
        "style",
        "style-transfer"
      ]
    },
    "tavily": {
      "model_count": 2,
      "models": [
        "search",
        "search-advanced"
      ]
    },
    "text-completion-codestral": {
      "model_count": 2,
      "models": [
        "codestral-2405",
        "codestral-latest"
      ]
    },
    "text-completion-openai": {
      "model_count": 6,
      "models": [
        "babbage-002",
        "davinci-002",
        "ft:babbage-002",
        "ft:davinci-002",
        "gpt-3.5-turbo-instruct",
        "gpt-3.5-turbo-instruct-0914"
      ]
    },
    "together": {
      "model_count": 40,
      "models": [
        "BAAI/bge-base-en-v1.5",
        "Qwen/Qwen2.5-72B-Instruct-Turbo",
        "Qwen/Qwen2.5-7B-Instruct-Turbo",
        "Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-235B-A22B-fp8-tput",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Thinking",
        "baai/bge-base-en-v1.5",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-0528-tput",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3.1",
        "meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "mistralai/Mistral-7B-Instruct-v0.1",
        "mistralai/Mistral-Small-24B-Instruct-2501",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Instruct-0905",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "together-ai-21.1b-41b",
        "together-ai-4.1b-8b",
        "together-ai-41.1b-80b",
        "together-ai-8.1b-21b",
        "together-ai-81.1b-110b",
        "together-ai-embedding-151m-to-350m",
        "together-ai-embedding-up-to-150m",
        "together-ai-up-to-4b",
        "togethercomputer/CodeLlama-34b-Instruct",
        "zai-org/GLM-4.5-Air-FP8",
        "zai-org/GLM-4.6"
      ]
    },
    "v0": {
      "model_count": 3,
      "models": [
        "v0-1.0-md",
        "v0-1.5-lg",
        "v0-1.5-md"
      ]
    },
    "vercel_ai_gateway": {
      "model_count": 91,
      "models": [
        "alibaba/qwen-3-14b",
        "alibaba/qwen-3-235b",
        "alibaba/qwen-3-30b",
        "alibaba/qwen-3-32b",
        "alibaba/qwen3-coder",
        "amazon/nova-lite",
        "amazon/nova-micro",
        "amazon/nova-pro",
        "amazon/titan-embed-text-v2",
        "anthropic/claude-3-haiku",
        "anthropic/claude-3-opus",
        "anthropic/claude-3.5-haiku",
        "anthropic/claude-3.5-sonnet",
        "anthropic/claude-3.7-sonnet",
        "anthropic/claude-4-opus",
        "anthropic/claude-4-sonnet",
        "cohere/command-a",
        "cohere/command-r",
        "cohere/command-r-plus",
        "cohere/embed-v4.0",
        "deepseek/deepseek-r1",
        "deepseek/deepseek-r1-distill-llama-70b",
        "deepseek/deepseek-v3",
        "google/gemini-2.0-flash",
        "google/gemini-2.0-flash-lite",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-pro",
        "google/gemini-embedding-001",
        "google/gemma-2-9b",
        "google/text-embedding-005",
        "google/text-multilingual-embedding-002",
        "inception/mercury-coder-small",
        "meta/llama-3-70b",
        "meta/llama-3-8b",
        "meta/llama-3.1-70b",
        "meta/llama-3.1-8b",
        "meta/llama-3.2-11b",
        "meta/llama-3.2-1b",
        "meta/llama-3.2-3b",
        "meta/llama-3.2-90b",
        "meta/llama-3.3-70b",
        "meta/llama-4-maverick",
        "meta/llama-4-scout",
        "mistral/codestral",
        "mistral/codestral-embed",
        "mistral/devstral-small",
        "mistral/magistral-medium",
        "mistral/magistral-small",
        "mistral/ministral-3b",
        "mistral/ministral-8b",
        "mistral/mistral-embed",
        "mistral/mistral-large",
        "mistral/mistral-saba-24b",
        "mistral/mistral-small",
        "mistral/mixtral-8x22b-instruct",
        "mistral/pixtral-12b",
        "mistral/pixtral-large",
        "moonshotai/kimi-k2",
        "morph/morph-v3-fast",
        "morph/morph-v3-large",
        "openai/gpt-3.5-turbo",
        "openai/gpt-3.5-turbo-instruct",
        "openai/gpt-4-turbo",
        "openai/gpt-4.1",
        "openai/gpt-4.1-mini",
        "openai/gpt-4.1-nano",
        "openai/gpt-4o",
        "openai/gpt-4o-mini",
        "openai/o1",
        "openai/o3",
        "openai/o3-mini",
        "openai/o4-mini",
        "openai/text-embedding-3-large",
        "openai/text-embedding-3-small",
        "openai/text-embedding-ada-002",
        "perplexity/sonar",
        "perplexity/sonar-pro",
        "perplexity/sonar-reasoning",
        "perplexity/sonar-reasoning-pro",
        "vercel/v0-1.0-md",
        "vercel/v0-1.5-md",
        "xai/grok-2",
        "xai/grok-2-vision",
        "xai/grok-3",
        "xai/grok-3-fast",
        "xai/grok-3-mini",
        "xai/grok-3-mini-fast",
        "xai/grok-4",
        "zai/glm-4.5",
        "zai/glm-4.5-air",
        "zai/glm-4.6"
      ]
    },
    "vertex_ai-ai21_models": {
      "model_count": 5,
      "models": [
        "vertex_ai/jamba-1.5",
        "vertex_ai/jamba-1.5-large",
        "vertex_ai/jamba-1.5-large@001",
        "vertex_ai/jamba-1.5-mini",
        "vertex_ai/jamba-1.5-mini@001"
      ]
    },
    "vertex_ai-anthropic_models": {
      "model_count": 24,
      "models": [
        "vertex_ai/claude-3-5-haiku",
        "vertex_ai/claude-3-5-haiku@20241022",
        "vertex_ai/claude-3-5-sonnet",
        "vertex_ai/claude-3-5-sonnet-v2",
        "vertex_ai/claude-3-5-sonnet-v2@20241022",
        "vertex_ai/claude-3-5-sonnet@20240620",
        "vertex_ai/claude-3-7-sonnet@20250219",
        "vertex_ai/claude-3-haiku",
        "vertex_ai/claude-3-haiku@20240307",
        "vertex_ai/claude-3-opus",
        "vertex_ai/claude-3-opus@20240229",
        "vertex_ai/claude-3-sonnet",
        "vertex_ai/claude-3-sonnet@20240229",
        "vertex_ai/claude-haiku-4-5@20251001",
        "vertex_ai/claude-opus-4",
        "vertex_ai/claude-opus-4-1",
        "vertex_ai/claude-opus-4-1@20250805",
        "vertex_ai/claude-opus-4-5",
        "vertex_ai/claude-opus-4-5@20251101",
        "vertex_ai/claude-opus-4@20250514",
        "vertex_ai/claude-sonnet-4",
        "vertex_ai/claude-sonnet-4-5",
        "vertex_ai/claude-sonnet-4-5@20250929",
        "vertex_ai/claude-sonnet-4@20250514"
      ]
    },
    "vertex_ai-chat-models": {
      "model_count": 5,
      "models": [
        "chat-bison",
        "chat-bison-32k",
        "chat-bison-32k@002",
        "chat-bison@001",
        "chat-bison@002"
      ]
    },
    "vertex_ai-code-chat-models": {
      "model_count": 6,
      "models": [
        "codechat-bison",
        "codechat-bison-32k",
        "codechat-bison-32k@002",
        "codechat-bison@001",
        "codechat-bison@002",
        "codechat-bison@latest"
      ]
    },
    "vertex_ai-code-text-models": {
      "model_count": 9,
      "models": [
        "code-bison",
        "code-bison-32k@002",
        "code-bison32k",
        "code-bison@001",
        "code-bison@002",
        "code-gecko",
        "code-gecko-latest",
        "code-gecko@001",
        "code-gecko@002"
      ]
    },
    "vertex_ai-deepseek_models": {
      "model_count": 3,
      "models": [
        "vertex_ai/deepseek-ai/deepseek-r1-0528-maas",
        "vertex_ai/deepseek-ai/deepseek-v3.1-maas",
        "vertex_ai/deepseek-ai/deepseek-v3.2-maas"
      ]
    },
    "vertex_ai-embedding-models": {
      "model_count": 14,
      "models": [
        "gemini-embedding-001",
        "multimodalembedding",
        "multimodalembedding@001",
        "text-embedding-004",
        "text-embedding-005",
        "text-embedding-large-exp-03-07",
        "text-embedding-preview-0409",
        "text-multilingual-embedding-002",
        "text-multilingual-embedding-preview-0409",
        "textembedding-gecko",
        "textembedding-gecko-multilingual",
        "textembedding-gecko-multilingual@001",
        "textembedding-gecko@001",
        "textembedding-gecko@003"
      ]
    },
    "vertex_ai-image-models": {
      "model_count": 8,
      "models": [
        "vertex_ai/imagegeneration@006",
        "vertex_ai/imagen-3.0-capability-001",
        "vertex_ai/imagen-3.0-fast-generate-001",
        "vertex_ai/imagen-3.0-generate-001",
        "vertex_ai/imagen-3.0-generate-002",
        "vertex_ai/imagen-4.0-fast-generate-001",
        "vertex_ai/imagen-4.0-generate-001",
        "vertex_ai/imagen-4.0-ultra-generate-001"
      ]
    },
    "vertex_ai-llama_models": {
      "model_count": 11,
      "models": [
        "vertex_ai/meta/llama-3.1-405b-instruct-maas",
        "vertex_ai/meta/llama-3.1-70b-instruct-maas",
        "vertex_ai/meta/llama-3.1-8b-instruct-maas",
        "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
        "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas",
        "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas",
        "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas",
        "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas",
        "vertex_ai/meta/llama3-405b-instruct-maas",
        "vertex_ai/meta/llama3-70b-instruct-maas",
        "vertex_ai/meta/llama3-8b-instruct-maas"
      ]
    },
    "vertex_ai-minimax_models": {
      "model_count": 1,
      "models": [
        "vertex_ai/minimaxai/minimax-m2-maas"
      ]
    },
    "vertex_ai-mistral_models": {
      "model_count": 19,
      "models": [
        "vertex_ai/codestral-2",
        "vertex_ai/codestral-2501",
        "vertex_ai/codestral-2@001",
        "vertex_ai/codestral@2405",
        "vertex_ai/codestral@latest",
        "vertex_ai/mistral-large-2411",
        "vertex_ai/mistral-large@2407",
        "vertex_ai/mistral-large@2411-001",
        "vertex_ai/mistral-large@latest",
        "vertex_ai/mistral-medium-3",
        "vertex_ai/mistral-medium-3@001",
        "vertex_ai/mistral-nemo@2407",
        "vertex_ai/mistral-nemo@latest",
        "vertex_ai/mistral-small-2503",
        "vertex_ai/mistral-small-2503@001",
        "vertex_ai/mistralai/codestral-2",
        "vertex_ai/mistralai/codestral-2@001",
        "vertex_ai/mistralai/mistral-medium-3",
        "vertex_ai/mistralai/mistral-medium-3@001"
      ]
    },
    "vertex_ai-moonshot_models": {
      "model_count": 1,
      "models": [
        "vertex_ai/moonshotai/kimi-k2-thinking-maas"
      ]
    },
    "vertex_ai-openai_models": {
      "model_count": 2,
      "models": [
        "vertex_ai/openai/gpt-oss-120b-maas",
        "vertex_ai/openai/gpt-oss-20b-maas"
      ]
    },
    "vertex_ai-qwen_models": {
      "model_count": 4,
      "models": [
        "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas",
        "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas",
        "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas",
        "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas"
      ]
    },
    "vertex_ai-text-models": {
      "model_count": 7,
      "models": [
        "text-bison",
        "text-bison32k",
        "text-bison32k@002",
        "text-bison@001",
        "text-bison@002",
        "text-unicorn",
        "text-unicorn@001"
      ]
    },
    "vertex_ai-video-models": {
      "model_count": 9,
      "models": [
        "vertex_ai/veo-2.0-generate-001",
        "vertex_ai/veo-3.0-fast-generate-001",
        "vertex_ai/veo-3.0-fast-generate-preview",
        "vertex_ai/veo-3.0-generate-001",
        "vertex_ai/veo-3.0-generate-preview",
        "vertex_ai/veo-3.1-fast-generate-001",
        "vertex_ai/veo-3.1-fast-generate-preview",
        "vertex_ai/veo-3.1-generate-001",
        "vertex_ai/veo-3.1-generate-preview"
      ]
    },
    "vertex_ai-vision-models": {
      "model_count": 3,
      "models": [
        "gemini-1.0-pro-vision",
        "gemini-1.0-pro-vision-001",
        "gemini-pro-vision"
      ]
    },
    "volcengine": {
      "model_count": 5,
      "models": [
        "doubao-embedding",
        "doubao-embedding-large",
        "doubao-embedding-large-text-240915",
        "doubao-embedding-large-text-250515",
        "doubao-embedding-text-240715"
      ]
    },
    "voyage": {
      "model_count": 19,
      "models": [
        "rerank-2",
        "rerank-2-lite",
        "rerank-2.5",
        "rerank-2.5-lite",
        "voyage-2",
        "voyage-3",
        "voyage-3-large",
        "voyage-3-lite",
        "voyage-3.5",
        "voyage-3.5-lite",
        "voyage-code-2",
        "voyage-code-3",
        "voyage-context-3",
        "voyage-finance-2",
        "voyage-large-2",
        "voyage-law-2",
        "voyage-lite-01",
        "voyage-lite-02-instruct",
        "voyage-multimodal-3"
      ]
    },
    "wandb": {
      "model_count": 14,
      "models": [
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/DeepSeek-V3-0324",
        "deepseek-ai/DeepSeek-V3.1",
        "meta-llama/Llama-3.1-8B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "microsoft/Phi-4-mini-instruct",
        "moonshotai/Kimi-K2-Instruct",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "zai-org/GLM-4.5"
      ]
    },
    "watsonx": {
      "model_count": 29,
      "models": [
        "bigscience/mt0-xxl-13b",
        "core42/jais-13b-chat",
        "google/flan-t5-xl-3b",
        "ibm/granite-13b-chat-v2",
        "ibm/granite-13b-instruct-v2",
        "ibm/granite-3-3-8b-instruct",
        "ibm/granite-3-8b-instruct",
        "ibm/granite-4-h-small",
        "ibm/granite-guardian-3-2-2b",
        "ibm/granite-guardian-3-3-8b",
        "ibm/granite-ttm-1024-96-r2",
        "ibm/granite-ttm-1536-96-r2",
        "ibm/granite-ttm-512-96-r2",
        "ibm/granite-vision-3-2-2b",
        "meta-llama/llama-3-2-11b-vision-instruct",
        "meta-llama/llama-3-2-1b-instruct",
        "meta-llama/llama-3-2-3b-instruct",
        "meta-llama/llama-3-2-90b-vision-instruct",
        "meta-llama/llama-3-3-70b-instruct",
        "meta-llama/llama-4-maverick-17b",
        "meta-llama/llama-guard-3-11b-vision",
        "mistralai/mistral-large",
        "mistralai/mistral-medium-2505",
        "mistralai/mistral-small-2503",
        "mistralai/mistral-small-3-1-24b-instruct-2503",
        "mistralai/pixtral-12b-2409",
        "openai/gpt-oss-120b",
        "sdaia/allam-1-13b-instruct",
        "whisper-large-v3-turbo"
      ]
    },
    "xai": {
      "model_count": 32,
      "models": [
        "grok-2",
        "grok-2-1212",
        "grok-2-latest",
        "grok-2-vision",
        "grok-2-vision-1212",
        "grok-2-vision-latest",
        "grok-3",
        "grok-3-beta",
        "grok-3-fast-beta",
        "grok-3-fast-latest",
        "grok-3-latest",
        "grok-3-mini",
        "grok-3-mini-beta",
        "grok-3-mini-fast",
        "grok-3-mini-fast-beta",
        "grok-3-mini-fast-latest",
        "grok-3-mini-latest",
        "grok-4",
        "grok-4-0709",
        "grok-4-1-fast",
        "grok-4-1-fast-non-reasoning",
        "grok-4-1-fast-non-reasoning-latest",
        "grok-4-1-fast-reasoning",
        "grok-4-1-fast-reasoning-latest",
        "grok-4-fast-non-reasoning",
        "grok-4-fast-reasoning",
        "grok-4-latest",
        "grok-beta",
        "grok-code-fast",
        "grok-code-fast-1",
        "grok-code-fast-1-0825",
        "grok-vision-beta"
      ]
    },
    "zai": {
      "model_count": 8,
      "models": [
        "glm-4-32b-0414-128k",
        "glm-4.5",
        "glm-4.5-air",
        "glm-4.5-airx",
        "glm-4.5-flash",
        "glm-4.5-x",
        "glm-4.5v",
        "glm-4.6"
      ]
    }
  },
  "models": {
    "aws_bedrock/ai21.j2-mid-v1": {
      "id": "ai21.j2-mid-v1",
      "litellm_id": "ai21.j2-mid-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0125,
      "output_cost_per_1k": 0.0125
    },
    "aws_bedrock/ai21.j2-ultra-v1": {
      "id": "ai21.j2-ultra-v1",
      "litellm_id": "ai21.j2-ultra-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0188,
      "output_cost_per_1k": 0.0188
    },
    "aws_bedrock/ai21.jamba-1-5-large-v1:0": {
      "id": "ai21.jamba-1-5-large-v1:0",
      "litellm_id": "ai21.jamba-1-5-large-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "aws_bedrock/ai21.jamba-1-5-mini-v1:0": {
      "id": "ai21.jamba-1-5-mini-v1:0",
      "litellm_id": "ai21.jamba-1-5-mini-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "aws_bedrock/ai21.jamba-instruct-v1:0": {
      "id": "ai21.jamba-instruct-v1:0",
      "litellm_id": "ai21.jamba-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "system_messages"
      ]
    },
    "aiml/dall-e-2": {
      "id": "dall-e-2",
      "litellm_id": "aiml/dall-e-2",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/dall-e-3": {
      "id": "dall-e-3",
      "litellm_id": "aiml/dall-e-3",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux-pro": {
      "id": "flux-pro",
      "litellm_id": "aiml/flux-pro",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux-pro/v1.1": {
      "id": "flux-pro/v1.1",
      "litellm_id": "aiml/flux-pro/v1.1",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux-pro/v1.1-ultra": {
      "id": "flux-pro/v1.1-ultra",
      "litellm_id": "aiml/flux-pro/v1.1-ultra",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux-realism": {
      "id": "flux-realism",
      "litellm_id": "aiml/flux-realism",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux/dev": {
      "id": "flux/dev",
      "litellm_id": "aiml/flux/dev",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux/kontext-max/text-to-image": {
      "id": "flux/kontext-max/text-to-image",
      "litellm_id": "aiml/flux/kontext-max/text-to-image",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux/kontext-pro/text-to-image": {
      "id": "flux/kontext-pro/text-to-image",
      "litellm_id": "aiml/flux/kontext-pro/text-to-image",
      "provider": "aiml",
      "mode": "image"
    },
    "aiml/flux/schnell": {
      "id": "flux/schnell",
      "litellm_id": "aiml/flux/schnell",
      "provider": "aiml",
      "mode": "image"
    },
    "aws_bedrock/amazon.nova-canvas-v1:0": {
      "id": "amazon.nova-canvas-v1:0",
      "litellm_id": "amazon.nova-canvas-v1:0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 2600
    },
    "bedrock_converse/us.writer.palmyra-x4-v1:0": {
      "id": "us.writer.palmyra-x4-v1:0",
      "litellm_id": "us.writer.palmyra-x4-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/us.writer.palmyra-x5-v1:0": {
      "id": "us.writer.palmyra-x5-v1:0",
      "litellm_id": "us.writer.palmyra-x5-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/writer.palmyra-x4-v1:0": {
      "id": "writer.palmyra-x4-v1:0",
      "litellm_id": "writer.palmyra-x4-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/writer.palmyra-x5-v1:0": {
      "id": "writer.palmyra-x5-v1:0",
      "litellm_id": "writer.palmyra-x5-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/amazon.nova-lite-v1:0": {
      "id": "amazon.nova-lite-v1:0",
      "litellm_id": "amazon.nova-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/amazon.nova-2-lite-v1:0": {
      "id": "amazon.nova-2-lite-v1:0",
      "litellm_id": "amazon.nova-2-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/apac.amazon.nova-2-lite-v1:0": {
      "id": "apac.amazon.nova-2-lite-v1:0",
      "litellm_id": "apac.amazon.nova-2-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00033,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/eu.amazon.nova-2-lite-v1:0": {
      "id": "eu.amazon.nova-2-lite-v1:0",
      "litellm_id": "eu.amazon.nova-2-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00033,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/us.amazon.nova-2-lite-v1:0": {
      "id": "us.amazon.nova-2-lite-v1:0",
      "litellm_id": "us.amazon.nova-2-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00033,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/amazon.nova-micro-v1:0": {
      "id": "amazon.nova-micro-v1:0",
      "litellm_id": "amazon.nova-micro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/amazon.nova-pro-v1:0": {
      "id": "amazon.nova-pro-v1:0",
      "litellm_id": "amazon.nova-pro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/amazon.rerank-v1:0": {
      "id": "amazon.rerank-v1:0",
      "litellm_id": "amazon.rerank-v1:0",
      "provider": "aws_bedrock",
      "mode": "rerank",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000
    },
    "aws_bedrock/amazon.titan-embed-image-v1": {
      "id": "amazon.titan-embed-image-v1",
      "litellm_id": "amazon.titan-embed-image-v1",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 128,
      "input_cost_per_1k": 0.0008
    },
    "aws_bedrock/amazon.titan-embed-text-v1": {
      "id": "amazon.titan-embed-text-v1",
      "litellm_id": "amazon.titan-embed-text-v1",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0001
    },
    "aws_bedrock/amazon.titan-embed-text-v2:0": {
      "id": "amazon.titan-embed-text-v2:0",
      "litellm_id": "amazon.titan-embed-text-v2:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0002
    },
    "aws_bedrock/amazon.titan-image-generator-v1": {
      "id": "amazon.titan-image-generator-v1",
      "litellm_id": "amazon.titan-image-generator-v1",
      "provider": "aws_bedrock",
      "mode": "image"
    },
    "aws_bedrock/amazon.titan-image-generator-v2": {
      "id": "amazon.titan-image-generator-v2",
      "litellm_id": "amazon.titan-image-generator-v2",
      "provider": "aws_bedrock",
      "mode": "image"
    },
    "aws_bedrock/amazon.titan-image-generator-v2:0": {
      "id": "amazon.titan-image-generator-v2:0",
      "litellm_id": "amazon.titan-image-generator-v2:0",
      "provider": "aws_bedrock",
      "mode": "image"
    },
    "aws_bedrock/twelvelabs.marengo-embed-2-7-v1:0": {
      "id": "twelvelabs.marengo-embed-2-7-v1:0",
      "litellm_id": "twelvelabs.marengo-embed-2-7-v1:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 77,
      "input_cost_per_1k": 0.07
    },
    "aws_bedrock/us.twelvelabs.marengo-embed-2-7-v1:0": {
      "id": "us.twelvelabs.marengo-embed-2-7-v1:0",
      "litellm_id": "us.twelvelabs.marengo-embed-2-7-v1:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 77,
      "input_cost_per_1k": 0.07
    },
    "aws_bedrock/eu.twelvelabs.marengo-embed-2-7-v1:0": {
      "id": "eu.twelvelabs.marengo-embed-2-7-v1:0",
      "litellm_id": "eu.twelvelabs.marengo-embed-2-7-v1:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 77,
      "input_cost_per_1k": 0.07
    },
    "aws_bedrock/twelvelabs.pegasus-1-2-v1:0": {
      "id": "twelvelabs.pegasus-1-2-v1:0",
      "litellm_id": "twelvelabs.pegasus-1-2-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "output_cost_per_1k": 0.0075
    },
    "aws_bedrock/us.twelvelabs.pegasus-1-2-v1:0": {
      "id": "us.twelvelabs.pegasus-1-2-v1:0",
      "litellm_id": "us.twelvelabs.pegasus-1-2-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "output_cost_per_1k": 0.0075
    },
    "aws_bedrock/eu.twelvelabs.pegasus-1-2-v1:0": {
      "id": "eu.twelvelabs.pegasus-1-2-v1:0",
      "litellm_id": "eu.twelvelabs.pegasus-1-2-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "output_cost_per_1k": 0.0075
    },
    "aws_bedrock/amazon.titan-text-express-v1": {
      "id": "amazon.titan-text-express-v1",
      "litellm_id": "amazon.titan-text-express-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0013,
      "output_cost_per_1k": 0.0017
    },
    "aws_bedrock/amazon.titan-text-lite-v1": {
      "id": "amazon.titan-text-lite-v1",
      "litellm_id": "amazon.titan-text-lite-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0004
    },
    "aws_bedrock/amazon.titan-text-premier-v1:0": {
      "id": "amazon.titan-text-premier-v1:0",
      "litellm_id": "amazon.titan-text-premier-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015
    },
    "aws_bedrock/anthropic.claude-3-5-haiku-20241022-v1:0": {
      "id": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "litellm_id": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/anthropic.claude-haiku-4-5@20251001": {
      "id": "anthropic.claude-haiku-4-5@20251001",
      "litellm_id": "anthropic.claude-haiku-4-5@20251001",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "litellm_id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/anthropic.claude-3-7-sonnet-20240620-v1:0": {
      "id": "anthropic.claude-3-7-sonnet-20240620-v1:0",
      "litellm_id": "anthropic.claude-3-7-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0036,
      "output_cost_per_1k": 0.018,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "litellm_id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "anthropic.claude-3-haiku-20240307-v1:0",
      "litellm_id": "anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/anthropic.claude-3-opus-20240229-v1:0": {
      "id": "anthropic.claude-3-opus-20240229-v1:0",
      "litellm_id": "anthropic.claude-3-opus-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/anthropic.claude-3-sonnet-20240229-v1:0": {
      "id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "litellm_id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/anthropic.claude-instant-v1": {
      "id": "anthropic.claude-instant-v1",
      "litellm_id": "anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0024
    },
    "bedrock_converse/anthropic.claude-opus-4-1-20250805-v1:0": {
      "id": "anthropic.claude-opus-4-1-20250805-v1:0",
      "litellm_id": "anthropic.claude-opus-4-1-20250805-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/anthropic.claude-opus-4-20250514-v1:0": {
      "id": "anthropic.claude-opus-4-20250514-v1:0",
      "litellm_id": "anthropic.claude-opus-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/anthropic.claude-opus-4-5-20251101-v1:0": {
      "id": "anthropic.claude-opus-4-5-20251101-v1:0",
      "litellm_id": "anthropic.claude-opus-4-5-20251101-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/anthropic.claude-sonnet-4-20250514-v1:0": {
      "id": "anthropic.claude-sonnet-4-20250514-v1:0",
      "litellm_id": "anthropic.claude-sonnet-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "anthropic.claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/anthropic.claude-v1": {
      "id": "anthropic.claude-v1",
      "litellm_id": "anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/anthropic.claude-v2:1": {
      "id": "anthropic.claude-v2:1",
      "litellm_id": "anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "anyscale/HuggingFaceH4/zephyr-7b-beta": {
      "id": "HuggingFaceH4/zephyr-7b-beta",
      "litellm_id": "anyscale/HuggingFaceH4/zephyr-7b-beta",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "anyscale/codellama/CodeLlama-34b-Instruct-hf": {
      "id": "codellama/CodeLlama-34b-Instruct-hf",
      "litellm_id": "anyscale/codellama/CodeLlama-34b-Instruct-hf",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "anyscale/codellama/CodeLlama-70b-Instruct-hf": {
      "id": "codellama/CodeLlama-70b-Instruct-hf",
      "litellm_id": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "anyscale/google/gemma-7b-it": {
      "id": "google/gemma-7b-it",
      "litellm_id": "anyscale/google/gemma-7b-it",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "anyscale/meta-llama/Llama-2-13b-chat-hf": {
      "id": "meta-llama/Llama-2-13b-chat-hf",
      "litellm_id": "anyscale/meta-llama/Llama-2-13b-chat-hf",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025
    },
    "anyscale/meta-llama/Llama-2-70b-chat-hf": {
      "id": "meta-llama/Llama-2-70b-chat-hf",
      "litellm_id": "anyscale/meta-llama/Llama-2-70b-chat-hf",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "anyscale/meta-llama/Llama-2-7b-chat-hf": {
      "id": "meta-llama/Llama-2-7b-chat-hf",
      "litellm_id": "anyscale/meta-llama/Llama-2-7b-chat-hf",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": {
      "id": "meta-llama/Meta-Llama-3-70B-Instruct",
      "litellm_id": "anyscale/meta-llama/Meta-Llama-3-70B-Instruct",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": {
      "id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "litellm_id": "anyscale/meta-llama/Meta-Llama-3-8B-Instruct",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "anyscale/mistralai/Mistral-7B-Instruct-v0.1": {
      "id": "mistralai/Mistral-7B-Instruct-v0.1",
      "litellm_id": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": {
      "id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "litellm_id": "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling"
      ]
    },
    "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "litellm_id": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "provider": "anyscale",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/apac.amazon.nova-lite-v1:0": {
      "id": "apac.amazon.nova-lite-v1:0",
      "litellm_id": "apac.amazon.nova-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 6.3e-05,
      "output_cost_per_1k": 0.000252,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/apac.amazon.nova-micro-v1:0": {
      "id": "apac.amazon.nova-micro-v1:0",
      "litellm_id": "apac.amazon.nova-micro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 3.7e-05,
      "output_cost_per_1k": 0.000148,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/apac.amazon.nova-pro-v1:0": {
      "id": "apac.amazon.nova-pro-v1:0",
      "litellm_id": "apac.amazon.nova-pro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.00084,
      "output_cost_per_1k": 0.00336,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "id": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "litellm_id": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/apac.anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "apac.anthropic.claude-3-haiku-20240307-v1:0",
      "litellm_id": "apac.anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "bedrock_converse/apac.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "apac.anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "apac.anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0055,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/apac.anthropic.claude-3-sonnet-20240229-v1:0": {
      "id": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
      "litellm_id": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "bedrock_converse/apac.anthropic.claude-sonnet-4-20250514-v1:0": {
      "id": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
      "litellm_id": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "assemblyai/best": {
      "id": "best",
      "litellm_id": "assemblyai/best",
      "provider": "assemblyai",
      "mode": "audio_transcription"
    },
    "assemblyai/nano": {
      "id": "nano",
      "litellm_id": "assemblyai/nano",
      "provider": "assemblyai",
      "mode": "audio_transcription"
    },
    "bedrock_converse/au.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "au.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "au.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/ada": {
      "id": "ada",
      "litellm_id": "azure/ada",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 0.0001
    },
    "azure_openai/codex-mini": {
      "id": "codex-mini",
      "litellm_id": "azure/codex-mini",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/command-r-plus": {
      "id": "command-r-plus",
      "litellm_id": "azure/command-r-plus",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "litellm_id": "azure_ai/claude-haiku-4-5",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "litellm_id": "azure_ai/claude-opus-4-1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "litellm_id": "azure_ai/claude-sonnet-4-5",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/computer-use-preview": {
      "id": "computer-use-preview",
      "litellm_id": "computer-use-preview",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "reasoning"
      ]
    },
    "azure_openai/container": {
      "id": "container",
      "litellm_id": "azure/container",
      "provider": "azure_openai",
      "mode": "chat"
    },
    "azure_openai/eu/gpt-4o-2024-08-06": {
      "id": "eu/gpt-4o-2024-08-06",
      "litellm_id": "azure/eu/gpt-4o-2024-08-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00275,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-27"
    },
    "azure_openai/eu/gpt-4o-2024-11-20": {
      "id": "eu/gpt-4o-2024-11-20",
      "litellm_id": "azure/eu/gpt-4o-2024-11-20",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00275,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-01"
    },
    "azure_openai/eu/gpt-4o-mini-2024-07-18": {
      "id": "eu/gpt-4o-mini-2024-07-18",
      "litellm_id": "azure/eu/gpt-4o-mini-2024-07-18",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000165,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
      "id": "eu/gpt-4o-mini-realtime-preview-2024-12-17",
      "litellm_id": "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00066,
      "output_cost_per_1k": 0.00264,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/eu/gpt-4o-realtime-preview-2024-10-01": {
      "id": "eu/gpt-4o-realtime-preview-2024-10-01",
      "litellm_id": "azure/eu/gpt-4o-realtime-preview-2024-10-01",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0055,
      "output_cost_per_1k": 0.022,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/eu/gpt-4o-realtime-preview-2024-12-17": {
      "id": "eu/gpt-4o-realtime-preview-2024-12-17",
      "litellm_id": "azure/eu/gpt-4o-realtime-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0055,
      "output_cost_per_1k": 0.022,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/eu/gpt-5-2025-08-07": {
      "id": "eu/gpt-5-2025-08-07",
      "litellm_id": "azure/eu/gpt-5-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.001375,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/gpt-5-mini-2025-08-07": {
      "id": "eu/gpt-5-mini-2025-08-07",
      "litellm_id": "azure/eu/gpt-5-mini-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000275,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/gpt-5.1": {
      "id": "eu/gpt-5.1",
      "litellm_id": "azure/eu/gpt-5.1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00138,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/gpt-5.1-chat": {
      "id": "eu/gpt-5.1-chat",
      "litellm_id": "azure/eu/gpt-5.1-chat",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00138,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/gpt-5.1-codex": {
      "id": "eu/gpt-5.1-codex",
      "litellm_id": "azure/eu/gpt-5.1-codex",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00138,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/gpt-5.1-codex-mini": {
      "id": "eu/gpt-5.1-codex-mini",
      "litellm_id": "azure/eu/gpt-5.1-codex-mini",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000275,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/gpt-5-nano-2025-08-07": {
      "id": "eu/gpt-5-nano-2025-08-07",
      "litellm_id": "azure/eu/gpt-5-nano-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5.5e-05,
      "output_cost_per_1k": 0.00044,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/eu/o1-2024-12-17": {
      "id": "eu/o1-2024-12-17",
      "litellm_id": "azure/eu/o1-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.066,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/eu/o1-mini-2024-09-12": {
      "id": "eu/o1-mini-2024-09-12",
      "litellm_id": "azure/eu/o1-mini-2024-09-12",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00121,
      "output_cost_per_1k": 0.00484,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/eu/o1-preview-2024-09-12": {
      "id": "eu/o1-preview-2024-09-12",
      "litellm_id": "azure/eu/o1-preview-2024-09-12",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.066,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/eu/o3-mini-2025-01-31": {
      "id": "eu/o3-mini-2025-01-31",
      "litellm_id": "azure/eu/o3-mini-2025-01-31",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00121,
      "output_cost_per_1k": 0.00484,
      "capabilities": [
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/global-standard/gpt-4o-2024-08-06": {
      "id": "global-standard/gpt-4o-2024-08-06",
      "litellm_id": "azure/global-standard/gpt-4o-2024-08-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-27"
    },
    "azure_openai/global-standard/gpt-4o-2024-11-20": {
      "id": "global-standard/gpt-4o-2024-11-20",
      "litellm_id": "azure/global-standard/gpt-4o-2024-11-20",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-01"
    },
    "azure_openai/global-standard/gpt-4o-mini": {
      "id": "global-standard/gpt-4o-mini",
      "litellm_id": "azure/global-standard/gpt-4o-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "azure_openai/global/gpt-4o-2024-08-06": {
      "id": "global/gpt-4o-2024-08-06",
      "litellm_id": "azure/global/gpt-4o-2024-08-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-27"
    },
    "azure_openai/global/gpt-4o-2024-11-20": {
      "id": "global/gpt-4o-2024-11-20",
      "litellm_id": "azure/global/gpt-4o-2024-11-20",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-01"
    },
    "azure_openai/global/gpt-5.1": {
      "id": "global/gpt-5.1",
      "litellm_id": "azure/global/gpt-5.1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/global/gpt-5.1-chat": {
      "id": "global/gpt-5.1-chat",
      "litellm_id": "azure/global/gpt-5.1-chat",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/global/gpt-5.1-codex": {
      "id": "global/gpt-5.1-codex",
      "litellm_id": "azure/global/gpt-5.1-codex",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/global/gpt-5.1-codex-mini": {
      "id": "global/gpt-5.1-codex-mini",
      "litellm_id": "azure/global/gpt-5.1-codex-mini",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-3.5-turbo": {
      "id": "gpt-3.5-turbo",
      "litellm_id": "azure/gpt-3.5-turbo",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/gpt-3.5-turbo-0125": {
      "id": "gpt-3.5-turbo-0125",
      "litellm_id": "azure/gpt-3.5-turbo-0125",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-03-31"
    },
    "azure_text/azure/gpt-3.5-turbo-instruct-0914": {
      "id": "azure/gpt-3.5-turbo-instruct-0914",
      "litellm_id": "azure/gpt-3.5-turbo-instruct-0914",
      "provider": "azure_text",
      "mode": "completion",
      "max_input_tokens": 4097,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "azure_openai/gpt-35-turbo": {
      "id": "gpt-35-turbo",
      "litellm_id": "azure/gpt-35-turbo",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/gpt-35-turbo-0125": {
      "id": "gpt-35-turbo-0125",
      "litellm_id": "azure/gpt-35-turbo-0125",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-05-31"
    },
    "azure_openai/gpt-35-turbo-0301": {
      "id": "gpt-35-turbo-0301",
      "litellm_id": "azure/gpt-35-turbo-0301",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-02-13"
    },
    "azure_openai/gpt-35-turbo-0613": {
      "id": "gpt-35-turbo-0613",
      "litellm_id": "azure/gpt-35-turbo-0613",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-02-13"
    },
    "azure_openai/gpt-35-turbo-1106": {
      "id": "gpt-35-turbo-1106",
      "litellm_id": "azure/gpt-35-turbo-1106",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-03-31"
    },
    "azure_openai/gpt-35-turbo-16k": {
      "id": "gpt-35-turbo-16k",
      "litellm_id": "azure/gpt-35-turbo-16k",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004
    },
    "azure_openai/gpt-35-turbo-16k-0613": {
      "id": "gpt-35-turbo-16k-0613",
      "litellm_id": "azure/gpt-35-turbo-16k-0613",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_text/azure/gpt-35-turbo-instruct": {
      "id": "azure/gpt-35-turbo-instruct",
      "litellm_id": "azure/gpt-35-turbo-instruct",
      "provider": "azure_text",
      "mode": "completion",
      "max_input_tokens": 4097,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "azure_text/azure/gpt-35-turbo-instruct-0914": {
      "id": "azure/gpt-35-turbo-instruct-0914",
      "litellm_id": "azure/gpt-35-turbo-instruct-0914",
      "provider": "azure_text",
      "mode": "completion",
      "max_input_tokens": 4097,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "azure_openai/gpt-4": {
      "id": "gpt-4",
      "litellm_id": "azure/gpt-4",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/gpt-4-0125-preview": {
      "id": "gpt-4-0125-preview",
      "litellm_id": "azure/gpt-4-0125-preview",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "azure_openai/gpt-4-0613": {
      "id": "gpt-4-0613",
      "litellm_id": "azure/gpt-4-0613",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/gpt-4-1106-preview": {
      "id": "gpt-4-1106-preview",
      "litellm_id": "azure/gpt-4-1106-preview",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "azure_openai/gpt-4-32k": {
      "id": "gpt-4-32k",
      "litellm_id": "azure/gpt-4-32k",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12
    },
    "azure_openai/gpt-4-32k-0613": {
      "id": "gpt-4-32k-0613",
      "litellm_id": "azure/gpt-4-32k-0613",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12
    },
    "azure_openai/gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "litellm_id": "azure/gpt-4-turbo",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "azure_openai/gpt-4-turbo-2024-04-09": {
      "id": "gpt-4-turbo-2024-04-09",
      "litellm_id": "azure/gpt-4-turbo-2024-04-09",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "azure_openai/gpt-4-turbo-vision-preview": {
      "id": "gpt-4-turbo-vision-preview",
      "litellm_id": "azure/gpt-4-turbo-vision-preview",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision"
      ]
    },
    "azure_openai/gpt-4.1": {
      "id": "gpt-4.1",
      "litellm_id": "azure/gpt-4.1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4.1-2025-04-14": {
      "id": "gpt-4.1-2025-04-14",
      "litellm_id": "azure/gpt-4.1-2025-04-14",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-11-04"
    },
    "azure_openai/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "litellm_id": "azure/gpt-4.1-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4.1-mini-2025-04-14": {
      "id": "gpt-4.1-mini-2025-04-14",
      "litellm_id": "azure/gpt-4.1-mini-2025-04-14",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-11-04"
    },
    "azure_openai/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "litellm_id": "azure/gpt-4.1-nano",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4.1-nano-2025-04-14": {
      "id": "gpt-4.1-nano-2025-04-14",
      "litellm_id": "azure/gpt-4.1-nano-2025-04-14",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-11-04"
    },
    "azure_openai/gpt-4.5-preview": {
      "id": "gpt-4.5-preview",
      "litellm_id": "azure/gpt-4.5-preview",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.075,
      "output_cost_per_1k": 0.15,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4o": {
      "id": "gpt-4o",
      "litellm_id": "azure/gpt-4o",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4o-2024-05-13": {
      "id": "gpt-4o-2024-05-13",
      "litellm_id": "azure/gpt-4o-2024-05-13",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4o-2024-08-06": {
      "id": "gpt-4o-2024-08-06",
      "litellm_id": "azure/gpt-4o-2024-08-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-27"
    },
    "azure_openai/gpt-4o-2024-11-20": {
      "id": "gpt-4o-2024-11-20",
      "litellm_id": "azure/gpt-4o-2024-11-20",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00275,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-01"
    },
    "azure_openai/gpt-audio-2025-08-28": {
      "id": "gpt-audio-2025-08-28",
      "litellm_id": "azure/gpt-audio-2025-08-28",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "azure_openai/gpt-audio-mini-2025-10-06": {
      "id": "gpt-audio-mini-2025-10-06",
      "litellm_id": "azure/gpt-audio-mini-2025-10-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "azure_openai/gpt-4o-audio-preview-2024-12-17": {
      "id": "gpt-4o-audio-preview-2024-12-17",
      "litellm_id": "azure/gpt-4o-audio-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "azure_openai/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "litellm_id": "azure/gpt-4o-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000165,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4o-mini-2024-07-18": {
      "id": "gpt-4o-mini-2024-07-18",
      "litellm_id": "azure/gpt-4o-mini-2024-07-18",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000165,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/gpt-4o-mini-audio-preview-2024-12-17": {
      "id": "gpt-4o-mini-audio-preview-2024-12-17",
      "litellm_id": "azure/gpt-4o-mini-audio-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "azure_openai/gpt-4o-mini-realtime-preview-2024-12-17": {
      "id": "gpt-4o-mini-realtime-preview-2024-12-17",
      "litellm_id": "azure/gpt-4o-mini-realtime-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/gpt-realtime-2025-08-28": {
      "id": "gpt-realtime-2025-08-28",
      "litellm_id": "azure/gpt-realtime-2025-08-28",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.004,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/gpt-realtime-mini-2025-10-06": {
      "id": "gpt-realtime-mini-2025-10-06",
      "litellm_id": "azure/gpt-realtime-mini-2025-10-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/gpt-4o-mini-transcribe": {
      "id": "gpt-4o-mini-transcribe",
      "litellm_id": "azure/gpt-4o-mini-transcribe",
      "provider": "azure_openai",
      "mode": "audio_transcription",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.005
    },
    "azure_openai/gpt-4o-mini-tts": {
      "id": "gpt-4o-mini-tts",
      "litellm_id": "azure/gpt-4o-mini-tts",
      "provider": "azure_openai",
      "mode": "audio_speech",
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "azure_openai/gpt-4o-realtime-preview-2024-10-01": {
      "id": "gpt-4o-realtime-preview-2024-10-01",
      "litellm_id": "azure/gpt-4o-realtime-preview-2024-10-01",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/gpt-4o-realtime-preview-2024-12-17": {
      "id": "gpt-4o-realtime-preview-2024-12-17",
      "litellm_id": "azure/gpt-4o-realtime-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/gpt-4o-transcribe": {
      "id": "gpt-4o-transcribe",
      "litellm_id": "azure/gpt-4o-transcribe",
      "provider": "azure_openai",
      "mode": "audio_transcription",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "azure_openai/gpt-4o-transcribe-diarize": {
      "id": "gpt-4o-transcribe-diarize",
      "litellm_id": "azure/gpt-4o-transcribe-diarize",
      "provider": "azure_openai",
      "mode": "audio_transcription",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "azure_openai/gpt-5.1-2025-11-13": {
      "id": "gpt-5.1-2025-11-13",
      "litellm_id": "azure/gpt-5.1-2025-11-13",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-chat-2025-11-13": {
      "id": "gpt-5.1-chat-2025-11-13",
      "litellm_id": "azure/gpt-5.1-chat-2025-11-13",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-codex-2025-11-13": {
      "id": "gpt-5.1-codex-2025-11-13",
      "litellm_id": "azure/gpt-5.1-codex-2025-11-13",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-codex-mini-2025-11-13": {
      "id": "gpt-5.1-codex-mini-2025-11-13",
      "litellm_id": "azure/gpt-5.1-codex-mini-2025-11-13",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5": {
      "id": "gpt-5",
      "litellm_id": "azure/gpt-5",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-2025-08-07": {
      "id": "gpt-5-2025-08-07",
      "litellm_id": "azure/gpt-5-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-chat": {
      "id": "gpt-5-chat",
      "litellm_id": "azure/gpt-5-chat",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-chat-latest": {
      "id": "gpt-5-chat-latest",
      "litellm_id": "azure/gpt-5-chat-latest",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-codex": {
      "id": "gpt-5-codex",
      "litellm_id": "azure/gpt-5-codex",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-mini": {
      "id": "gpt-5-mini",
      "litellm_id": "azure/gpt-5-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-mini-2025-08-07": {
      "id": "gpt-5-mini-2025-08-07",
      "litellm_id": "azure/gpt-5-mini-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-nano": {
      "id": "gpt-5-nano",
      "litellm_id": "azure/gpt-5-nano",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-nano-2025-08-07": {
      "id": "gpt-5-nano-2025-08-07",
      "litellm_id": "azure/gpt-5-nano-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5-pro": {
      "id": "gpt-5-pro",
      "litellm_id": "azure/gpt-5-pro",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1": {
      "id": "gpt-5.1",
      "litellm_id": "azure/gpt-5.1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-chat": {
      "id": "gpt-5.1-chat",
      "litellm_id": "azure/gpt-5.1-chat",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "litellm_id": "azure/gpt-5.1-codex",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "litellm_id": "azure/gpt-5.1-codex-max",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "litellm_id": "azure/gpt-5.1-codex-mini",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.2": {
      "id": "gpt-5.2",
      "litellm_id": "azure/gpt-5.2",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.2-2025-12-11": {
      "id": "gpt-5.2-2025-12-11",
      "litellm_id": "azure/gpt-5.2-2025-12-11",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.2-chat-2025-12-11": {
      "id": "gpt-5.2-chat-2025-12-11",
      "litellm_id": "azure/gpt-5.2-chat-2025-12-11",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/gpt-5.2-pro": {
      "id": "gpt-5.2-pro",
      "litellm_id": "azure/gpt-5.2-pro",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "azure_openai/gpt-5.2-pro-2025-12-11": {
      "id": "gpt-5.2-pro-2025-12-11",
      "litellm_id": "azure/gpt-5.2-pro-2025-12-11",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "azure_openai/gpt-image-1": {
      "id": "gpt-image-1",
      "litellm_id": "azure/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/hd/1024-x-1024/dall-e-3": {
      "id": "hd/1024-x-1024/dall-e-3",
      "litellm_id": "azure/hd/1024-x-1024/dall-e-3",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/hd/1024-x-1792/dall-e-3": {
      "id": "hd/1024-x-1792/dall-e-3",
      "litellm_id": "azure/hd/1024-x-1792/dall-e-3",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/hd/1792-x-1024/dall-e-3": {
      "id": "hd/1792-x-1024/dall-e-3",
      "litellm_id": "azure/hd/1792-x-1024/dall-e-3",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/high/1024-x-1024/gpt-image-1": {
      "id": "high/1024-x-1024/gpt-image-1",
      "litellm_id": "azure/high/1024-x-1024/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/high/1024-x-1536/gpt-image-1": {
      "id": "high/1024-x-1536/gpt-image-1",
      "litellm_id": "azure/high/1024-x-1536/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/high/1536-x-1024/gpt-image-1": {
      "id": "high/1536-x-1024/gpt-image-1",
      "litellm_id": "azure/high/1536-x-1024/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/low/1024-x-1024/gpt-image-1": {
      "id": "low/1024-x-1024/gpt-image-1",
      "litellm_id": "azure/low/1024-x-1024/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/low/1024-x-1536/gpt-image-1": {
      "id": "low/1024-x-1536/gpt-image-1",
      "litellm_id": "azure/low/1024-x-1536/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/low/1536-x-1024/gpt-image-1": {
      "id": "low/1536-x-1024/gpt-image-1",
      "litellm_id": "azure/low/1536-x-1024/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/medium/1024-x-1024/gpt-image-1": {
      "id": "medium/1024-x-1024/gpt-image-1",
      "litellm_id": "azure/medium/1024-x-1024/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/medium/1024-x-1536/gpt-image-1": {
      "id": "medium/1024-x-1536/gpt-image-1",
      "litellm_id": "azure/medium/1024-x-1536/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/medium/1536-x-1024/gpt-image-1": {
      "id": "medium/1536-x-1024/gpt-image-1",
      "litellm_id": "azure/medium/1536-x-1024/gpt-image-1",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/gpt-image-1-mini": {
      "id": "gpt-image-1-mini",
      "litellm_id": "azure/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/low/1024-x-1024/gpt-image-1-mini": {
      "id": "low/1024-x-1024/gpt-image-1-mini",
      "litellm_id": "azure/low/1024-x-1024/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/low/1024-x-1536/gpt-image-1-mini": {
      "id": "low/1024-x-1536/gpt-image-1-mini",
      "litellm_id": "azure/low/1024-x-1536/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/low/1536-x-1024/gpt-image-1-mini": {
      "id": "low/1536-x-1024/gpt-image-1-mini",
      "litellm_id": "azure/low/1536-x-1024/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/medium/1024-x-1024/gpt-image-1-mini": {
      "id": "medium/1024-x-1024/gpt-image-1-mini",
      "litellm_id": "azure/medium/1024-x-1024/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/medium/1024-x-1536/gpt-image-1-mini": {
      "id": "medium/1024-x-1536/gpt-image-1-mini",
      "litellm_id": "azure/medium/1024-x-1536/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/medium/1536-x-1024/gpt-image-1-mini": {
      "id": "medium/1536-x-1024/gpt-image-1-mini",
      "litellm_id": "azure/medium/1536-x-1024/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/high/1024-x-1024/gpt-image-1-mini": {
      "id": "high/1024-x-1024/gpt-image-1-mini",
      "litellm_id": "azure/high/1024-x-1024/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/high/1024-x-1536/gpt-image-1-mini": {
      "id": "high/1024-x-1536/gpt-image-1-mini",
      "litellm_id": "azure/high/1024-x-1536/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/high/1536-x-1024/gpt-image-1-mini": {
      "id": "high/1536-x-1024/gpt-image-1-mini",
      "litellm_id": "azure/high/1536-x-1024/gpt-image-1-mini",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/mistral-large-2402": {
      "id": "mistral-large-2402",
      "litellm_id": "azure/mistral-large-2402",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-large-latest": {
      "id": "mistral-large-latest",
      "litellm_id": "azure_ai/mistral-large-latest",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/o1": {
      "id": "o1",
      "litellm_id": "azure/o1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o1-2024-12-17": {
      "id": "o1-2024-12-17",
      "litellm_id": "azure/o1-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o1-mini": {
      "id": "o1-mini",
      "litellm_id": "azure/o1-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00121,
      "output_cost_per_1k": 0.00484,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o1-mini-2024-09-12": {
      "id": "o1-mini-2024-09-12",
      "litellm_id": "azure/o1-mini-2024-09-12",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o1-preview": {
      "id": "o1-preview",
      "litellm_id": "azure/o1-preview",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o1-preview-2024-09-12": {
      "id": "o1-preview-2024-09-12",
      "litellm_id": "azure/o1-preview-2024-09-12",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o3": {
      "id": "o3",
      "litellm_id": "azure/o3",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o3-2025-04-16": {
      "id": "o3-2025-04-16",
      "litellm_id": "azure/o3-2025-04-16",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2026-04-16"
    },
    "azure_openai/o3-deep-research": {
      "id": "o3-deep-research",
      "litellm_id": "azure/o3-deep-research",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.04,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "azure_openai/o3-mini": {
      "id": "o3-mini",
      "litellm_id": "azure/o3-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o3-mini-2025-01-31": {
      "id": "o3-mini-2025-01-31",
      "litellm_id": "azure/o3-mini-2025-01-31",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o3-pro": {
      "id": "o3-pro",
      "litellm_id": "azure/o3-pro",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "azure_openai/o3-pro-2025-06-10": {
      "id": "o3-pro-2025-06-10",
      "litellm_id": "azure/o3-pro-2025-06-10",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "azure_openai/o4-mini": {
      "id": "o4-mini",
      "litellm_id": "azure/o4-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/o4-mini-2025-04-16": {
      "id": "o4-mini-2025-04-16",
      "litellm_id": "azure/o4-mini-2025-04-16",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/standard/1024-x-1024/dall-e-2": {
      "id": "standard/1024-x-1024/dall-e-2",
      "litellm_id": "azure/standard/1024-x-1024/dall-e-2",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/standard/1024-x-1024/dall-e-3": {
      "id": "standard/1024-x-1024/dall-e-3",
      "litellm_id": "azure/standard/1024-x-1024/dall-e-3",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/standard/1024-x-1792/dall-e-3": {
      "id": "standard/1024-x-1792/dall-e-3",
      "litellm_id": "azure/standard/1024-x-1792/dall-e-3",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/standard/1792-x-1024/dall-e-3": {
      "id": "standard/1792-x-1024/dall-e-3",
      "litellm_id": "azure/standard/1792-x-1024/dall-e-3",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/text-embedding-3-large": {
      "id": "text-embedding-3-large",
      "litellm_id": "azure/text-embedding-3-large",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 0.00013
    },
    "azure_openai/text-embedding-3-small": {
      "id": "text-embedding-3-small",
      "litellm_id": "azure/text-embedding-3-small",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 2e-05,
      "deprecated": true,
      "deprecation_date": "2026-04-30"
    },
    "azure_openai/text-embedding-ada-002": {
      "id": "text-embedding-ada-002",
      "litellm_id": "azure/text-embedding-ada-002",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 0.0001
    },
    "azure_openai/speech/azure-tts": {
      "id": "speech/azure-tts",
      "litellm_id": "azure/speech/azure-tts",
      "provider": "azure_openai",
      "mode": "audio_speech"
    },
    "azure_openai/speech/azure-tts-hd": {
      "id": "speech/azure-tts-hd",
      "litellm_id": "azure/speech/azure-tts-hd",
      "provider": "azure_openai",
      "mode": "audio_speech"
    },
    "azure_openai/tts-1": {
      "id": "tts-1",
      "litellm_id": "azure/tts-1",
      "provider": "azure_openai",
      "mode": "audio_speech"
    },
    "azure_openai/tts-1-hd": {
      "id": "tts-1-hd",
      "litellm_id": "azure/tts-1-hd",
      "provider": "azure_openai",
      "mode": "audio_speech"
    },
    "azure_openai/us/gpt-4.1-2025-04-14": {
      "id": "us/gpt-4.1-2025-04-14",
      "litellm_id": "azure/us/gpt-4.1-2025-04-14",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0022,
      "output_cost_per_1k": 0.0088,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-11-04"
    },
    "azure_openai/us/gpt-4.1-mini-2025-04-14": {
      "id": "us/gpt-4.1-mini-2025-04-14",
      "litellm_id": "azure/us/gpt-4.1-mini-2025-04-14",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00044,
      "output_cost_per_1k": 0.00176,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-11-04"
    },
    "azure_openai/us/gpt-4.1-nano-2025-04-14": {
      "id": "us/gpt-4.1-nano-2025-04-14",
      "litellm_id": "azure/us/gpt-4.1-nano-2025-04-14",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00044,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-11-04"
    },
    "azure_openai/us/gpt-4o-2024-08-06": {
      "id": "us/gpt-4o-2024-08-06",
      "litellm_id": "azure/us/gpt-4o-2024-08-06",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00275,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-27"
    },
    "azure_openai/us/gpt-4o-2024-11-20": {
      "id": "us/gpt-4o-2024-11-20",
      "litellm_id": "azure/us/gpt-4o-2024-11-20",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00275,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-01"
    },
    "azure_openai/us/gpt-4o-mini-2024-07-18": {
      "id": "us/gpt-4o-mini-2024-07-18",
      "litellm_id": "azure/us/gpt-4o-mini-2024-07-18",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000165,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "azure_openai/us/gpt-4o-mini-realtime-preview-2024-12-17": {
      "id": "us/gpt-4o-mini-realtime-preview-2024-12-17",
      "litellm_id": "azure/us/gpt-4o-mini-realtime-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00066,
      "output_cost_per_1k": 0.00264,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/us/gpt-4o-realtime-preview-2024-10-01": {
      "id": "us/gpt-4o-realtime-preview-2024-10-01",
      "litellm_id": "azure/us/gpt-4o-realtime-preview-2024-10-01",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0055,
      "output_cost_per_1k": 0.022,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/us/gpt-4o-realtime-preview-2024-12-17": {
      "id": "us/gpt-4o-realtime-preview-2024-12-17",
      "litellm_id": "azure/us/gpt-4o-realtime-preview-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0055,
      "output_cost_per_1k": 0.022,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "azure_openai/us/gpt-5-2025-08-07": {
      "id": "us/gpt-5-2025-08-07",
      "litellm_id": "azure/us/gpt-5-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.001375,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/gpt-5-mini-2025-08-07": {
      "id": "us/gpt-5-mini-2025-08-07",
      "litellm_id": "azure/us/gpt-5-mini-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000275,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/gpt-5-nano-2025-08-07": {
      "id": "us/gpt-5-nano-2025-08-07",
      "litellm_id": "azure/us/gpt-5-nano-2025-08-07",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5.5e-05,
      "output_cost_per_1k": 0.00044,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/gpt-5.1": {
      "id": "us/gpt-5.1",
      "litellm_id": "azure/us/gpt-5.1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00138,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/gpt-5.1-chat": {
      "id": "us/gpt-5.1-chat",
      "litellm_id": "azure/us/gpt-5.1-chat",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00138,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/gpt-5.1-codex": {
      "id": "us/gpt-5.1-codex",
      "litellm_id": "azure/us/gpt-5.1-codex",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00138,
      "output_cost_per_1k": 0.011,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/gpt-5.1-codex-mini": {
      "id": "us/gpt-5.1-codex-mini",
      "litellm_id": "azure/us/gpt-5.1-codex-mini",
      "provider": "azure_openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000275,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/o1-2024-12-17": {
      "id": "us/o1-2024-12-17",
      "litellm_id": "azure/us/o1-2024-12-17",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.066,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/us/o1-mini-2024-09-12": {
      "id": "us/o1-mini-2024-09-12",
      "litellm_id": "azure/us/o1-mini-2024-09-12",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00121,
      "output_cost_per_1k": 0.00484,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/us/o1-preview-2024-09-12": {
      "id": "us/o1-preview-2024-09-12",
      "litellm_id": "azure/us/o1-preview-2024-09-12",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.066,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "prompt_caching"
      ]
    },
    "azure_openai/us/o3-2025-04-16": {
      "id": "us/o3-2025-04-16",
      "litellm_id": "azure/us/o3-2025-04-16",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0022,
      "output_cost_per_1k": 0.0088,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2026-04-16"
    },
    "azure_openai/us/o3-mini-2025-01-31": {
      "id": "us/o3-mini-2025-01-31",
      "litellm_id": "azure/us/o3-mini-2025-01-31",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00121,
      "output_cost_per_1k": 0.00484,
      "capabilities": [
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/us/o4-mini-2025-04-16": {
      "id": "us/o4-mini-2025-04-16",
      "litellm_id": "azure/us/o4-mini-2025-04-16",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00121,
      "output_cost_per_1k": 0.00484,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/whisper-1": {
      "id": "whisper-1",
      "litellm_id": "azure/whisper-1",
      "provider": "azure_openai",
      "mode": "audio_transcription"
    },
    "azure_openai/Cohere-embed-v3-english": {
      "id": "Cohere-embed-v3-english",
      "litellm_id": "azure_ai/Cohere-embed-v3-english",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.0001
    },
    "azure_openai/Cohere-embed-v3-multilingual": {
      "id": "Cohere-embed-v3-multilingual",
      "litellm_id": "azure_ai/Cohere-embed-v3-multilingual",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.0001
    },
    "azure_openai/FLUX-1.1-pro": {
      "id": "FLUX-1.1-pro",
      "litellm_id": "azure_ai/FLUX-1.1-pro",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/FLUX.1-Kontext-pro": {
      "id": "FLUX.1-Kontext-pro",
      "litellm_id": "azure_ai/FLUX.1-Kontext-pro",
      "provider": "azure_openai",
      "mode": "image"
    },
    "azure_openai/Llama-3.2-11B-Vision-Instruct": {
      "id": "Llama-3.2-11B-Vision-Instruct",
      "litellm_id": "azure_ai/Llama-3.2-11B-Vision-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00037,
      "output_cost_per_1k": 0.00037,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "azure_openai/Llama-3.2-90B-Vision-Instruct": {
      "id": "Llama-3.2-90B-Vision-Instruct",
      "litellm_id": "azure_ai/Llama-3.2-90B-Vision-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00204,
      "output_cost_per_1k": 0.00204,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "azure_openai/Llama-3.3-70B-Instruct": {
      "id": "Llama-3.3-70B-Instruct",
      "litellm_id": "azure_ai/Llama-3.3-70B-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00071,
      "output_cost_per_1k": 0.00071,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "litellm_id": "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00141,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "azure_openai/Llama-4-Scout-17B-16E-Instruct": {
      "id": "Llama-4-Scout-17B-16E-Instruct",
      "litellm_id": "azure_ai/Llama-4-Scout-17B-16E-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 10000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.00078,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "azure_openai/Meta-Llama-3-70B-Instruct": {
      "id": "Meta-Llama-3-70B-Instruct",
      "litellm_id": "azure_ai/Meta-Llama-3-70B-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.00037
    },
    "azure_openai/Meta-Llama-3.1-405B-Instruct": {
      "id": "Meta-Llama-3.1-405B-Instruct",
      "litellm_id": "azure_ai/Meta-Llama-3.1-405B-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00533,
      "output_cost_per_1k": 0.016
    },
    "azure_openai/Meta-Llama-3.1-70B-Instruct": {
      "id": "Meta-Llama-3.1-70B-Instruct",
      "litellm_id": "azure_ai/Meta-Llama-3.1-70B-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00268,
      "output_cost_per_1k": 0.00354
    },
    "azure_openai/Meta-Llama-3.1-8B-Instruct": {
      "id": "Meta-Llama-3.1-8B-Instruct",
      "litellm_id": "azure_ai/Meta-Llama-3.1-8B-Instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00061
    },
    "azure_openai/Phi-3-medium-128k-instruct": {
      "id": "Phi-3-medium-128k-instruct",
      "litellm_id": "azure_ai/Phi-3-medium-128k-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00068
    },
    "azure_openai/Phi-3-medium-4k-instruct": {
      "id": "Phi-3-medium-4k-instruct",
      "litellm_id": "azure_ai/Phi-3-medium-4k-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00068
    },
    "azure_openai/Phi-3-mini-128k-instruct": {
      "id": "Phi-3-mini-128k-instruct",
      "litellm_id": "azure_ai/Phi-3-mini-128k-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052
    },
    "azure_openai/Phi-3-mini-4k-instruct": {
      "id": "Phi-3-mini-4k-instruct",
      "litellm_id": "azure_ai/Phi-3-mini-4k-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052
    },
    "azure_openai/Phi-3-small-128k-instruct": {
      "id": "Phi-3-small-128k-instruct",
      "litellm_id": "azure_ai/Phi-3-small-128k-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "azure_openai/Phi-3-small-8k-instruct": {
      "id": "Phi-3-small-8k-instruct",
      "litellm_id": "azure_ai/Phi-3-small-8k-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "azure_openai/Phi-3.5-MoE-instruct": {
      "id": "Phi-3.5-MoE-instruct",
      "litellm_id": "azure_ai/Phi-3.5-MoE-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00016,
      "output_cost_per_1k": 0.00064
    },
    "azure_openai/Phi-3.5-mini-instruct": {
      "id": "Phi-3.5-mini-instruct",
      "litellm_id": "azure_ai/Phi-3.5-mini-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052
    },
    "azure_openai/Phi-3.5-vision-instruct": {
      "id": "Phi-3.5-vision-instruct",
      "litellm_id": "azure_ai/Phi-3.5-vision-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "vision"
      ]
    },
    "azure_openai/Phi-4": {
      "id": "Phi-4",
      "litellm_id": "azure_ai/Phi-4",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/Phi-4-mini-instruct": {
      "id": "Phi-4-mini-instruct",
      "litellm_id": "azure_ai/Phi-4-mini-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/Phi-4-multimodal-instruct": {
      "id": "Phi-4-multimodal-instruct",
      "litellm_id": "azure_ai/Phi-4-multimodal-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00032,
      "capabilities": [
        "vision",
        "function_calling",
        "audio_input"
      ]
    },
    "azure_openai/Phi-4-mini-reasoning": {
      "id": "Phi-4-mini-reasoning",
      "litellm_id": "azure_ai/Phi-4-mini-reasoning",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00032,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/Phi-4-reasoning": {
      "id": "Phi-4-reasoning",
      "litellm_id": "azure_ai/Phi-4-reasoning",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "azure_openai/mistral-document-ai-2505": {
      "id": "mistral-document-ai-2505",
      "litellm_id": "azure_ai/mistral-document-ai-2505",
      "provider": "azure_openai",
      "mode": "ocr"
    },
    "azure_openai/doc-intelligence/prebuilt-read": {
      "id": "doc-intelligence/prebuilt-read",
      "litellm_id": "azure_ai/doc-intelligence/prebuilt-read",
      "provider": "azure_openai",
      "mode": "ocr"
    },
    "azure_openai/doc-intelligence/prebuilt-layout": {
      "id": "doc-intelligence/prebuilt-layout",
      "litellm_id": "azure_ai/doc-intelligence/prebuilt-layout",
      "provider": "azure_openai",
      "mode": "ocr"
    },
    "azure_openai/doc-intelligence/prebuilt-document": {
      "id": "doc-intelligence/prebuilt-document",
      "litellm_id": "azure_ai/doc-intelligence/prebuilt-document",
      "provider": "azure_openai",
      "mode": "ocr"
    },
    "azure_openai/MAI-DS-R1": {
      "id": "MAI-DS-R1",
      "litellm_id": "azure_ai/MAI-DS-R1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning"
      ]
    },
    "azure_openai/cohere-rerank-v3-english": {
      "id": "cohere-rerank-v3-english",
      "litellm_id": "azure_ai/cohere-rerank-v3-english",
      "provider": "azure_openai",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "azure_openai/cohere-rerank-v3-multilingual": {
      "id": "cohere-rerank-v3-multilingual",
      "litellm_id": "azure_ai/cohere-rerank-v3-multilingual",
      "provider": "azure_openai",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "azure_openai/cohere-rerank-v3.5": {
      "id": "cohere-rerank-v3.5",
      "litellm_id": "azure_ai/cohere-rerank-v3.5",
      "provider": "azure_openai",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "azure_openai/cohere-rerank-v4.0-pro": {
      "id": "cohere-rerank-v4.0-pro",
      "litellm_id": "azure_ai/cohere-rerank-v4.0-pro",
      "provider": "azure_openai",
      "mode": "rerank",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768
    },
    "azure_openai/cohere-rerank-v4.0-fast": {
      "id": "cohere-rerank-v4.0-fast",
      "litellm_id": "azure_ai/cohere-rerank-v4.0-fast",
      "provider": "azure_openai",
      "mode": "rerank",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768
    },
    "azure_openai/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "litellm_id": "azure_ai/deepseek-v3.2",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00058,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/deepseek-v3.2-speciale": {
      "id": "deepseek-v3.2-speciale",
      "litellm_id": "azure_ai/deepseek-v3.2-speciale",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00058,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "azure_openai/deepseek-r1": {
      "id": "deepseek-r1",
      "litellm_id": "azure_ai/deepseek-r1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning"
      ]
    },
    "azure_openai/deepseek-v3": {
      "id": "deepseek-v3",
      "litellm_id": "azure_ai/deepseek-v3",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00114,
      "output_cost_per_1k": 0.00456
    },
    "azure_openai/deepseek-v3-0324": {
      "id": "deepseek-v3-0324",
      "litellm_id": "azure_ai/deepseek-v3-0324",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00114,
      "output_cost_per_1k": 0.00456,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/embed-v-4-0": {
      "id": "embed-v-4-0",
      "litellm_id": "azure_ai/embed-v-4-0",
      "provider": "azure_openai",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.00012
    },
    "azure_openai/global/grok-3": {
      "id": "global/grok-3",
      "litellm_id": "azure_ai/global/grok-3",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "azure_openai/global/grok-3-mini": {
      "id": "global/grok-3-mini",
      "litellm_id": "azure_ai/global/grok-3-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00127,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "azure_openai/grok-3": {
      "id": "grok-3",
      "litellm_id": "azure_ai/grok-3",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "azure_openai/grok-3-mini": {
      "id": "grok-3-mini",
      "litellm_id": "azure_ai/grok-3-mini",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.000275,
      "output_cost_per_1k": 0.00138,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "azure_openai/grok-4": {
      "id": "grok-4",
      "litellm_id": "azure_ai/grok-4",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0055,
      "output_cost_per_1k": 0.0275,
      "capabilities": [
        "function_calling",
        "json_mode",
        "web_search"
      ]
    },
    "azure_openai/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "litellm_id": "azure_ai/grok-4-fast-non-reasoning",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00043,
      "output_cost_per_1k": 0.00173,
      "capabilities": [
        "function_calling",
        "json_mode",
        "web_search"
      ]
    },
    "azure_openai/grok-4-fast-reasoning": {
      "id": "grok-4-fast-reasoning",
      "litellm_id": "azure_ai/grok-4-fast-reasoning",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00043,
      "output_cost_per_1k": 0.00173,
      "capabilities": [
        "function_calling",
        "json_mode",
        "web_search"
      ]
    },
    "azure_openai/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "litellm_id": "azure_ai/grok-code-fast-1",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "web_search"
      ]
    },
    "azure_openai/jais-30b-chat": {
      "id": "jais-30b-chat",
      "litellm_id": "azure_ai/jais-30b-chat",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3.2,
      "output_cost_per_1k": 9.71
    },
    "azure_openai/jamba-instruct": {
      "id": "jamba-instruct",
      "litellm_id": "azure_ai/jamba-instruct",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0007
    },
    "azure_openai/ministral-3b": {
      "id": "ministral-3b",
      "litellm_id": "azure_ai/ministral-3b",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-large": {
      "id": "mistral-large",
      "litellm_id": "azure_ai/mistral-large",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.004,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-large-2407": {
      "id": "mistral-large-2407",
      "litellm_id": "azure_ai/mistral-large-2407",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-large-3": {
      "id": "mistral-large-3",
      "litellm_id": "azure_ai/mistral-large-3",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "azure_openai/mistral-medium-2505": {
      "id": "mistral-medium-2505",
      "litellm_id": "azure_ai/mistral-medium-2505",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-nemo": {
      "id": "mistral-nemo",
      "litellm_id": "azure_ai/mistral-nemo",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-small": {
      "id": "mistral-small",
      "litellm_id": "azure_ai/mistral-small",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling"
      ]
    },
    "azure_openai/mistral-small-2503": {
      "id": "mistral-small-2503",
      "litellm_id": "azure_ai/mistral-small-2503",
      "provider": "azure_openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "text-completion-openai/babbage-002": {
      "id": "babbage-002",
      "litellm_id": "babbage-002",
      "provider": "text-completion-openai",
      "mode": "completion",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004
    },
    "aws_bedrock/*/1-month-commitment/cohere.command-light-text-v14": {
      "id": "*/1-month-commitment/cohere.command-light-text-v14",
      "litellm_id": "bedrock/*/1-month-commitment/cohere.command-light-text-v14",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_bedrock/*/1-month-commitment/cohere.command-text-v14": {
      "id": "*/1-month-commitment/cohere.command-text-v14",
      "litellm_id": "bedrock/*/1-month-commitment/cohere.command-text-v14",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_bedrock/*/6-month-commitment/cohere.command-light-text-v14": {
      "id": "*/6-month-commitment/cohere.command-light-text-v14",
      "litellm_id": "bedrock/*/6-month-commitment/cohere.command-light-text-v14",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_bedrock/*/6-month-commitment/cohere.command-text-v14": {
      "id": "*/6-month-commitment/cohere.command-text-v14",
      "litellm_id": "bedrock/*/6-month-commitment/cohere.command-text-v14",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
      "id": "ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
      "id": "ap-northeast-1/1-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
      "id": "ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
      "id": "ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
      "id": "ap-northeast-1/6-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
      "id": "ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
      "id": "ap-northeast-1/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00223,
      "output_cost_per_1k": 0.00755
    },
    "aws_bedrock/ap-northeast-1/anthropic.claude-v1": {
      "id": "ap-northeast-1/anthropic.claude-v1",
      "litellm_id": "bedrock/ap-northeast-1/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/ap-northeast-1/anthropic.claude-v2:1": {
      "id": "ap-northeast-1/anthropic.claude-v2:1",
      "litellm_id": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": {
      "id": "ap-south-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00318,
      "output_cost_per_1k": 0.0042
    },
    "aws_bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": {
      "id": "ap-south-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00036,
      "output_cost_per_1k": 0.00072
    },
    "aws_bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": {
      "id": "ca-central-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00305,
      "output_cost_per_1k": 0.00403
    },
    "aws_bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": {
      "id": "ca-central-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00069
    },
    "aws_bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
      "id": "eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": {
      "id": "eu-central-1/1-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
      "id": "eu-central-1/1-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
      "id": "eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": {
      "id": "eu-central-1/6-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
      "id": "eu-central-1/6-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/eu-central-1/anthropic.claude-instant-v1": {
      "id": "eu-central-1/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/eu-central-1/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00248,
      "output_cost_per_1k": 0.00838
    },
    "aws_bedrock/eu-central-1/anthropic.claude-v1": {
      "id": "eu-central-1/anthropic.claude-v1",
      "litellm_id": "bedrock/eu-central-1/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/eu-central-1/anthropic.claude-v2:1": {
      "id": "eu-central-1/anthropic.claude-v2:1",
      "litellm_id": "bedrock/eu-central-1/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": {
      "id": "eu-west-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00286,
      "output_cost_per_1k": 0.00378
    },
    "aws_bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": {
      "id": "eu-west-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00032,
      "output_cost_per_1k": 0.00065
    },
    "aws_bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": {
      "id": "eu-west-2/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00345,
      "output_cost_per_1k": 0.00455
    },
    "aws_bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": {
      "id": "eu-west-2/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00039,
      "output_cost_per_1k": 0.00078
    },
    "aws_bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
      "id": "eu-west-3/mistral.mistral-7b-instruct-v0:2",
      "litellm_id": "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.00026
    },
    "aws_bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
      "id": "eu-west-3/mistral.mistral-large-2402-v1:0",
      "litellm_id": "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0104,
      "output_cost_per_1k": 0.0312,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
      "id": "eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
      "litellm_id": "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00091
    },
    "aws_bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": {
      "id": "sa-east-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00445,
      "output_cost_per_1k": 0.00588
    },
    "aws_bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": {
      "id": "sa-east-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00101
    },
    "aws_bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
      "id": "us-east-1/1-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": {
      "id": "us-east-1/1-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": {
      "id": "us-east-1/1-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
      "id": "us-east-1/6-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": {
      "id": "us-east-1/6-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": {
      "id": "us-east-1/6-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-east-1/anthropic.claude-instant-v1": {
      "id": "us-east-1/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/us-east-1/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0024
    },
    "aws_bedrock/us-east-1/anthropic.claude-v1": {
      "id": "us-east-1/anthropic.claude-v1",
      "litellm_id": "bedrock/us-east-1/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/us-east-1/anthropic.claude-v2:1": {
      "id": "us-east-1/anthropic.claude-v2:1",
      "litellm_id": "bedrock/us-east-1/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": {
      "id": "us-east-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00265,
      "output_cost_per_1k": 0.0035
    },
    "aws_bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": {
      "id": "us-east-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006
    },
    "aws_bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
      "id": "us-east-1/mistral.mistral-7b-instruct-v0:2",
      "litellm_id": "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0002
    },
    "aws_bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
      "id": "us-east-1/mistral.mistral-large-2402-v1:0",
      "litellm_id": "bedrock/us-east-1/mistral.mistral-large-2402-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
      "id": "us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
      "litellm_id": "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0007
    },
    "aws_bedrock/us-gov-east-1/amazon.nova-pro-v1:0": {
      "id": "us-gov-east-1/amazon.nova-pro-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/amazon.nova-pro-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.00096,
      "output_cost_per_1k": 0.00384,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/us-gov-east-1/amazon.titan-embed-text-v1": {
      "id": "us-gov-east-1/amazon.titan-embed-text-v1",
      "litellm_id": "bedrock/us-gov-east-1/amazon.titan-embed-text-v1",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0001
    },
    "aws_bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0": {
      "id": "us-gov-east-1/amazon.titan-embed-text-v2:0",
      "litellm_id": "bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0002
    },
    "aws_bedrock/us-gov-east-1/amazon.titan-text-express-v1": {
      "id": "us-gov-east-1/amazon.titan-text-express-v1",
      "litellm_id": "bedrock/us-gov-east-1/amazon.titan-text-express-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0013,
      "output_cost_per_1k": 0.0017
    },
    "aws_bedrock/us-gov-east-1/amazon.titan-text-lite-v1": {
      "id": "us-gov-east-1/amazon.titan-text-lite-v1",
      "litellm_id": "bedrock/us-gov-east-1/amazon.titan-text-lite-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0004
    },
    "aws_bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0": {
      "id": "us-gov-east-1/amazon.titan-text-premier-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015
    },
    "aws_bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0036,
      "output_cost_per_1k": 0.018,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
      "id": "us-gov-east-1/claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
      "id": "us-gov-east-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00265,
      "output_cost_per_1k": 0.0035
    },
    "aws_bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
      "id": "us-gov-east-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00265
    },
    "aws_bedrock/us-gov-west-1/amazon.nova-pro-v1:0": {
      "id": "us-gov-west-1/amazon.nova-pro-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/amazon.nova-pro-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.00096,
      "output_cost_per_1k": 0.00384,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/us-gov-west-1/amazon.titan-embed-text-v1": {
      "id": "us-gov-west-1/amazon.titan-embed-text-v1",
      "litellm_id": "bedrock/us-gov-west-1/amazon.titan-embed-text-v1",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0001
    },
    "aws_bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0": {
      "id": "us-gov-west-1/amazon.titan-embed-text-v2:0",
      "litellm_id": "bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0002
    },
    "aws_bedrock/us-gov-west-1/amazon.titan-text-express-v1": {
      "id": "us-gov-west-1/amazon.titan-text-express-v1",
      "litellm_id": "bedrock/us-gov-west-1/amazon.titan-text-express-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0013,
      "output_cost_per_1k": 0.0017
    },
    "aws_bedrock/us-gov-west-1/amazon.titan-text-lite-v1": {
      "id": "us-gov-west-1/amazon.titan-text-lite-v1",
      "litellm_id": "bedrock/us-gov-west-1/amazon.titan-text-lite-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0004
    },
    "aws_bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0": {
      "id": "us-gov-west-1/amazon.titan-text-premier-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015
    },
    "aws_bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "id": "us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0036,
      "output_cost_per_1k": 0.018,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0036,
      "output_cost_per_1k": 0.018,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
      "id": "us-gov-west-1/claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
      "id": "us-gov-west-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00265,
      "output_cost_per_1k": 0.0035
    },
    "aws_bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
      "id": "us-gov-west-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00265
    },
    "aws_bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": {
      "id": "us-west-1/meta.llama3-70b-instruct-v1:0",
      "litellm_id": "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00265,
      "output_cost_per_1k": 0.0035
    },
    "aws_bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": {
      "id": "us-west-1/meta.llama3-8b-instruct-v1:0",
      "litellm_id": "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006
    },
    "aws_bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
      "id": "us-west-2/1-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": {
      "id": "us-west-2/1-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": {
      "id": "us-west-2/1-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
      "id": "us-west-2/6-month-commitment/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": {
      "id": "us-west-2/6-month-commitment/anthropic.claude-v1",
      "litellm_id": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": {
      "id": "us-west-2/6-month-commitment/anthropic.claude-v2:1",
      "litellm_id": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191
    },
    "aws_bedrock/us-west-2/anthropic.claude-instant-v1": {
      "id": "us-west-2/anthropic.claude-instant-v1",
      "litellm_id": "bedrock/us-west-2/anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0024
    },
    "aws_bedrock/us-west-2/anthropic.claude-v1": {
      "id": "us-west-2/anthropic.claude-v1",
      "litellm_id": "bedrock/us-west-2/anthropic.claude-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/us-west-2/anthropic.claude-v2:1": {
      "id": "us-west-2/anthropic.claude-v2:1",
      "litellm_id": "bedrock/us-west-2/anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "aws_bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
      "id": "us-west-2/mistral.mistral-7b-instruct-v0:2",
      "litellm_id": "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0002
    },
    "aws_bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
      "id": "us-west-2/mistral.mistral-large-2402-v1:0",
      "litellm_id": "bedrock/us-west-2/mistral.mistral-large-2402-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
      "id": "us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
      "litellm_id": "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0007
    },
    "aws_bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "id": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
      "litellm_id": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "cerebras/llama-3.3-70b": {
      "id": "llama-3.3-70b",
      "litellm_id": "cerebras/llama-3.3-70b",
      "provider": "cerebras",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00085,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling"
      ]
    },
    "cerebras/llama3.1-70b": {
      "id": "llama3.1-70b",
      "litellm_id": "cerebras/llama3.1-70b",
      "provider": "cerebras",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "cerebras/llama3.1-8b": {
      "id": "llama3.1-8b",
      "litellm_id": "cerebras/llama3.1-8b",
      "provider": "cerebras",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling"
      ]
    },
    "cerebras/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "litellm_id": "cerebras/gpt-oss-120b",
      "provider": "cerebras",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00069,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "cerebras/qwen-3-32b": {
      "id": "qwen-3-32b",
      "litellm_id": "cerebras/qwen-3-32b",
      "provider": "cerebras",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling"
      ]
    },
    "cerebras/zai-glm-4.6": {
      "id": "zai-glm-4.6",
      "litellm_id": "cerebras/zai-glm-4.6",
      "provider": "cerebras",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00225,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "vertex_ai-chat-models/chat-bison": {
      "id": "chat-bison",
      "litellm_id": "chat-bison",
      "provider": "vertex_ai-chat-models",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-chat-models/chat-bison-32k": {
      "id": "chat-bison-32k",
      "litellm_id": "chat-bison-32k",
      "provider": "vertex_ai-chat-models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-chat-models/chat-bison-32k@002": {
      "id": "chat-bison-32k@002",
      "litellm_id": "chat-bison-32k@002",
      "provider": "vertex_ai-chat-models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-chat-models/chat-bison@001": {
      "id": "chat-bison@001",
      "litellm_id": "chat-bison@001",
      "provider": "vertex_ai-chat-models",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-chat-models/chat-bison@002": {
      "id": "chat-bison@002",
      "litellm_id": "chat-bison@002",
      "provider": "vertex_ai-chat-models",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125,
      "deprecated": true,
      "deprecation_date": "2025-04-09"
    },
    "nlp_cloud/chatdolphin": {
      "id": "chatdolphin",
      "litellm_id": "chatdolphin",
      "provider": "nlp_cloud",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "openai/chatgpt-4o-latest": {
      "id": "chatgpt-4o-latest",
      "litellm_id": "chatgpt-4o-latest",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-transcribe-diarize": {
      "id": "gpt-4o-transcribe-diarize",
      "litellm_id": "gpt-4o-transcribe-diarize",
      "provider": "openai",
      "mode": "audio_transcription",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "anthropic/claude-3-5-haiku-20241022": {
      "id": "claude-3-5-haiku-20241022",
      "litellm_id": "claude-3-5-haiku-20241022",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "web_search"
      ],
      "deprecated": true,
      "deprecation_date": "2025-10-01"
    },
    "anthropic/claude-3-5-haiku-latest": {
      "id": "claude-3-5-haiku-latest",
      "litellm_id": "claude-3-5-haiku-latest",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "web_search"
      ],
      "deprecated": true,
      "deprecation_date": "2025-10-01"
    },
    "anthropic/claude-haiku-4-5-20251001": {
      "id": "claude-haiku-4-5-20251001",
      "litellm_id": "claude-haiku-4-5-20251001",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "litellm_id": "claude-haiku-4-5",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-3-5-sonnet-20240620": {
      "id": "claude-3-5-sonnet-20240620",
      "litellm_id": "claude-3-5-sonnet-20240620",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-06-01"
    },
    "anthropic/claude-3-5-sonnet-20241022": {
      "id": "claude-3-5-sonnet-20241022",
      "litellm_id": "claude-3-5-sonnet-20241022",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "web_search"
      ],
      "deprecated": true,
      "deprecation_date": "2025-10-01"
    },
    "anthropic/claude-3-5-sonnet-latest": {
      "id": "claude-3-5-sonnet-latest",
      "litellm_id": "claude-3-5-sonnet-latest",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "web_search"
      ],
      "deprecated": true,
      "deprecation_date": "2025-06-01"
    },
    "anthropic/claude-3-7-sonnet-20250219": {
      "id": "claude-3-7-sonnet-20250219",
      "litellm_id": "claude-3-7-sonnet-20250219",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-19"
    },
    "anthropic/claude-3-7-sonnet-latest": {
      "id": "claude-3-7-sonnet-latest",
      "litellm_id": "claude-3-7-sonnet-latest",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2025-06-01"
    },
    "anthropic/claude-3-haiku-20240307": {
      "id": "claude-3-haiku-20240307",
      "litellm_id": "claude-3-haiku-20240307",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "anthropic/claude-3-opus-20240229": {
      "id": "claude-3-opus-20240229",
      "litellm_id": "claude-3-opus-20240229",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-05-01"
    },
    "anthropic/claude-3-opus-latest": {
      "id": "claude-3-opus-latest",
      "litellm_id": "claude-3-opus-latest",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-03-01"
    },
    "anthropic/claude-4-opus-20250514": {
      "id": "claude-4-opus-20250514",
      "litellm_id": "claude-4-opus-20250514",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-4-sonnet-20250514": {
      "id": "claude-4-sonnet-20250514",
      "litellm_id": "claude-4-sonnet-20250514",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "litellm_id": "claude-sonnet-4-5",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-sonnet-4-5-20250929": {
      "id": "claude-sonnet-4-5-20250929",
      "litellm_id": "claude-sonnet-4-5-20250929",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "aws_bedrock/claude-sonnet-4-5-20250929-v1:0": {
      "id": "claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "claude-sonnet-4-5-20250929-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "litellm_id": "claude-opus-4-1",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-opus-4-1-20250805": {
      "id": "claude-opus-4-1-20250805",
      "litellm_id": "claude-opus-4-1-20250805",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2026-08-05"
    },
    "anthropic/claude-opus-4-20250514": {
      "id": "claude-opus-4-20250514",
      "litellm_id": "claude-opus-4-20250514",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2026-05-14"
    },
    "anthropic/claude-opus-4-5-20251101": {
      "id": "claude-opus-4-5-20251101",
      "litellm_id": "claude-opus-4-5-20251101",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-opus-4-5": {
      "id": "claude-opus-4-5",
      "litellm_id": "claude-opus-4-5",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "anthropic/claude-sonnet-4-20250514": {
      "id": "claude-sonnet-4-20250514",
      "litellm_id": "claude-sonnet-4-20250514",
      "provider": "anthropic",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2026-05-14"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-fp16": {
      "id": "@cf/meta/llama-2-7b-chat-fp16",
      "litellm_id": "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
      "provider": "cloudflare",
      "mode": "chat",
      "max_input_tokens": 3072,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.001923,
      "output_cost_per_1k": 0.001923
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-int8": {
      "id": "@cf/meta/llama-2-7b-chat-int8",
      "litellm_id": "cloudflare/@cf/meta/llama-2-7b-chat-int8",
      "provider": "cloudflare",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.001923,
      "output_cost_per_1k": 0.001923
    },
    "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": {
      "id": "@cf/mistral/mistral-7b-instruct-v0.1",
      "litellm_id": "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1",
      "provider": "cloudflare",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001923,
      "output_cost_per_1k": 0.001923
    },
    "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": {
      "id": "@hf/thebloke/codellama-7b-instruct-awq",
      "litellm_id": "cloudflare/@hf/thebloke/codellama-7b-instruct-awq",
      "provider": "cloudflare",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001923,
      "output_cost_per_1k": 0.001923
    },
    "vertex_ai-code-text-models/code-bison": {
      "id": "code-bison",
      "litellm_id": "code-bison",
      "provider": "vertex_ai-code-text-models",
      "mode": "chat",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-bison-32k@002": {
      "id": "code-bison-32k@002",
      "litellm_id": "code-bison-32k@002",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-bison32k": {
      "id": "code-bison32k",
      "litellm_id": "code-bison32k",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-bison@001": {
      "id": "code-bison@001",
      "litellm_id": "code-bison@001",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-bison@002": {
      "id": "code-bison@002",
      "litellm_id": "code-bison@002",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-gecko": {
      "id": "code-gecko",
      "litellm_id": "code-gecko",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-gecko-latest": {
      "id": "code-gecko-latest",
      "litellm_id": "code-gecko-latest",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-gecko@001": {
      "id": "code-gecko@001",
      "litellm_id": "code-gecko@001",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-text-models/code-gecko@002": {
      "id": "code-gecko@002",
      "litellm_id": "code-gecko@002",
      "provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-chat-models/codechat-bison": {
      "id": "codechat-bison",
      "litellm_id": "codechat-bison",
      "provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-chat-models/codechat-bison-32k": {
      "id": "codechat-bison-32k",
      "litellm_id": "codechat-bison-32k",
      "provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-chat-models/codechat-bison-32k@002": {
      "id": "codechat-bison-32k@002",
      "litellm_id": "codechat-bison-32k@002",
      "provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-chat-models/codechat-bison@001": {
      "id": "codechat-bison@001",
      "litellm_id": "codechat-bison@001",
      "provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-chat-models/codechat-bison@002": {
      "id": "codechat-bison@002",
      "litellm_id": "codechat-bison@002",
      "provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-code-chat-models/codechat-bison@latest": {
      "id": "codechat-bison@latest",
      "litellm_id": "codechat-bison@latest",
      "provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "codestral/codestral-2405": {
      "id": "codestral-2405",
      "litellm_id": "codestral/codestral-2405",
      "provider": "codestral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191
    },
    "codestral/codestral-latest": {
      "id": "codestral-latest",
      "litellm_id": "codestral/codestral-latest",
      "provider": "codestral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191
    },
    "openai/codex-mini-latest": {
      "id": "codex-mini-latest",
      "litellm_id": "codex-mini-latest",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/cohere.command-light-text-v14": {
      "id": "cohere.command-light-text-v14",
      "litellm_id": "cohere.command-light-text-v14",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006
    },
    "aws_bedrock/cohere.command-r-plus-v1:0": {
      "id": "cohere.command-r-plus-v1:0",
      "litellm_id": "cohere.command-r-plus-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "aws_bedrock/cohere.command-r-v1:0": {
      "id": "cohere.command-r-v1:0",
      "litellm_id": "cohere.command-r-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015
    },
    "aws_bedrock/cohere.command-text-v14": {
      "id": "cohere.command-text-v14",
      "litellm_id": "cohere.command-text-v14",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "aws_bedrock/cohere.embed-english-v3": {
      "id": "cohere.embed-english-v3",
      "litellm_id": "cohere.embed-english-v3",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.0001
    },
    "aws_bedrock/cohere.embed-multilingual-v3": {
      "id": "cohere.embed-multilingual-v3",
      "litellm_id": "cohere.embed-multilingual-v3",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.0001
    },
    "aws_bedrock/cohere.embed-v4:0": {
      "id": "cohere.embed-v4:0",
      "litellm_id": "cohere.embed-v4:0",
      "provider": "aws_bedrock",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.00012
    },
    "cohere/embed-v4.0": {
      "id": "embed-v4.0",
      "litellm_id": "cohere/embed-v4.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.00012
    },
    "aws_bedrock/cohere.rerank-v3-5:0": {
      "id": "cohere.rerank-v3-5:0",
      "litellm_id": "cohere.rerank-v3-5:0",
      "provider": "aws_bedrock",
      "mode": "rerank",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000
    },
    "cohere/command": {
      "id": "command",
      "litellm_id": "command",
      "provider": "cohere",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002
    },
    "cohere/command-a-03-2025": {
      "id": "command-a-03-2025",
      "litellm_id": "command-a-03-2025",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling"
      ]
    },
    "cohere/command-light": {
      "id": "command-light",
      "litellm_id": "command-light",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006
    },
    "cohere/command-nightly": {
      "id": "command-nightly",
      "litellm_id": "command-nightly",
      "provider": "cohere",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002
    },
    "cohere/command-r": {
      "id": "command-r",
      "litellm_id": "command-r",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "cohere/command-r-08-2024": {
      "id": "command-r-08-2024",
      "litellm_id": "command-r-08-2024",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "cohere/command-r-plus": {
      "id": "command-r-plus",
      "litellm_id": "command-r-plus",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling"
      ]
    },
    "cohere/command-r-plus-08-2024": {
      "id": "command-r-plus-08-2024",
      "litellm_id": "command-r-plus-08-2024",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling"
      ]
    },
    "cohere/command-r7b-12-2024": {
      "id": "command-r7b-12-2024",
      "litellm_id": "command-r7b-12-2024",
      "provider": "cohere",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 3.75e-05,
      "capabilities": [
        "function_calling"
      ]
    },
    "deepseek/deepseek-chat": {
      "id": "deepseek-chat",
      "litellm_id": "deepseek/deepseek-chat",
      "provider": "deepseek",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "prompt_caching"
      ]
    },
    "deepseek/deepseek-reasoner": {
      "id": "deepseek-reasoner",
      "litellm_id": "deepseek/deepseek-reasoner",
      "provider": "deepseek",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "dashscope/qwen-coder": {
      "id": "qwen-coder",
      "litellm_id": "dashscope/qwen-coder",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-flash": {
      "id": "qwen-flash",
      "litellm_id": "dashscope/qwen-flash",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-flash-2025-07-28": {
      "id": "qwen-flash-2025-07-28",
      "litellm_id": "dashscope/qwen-flash-2025-07-28",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-max": {
      "id": "qwen-max",
      "litellm_id": "dashscope/qwen-max",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 30720,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.0064,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus": {
      "id": "qwen-plus",
      "litellm_id": "dashscope/qwen-plus",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus-2025-01-25": {
      "id": "qwen-plus-2025-01-25",
      "litellm_id": "dashscope/qwen-plus-2025-01-25",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 129024,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus-2025-04-28": {
      "id": "qwen-plus-2025-04-28",
      "litellm_id": "dashscope/qwen-plus-2025-04-28",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus-2025-07-14": {
      "id": "qwen-plus-2025-07-14",
      "litellm_id": "dashscope/qwen-plus-2025-07-14",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus-2025-07-28": {
      "id": "qwen-plus-2025-07-28",
      "litellm_id": "dashscope/qwen-plus-2025-07-28",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus-2025-09-11": {
      "id": "qwen-plus-2025-09-11",
      "litellm_id": "dashscope/qwen-plus-2025-09-11",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-plus-latest": {
      "id": "qwen-plus-latest",
      "litellm_id": "dashscope/qwen-plus-latest",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-turbo": {
      "id": "qwen-turbo",
      "litellm_id": "dashscope/qwen-turbo",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-turbo-2024-11-01": {
      "id": "qwen-turbo-2024-11-01",
      "litellm_id": "dashscope/qwen-turbo-2024-11-01",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-turbo-2025-04-28": {
      "id": "qwen-turbo-2025-04-28",
      "litellm_id": "dashscope/qwen-turbo-2025-04-28",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen-turbo-latest": {
      "id": "qwen-turbo-latest",
      "litellm_id": "dashscope/qwen-turbo-latest",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen3-30b-a3b": {
      "id": "qwen3-30b-a3b",
      "litellm_id": "dashscope/qwen3-30b-a3b",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen3-coder-flash": {
      "id": "qwen3-coder-flash",
      "litellm_id": "dashscope/qwen3-coder-flash",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 65536,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen3-coder-flash-2025-07-28": {
      "id": "qwen3-coder-flash-2025-07-28",
      "litellm_id": "dashscope/qwen3-coder-flash-2025-07-28",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 65536,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen3-coder-plus": {
      "id": "qwen3-coder-plus",
      "litellm_id": "dashscope/qwen3-coder-plus",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 65536,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen3-coder-plus-2025-07-22": {
      "id": "qwen3-coder-plus-2025-07-22",
      "litellm_id": "dashscope/qwen3-coder-plus-2025-07-22",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 997952,
      "max_output_tokens": 65536,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwen3-max-preview": {
      "id": "qwen3-max-preview",
      "litellm_id": "dashscope/qwen3-max-preview",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 258048,
      "max_output_tokens": 65536,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "dashscope/qwq-plus": {
      "id": "qwq-plus",
      "litellm_id": "dashscope/qwq-plus",
      "provider": "dashscope",
      "mode": "chat",
      "max_input_tokens": 98304,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-bge-large-en": {
      "id": "databricks-bge-large-en",
      "litellm_id": "databricks/databricks-bge-large-en",
      "provider": "databricks",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.00010003
    },
    "databricks/databricks-claude-3-7-sonnet": {
      "id": "databricks-claude-3-7-sonnet",
      "litellm_id": "databricks/databricks-claude-3-7-sonnet",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00299999,
      "output_cost_per_1k": 0.01500002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-haiku-4-5": {
      "id": "databricks-claude-haiku-4-5",
      "litellm_id": "databricks/databricks-claude-haiku-4-5",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00100002,
      "output_cost_per_1k": 0.00500003,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-opus-4": {
      "id": "databricks-claude-opus-4",
      "litellm_id": "databricks/databricks-claude-opus-4",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.01500002,
      "output_cost_per_1k": 0.07500003,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-opus-4-1": {
      "id": "databricks-claude-opus-4-1",
      "litellm_id": "databricks/databricks-claude-opus-4-1",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.01500002,
      "output_cost_per_1k": 0.07500003,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-opus-4-5": {
      "id": "databricks-claude-opus-4-5",
      "litellm_id": "databricks/databricks-claude-opus-4-5",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00500003,
      "output_cost_per_1k": 0.02500001,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-sonnet-4": {
      "id": "databricks-claude-sonnet-4",
      "litellm_id": "databricks/databricks-claude-sonnet-4",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00299999,
      "output_cost_per_1k": 0.01500002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-sonnet-4-1": {
      "id": "databricks-claude-sonnet-4-1",
      "litellm_id": "databricks/databricks-claude-sonnet-4-1",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00299999,
      "output_cost_per_1k": 0.01500002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-claude-sonnet-4-5": {
      "id": "databricks-claude-sonnet-4-5",
      "litellm_id": "databricks/databricks-claude-sonnet-4-5",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00299999,
      "output_cost_per_1k": 0.01500002,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "databricks/databricks-gemini-2-5-flash": {
      "id": "databricks-gemini-2-5-flash",
      "litellm_id": "databricks/databricks-gemini-2-5-flash",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00030002,
      "output_cost_per_1k": 0.00249998,
      "capabilities": [
        "function_calling"
      ]
    },
    "databricks/databricks-gemini-2-5-pro": {
      "id": "databricks-gemini-2-5-pro",
      "litellm_id": "databricks/databricks-gemini-2-5-pro",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00124999,
      "output_cost_per_1k": 0.00999999,
      "capabilities": [
        "function_calling"
      ]
    },
    "databricks/databricks-gemma-3-12b": {
      "id": "databricks-gemma-3-12b",
      "litellm_id": "databricks/databricks-gemma-3-12b",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00015001,
      "output_cost_per_1k": 0.00050001
    },
    "databricks/databricks-gpt-5": {
      "id": "databricks-gpt-5",
      "litellm_id": "databricks/databricks-gpt-5",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00124999,
      "output_cost_per_1k": 0.00999999
    },
    "databricks/databricks-gpt-5-1": {
      "id": "databricks-gpt-5-1",
      "litellm_id": "databricks/databricks-gpt-5-1",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00124999,
      "output_cost_per_1k": 0.00999999
    },
    "databricks/databricks-gpt-5-mini": {
      "id": "databricks-gpt-5-mini",
      "litellm_id": "databricks/databricks-gpt-5-mini",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00024997,
      "output_cost_per_1k": 0.00199997
    },
    "databricks/databricks-gpt-5-nano": {
      "id": "databricks-gpt-5-nano",
      "litellm_id": "databricks/databricks-gpt-5-nano",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 4.998e-05,
      "output_cost_per_1k": 0.00039998
    },
    "databricks/databricks-gpt-oss-120b": {
      "id": "databricks-gpt-oss-120b",
      "litellm_id": "databricks/databricks-gpt-oss-120b",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015001,
      "output_cost_per_1k": 0.00059997
    },
    "databricks/databricks-gpt-oss-20b": {
      "id": "databricks-gpt-oss-20b",
      "litellm_id": "databricks/databricks-gpt-oss-20b",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00030002
    },
    "databricks/databricks-gte-large-en": {
      "id": "databricks-gte-large-en",
      "litellm_id": "databricks/databricks-gte-large-en",
      "provider": "databricks",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00012999
    },
    "databricks/databricks-llama-2-70b-chat": {
      "id": "databricks-llama-2-70b-chat",
      "litellm_id": "databricks/databricks-llama-2-70b-chat",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00050001,
      "output_cost_per_1k": 0.00150003
    },
    "databricks/databricks-llama-4-maverick": {
      "id": "databricks-llama-4-maverick",
      "litellm_id": "databricks/databricks-llama-4-maverick",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00050001,
      "output_cost_per_1k": 0.00150003
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
      "id": "databricks-meta-llama-3-1-405b-instruct",
      "litellm_id": "databricks/databricks-meta-llama-3-1-405b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00500003,
      "output_cost_per_1k": 0.01500002
    },
    "databricks/databricks-meta-llama-3-1-8b-instruct": {
      "id": "databricks-meta-llama-3-1-8b-instruct",
      "litellm_id": "databricks/databricks-meta-llama-3-1-8b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015001,
      "output_cost_per_1k": 0.00045003
    },
    "databricks/databricks-meta-llama-3-3-70b-instruct": {
      "id": "databricks-meta-llama-3-3-70b-instruct",
      "litellm_id": "databricks/databricks-meta-llama-3-3-70b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00050001,
      "output_cost_per_1k": 0.00150003
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
      "id": "databricks-meta-llama-3-70b-instruct",
      "litellm_id": "databricks/databricks-meta-llama-3-70b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00100002,
      "output_cost_per_1k": 0.00299999
    },
    "databricks/databricks-mixtral-8x7b-instruct": {
      "id": "databricks-mixtral-8x7b-instruct",
      "litellm_id": "databricks/databricks-mixtral-8x7b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00050001,
      "output_cost_per_1k": 0.00100002
    },
    "databricks/databricks-mpt-30b-instruct": {
      "id": "databricks-mpt-30b-instruct",
      "litellm_id": "databricks/databricks-mpt-30b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00100002,
      "output_cost_per_1k": 0.00100002
    },
    "databricks/databricks-mpt-7b-instruct": {
      "id": "databricks-mpt-7b-instruct",
      "litellm_id": "databricks/databricks-mpt-7b-instruct",
      "provider": "databricks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00050001
    },
    "dataforseo/search": {
      "id": "search",
      "litellm_id": "dataforseo/search",
      "provider": "dataforseo",
      "mode": "search"
    },
    "text-completion-openai/davinci-002": {
      "id": "davinci-002",
      "litellm_id": "davinci-002",
      "provider": "text-completion-openai",
      "mode": "completion",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002
    },
    "deepgram/base": {
      "id": "base",
      "litellm_id": "deepgram/base",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-conversationalai": {
      "id": "base-conversationalai",
      "litellm_id": "deepgram/base-conversationalai",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-finance": {
      "id": "base-finance",
      "litellm_id": "deepgram/base-finance",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-general": {
      "id": "base-general",
      "litellm_id": "deepgram/base-general",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-meeting": {
      "id": "base-meeting",
      "litellm_id": "deepgram/base-meeting",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-phonecall": {
      "id": "base-phonecall",
      "litellm_id": "deepgram/base-phonecall",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-video": {
      "id": "base-video",
      "litellm_id": "deepgram/base-video",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/base-voicemail": {
      "id": "base-voicemail",
      "litellm_id": "deepgram/base-voicemail",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/enhanced": {
      "id": "enhanced",
      "litellm_id": "deepgram/enhanced",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/enhanced-finance": {
      "id": "enhanced-finance",
      "litellm_id": "deepgram/enhanced-finance",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/enhanced-general": {
      "id": "enhanced-general",
      "litellm_id": "deepgram/enhanced-general",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/enhanced-meeting": {
      "id": "enhanced-meeting",
      "litellm_id": "deepgram/enhanced-meeting",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/enhanced-phonecall": {
      "id": "enhanced-phonecall",
      "litellm_id": "deepgram/enhanced-phonecall",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova": {
      "id": "nova",
      "litellm_id": "deepgram/nova",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2": {
      "id": "nova-2",
      "litellm_id": "deepgram/nova-2",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-atc": {
      "id": "nova-2-atc",
      "litellm_id": "deepgram/nova-2-atc",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-automotive": {
      "id": "nova-2-automotive",
      "litellm_id": "deepgram/nova-2-automotive",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-conversationalai": {
      "id": "nova-2-conversationalai",
      "litellm_id": "deepgram/nova-2-conversationalai",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-drivethru": {
      "id": "nova-2-drivethru",
      "litellm_id": "deepgram/nova-2-drivethru",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-finance": {
      "id": "nova-2-finance",
      "litellm_id": "deepgram/nova-2-finance",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-general": {
      "id": "nova-2-general",
      "litellm_id": "deepgram/nova-2-general",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-meeting": {
      "id": "nova-2-meeting",
      "litellm_id": "deepgram/nova-2-meeting",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-phonecall": {
      "id": "nova-2-phonecall",
      "litellm_id": "deepgram/nova-2-phonecall",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-video": {
      "id": "nova-2-video",
      "litellm_id": "deepgram/nova-2-video",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-2-voicemail": {
      "id": "nova-2-voicemail",
      "litellm_id": "deepgram/nova-2-voicemail",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-3": {
      "id": "nova-3",
      "litellm_id": "deepgram/nova-3",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-3-general": {
      "id": "nova-3-general",
      "litellm_id": "deepgram/nova-3-general",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-3-medical": {
      "id": "nova-3-medical",
      "litellm_id": "deepgram/nova-3-medical",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-general": {
      "id": "nova-general",
      "litellm_id": "deepgram/nova-general",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/nova-phonecall": {
      "id": "nova-phonecall",
      "litellm_id": "deepgram/nova-phonecall",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/whisper": {
      "id": "whisper",
      "litellm_id": "deepgram/whisper",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/whisper-base": {
      "id": "whisper-base",
      "litellm_id": "deepgram/whisper-base",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/whisper-large": {
      "id": "whisper-large",
      "litellm_id": "deepgram/whisper-large",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/whisper-medium": {
      "id": "whisper-medium",
      "litellm_id": "deepgram/whisper-medium",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/whisper-small": {
      "id": "whisper-small",
      "litellm_id": "deepgram/whisper-small",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepgram/whisper-tiny": {
      "id": "whisper-tiny",
      "litellm_id": "deepgram/whisper-tiny",
      "provider": "deepgram",
      "mode": "audio_transcription"
    },
    "deepinfra/Gryphe/MythoMax-L2-13b": {
      "id": "Gryphe/MythoMax-L2-13b",
      "litellm_id": "deepinfra/Gryphe/MythoMax-L2-13b",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 9e-05
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B": {
      "id": "NousResearch/Hermes-3-Llama-3.1-405B",
      "litellm_id": "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B": {
      "id": "NousResearch/Hermes-3-Llama-3.1-70B",
      "litellm_id": "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0003
    },
    "deepinfra/Qwen/QwQ-32B": {
      "id": "Qwen/QwQ-32B",
      "litellm_id": "deepinfra/Qwen/QwQ-32B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0004
    },
    "deepinfra/Qwen/Qwen2.5-72B-Instruct": {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "litellm_id": "deepinfra/Qwen/Qwen2.5-72B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.00039
    },
    "deepinfra/Qwen/Qwen2.5-7B-Instruct": {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "litellm_id": "deepinfra/Qwen/Qwen2.5-7B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.0001
    },
    "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "litellm_id": "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision"
      ]
    },
    "deepinfra/Qwen/Qwen3-14B": {
      "id": "Qwen/Qwen3-14B",
      "litellm_id": "deepinfra/Qwen/Qwen3-14B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024
    },
    "deepinfra/Qwen/Qwen3-235B-A22B": {
      "id": "Qwen/Qwen3-235B-A22B",
      "litellm_id": "deepinfra/Qwen/Qwen3-235B-A22B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00054
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "litellm_id": "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0006
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "litellm_id": "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0029
    },
    "deepinfra/Qwen/Qwen3-30B-A3B": {
      "id": "Qwen/Qwen3-30B-A3B",
      "litellm_id": "deepinfra/Qwen/Qwen3-30B-A3B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00029
    },
    "deepinfra/Qwen/Qwen3-32B": {
      "id": "Qwen/Qwen3-32B",
      "litellm_id": "deepinfra/Qwen/Qwen3-32B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00028
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "litellm_id": "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "litellm_id": "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.0012
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "litellm_id": "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "litellm_id": "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014
    },
    "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo": {
      "id": "Sao10K/L3-8B-Lunaris-v1-Turbo",
      "litellm_id": "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 5e-05
    },
    "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2": {
      "id": "Sao10K/L3.1-70B-Euryale-v2.2",
      "litellm_id": "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00075
    },
    "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3": {
      "id": "Sao10K/L3.3-70B-Euryale-v2.3",
      "litellm_id": "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00075
    },
    "deepinfra/allenai/olmOCR-7B-0725-FP8": {
      "id": "allenai/olmOCR-7B-0725-FP8",
      "litellm_id": "deepinfra/allenai/olmOCR-7B-0725-FP8",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.0015
    },
    "deepinfra/anthropic/claude-3-7-sonnet-latest": {
      "id": "anthropic/claude-3-7-sonnet-latest",
      "litellm_id": "deepinfra/anthropic/claude-3-7-sonnet-latest",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165
    },
    "deepinfra/anthropic/claude-4-opus": {
      "id": "anthropic/claude-4-opus",
      "litellm_id": "deepinfra/anthropic/claude-4-opus",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.0825
    },
    "deepinfra/anthropic/claude-4-sonnet": {
      "id": "anthropic/claude-4-sonnet",
      "litellm_id": "deepinfra/anthropic/claude-4-sonnet",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165
    },
    "deepinfra/deepseek-ai/DeepSeek-R1": {
      "id": "deepseek-ai/DeepSeek-R1",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-R1",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0024
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-R1-0528",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00215
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo": {
      "id": "deepseek-ai/DeepSeek-R1-0528-Turbo",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00027
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Turbo": {
      "id": "deepseek-ai/DeepSeek-R1-Turbo",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-R1-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003
    },
    "deepinfra/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-V3",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00038,
      "output_cost_per_1k": 0.00089
    },
    "deepinfra/deepseek-ai/DeepSeek-V3-0324": {
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-V3-0324",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00088
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-V3.1",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "reasoning"
      ]
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus": {
      "id": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "litellm_id": "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001
    },
    "deepinfra/google/gemini-2.0-flash-001": {
      "id": "google/gemini-2.0-flash-001",
      "litellm_id": "deepinfra/google/gemini-2.0-flash-001",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004
    },
    "deepinfra/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "litellm_id": "deepinfra/google/gemini-2.5-flash",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025
    },
    "deepinfra/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "litellm_id": "deepinfra/google/gemini-2.5-pro",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01
    },
    "deepinfra/google/gemma-3-12b-it": {
      "id": "google/gemma-3-12b-it",
      "litellm_id": "deepinfra/google/gemma-3-12b-it",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001
    },
    "deepinfra/google/gemma-3-27b-it": {
      "id": "google/gemma-3-27b-it",
      "litellm_id": "deepinfra/google/gemma-3-27b-it",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00016
    },
    "deepinfra/google/gemma-3-4b-it": {
      "id": "google/gemma-3-4b-it",
      "litellm_id": "deepinfra/google/gemma-3-4b-it",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 8e-05
    },
    "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct": {
      "id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "litellm_id": "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 4.9e-05,
      "output_cost_per_1k": 4.9e-05
    },
    "deepinfra/meta-llama/Llama-3.2-3B-Instruct": {
      "id": "meta-llama/Llama-3.2-3B-Instruct",
      "litellm_id": "deepinfra/meta-llama/Llama-3.2-3B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 2e-05
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct": {
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "litellm_id": "deepinfra/meta-llama/Llama-3.3-70B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.0004
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "litellm_id": "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00039
    },
    "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "litellm_id": "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 1048576,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "litellm_id": "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 327680,
      "max_output_tokens": 327680,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.0003
    },
    "deepinfra/meta-llama/Llama-Guard-3-8B": {
      "id": "meta-llama/Llama-Guard-3-8B",
      "litellm_id": "deepinfra/meta-llama/Llama-Guard-3-8B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5.5e-05,
      "output_cost_per_1k": 5.5e-05
    },
    "deepinfra/meta-llama/Llama-Guard-4-12B": {
      "id": "meta-llama/Llama-Guard-4-12B",
      "litellm_id": "deepinfra/meta-llama/Llama-Guard-4-12B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018
    },
    "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": {
      "id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "litellm_id": "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 6e-05
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "litellm_id": "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "litellm_id": "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00028
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "litellm_id": "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 5e-05
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "litellm_id": "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 3e-05
    },
    "deepinfra/microsoft/WizardLM-2-8x22B": {
      "id": "microsoft/WizardLM-2-8x22B",
      "litellm_id": "deepinfra/microsoft/WizardLM-2-8x22B",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00048,
      "output_cost_per_1k": 0.00048
    },
    "deepinfra/microsoft/phi-4": {
      "id": "microsoft/phi-4",
      "litellm_id": "deepinfra/microsoft/phi-4",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00014
    },
    "deepinfra/mistralai/Mistral-Nemo-Instruct-2407": {
      "id": "mistralai/Mistral-Nemo-Instruct-2407",
      "litellm_id": "deepinfra/mistralai/Mistral-Nemo-Instruct-2407",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 4e-05
    },
    "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501": {
      "id": "mistralai/Mistral-Small-24B-Instruct-2501",
      "litellm_id": "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05
    },
    "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
      "id": "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "litellm_id": "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0002
    },
    "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "litellm_id": "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "litellm_id": "deepinfra/moonshotai/Kimi-K2-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "litellm_id": "deepinfra/moonshotai/Kimi-K2-Instruct-0905",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002
    },
    "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct": {
      "id": "nvidia/Llama-3.1-Nemotron-70B-Instruct",
      "litellm_id": "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006
    },
    "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5": {
      "id": "nvidia/Llama-3.3-Nemotron-Super-49B-v1.5",
      "litellm_id": "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004
    },
    "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2": {
      "id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "litellm_id": "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00016
    },
    "deepinfra/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "litellm_id": "deepinfra/openai/gpt-oss-120b",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00045
    },
    "deepinfra/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "litellm_id": "deepinfra/openai/gpt-oss-20b",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00015
    },
    "deepinfra/zai-org/GLM-4.5": {
      "id": "zai-org/GLM-4.5",
      "litellm_id": "deepinfra/zai-org/GLM-4.5",
      "provider": "deepinfra",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016
    },
    "deepseek/deepseek-coder": {
      "id": "deepseek-coder",
      "litellm_id": "deepseek/deepseek-coder",
      "provider": "deepseek",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "prompt_caching"
      ]
    },
    "deepseek/deepseek-r1": {
      "id": "deepseek-r1",
      "litellm_id": "deepseek/deepseek-r1",
      "provider": "deepseek",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "deepseek/deepseek-v3": {
      "id": "deepseek-v3",
      "litellm_id": "deepseek/deepseek-v3",
      "provider": "deepseek",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "prompt_caching"
      ]
    },
    "deepseek/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "litellm_id": "deepseek/deepseek-v3.2",
      "provider": "deepseek",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/deepseek.v3-v1:0": {
      "id": "deepseek.v3-v1:0",
      "litellm_id": "deepseek.v3-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 81920,
      "input_cost_per_1k": 0.00058,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "nlp_cloud/dolphin": {
      "id": "dolphin",
      "litellm_id": "dolphin",
      "provider": "nlp_cloud",
      "mode": "completion",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "volcengine/doubao-embedding": {
      "id": "doubao-embedding",
      "litellm_id": "doubao-embedding",
      "provider": "volcengine",
      "mode": "embedding",
      "max_input_tokens": 4096
    },
    "volcengine/doubao-embedding-large": {
      "id": "doubao-embedding-large",
      "litellm_id": "doubao-embedding-large",
      "provider": "volcengine",
      "mode": "embedding",
      "max_input_tokens": 4096
    },
    "volcengine/doubao-embedding-large-text-240915": {
      "id": "doubao-embedding-large-text-240915",
      "litellm_id": "doubao-embedding-large-text-240915",
      "provider": "volcengine",
      "mode": "embedding",
      "max_input_tokens": 4096
    },
    "volcengine/doubao-embedding-large-text-250515": {
      "id": "doubao-embedding-large-text-250515",
      "litellm_id": "doubao-embedding-large-text-250515",
      "provider": "volcengine",
      "mode": "embedding",
      "max_input_tokens": 4096
    },
    "volcengine/doubao-embedding-text-240715": {
      "id": "doubao-embedding-text-240715",
      "litellm_id": "doubao-embedding-text-240715",
      "provider": "volcengine",
      "mode": "embedding",
      "max_input_tokens": 4096
    },
    "exa_ai/search": {
      "id": "search",
      "litellm_id": "exa_ai/search",
      "provider": "exa_ai",
      "mode": "search"
    },
    "firecrawl/search": {
      "id": "search",
      "litellm_id": "firecrawl/search",
      "provider": "firecrawl",
      "mode": "search"
    },
    "perplexity/search": {
      "id": "search",
      "litellm_id": "perplexity/search",
      "provider": "perplexity",
      "mode": "search"
    },
    "searxng/search": {
      "id": "search",
      "litellm_id": "searxng/search",
      "provider": "searxng",
      "mode": "search"
    },
    "elevenlabs/scribe_v1": {
      "id": "scribe_v1",
      "litellm_id": "elevenlabs/scribe_v1",
      "provider": "elevenlabs",
      "mode": "audio_transcription"
    },
    "elevenlabs/scribe_v1_experimental": {
      "id": "scribe_v1_experimental",
      "litellm_id": "elevenlabs/scribe_v1_experimental",
      "provider": "elevenlabs",
      "mode": "audio_transcription"
    },
    "cohere/embed-english-light-v2.0": {
      "id": "embed-english-light-v2.0",
      "litellm_id": "embed-english-light-v2.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.0001
    },
    "cohere/embed-english-light-v3.0": {
      "id": "embed-english-light-v3.0",
      "litellm_id": "embed-english-light-v3.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.0001
    },
    "cohere/embed-english-v2.0": {
      "id": "embed-english-v2.0",
      "litellm_id": "embed-english-v2.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.0001
    },
    "cohere/embed-english-v3.0": {
      "id": "embed-english-v3.0",
      "litellm_id": "embed-english-v3.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.0001
    },
    "cohere/embed-multilingual-v2.0": {
      "id": "embed-multilingual-v2.0",
      "litellm_id": "embed-multilingual-v2.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 768,
      "input_cost_per_1k": 0.0001
    },
    "cohere/embed-multilingual-v3.0": {
      "id": "embed-multilingual-v3.0",
      "litellm_id": "embed-multilingual-v3.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.0001
    },
    "cohere/embed-multilingual-light-v3.0": {
      "id": "embed-multilingual-light-v3.0",
      "litellm_id": "embed-multilingual-light-v3.0",
      "provider": "cohere",
      "mode": "embedding",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.1
    },
    "bedrock_converse/eu.amazon.nova-lite-v1:0": {
      "id": "eu.amazon.nova-lite-v1:0",
      "litellm_id": "eu.amazon.nova-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 7.8e-05,
      "output_cost_per_1k": 0.000312,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/eu.amazon.nova-micro-v1:0": {
      "id": "eu.amazon.nova-micro-v1:0",
      "litellm_id": "eu.amazon.nova-micro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 4.6e-05,
      "output_cost_per_1k": 0.000184,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/eu.amazon.nova-pro-v1:0": {
      "id": "eu.amazon.nova-pro-v1:0",
      "litellm_id": "eu.amazon.nova-pro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.00105,
      "output_cost_per_1k": 0.0042,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "id": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
      "litellm_id": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "eu.anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "eu.anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0055,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2026-10-15"
    },
    "aws_bedrock/eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "id": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "litellm_id": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "aws_bedrock/eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "id": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "litellm_id": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/eu.anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "eu.anthropic.claude-3-haiku-20240307-v1:0",
      "litellm_id": "eu.anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/eu.anthropic.claude-3-opus-20240229-v1:0": {
      "id": "eu.anthropic.claude-3-opus-20240229-v1:0",
      "litellm_id": "eu.anthropic.claude-3-opus-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/eu.anthropic.claude-3-sonnet-20240229-v1:0": {
      "id": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
      "litellm_id": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "bedrock_converse/eu.anthropic.claude-opus-4-1-20250805-v1:0": {
      "id": "eu.anthropic.claude-opus-4-1-20250805-v1:0",
      "litellm_id": "eu.anthropic.claude-opus-4-1-20250805-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/eu.anthropic.claude-opus-4-20250514-v1:0": {
      "id": "eu.anthropic.claude-opus-4-20250514-v1:0",
      "litellm_id": "eu.anthropic.claude-opus-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/eu.anthropic.claude-sonnet-4-20250514-v1:0": {
      "id": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
      "litellm_id": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "eu.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "eu.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/eu.meta.llama3-2-1b-instruct-v1:0": {
      "id": "eu.meta.llama3-2-1b-instruct-v1:0",
      "litellm_id": "eu.meta.llama3-2-1b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/eu.meta.llama3-2-3b-instruct-v1:0": {
      "id": "eu.meta.llama3-2-3b-instruct-v1:0",
      "litellm_id": "eu.meta.llama3-2-3b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00019,
      "output_cost_per_1k": 0.00019,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/eu.mistral.pixtral-large-2502-v1:0": {
      "id": "eu.mistral.pixtral-large-2502-v1:0",
      "litellm_id": "eu.mistral.pixtral-large-2502-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "fal_ai/bria/text-to-image/3.2": {
      "id": "bria/text-to-image/3.2",
      "litellm_id": "fal_ai/bria/text-to-image/3.2",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/flux-pro/v1.1": {
      "id": "fal-ai/flux-pro/v1.1",
      "litellm_id": "fal_ai/fal-ai/flux-pro/v1.1",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/flux-pro/v1.1-ultra": {
      "id": "fal-ai/flux-pro/v1.1-ultra",
      "litellm_id": "fal_ai/fal-ai/flux-pro/v1.1-ultra",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/flux/schnell": {
      "id": "fal-ai/flux/schnell",
      "litellm_id": "fal_ai/fal-ai/flux/schnell",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/bytedance/seedream/v3/text-to-image": {
      "id": "fal-ai/bytedance/seedream/v3/text-to-image",
      "litellm_id": "fal_ai/fal-ai/bytedance/seedream/v3/text-to-image",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/bytedance/dreamina/v3.1/text-to-image": {
      "id": "fal-ai/bytedance/dreamina/v3.1/text-to-image",
      "litellm_id": "fal_ai/fal-ai/bytedance/dreamina/v3.1/text-to-image",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/ideogram/v3": {
      "id": "fal-ai/ideogram/v3",
      "litellm_id": "fal_ai/fal-ai/ideogram/v3",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/imagen4/preview": {
      "id": "fal-ai/imagen4/preview",
      "litellm_id": "fal_ai/fal-ai/imagen4/preview",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/imagen4/preview/fast": {
      "id": "fal-ai/imagen4/preview/fast",
      "litellm_id": "fal_ai/fal-ai/imagen4/preview/fast",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/imagen4/preview/ultra": {
      "id": "fal-ai/imagen4/preview/ultra",
      "litellm_id": "fal_ai/fal-ai/imagen4/preview/ultra",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/recraft/v3/text-to-image": {
      "id": "fal-ai/recraft/v3/text-to-image",
      "litellm_id": "fal_ai/fal-ai/recraft/v3/text-to-image",
      "provider": "fal_ai",
      "mode": "image"
    },
    "fal_ai/fal-ai/stable-diffusion-v35-medium": {
      "id": "fal-ai/stable-diffusion-v35-medium",
      "litellm_id": "fal_ai/fal-ai/stable-diffusion-v35-medium",
      "provider": "fal_ai",
      "mode": "image"
    },
    "featherless_ai/featherless-ai/Qwerky-72B": {
      "id": "featherless-ai/Qwerky-72B",
      "litellm_id": "featherless_ai/featherless-ai/Qwerky-72B",
      "provider": "featherless_ai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096
    },
    "featherless_ai/featherless-ai/Qwerky-QwQ-32B": {
      "id": "featherless-ai/Qwerky-QwQ-32B",
      "litellm_id": "featherless_ai/featherless-ai/Qwerky-QwQ-32B",
      "provider": "featherless_ai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096
    },
    "fireworks/fireworks-ai-4.1b-to-16b": {
      "id": "fireworks-ai-4.1b-to-16b",
      "litellm_id": "fireworks-ai-4.1b-to-16b",
      "provider": "fireworks",
      "mode": "chat",
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/fireworks-ai-56b-to-176b": {
      "id": "fireworks-ai-56b-to-176b",
      "litellm_id": "fireworks-ai-56b-to-176b",
      "provider": "fireworks",
      "mode": "chat",
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/fireworks-ai-above-16b": {
      "id": "fireworks-ai-above-16b",
      "litellm_id": "fireworks-ai-above-16b",
      "provider": "fireworks",
      "mode": "chat",
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/fireworks-ai-default": {
      "id": "fireworks-ai-default",
      "litellm_id": "fireworks-ai-default",
      "provider": "fireworks",
      "mode": "chat"
    },
    "fireworks_ai-embedding-models/fireworks-ai-embedding-150m-to-350m": {
      "id": "fireworks-ai-embedding-150m-to-350m",
      "litellm_id": "fireworks-ai-embedding-150m-to-350m",
      "provider": "fireworks_ai-embedding-models",
      "mode": "chat",
      "input_cost_per_1k": 1.6e-05
    },
    "fireworks_ai-embedding-models/fireworks-ai-embedding-up-to-150m": {
      "id": "fireworks-ai-embedding-up-to-150m",
      "litellm_id": "fireworks-ai-embedding-up-to-150m",
      "provider": "fireworks_ai-embedding-models",
      "mode": "chat",
      "input_cost_per_1k": 8e-06
    },
    "fireworks/fireworks-ai-moe-up-to-56b": {
      "id": "fireworks-ai-moe-up-to-56b",
      "litellm_id": "fireworks-ai-moe-up-to-56b",
      "provider": "fireworks",
      "mode": "chat",
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/fireworks-ai-up-to-4b": {
      "id": "fireworks-ai-up-to-4b",
      "litellm_id": "fireworks-ai-up-to-4b",
      "provider": "fireworks",
      "mode": "chat",
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks_ai-embedding-models/fireworks_ai/WhereIsAI/UAE-Large-V1": {
      "id": "fireworks_ai/WhereIsAI/UAE-Large-V1",
      "litellm_id": "fireworks_ai/WhereIsAI/UAE-Large-V1",
      "provider": "fireworks_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 1.6e-05
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-v2-instruct": {
      "id": "accounts/fireworks/models/deepseek-coder-v2-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-r1": {
      "id": "accounts/fireworks/models/deepseek-r1",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-0528": {
      "id": "accounts/fireworks/models/deepseek-r1-0528",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 160000,
      "max_output_tokens": 160000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-basic": {
      "id": "accounts/fireworks/models/deepseek-r1-basic",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-v3": {
      "id": "accounts/fireworks/models/deepseek-v3",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-v3-0324": {
      "id": "accounts/fireworks/models/deepseek-v3-0324",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p1": {
      "id": "accounts/fireworks/models/deepseek-v3p1",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p1",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p1-terminus": {
      "id": "accounts/fireworks/models/deepseek-v3p1-terminus",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p2": {
      "id": "accounts/fireworks/models/deepseek-v3p2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/firefunction-v2": {
      "id": "accounts/fireworks/models/firefunction-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/glm-4p5": {
      "id": "accounts/fireworks/models/glm-4p5",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/glm-4p5",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/glm-4p5-air": {
      "id": "accounts/fireworks/models/glm-4p5-air",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/glm-4p5-air",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/glm-4p6": {
      "id": "accounts/fireworks/models/glm-4p6",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/glm-4p6",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 202800,
      "max_output_tokens": 202800,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/gpt-oss-120b": {
      "id": "accounts/fireworks/models/gpt-oss-120b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gpt-oss-120b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/gpt-oss-20b": {
      "id": "accounts/fireworks/models/gpt-oss-20b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gpt-oss-20b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/kimi-k2-instruct": {
      "id": "accounts/fireworks/models/kimi-k2-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/kimi-k2-instruct-0905": {
      "id": "accounts/fireworks/models/kimi-k2-instruct-0905",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/kimi-k2-thinking": {
      "id": "accounts/fireworks/models/kimi-k2-thinking",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "json_mode",
        "web_search"
      ]
    },
    "fireworks/accounts/fireworks/models/llama-v3p1-405b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p1-405b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama-v3p1-8b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p1-8b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
      "id": "accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "vision",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama-v3p2-1b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p2-1b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama-v3p2-3b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p2-3b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
      "id": "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "vision",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama4-maverick-instruct-basic": {
      "id": "accounts/fireworks/models/llama4-maverick-instruct-basic",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/llama4-scout-instruct-basic": {
      "id": "accounts/fireworks/models/llama4-scout-instruct-basic",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
      "id": "accounts/fireworks/models/mixtral-8x22b-instruct-hf",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/qwen2-72b-instruct": {
      "id": "accounts/fireworks/models/qwen2-72b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks/accounts/fireworks/models/yi-large": {
      "id": "accounts/fireworks/models/yi-large",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/yi-large",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "json_mode"
      ]
    },
    "fireworks_ai-embedding-models/fireworks_ai/nomic-ai/nomic-embed-text-v1": {
      "id": "fireworks_ai/nomic-ai/nomic-embed-text-v1",
      "litellm_id": "fireworks_ai/nomic-ai/nomic-embed-text-v1",
      "provider": "fireworks_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 8e-06
    },
    "fireworks_ai-embedding-models/fireworks_ai/nomic-ai/nomic-embed-text-v1.5": {
      "id": "fireworks_ai/nomic-ai/nomic-embed-text-v1.5",
      "litellm_id": "fireworks_ai/nomic-ai/nomic-embed-text-v1.5",
      "provider": "fireworks_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 8e-06
    },
    "fireworks_ai-embedding-models/fireworks_ai/thenlper/gte-base": {
      "id": "fireworks_ai/thenlper/gte-base",
      "litellm_id": "fireworks_ai/thenlper/gte-base",
      "provider": "fireworks_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 8e-06
    },
    "fireworks_ai-embedding-models/fireworks_ai/thenlper/gte-large": {
      "id": "fireworks_ai/thenlper/gte-large",
      "litellm_id": "fireworks_ai/thenlper/gte-large",
      "provider": "fireworks_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 1.6e-05
    },
    "friendliai/meta-llama-3.1-70b-instruct": {
      "id": "meta-llama-3.1-70b-instruct",
      "litellm_id": "friendliai/meta-llama-3.1-70b-instruct",
      "provider": "friendliai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "friendliai/meta-llama-3.1-8b-instruct": {
      "id": "meta-llama-3.1-8b-instruct",
      "litellm_id": "friendliai/meta-llama-3.1-8b-instruct",
      "provider": "friendliai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "text-completion-openai/ft:babbage-002": {
      "id": "ft:babbage-002",
      "litellm_id": "ft:babbage-002",
      "provider": "text-completion-openai",
      "mode": "completion",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.0016
    },
    "text-completion-openai/ft:davinci-002": {
      "id": "ft:davinci-002",
      "litellm_id": "ft:davinci-002",
      "provider": "text-completion-openai",
      "mode": "completion",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.012,
      "output_cost_per_1k": 0.012
    },
    "openai/ft:gpt-3.5-turbo": {
      "id": "ft:gpt-3.5-turbo",
      "litellm_id": "ft:gpt-3.5-turbo",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "system_messages"
      ]
    },
    "openai/ft:gpt-3.5-turbo-0125": {
      "id": "ft:gpt-3.5-turbo-0125",
      "litellm_id": "ft:gpt-3.5-turbo-0125",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "system_messages"
      ]
    },
    "openai/ft:gpt-3.5-turbo-0613": {
      "id": "ft:gpt-3.5-turbo-0613",
      "litellm_id": "ft:gpt-3.5-turbo-0613",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "system_messages"
      ]
    },
    "openai/ft:gpt-3.5-turbo-1106": {
      "id": "ft:gpt-3.5-turbo-1106",
      "litellm_id": "ft:gpt-3.5-turbo-1106",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "system_messages"
      ]
    },
    "openai/ft:gpt-4-0613": {
      "id": "ft:gpt-4-0613",
      "litellm_id": "ft:gpt-4-0613",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "openai/ft:gpt-4o-2024-08-06": {
      "id": "ft:gpt-4o-2024-08-06",
      "litellm_id": "ft:gpt-4o-2024-08-06",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00375,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/ft:gpt-4o-2024-11-20": {
      "id": "ft:gpt-4o-2024-11-20",
      "litellm_id": "ft:gpt-4o-2024-11-20",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00375,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/ft:gpt-4o-mini-2024-07-18": {
      "id": "ft:gpt-4o-mini-2024-07-18",
      "litellm_id": "ft:gpt-4o-mini-2024-07-18",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/ft:gpt-4.1-2025-04-14": {
      "id": "ft:gpt-4.1-2025-04-14",
      "litellm_id": "ft:gpt-4.1-2025-04-14",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/ft:gpt-4.1-mini-2025-04-14": {
      "id": "ft:gpt-4.1-mini-2025-04-14",
      "litellm_id": "ft:gpt-4.1-mini-2025-04-14",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/ft:gpt-4.1-nano-2025-04-14": {
      "id": "ft:gpt-4.1-nano-2025-04-14",
      "litellm_id": "ft:gpt-4.1-nano-2025-04-14",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/ft:o4-mini-2025-04-16": {
      "id": "ft:o4-mini-2025-04-16",
      "litellm_id": "ft:o4-mini-2025-04-16",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.004,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "google/gemini-1.0-pro": {
      "id": "gemini-1.0-pro",
      "litellm_id": "gemini-1.0-pro",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "google/gemini-1.0-pro-001": {
      "id": "gemini-1.0-pro-001",
      "litellm_id": "gemini-1.0-pro-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-09"
    },
    "google/gemini-1.0-pro-002": {
      "id": "gemini-1.0-pro-002",
      "litellm_id": "gemini-1.0-pro-002",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-09"
    },
    "vertex_ai-vision-models/gemini-1.0-pro-vision": {
      "id": "gemini-1.0-pro-vision",
      "litellm_id": "gemini-1.0-pro-vision",
      "provider": "vertex_ai-vision-models",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "vertex_ai-vision-models/gemini-1.0-pro-vision-001": {
      "id": "gemini-1.0-pro-vision-001",
      "litellm_id": "gemini-1.0-pro-vision-001",
      "provider": "vertex_ai-vision-models",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-09"
    },
    "google/gemini-1.0-ultra": {
      "id": "gemini-1.0-ultra",
      "litellm_id": "gemini-1.0-ultra",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "google/gemini-1.0-ultra-001": {
      "id": "gemini-1.0-ultra-001",
      "litellm_id": "gemini-1.0-ultra-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "google/gemini-1.5-flash": {
      "id": "gemini-1.5-flash",
      "litellm_id": "gemini/gemini-1.5-flash",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-flash-001": {
      "id": "gemini-1.5-flash-001",
      "litellm_id": "gemini/gemini-1.5-flash-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-05-24"
    },
    "google/gemini-1.5-flash-002": {
      "id": "gemini-1.5-flash-002",
      "litellm_id": "gemini/gemini-1.5-flash-002",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-09-24"
    },
    "google/gemini-1.5-flash-exp-0827": {
      "id": "gemini-1.5-flash-exp-0827",
      "litellm_id": "gemini/gemini-1.5-flash-exp-0827",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-flash-preview-0514": {
      "id": "gemini-1.5-flash-preview-0514",
      "litellm_id": "gemini-1.5-flash-preview-0514",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 4.69e-06,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "google/gemini-1.5-pro": {
      "id": "gemini-1.5-pro",
      "litellm_id": "gemini/gemini-1.5-pro",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0105,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-pro-001": {
      "id": "gemini-1.5-pro-001",
      "litellm_id": "gemini/gemini-1.5-pro-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0105,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-05-24"
    },
    "google/gemini-1.5-pro-002": {
      "id": "gemini-1.5-pro-002",
      "litellm_id": "gemini/gemini-1.5-pro-002",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0105,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-09-24"
    },
    "google/gemini-1.5-pro-preview-0215": {
      "id": "gemini-1.5-pro-preview-0215",
      "litellm_id": "gemini-1.5-pro-preview-0215",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.813e-05,
      "output_cost_per_1k": 0.0003125,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-pro-preview-0409": {
      "id": "gemini-1.5-pro-preview-0409",
      "litellm_id": "gemini-1.5-pro-preview-0409",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.813e-05,
      "output_cost_per_1k": 0.0003125,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "google/gemini-1.5-pro-preview-0514": {
      "id": "gemini-1.5-pro-preview-0514",
      "litellm_id": "gemini-1.5-pro-preview-0514",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.813e-05,
      "output_cost_per_1k": 0.0003125,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-2.0-flash": {
      "id": "gemini-2.0-flash",
      "litellm_id": "gemini/gemini-2.0-flash",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_input",
        "audio_output"
      ]
    },
    "google/gemini-2.0-flash-001": {
      "id": "gemini-2.0-flash-001",
      "litellm_id": "gemini/gemini-2.0-flash-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-2.0-flash-exp": {
      "id": "gemini-2.0-flash-exp",
      "litellm_id": "gemini/gemini-2.0-flash-exp",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_output"
      ]
    },
    "google/gemini-2.0-flash-lite": {
      "id": "gemini-2.0-flash-lite",
      "litellm_id": "gemini/gemini-2.0-flash-lite",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_output"
      ]
    },
    "google/gemini-2.0-flash-lite-001": {
      "id": "gemini-2.0-flash-lite-001",
      "litellm_id": "gemini-2.0-flash-lite-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_output"
      ],
      "deprecated": true,
      "deprecation_date": "2026-02-25"
    },
    "google/gemini-2.0-flash-live-preview-04-09": {
      "id": "gemini-2.0-flash-live-preview-04-09",
      "litellm_id": "gemini-2.0-flash-live-preview-04-09",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search",
        "audio_output"
      ]
    },
    "google/gemini-2.0-flash-preview-image-generation": {
      "id": "gemini-2.0-flash-preview-image-generation",
      "litellm_id": "gemini/gemini-2.0-flash-preview-image-generation",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_input",
        "audio_output"
      ]
    },
    "google/gemini-2.0-flash-thinking-exp": {
      "id": "gemini-2.0-flash-thinking-exp",
      "litellm_id": "gemini/gemini-2.0-flash-thinking-exp",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_output"
      ]
    },
    "google/gemini-2.0-flash-thinking-exp-01-21": {
      "id": "gemini-2.0-flash-thinking-exp-01-21",
      "litellm_id": "gemini/gemini-2.0-flash-thinking-exp-01-21",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search",
        "audio_output"
      ]
    },
    "google/gemini-2.0-pro-exp-02-05": {
      "id": "gemini-2.0-pro-exp-02-05",
      "litellm_id": "gemini/gemini-2.0-pro-exp-02-05",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_input"
      ]
    },
    "google/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "litellm_id": "gemini/gemini-2.5-flash",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-image": {
      "id": "gemini-2.5-flash-image",
      "litellm_id": "gemini-2.5-flash-image",
      "provider": "google",
      "mode": "image",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "google/gemini-2.5-flash-image-preview": {
      "id": "gemini-2.5-flash-image-preview",
      "litellm_id": "gemini/gemini-2.5-flash-image-preview",
      "provider": "google",
      "mode": "image",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-3-pro-image-preview": {
      "id": "gemini-3-pro-image-preview",
      "litellm_id": "gemini/gemini-3-pro-image-preview",
      "provider": "google",
      "mode": "image",
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "vision",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-lite": {
      "id": "gemini-2.5-flash-lite",
      "litellm_id": "gemini/gemini-2.5-flash-lite",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-lite-preview-09-2025": {
      "id": "gemini-2.5-flash-lite-preview-09-2025",
      "litellm_id": "gemini/gemini-2.5-flash-lite-preview-09-2025",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-preview-09-2025": {
      "id": "gemini-2.5-flash-preview-09-2025",
      "litellm_id": "gemini/gemini-2.5-flash-preview-09-2025",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-live-2.5-flash-preview-native-audio-09-2025": {
      "id": "gemini-live-2.5-flash-preview-native-audio-09-2025",
      "litellm_id": "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_input",
        "audio_output"
      ]
    },
    "google/gemini-2.5-flash-lite-preview-06-17": {
      "id": "gemini-2.5-flash-lite-preview-06-17",
      "litellm_id": "gemini/gemini-2.5-flash-lite-preview-06-17",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-preview-04-17": {
      "id": "gemini-2.5-flash-preview-04-17",
      "litellm_id": "gemini/gemini-2.5-flash-preview-04-17",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-preview-05-20": {
      "id": "gemini-2.5-flash-preview-05-20",
      "litellm_id": "gemini/gemini-2.5-flash-preview-05-20",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "litellm_id": "gemini/gemini-2.5-pro",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search",
        "audio_input"
      ]
    },
    "google/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "litellm_id": "gemini/gemini-3-pro-preview",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search",
        "audio_input"
      ]
    },
    "google/gemini-3-flash-preview": {
      "id": "gemini-3-flash-preview",
      "litellm_id": "gemini-3-flash-preview",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-pro-exp-03-25": {
      "id": "gemini-2.5-pro-exp-03-25",
      "litellm_id": "gemini/gemini-2.5-pro-exp-03-25",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search",
        "audio_input"
      ]
    },
    "google/gemini-2.5-pro-preview-03-25": {
      "id": "gemini-2.5-pro-preview-03-25",
      "litellm_id": "gemini/gemini-2.5-pro-preview-03-25",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-2.5-pro-preview-05-06": {
      "id": "gemini-2.5-pro-preview-05-06",
      "litellm_id": "gemini/gemini-2.5-pro-preview-05-06",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-2.5-pro-preview-06-05": {
      "id": "gemini-2.5-pro-preview-06-05",
      "litellm_id": "gemini/gemini-2.5-pro-preview-06-05",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-2.5-pro-preview-tts": {
      "id": "gemini-2.5-pro-preview-tts",
      "litellm_id": "gemini/gemini-2.5-pro-preview-tts",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "vertex_ai-embedding-models/gemini-embedding-001": {
      "id": "gemini-embedding-001",
      "litellm_id": "gemini-embedding-001",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.00015
    },
    "google/gemini-flash-experimental": {
      "id": "gemini-flash-experimental",
      "litellm_id": "gemini-flash-experimental",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "capabilities": [
        "parallel_function_calling"
      ]
    },
    "google/gemini-pro": {
      "id": "gemini-pro",
      "litellm_id": "gemini/gemini-pro",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00105,
      "capabilities": [
        "function_calling"
      ]
    },
    "google/gemini-pro-experimental": {
      "id": "gemini-pro-experimental",
      "litellm_id": "gemini-pro-experimental",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "capabilities": [
        "parallel_function_calling"
      ]
    },
    "vertex_ai-vision-models/gemini-pro-vision": {
      "id": "gemini-pro-vision",
      "litellm_id": "gemini-pro-vision",
      "provider": "vertex_ai-vision-models",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "google/gemini-embedding-001": {
      "id": "gemini-embedding-001",
      "litellm_id": "gemini/gemini-embedding-001",
      "provider": "google",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.00015
    },
    "google/gemini-1.5-flash-8b": {
      "id": "gemini-1.5-flash-8b",
      "litellm_id": "gemini/gemini-1.5-flash-8b",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "google/gemini-1.5-flash-8b-exp-0827": {
      "id": "gemini-1.5-flash-8b-exp-0827",
      "litellm_id": "gemini/gemini-1.5-flash-8b-exp-0827",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-flash-8b-exp-0924": {
      "id": "gemini-1.5-flash-8b-exp-0924",
      "litellm_id": "gemini/gemini-1.5-flash-8b-exp-0924",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "google/gemini-1.5-flash-latest": {
      "id": "gemini-1.5-flash-latest",
      "litellm_id": "gemini/gemini-1.5-flash-latest",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "google/gemini-1.5-pro-exp-0801": {
      "id": "gemini-1.5-pro-exp-0801",
      "litellm_id": "gemini/gemini-1.5-pro-exp-0801",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0105,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-pro-exp-0827": {
      "id": "gemini-1.5-pro-exp-0827",
      "litellm_id": "gemini/gemini-1.5-pro-exp-0827",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-1.5-pro-latest": {
      "id": "gemini-1.5-pro-latest",
      "litellm_id": "gemini/gemini-1.5-pro-latest",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.00105,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-2.0-flash-lite-preview-02-05": {
      "id": "gemini-2.0-flash-lite-preview-02-05",
      "litellm_id": "gemini/gemini-2.0-flash-lite-preview-02-05",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-2.0-flash-live-001": {
      "id": "gemini-2.0-flash-live-001",
      "litellm_id": "gemini/gemini-2.0-flash-live-001",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search",
        "audio_output"
      ]
    },
    "google/gemini/gemini-2.5-flash-image": {
      "id": "gemini/gemini-2.5-flash-image",
      "litellm_id": "gemini/gemini-2.5-flash-image",
      "provider": "google",
      "mode": "image",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "google/gemini-flash-latest": {
      "id": "gemini-flash-latest",
      "litellm_id": "gemini/gemini-flash-latest",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-flash-lite-latest": {
      "id": "gemini-flash-lite-latest",
      "litellm_id": "gemini/gemini-flash-lite-latest",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-flash-preview-tts": {
      "id": "gemini-2.5-flash-preview-tts",
      "litellm_id": "gemini/gemini-2.5-flash-preview-tts",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "google/gemini-2.5-computer-use-preview-10-2025": {
      "id": "gemini-2.5-computer-use-preview-10-2025",
      "litellm_id": "gemini/gemini-2.5-computer-use-preview-10-2025",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages"
      ]
    },
    "google/gemini-exp-1114": {
      "id": "gemini-exp-1114",
      "litellm_id": "gemini/gemini-exp-1114",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-exp-1206": {
      "id": "gemini-exp-1206",
      "litellm_id": "gemini/gemini-exp-1206",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/gemini-gemma-2-27b-it": {
      "id": "gemini-gemma-2-27b-it",
      "litellm_id": "gemini/gemini-gemma-2-27b-it",
      "provider": "google",
      "mode": "chat",
      "max_output_tokens": 8192,
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00105,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "google/gemini-gemma-2-9b-it": {
      "id": "gemini-gemma-2-9b-it",
      "litellm_id": "gemini/gemini-gemma-2-9b-it",
      "provider": "google",
      "mode": "chat",
      "max_output_tokens": 8192,
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00105,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "google/gemini-pro-vision": {
      "id": "gemini-pro-vision",
      "litellm_id": "gemini/gemini-pro-vision",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 30720,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00105,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "google/gemma-3-27b-it": {
      "id": "gemma-3-27b-it",
      "litellm_id": "gemini/gemma-3-27b-it",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "google/imagen-3.0-fast-generate-001": {
      "id": "imagen-3.0-fast-generate-001",
      "litellm_id": "gemini/imagen-3.0-fast-generate-001",
      "provider": "google",
      "mode": "image"
    },
    "google/imagen-3.0-generate-001": {
      "id": "imagen-3.0-generate-001",
      "litellm_id": "gemini/imagen-3.0-generate-001",
      "provider": "google",
      "mode": "image"
    },
    "google/imagen-3.0-generate-002": {
      "id": "imagen-3.0-generate-002",
      "litellm_id": "gemini/imagen-3.0-generate-002",
      "provider": "google",
      "mode": "image"
    },
    "google/imagen-4.0-fast-generate-001": {
      "id": "imagen-4.0-fast-generate-001",
      "litellm_id": "gemini/imagen-4.0-fast-generate-001",
      "provider": "google",
      "mode": "image"
    },
    "google/imagen-4.0-generate-001": {
      "id": "imagen-4.0-generate-001",
      "litellm_id": "gemini/imagen-4.0-generate-001",
      "provider": "google",
      "mode": "image"
    },
    "google/imagen-4.0-ultra-generate-001": {
      "id": "imagen-4.0-ultra-generate-001",
      "litellm_id": "gemini/imagen-4.0-ultra-generate-001",
      "provider": "google",
      "mode": "image"
    },
    "google/learnlm-1.5-pro-experimental": {
      "id": "learnlm-1.5-pro-experimental",
      "litellm_id": "gemini/learnlm-1.5-pro-experimental",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 32767,
      "max_output_tokens": 8192,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode"
      ]
    },
    "google/veo-2.0-generate-001": {
      "id": "veo-2.0-generate-001",
      "litellm_id": "gemini/veo-2.0-generate-001",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "google/veo-3.0-fast-generate-preview": {
      "id": "veo-3.0-fast-generate-preview",
      "litellm_id": "gemini/veo-3.0-fast-generate-preview",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "google/veo-3.0-generate-preview": {
      "id": "veo-3.0-generate-preview",
      "litellm_id": "gemini/veo-3.0-generate-preview",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "google/veo-3.1-fast-generate-preview": {
      "id": "veo-3.1-fast-generate-preview",
      "litellm_id": "gemini/veo-3.1-fast-generate-preview",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "google/veo-3.1-generate-preview": {
      "id": "veo-3.1-generate-preview",
      "litellm_id": "gemini/veo-3.1-generate-preview",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "google/veo-3.1-fast-generate-001": {
      "id": "veo-3.1-fast-generate-001",
      "litellm_id": "gemini/veo-3.1-fast-generate-001",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "google/veo-3.1-generate-001": {
      "id": "veo-3.1-generate-001",
      "litellm_id": "gemini/veo-3.1-generate-001",
      "provider": "google",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "github_copilot/claude-haiku-4.5": {
      "id": "claude-haiku-4.5",
      "litellm_id": "github_copilot/claude-haiku-4.5",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/claude-opus-4.5": {
      "id": "claude-opus-4.5",
      "litellm_id": "github_copilot/claude-opus-4.5",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/claude-opus-41": {
      "id": "claude-opus-41",
      "litellm_id": "github_copilot/claude-opus-41",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 80000,
      "max_output_tokens": 16000,
      "capabilities": [
        "vision"
      ]
    },
    "github_copilot/claude-sonnet-4": {
      "id": "claude-sonnet-4",
      "litellm_id": "github_copilot/claude-sonnet-4",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/claude-sonnet-4.5": {
      "id": "claude-sonnet-4.5",
      "litellm_id": "github_copilot/claude-sonnet-4.5",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "litellm_id": "github_copilot/gemini-2.5-pro",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "litellm_id": "github_copilot/gemini-3-pro-preview",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-3.5-turbo": {
      "id": "gpt-3.5-turbo",
      "litellm_id": "github_copilot/gpt-3.5-turbo",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "github_copilot/gpt-3.5-turbo-0613": {
      "id": "gpt-3.5-turbo-0613",
      "litellm_id": "github_copilot/gpt-3.5-turbo-0613",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "github_copilot/gpt-4": {
      "id": "gpt-4",
      "litellm_id": "github_copilot/gpt-4",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "github_copilot/gpt-4-0613": {
      "id": "gpt-4-0613",
      "litellm_id": "github_copilot/gpt-4-0613",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "github_copilot/gpt-4-o-preview": {
      "id": "gpt-4-o-preview",
      "litellm_id": "github_copilot/gpt-4-o-preview",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-4.1": {
      "id": "gpt-4.1",
      "litellm_id": "github_copilot/gpt-4.1",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/gpt-4.1-2025-04-14": {
      "id": "gpt-4.1-2025-04-14",
      "litellm_id": "github_copilot/gpt-4.1-2025-04-14",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/gpt-41-copilot": {
      "id": "gpt-41-copilot",
      "litellm_id": "github_copilot/gpt-41-copilot",
      "provider": "github_copilot",
      "mode": "completion"
    },
    "github_copilot/gpt-4o": {
      "id": "gpt-4o",
      "litellm_id": "github_copilot/gpt-4o",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-4o-2024-05-13": {
      "id": "gpt-4o-2024-05-13",
      "litellm_id": "github_copilot/gpt-4o-2024-05-13",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-4o-2024-08-06": {
      "id": "gpt-4o-2024-08-06",
      "litellm_id": "github_copilot/gpt-4o-2024-08-06",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-4o-2024-11-20": {
      "id": "gpt-4o-2024-11-20",
      "litellm_id": "github_copilot/gpt-4o-2024-11-20",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "litellm_id": "github_copilot/gpt-4o-mini",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-4o-mini-2024-07-18": {
      "id": "gpt-4o-mini-2024-07-18",
      "litellm_id": "github_copilot/gpt-4o-mini-2024-07-18",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "github_copilot/gpt-5": {
      "id": "gpt-5",
      "litellm_id": "github_copilot/gpt-5",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/gpt-5-mini": {
      "id": "gpt-5-mini",
      "litellm_id": "github_copilot/gpt-5-mini",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/gpt-5.1": {
      "id": "gpt-5.1",
      "litellm_id": "github_copilot/gpt-5.1",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "litellm_id": "github_copilot/gpt-5.1-codex-max",
      "provider": "github_copilot",
      "mode": "responses",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/gpt-5.2": {
      "id": "gpt-5.2",
      "litellm_id": "github_copilot/gpt-5.2",
      "provider": "github_copilot",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "github_copilot/text-embedding-3-small": {
      "id": "text-embedding-3-small",
      "litellm_id": "github_copilot/text-embedding-3-small",
      "provider": "github_copilot",
      "mode": "embedding",
      "max_input_tokens": 8191
    },
    "github_copilot/text-embedding-3-small-inference": {
      "id": "text-embedding-3-small-inference",
      "litellm_id": "github_copilot/text-embedding-3-small-inference",
      "provider": "github_copilot",
      "mode": "embedding",
      "max_input_tokens": 8191
    },
    "github_copilot/text-embedding-ada-002": {
      "id": "text-embedding-ada-002",
      "litellm_id": "github_copilot/text-embedding-ada-002",
      "provider": "github_copilot",
      "mode": "embedding",
      "max_input_tokens": 8191
    },
    "bedrock_converse/google.gemma-3-12b-it": {
      "id": "google.gemma-3-12b-it",
      "litellm_id": "google.gemma-3-12b-it",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00029,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "bedrock_converse/google.gemma-3-27b-it": {
      "id": "google.gemma-3-27b-it",
      "litellm_id": "google.gemma-3-27b-it",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.00038,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "bedrock_converse/google.gemma-3-4b-it": {
      "id": "google.gemma-3-4b-it",
      "litellm_id": "google.gemma-3-4b-it",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 8e-05,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "google_pse/search": {
      "id": "search",
      "litellm_id": "google_pse/search",
      "provider": "google_pse",
      "mode": "search"
    },
    "bedrock_converse/global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/global.anthropic.claude-sonnet-4-20250514-v1:0": {
      "id": "global.anthropic.claude-sonnet-4-20250514-v1:0",
      "litellm_id": "global.anthropic.claude-sonnet-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/global.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "global.anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "global.anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/global.amazon.nova-2-lite-v1:0": {
      "id": "global.amazon.nova-2-lite-v1:0",
      "litellm_id": "global.amazon.nova-2-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-3.5-turbo": {
      "id": "gpt-3.5-turbo",
      "litellm_id": "gpt-3.5-turbo",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-3.5-turbo-0125": {
      "id": "gpt-3.5-turbo-0125",
      "litellm_id": "gpt-3.5-turbo-0125",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-3.5-turbo-0301": {
      "id": "gpt-3.5-turbo-0301",
      "litellm_id": "gpt-3.5-turbo-0301",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-3.5-turbo-0613": {
      "id": "gpt-3.5-turbo-0613",
      "litellm_id": "gpt-3.5-turbo-0613",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-3.5-turbo-1106": {
      "id": "gpt-3.5-turbo-1106",
      "litellm_id": "gpt-3.5-turbo-1106",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-09-28"
    },
    "openai/gpt-3.5-turbo-16k": {
      "id": "gpt-3.5-turbo-16k",
      "litellm_id": "gpt-3.5-turbo-16k",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-3.5-turbo-16k-0613": {
      "id": "gpt-3.5-turbo-16k-0613",
      "litellm_id": "gpt-3.5-turbo-16k-0613",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "text-completion-openai/gpt-3.5-turbo-instruct": {
      "id": "gpt-3.5-turbo-instruct",
      "litellm_id": "gpt-3.5-turbo-instruct",
      "provider": "text-completion-openai",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "text-completion-openai/gpt-3.5-turbo-instruct-0914": {
      "id": "gpt-3.5-turbo-instruct-0914",
      "litellm_id": "gpt-3.5-turbo-instruct-0914",
      "provider": "text-completion-openai",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 4097,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "openai/gpt-4": {
      "id": "gpt-4",
      "litellm_id": "gpt-4",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-0125-preview": {
      "id": "gpt-4-0125-preview",
      "litellm_id": "gpt-4-0125-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-26"
    },
    "openai/gpt-4-0314": {
      "id": "gpt-4-0314",
      "litellm_id": "gpt-4-0314",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-0613": {
      "id": "gpt-4-0613",
      "litellm_id": "gpt-4-0613",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "system_messages",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-06-06"
    },
    "openai/gpt-4-1106-preview": {
      "id": "gpt-4-1106-preview",
      "litellm_id": "gpt-4-1106-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2026-03-26"
    },
    "openai/gpt-4-1106-vision-preview": {
      "id": "gpt-4-1106-vision-preview",
      "litellm_id": "gpt-4-1106-vision-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "system_messages",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2024-12-06"
    },
    "openai/gpt-4-32k": {
      "id": "gpt-4-32k",
      "litellm_id": "gpt-4-32k",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-32k-0314": {
      "id": "gpt-4-32k-0314",
      "litellm_id": "gpt-4-32k-0314",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-32k-0613": {
      "id": "gpt-4-32k-0613",
      "litellm_id": "gpt-4-32k-0613",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "litellm_id": "gpt-4-turbo",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-turbo-2024-04-09": {
      "id": "gpt-4-turbo-2024-04-09",
      "litellm_id": "gpt-4-turbo-2024-04-09",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-turbo-preview": {
      "id": "gpt-4-turbo-preview",
      "litellm_id": "gpt-4-turbo-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4-vision-preview": {
      "id": "gpt-4-vision-preview",
      "litellm_id": "gpt-4-vision-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "system_messages",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2024-12-06"
    },
    "openai/gpt-4.1": {
      "id": "gpt-4.1",
      "litellm_id": "gpt-4.1",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.1-2025-04-14": {
      "id": "gpt-4.1-2025-04-14",
      "litellm_id": "gpt-4.1-2025-04-14",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "litellm_id": "gpt-4.1-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.1-mini-2025-04-14": {
      "id": "gpt-4.1-mini-2025-04-14",
      "litellm_id": "gpt-4.1-mini-2025-04-14",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "litellm_id": "gpt-4.1-nano",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.1-nano-2025-04-14": {
      "id": "gpt-4.1-nano-2025-04-14",
      "litellm_id": "gpt-4.1-nano-2025-04-14",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.5-preview": {
      "id": "gpt-4.5-preview",
      "litellm_id": "gpt-4.5-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.075,
      "output_cost_per_1k": 0.15,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4.5-preview-2025-02-27": {
      "id": "gpt-4.5-preview-2025-02-27",
      "litellm_id": "gpt-4.5-preview-2025-02-27",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.075,
      "output_cost_per_1k": 0.15,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ],
      "deprecated": true,
      "deprecation_date": "2025-07-14"
    },
    "openai/gpt-4o": {
      "id": "gpt-4o",
      "litellm_id": "gpt-4o",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-2024-05-13": {
      "id": "gpt-4o-2024-05-13",
      "litellm_id": "gpt-4o-2024-05-13",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-2024-08-06": {
      "id": "gpt-4o-2024-08-06",
      "litellm_id": "gpt-4o-2024-08-06",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-2024-11-20": {
      "id": "gpt-4o-2024-11-20",
      "litellm_id": "gpt-4o-2024-11-20",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-audio-preview": {
      "id": "gpt-4o-audio-preview",
      "litellm_id": "gpt-4o-audio-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-audio-preview-2024-10-01": {
      "id": "gpt-4o-audio-preview-2024-10-01",
      "litellm_id": "gpt-4o-audio-preview-2024-10-01",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-audio-preview-2024-12-17": {
      "id": "gpt-4o-audio-preview-2024-12-17",
      "litellm_id": "gpt-4o-audio-preview-2024-12-17",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-audio-preview-2025-06-03": {
      "id": "gpt-4o-audio-preview-2025-06-03",
      "litellm_id": "gpt-4o-audio-preview-2025-06-03",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "litellm_id": "gpt-4o-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-mini-2024-07-18": {
      "id": "gpt-4o-mini-2024-07-18",
      "litellm_id": "gpt-4o-mini-2024-07-18",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-mini-audio-preview": {
      "id": "gpt-4o-mini-audio-preview",
      "litellm_id": "gpt-4o-mini-audio-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-mini-audio-preview-2024-12-17": {
      "id": "gpt-4o-mini-audio-preview-2024-12-17",
      "litellm_id": "gpt-4o-mini-audio-preview-2024-12-17",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-mini-realtime-preview": {
      "id": "gpt-4o-mini-realtime-preview",
      "litellm_id": "gpt-4o-mini-realtime-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-mini-realtime-preview-2024-12-17": {
      "id": "gpt-4o-mini-realtime-preview-2024-12-17",
      "litellm_id": "gpt-4o-mini-realtime-preview-2024-12-17",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-mini-search-preview": {
      "id": "gpt-4o-mini-search-preview",
      "litellm_id": "gpt-4o-mini-search-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "openai/gpt-4o-mini-search-preview-2025-03-11": {
      "id": "gpt-4o-mini-search-preview-2025-03-11",
      "litellm_id": "gpt-4o-mini-search-preview-2025-03-11",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-mini-transcribe": {
      "id": "gpt-4o-mini-transcribe",
      "litellm_id": "gpt-4o-mini-transcribe",
      "provider": "openai",
      "mode": "audio_transcription",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.005
    },
    "openai/gpt-4o-mini-tts": {
      "id": "gpt-4o-mini-tts",
      "litellm_id": "gpt-4o-mini-tts",
      "provider": "openai",
      "mode": "audio_speech",
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "openai/gpt-4o-realtime-preview": {
      "id": "gpt-4o-realtime-preview",
      "litellm_id": "gpt-4o-realtime-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-realtime-preview-2024-10-01": {
      "id": "gpt-4o-realtime-preview-2024-10-01",
      "litellm_id": "gpt-4o-realtime-preview-2024-10-01",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-realtime-preview-2024-12-17": {
      "id": "gpt-4o-realtime-preview-2024-12-17",
      "litellm_id": "gpt-4o-realtime-preview-2024-12-17",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-realtime-preview-2025-06-03": {
      "id": "gpt-4o-realtime-preview-2025-06-03",
      "litellm_id": "gpt-4o-realtime-preview-2025-06-03",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-4o-search-preview": {
      "id": "gpt-4o-search-preview",
      "litellm_id": "gpt-4o-search-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "web_search"
      ]
    },
    "openai/gpt-4o-search-preview-2025-03-11": {
      "id": "gpt-4o-search-preview-2025-03-11",
      "litellm_id": "gpt-4o-search-preview-2025-03-11",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/gpt-4o-transcribe": {
      "id": "gpt-4o-transcribe",
      "litellm_id": "gpt-4o-transcribe",
      "provider": "openai",
      "mode": "audio_transcription",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "openai/gpt-image-1.5": {
      "id": "gpt-image-1.5",
      "litellm_id": "gpt-image-1.5",
      "provider": "openai",
      "mode": "image",
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision"
      ]
    },
    "openai/gpt-image-1.5-2025-12-16": {
      "id": "gpt-image-1.5-2025-12-16",
      "litellm_id": "gpt-image-1.5-2025-12-16",
      "provider": "openai",
      "mode": "image",
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision"
      ]
    },
    "openai/gpt-5": {
      "id": "gpt-5",
      "litellm_id": "gpt-5",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.1": {
      "id": "gpt-5.1",
      "litellm_id": "gpt-5.1",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.1-2025-11-13": {
      "id": "gpt-5.1-2025-11-13",
      "litellm_id": "gpt-5.1-2025-11-13",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.1-chat-latest": {
      "id": "gpt-5.1-chat-latest",
      "litellm_id": "gpt-5.1-chat-latest",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.2": {
      "id": "gpt-5.2",
      "litellm_id": "gpt-5.2",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.2-2025-12-11": {
      "id": "gpt-5.2-2025-12-11",
      "litellm_id": "gpt-5.2-2025-12-11",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.2-chat-latest": {
      "id": "gpt-5.2-chat-latest",
      "litellm_id": "gpt-5.2-chat-latest",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.2-pro": {
      "id": "gpt-5.2-pro",
      "litellm_id": "gpt-5.2-pro",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "openai/gpt-5.2-pro-2025-12-11": {
      "id": "gpt-5.2-pro-2025-12-11",
      "litellm_id": "gpt-5.2-pro-2025-12-11",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "openai/gpt-5-pro": {
      "id": "gpt-5-pro",
      "litellm_id": "gpt-5-pro",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "openai/gpt-5-pro-2025-10-06": {
      "id": "gpt-5-pro-2025-10-06",
      "litellm_id": "gpt-5-pro-2025-10-06",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search"
      ]
    },
    "openai/gpt-5-2025-08-07": {
      "id": "gpt-5-2025-08-07",
      "litellm_id": "gpt-5-2025-08-07",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-chat": {
      "id": "gpt-5-chat",
      "litellm_id": "gpt-5-chat",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-chat-latest": {
      "id": "gpt-5-chat-latest",
      "litellm_id": "gpt-5-chat-latest",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-codex": {
      "id": "gpt-5-codex",
      "litellm_id": "gpt-5-codex",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "litellm_id": "gpt-5.1-codex",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "litellm_id": "gpt-5.1-codex-max",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "litellm_id": "gpt-5.1-codex-mini",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-mini": {
      "id": "gpt-5-mini",
      "litellm_id": "gpt-5-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-mini-2025-08-07": {
      "id": "gpt-5-mini-2025-08-07",
      "litellm_id": "gpt-5-mini-2025-08-07",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-nano": {
      "id": "gpt-5-nano",
      "litellm_id": "gpt-5-nano",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-5-nano-2025-08-07": {
      "id": "gpt-5-nano-2025-08-07",
      "litellm_id": "gpt-5-nano-2025-08-07",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/gpt-image-1": {
      "id": "gpt-image-1",
      "litellm_id": "gpt-image-1",
      "provider": "openai",
      "mode": "image",
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.04
    },
    "openai/gpt-image-1-mini": {
      "id": "gpt-image-1-mini",
      "litellm_id": "gpt-image-1-mini",
      "provider": "openai",
      "mode": "image",
      "input_cost_per_1k": 0.002
    },
    "openai/gpt-realtime": {
      "id": "gpt-realtime",
      "litellm_id": "gpt-realtime",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.004,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-realtime-mini": {
      "id": "gpt-realtime-mini",
      "litellm_id": "gpt-realtime-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "openai/gpt-realtime-2025-08-28": {
      "id": "gpt-realtime-2025-08-28",
      "litellm_id": "gpt-realtime-2025-08-28",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.004,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "audio_input",
        "audio_output"
      ]
    },
    "gradient_ai/alibaba-qwen3-32b": {
      "id": "alibaba-qwen3-32b",
      "litellm_id": "gradient_ai/alibaba-qwen3-32b",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 2048
    },
    "gradient_ai/anthropic-claude-3-opus": {
      "id": "anthropic-claude-3-opus",
      "litellm_id": "gradient_ai/anthropic-claude-3-opus",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075
    },
    "gradient_ai/anthropic-claude-3.5-haiku": {
      "id": "anthropic-claude-3.5-haiku",
      "litellm_id": "gradient_ai/anthropic-claude-3.5-haiku",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004
    },
    "gradient_ai/anthropic-claude-3.5-sonnet": {
      "id": "anthropic-claude-3.5-sonnet",
      "litellm_id": "gradient_ai/anthropic-claude-3.5-sonnet",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "gradient_ai/anthropic-claude-3.7-sonnet": {
      "id": "anthropic-claude-3.7-sonnet",
      "litellm_id": "gradient_ai/anthropic-claude-3.7-sonnet",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 1024,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "gradient_ai/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "litellm_id": "gradient_ai/deepseek-r1-distill-llama-70b",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 8000,
      "input_cost_per_1k": 0.00099,
      "output_cost_per_1k": 0.00099
    },
    "gradient_ai/llama3-8b-instruct": {
      "id": "llama3-8b-instruct",
      "litellm_id": "gradient_ai/llama3-8b-instruct",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "gradient_ai/llama3.3-70b-instruct": {
      "id": "llama3.3-70b-instruct",
      "litellm_id": "gradient_ai/llama3.3-70b-instruct",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00065
    },
    "gradient_ai/mistral-nemo-instruct-2407": {
      "id": "mistral-nemo-instruct-2407",
      "litellm_id": "gradient_ai/mistral-nemo-instruct-2407",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 512,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0003
    },
    "gradient_ai/openai-gpt-4o": {
      "id": "openai-gpt-4o",
      "litellm_id": "gradient_ai/openai-gpt-4o",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 16384
    },
    "gradient_ai/openai-gpt-4o-mini": {
      "id": "openai-gpt-4o-mini",
      "litellm_id": "gradient_ai/openai-gpt-4o-mini",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 16384
    },
    "gradient_ai/openai-o3": {
      "id": "openai-o3",
      "litellm_id": "gradient_ai/openai-o3",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "gradient_ai/openai-o3-mini": {
      "id": "openai-o3-mini",
      "litellm_id": "gradient_ai/openai-o3-mini",
      "provider": "gradient_ai",
      "mode": "chat",
      "max_input_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044
    },
    "lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF": {
      "id": "Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "litellm_id": "lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "provider": "lemonade",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "lemonade/gpt-oss-20b-mxfp4-GGUF": {
      "id": "gpt-oss-20b-mxfp4-GGUF",
      "litellm_id": "lemonade/gpt-oss-20b-mxfp4-GGUF",
      "provider": "lemonade",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "lemonade/gpt-oss-120b-mxfp-GGUF": {
      "id": "gpt-oss-120b-mxfp-GGUF",
      "litellm_id": "lemonade/gpt-oss-120b-mxfp-GGUF",
      "provider": "lemonade",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "lemonade/Gemma-3-4b-it-GGUF": {
      "id": "Gemma-3-4b-it-GGUF",
      "litellm_id": "lemonade/Gemma-3-4b-it-GGUF",
      "provider": "lemonade",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "lemonade/Qwen3-4B-Instruct-2507-GGUF": {
      "id": "Qwen3-4B-Instruct-2507-GGUF",
      "litellm_id": "lemonade/Qwen3-4B-Instruct-2507-GGUF",
      "provider": "lemonade",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "amazon_nova/amazon-nova/nova-micro-v1": {
      "id": "amazon-nova/nova-micro-v1",
      "litellm_id": "amazon-nova/nova-micro-v1",
      "provider": "amazon_nova",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "amazon_nova/amazon-nova/nova-lite-v1": {
      "id": "amazon-nova/nova-lite-v1",
      "litellm_id": "amazon-nova/nova-lite-v1",
      "provider": "amazon_nova",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "amazon_nova/amazon-nova/nova-premier-v1": {
      "id": "amazon-nova/nova-premier-v1",
      "litellm_id": "amazon-nova/nova-premier-v1",
      "provider": "amazon_nova",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.0125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "amazon_nova/amazon-nova/nova-pro-v1": {
      "id": "amazon-nova/nova-pro-v1",
      "litellm_id": "amazon-nova/nova-pro-v1",
      "provider": "amazon_nova",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "groq/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "litellm_id": "groq/deepseek-r1-distill-llama-70b",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.00099,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "groq/distil-whisper-large-v3-en": {
      "id": "distil-whisper-large-v3-en",
      "litellm_id": "groq/distil-whisper-large-v3-en",
      "provider": "groq",
      "mode": "audio_transcription"
    },
    "groq/gemma-7b-it": {
      "id": "gemma-7b-it",
      "litellm_id": "groq/gemma-7b-it",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2024-12-18"
    },
    "groq/gemma2-9b-it": {
      "id": "gemma2-9b-it",
      "litellm_id": "groq/gemma2-9b-it",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "groq/llama-3.1-405b-reasoning": {
      "id": "llama-3.1-405b-reasoning",
      "litellm_id": "groq/llama-3.1-405b-reasoning",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling"
      ]
    },
    "groq/llama-3.1-70b-versatile": {
      "id": "llama-3.1-70b-versatile",
      "litellm_id": "groq/llama-3.1-70b-versatile",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-01-24"
    },
    "groq/llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "litellm_id": "groq/llama-3.1-8b-instant",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling"
      ]
    },
    "groq/llama-3.2-11b-text-preview": {
      "id": "llama-3.2-11b-text-preview",
      "litellm_id": "groq/llama-3.2-11b-text-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2024-10-28"
    },
    "groq/llama-3.2-11b-vision-preview": {
      "id": "llama-3.2-11b-vision-preview",
      "litellm_id": "groq/llama-3.2-11b-vision-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "vision",
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-14"
    },
    "groq/llama-3.2-1b-preview": {
      "id": "llama-3.2-1b-preview",
      "litellm_id": "groq/llama-3.2-1b-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-14"
    },
    "groq/llama-3.2-3b-preview": {
      "id": "llama-3.2-3b-preview",
      "litellm_id": "groq/llama-3.2-3b-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-14"
    },
    "groq/llama-3.2-90b-text-preview": {
      "id": "llama-3.2-90b-text-preview",
      "litellm_id": "groq/llama-3.2-90b-text-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2024-11-25"
    },
    "groq/llama-3.2-90b-vision-preview": {
      "id": "llama-3.2-90b-vision-preview",
      "litellm_id": "groq/llama-3.2-90b-vision-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "vision",
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-04-14"
    },
    "groq/llama-3.3-70b-specdec": {
      "id": "llama-3.3-70b-specdec",
      "litellm_id": "groq/llama-3.3-70b-specdec",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00099,
      "deprecated": true,
      "deprecation_date": "2025-04-14"
    },
    "groq/llama-3.3-70b-versatile": {
      "id": "llama-3.3-70b-versatile",
      "litellm_id": "groq/llama-3.3-70b-versatile",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling"
      ]
    },
    "groq/llama-guard-3-8b": {
      "id": "llama-guard-3-8b",
      "litellm_id": "groq/llama-guard-3-8b",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "groq/llama2-70b-4096": {
      "id": "llama2-70b-4096",
      "litellm_id": "groq/llama2-70b-4096",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling"
      ]
    },
    "groq/llama3-groq-70b-8192-tool-use-preview": {
      "id": "llama3-groq-70b-8192-tool-use-preview",
      "litellm_id": "groq/llama3-groq-70b-8192-tool-use-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00089,
      "output_cost_per_1k": 0.00089,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-01-06"
    },
    "groq/llama3-groq-8b-8192-tool-use-preview": {
      "id": "llama3-groq-8b-8192-tool-use-preview",
      "litellm_id": "groq/llama3-groq-8b-8192-tool-use-preview",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00019,
      "output_cost_per_1k": 0.00019,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-01-06"
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
      "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "litellm_id": "groq/meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
      "id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "litellm_id": "groq/meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "groq/mistral-saba-24b": {
      "id": "mistral-saba-24b",
      "litellm_id": "groq/mistral-saba-24b",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00079,
      "output_cost_per_1k": 0.00079
    },
    "groq/mixtral-8x7b-32768": {
      "id": "mixtral-8x7b-32768",
      "litellm_id": "groq/mixtral-8x7b-32768",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00024,
      "output_cost_per_1k": 0.00024,
      "capabilities": [
        "function_calling"
      ],
      "deprecated": true,
      "deprecation_date": "2025-03-20"
    },
    "groq/moonshotai/kimi-k2-instruct": {
      "id": "moonshotai/kimi-k2-instruct",
      "litellm_id": "groq/moonshotai/kimi-k2-instruct",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
      "id": "moonshotai/kimi-k2-instruct-0905",
      "litellm_id": "groq/moonshotai/kimi-k2-instruct-0905",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "groq/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "litellm_id": "groq/openai/gpt-oss-120b",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32766,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "reasoning",
        "web_search"
      ]
    },
    "groq/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "litellm_id": "groq/openai/gpt-oss-20b",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "reasoning",
        "web_search"
      ]
    },
    "groq/playai-tts": {
      "id": "playai-tts",
      "litellm_id": "groq/playai-tts",
      "provider": "groq",
      "mode": "audio_speech",
      "max_input_tokens": 10000,
      "max_output_tokens": 10000
    },
    "groq/qwen/qwen3-32b": {
      "id": "qwen/qwen3-32b",
      "litellm_id": "groq/qwen/qwen3-32b",
      "provider": "groq",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "groq/whisper-large-v3": {
      "id": "whisper-large-v3",
      "litellm_id": "groq/whisper-large-v3",
      "provider": "groq",
      "mode": "audio_transcription"
    },
    "groq/whisper-large-v3-turbo": {
      "id": "whisper-large-v3-turbo",
      "litellm_id": "groq/whisper-large-v3-turbo",
      "provider": "groq",
      "mode": "audio_transcription"
    },
    "openai/hd/1024-x-1024/dall-e-3": {
      "id": "hd/1024-x-1024/dall-e-3",
      "litellm_id": "hd/1024-x-1024/dall-e-3",
      "provider": "openai",
      "mode": "image"
    },
    "openai/hd/1024-x-1792/dall-e-3": {
      "id": "hd/1024-x-1792/dall-e-3",
      "litellm_id": "hd/1024-x-1792/dall-e-3",
      "provider": "openai",
      "mode": "image"
    },
    "openai/hd/1792-x-1024/dall-e-3": {
      "id": "hd/1792-x-1024/dall-e-3",
      "litellm_id": "hd/1792-x-1024/dall-e-3",
      "provider": "openai",
      "mode": "image"
    },
    "heroku/claude-3-5-haiku": {
      "id": "claude-3-5-haiku",
      "litellm_id": "heroku/claude-3-5-haiku",
      "provider": "heroku",
      "mode": "chat",
      "max_input_tokens": 4096,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "heroku/claude-3-5-sonnet-latest": {
      "id": "claude-3-5-sonnet-latest",
      "litellm_id": "heroku/claude-3-5-sonnet-latest",
      "provider": "heroku",
      "mode": "chat",
      "max_input_tokens": 8192,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "heroku/claude-3-7-sonnet": {
      "id": "claude-3-7-sonnet",
      "litellm_id": "heroku/claude-3-7-sonnet",
      "provider": "heroku",
      "mode": "chat",
      "max_input_tokens": 8192,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "heroku/claude-4-sonnet": {
      "id": "claude-4-sonnet",
      "litellm_id": "heroku/claude-4-sonnet",
      "provider": "heroku",
      "mode": "chat",
      "max_input_tokens": 8192,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "openai/high/1024-x-1024/gpt-image-1": {
      "id": "high/1024-x-1024/gpt-image-1",
      "litellm_id": "high/1024-x-1024/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/high/1024-x-1536/gpt-image-1": {
      "id": "high/1024-x-1536/gpt-image-1",
      "litellm_id": "high/1024-x-1536/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/high/1536-x-1024/gpt-image-1": {
      "id": "high/1536-x-1024/gpt-image-1",
      "litellm_id": "high/1536-x-1024/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
      "id": "NousResearch/Hermes-3-Llama-3.1-70B",
      "litellm_id": "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/Qwen/QwQ-32B": {
      "id": "Qwen/QwQ-32B",
      "litellm_id": "hyperbolic/Qwen/QwQ-32B",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "litellm_id": "hyperbolic/Qwen/Qwen2.5-72B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "litellm_id": "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/Qwen/Qwen3-235B-A22B": {
      "id": "Qwen/Qwen3-235B-A22B",
      "litellm_id": "hyperbolic/Qwen/Qwen3-235B-A22B",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1": {
      "id": "deepseek-ai/DeepSeek-R1",
      "litellm_id": "hyperbolic/deepseek-ai/DeepSeek-R1",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "litellm_id": "hyperbolic/deepseek-ai/DeepSeek-R1-0528",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "litellm_id": "hyperbolic/deepseek-ai/DeepSeek-V3",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "litellm_id": "hyperbolic/deepseek-ai/DeepSeek-V3-0324",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
      "id": "meta-llama/Llama-3.2-3B-Instruct",
      "litellm_id": "hyperbolic/meta-llama/Llama-3.2-3B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "litellm_id": "hyperbolic/meta-llama/Llama-3.3-70B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
      "id": "meta-llama/Meta-Llama-3-70B-Instruct",
      "litellm_id": "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "litellm_id": "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "litellm_id": "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "litellm_id": "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "hyperbolic/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "litellm_id": "hyperbolic/moonshotai/Kimi-K2-Instruct",
      "provider": "hyperbolic",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "ai21/j2-light": {
      "id": "j2-light",
      "litellm_id": "j2-light",
      "provider": "ai21",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.003
    },
    "ai21/j2-mid": {
      "id": "j2-mid",
      "litellm_id": "j2-mid",
      "provider": "ai21",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.01
    },
    "ai21/j2-ultra": {
      "id": "j2-ultra",
      "litellm_id": "j2-ultra",
      "provider": "ai21",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.015
    },
    "ai21/jamba-1.5": {
      "id": "jamba-1.5",
      "litellm_id": "jamba-1.5",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "ai21/jamba-1.5-large": {
      "id": "jamba-1.5-large",
      "litellm_id": "jamba-1.5-large",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "ai21/jamba-1.5-large@001": {
      "id": "jamba-1.5-large@001",
      "litellm_id": "jamba-1.5-large@001",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "ai21/jamba-1.5-mini": {
      "id": "jamba-1.5-mini",
      "litellm_id": "jamba-1.5-mini",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "ai21/jamba-1.5-mini@001": {
      "id": "jamba-1.5-mini@001",
      "litellm_id": "jamba-1.5-mini@001",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "ai21/jamba-large-1.6": {
      "id": "jamba-large-1.6",
      "litellm_id": "jamba-large-1.6",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "ai21/jamba-large-1.7": {
      "id": "jamba-large-1.7",
      "litellm_id": "jamba-large-1.7",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "ai21/jamba-mini-1.6": {
      "id": "jamba-mini-1.6",
      "litellm_id": "jamba-mini-1.6",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "ai21/jamba-mini-1.7": {
      "id": "jamba-mini-1.7",
      "litellm_id": "jamba-mini-1.7",
      "provider": "ai21",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "jina_ai/jina-reranker-v2-base-multilingual": {
      "id": "jina-reranker-v2-base-multilingual",
      "litellm_id": "jina-reranker-v2-base-multilingual",
      "provider": "jina_ai",
      "mode": "rerank",
      "max_input_tokens": 1024,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 1.8e-05,
      "output_cost_per_1k": 1.8e-05
    },
    "bedrock_converse/jp.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "jp.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "jp.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/jp.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "jp.anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "jp.anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0055,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "lambda_ai/deepseek-llama3.3-70b": {
      "id": "deepseek-llama3.3-70b",
      "litellm_id": "lambda_ai/deepseek-llama3.3-70b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "reasoning"
      ]
    },
    "lambda_ai/deepseek-r1-0528": {
      "id": "deepseek-r1-0528",
      "litellm_id": "lambda_ai/deepseek-r1-0528",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "reasoning"
      ]
    },
    "lambda_ai/deepseek-r1-671b": {
      "id": "deepseek-r1-671b",
      "litellm_id": "lambda_ai/deepseek-r1-671b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "reasoning"
      ]
    },
    "lambda_ai/deepseek-v3-0324": {
      "id": "deepseek-v3-0324",
      "litellm_id": "lambda_ai/deepseek-v3-0324",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/hermes3-405b": {
      "id": "hermes3-405b",
      "litellm_id": "lambda_ai/hermes3-405b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/hermes3-70b": {
      "id": "hermes3-70b",
      "litellm_id": "lambda_ai/hermes3-70b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/hermes3-8b": {
      "id": "hermes3-8b",
      "litellm_id": "lambda_ai/hermes3-8b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2.5e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/lfm-40b": {
      "id": "lfm-40b",
      "litellm_id": "lambda_ai/lfm-40b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/lfm-7b": {
      "id": "lfm-7b",
      "litellm_id": "lambda_ai/lfm-7b",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2.5e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "litellm_id": "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama-4-scout-17b-16e-instruct": {
      "id": "llama-4-scout-17b-16e-instruct",
      "litellm_id": "lambda_ai/llama-4-scout-17b-16e-instruct",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.1-405b-instruct-fp8": {
      "id": "llama3.1-405b-instruct-fp8",
      "litellm_id": "lambda_ai/llama3.1-405b-instruct-fp8",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.1-70b-instruct-fp8": {
      "id": "llama3.1-70b-instruct-fp8",
      "litellm_id": "lambda_ai/llama3.1-70b-instruct-fp8",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.1-8b-instruct": {
      "id": "llama3.1-8b-instruct",
      "litellm_id": "lambda_ai/llama3.1-8b-instruct",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2.5e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
      "id": "llama3.1-nemotron-70b-instruct-fp8",
      "litellm_id": "lambda_ai/llama3.1-nemotron-70b-instruct-fp8",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.2-11b-vision-instruct": {
      "id": "llama3.2-11b-vision-instruct",
      "litellm_id": "lambda_ai/llama3.2-11b-vision-instruct",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 1.5e-05,
      "output_cost_per_1k": 2.5e-05,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.2-3b-instruct": {
      "id": "llama3.2-3b-instruct",
      "litellm_id": "lambda_ai/llama3.2-3b-instruct",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 1.5e-05,
      "output_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/llama3.3-70b-instruct-fp8": {
      "id": "llama3.3-70b-instruct-fp8",
      "litellm_id": "lambda_ai/llama3.3-70b-instruct-fp8",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/qwen25-coder-32b-instruct": {
      "id": "qwen25-coder-32b-instruct",
      "litellm_id": "lambda_ai/qwen25-coder-32b-instruct",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "lambda_ai/qwen3-32b-fp8": {
      "id": "qwen3-32b-fp8",
      "litellm_id": "lambda_ai/qwen3-32b-fp8",
      "provider": "lambda_ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "reasoning"
      ]
    },
    "openai/low/1024-x-1024/gpt-image-1": {
      "id": "low/1024-x-1024/gpt-image-1",
      "litellm_id": "low/1024-x-1024/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/low/1024-x-1536/gpt-image-1": {
      "id": "low/1024-x-1536/gpt-image-1",
      "litellm_id": "low/1024-x-1536/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/low/1536-x-1024/gpt-image-1": {
      "id": "low/1536-x-1024/gpt-image-1",
      "litellm_id": "low/1536-x-1024/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "aleph_alpha/luminous-base": {
      "id": "luminous-base",
      "litellm_id": "luminous-base",
      "provider": "aleph_alpha",
      "mode": "completion",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.033
    },
    "aleph_alpha/luminous-base-control": {
      "id": "luminous-base-control",
      "litellm_id": "luminous-base-control",
      "provider": "aleph_alpha",
      "mode": "chat",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.0375,
      "output_cost_per_1k": 0.04125
    },
    "aleph_alpha/luminous-extended": {
      "id": "luminous-extended",
      "litellm_id": "luminous-extended",
      "provider": "aleph_alpha",
      "mode": "completion",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.045,
      "output_cost_per_1k": 0.0495
    },
    "aleph_alpha/luminous-extended-control": {
      "id": "luminous-extended-control",
      "litellm_id": "luminous-extended-control",
      "provider": "aleph_alpha",
      "mode": "chat",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.05625,
      "output_cost_per_1k": 0.061875
    },
    "aleph_alpha/luminous-supreme": {
      "id": "luminous-supreme",
      "litellm_id": "luminous-supreme",
      "provider": "aleph_alpha",
      "mode": "completion",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.175,
      "output_cost_per_1k": 0.1925
    },
    "aleph_alpha/luminous-supreme-control": {
      "id": "luminous-supreme-control",
      "litellm_id": "luminous-supreme-control",
      "provider": "aleph_alpha",
      "mode": "chat",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.21875,
      "output_cost_per_1k": 0.240625
    },
    "aws_bedrock/max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
      "id": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
      "litellm_id": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "aws_bedrock/max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
      "id": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
      "litellm_id": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "openai/medium/1024-x-1024/gpt-image-1": {
      "id": "medium/1024-x-1024/gpt-image-1",
      "litellm_id": "medium/1024-x-1024/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/medium/1024-x-1536/gpt-image-1": {
      "id": "medium/1024-x-1536/gpt-image-1",
      "litellm_id": "medium/1024-x-1536/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/medium/1536-x-1024/gpt-image-1": {
      "id": "medium/1536-x-1024/gpt-image-1",
      "litellm_id": "medium/1536-x-1024/gpt-image-1",
      "provider": "openai",
      "mode": "image"
    },
    "openai/low/1024-x-1024/gpt-image-1-mini": {
      "id": "low/1024-x-1024/gpt-image-1-mini",
      "litellm_id": "low/1024-x-1024/gpt-image-1-mini",
      "provider": "openai",
      "mode": "image"
    },
    "openai/low/1024-x-1536/gpt-image-1-mini": {
      "id": "low/1024-x-1536/gpt-image-1-mini",
      "litellm_id": "low/1024-x-1536/gpt-image-1-mini",
      "provider": "openai",
      "mode": "image"
    },
    "openai/low/1536-x-1024/gpt-image-1-mini": {
      "id": "low/1536-x-1024/gpt-image-1-mini",
      "litellm_id": "low/1536-x-1024/gpt-image-1-mini",
      "provider": "openai",
      "mode": "image"
    },
    "openai/medium/1024-x-1024/gpt-image-1-mini": {
      "id": "medium/1024-x-1024/gpt-image-1-mini",
      "litellm_id": "medium/1024-x-1024/gpt-image-1-mini",
      "provider": "openai",
      "mode": "image"
    },
    "openai/medium/1024-x-1536/gpt-image-1-mini": {
      "id": "medium/1024-x-1536/gpt-image-1-mini",
      "litellm_id": "medium/1024-x-1536/gpt-image-1-mini",
      "provider": "openai",
      "mode": "image"
    },
    "openai/medium/1536-x-1024/gpt-image-1-mini": {
      "id": "medium/1536-x-1024/gpt-image-1-mini",
      "litellm_id": "medium/1536-x-1024/gpt-image-1-mini",
      "provider": "openai",
      "mode": "image"
    },
    "google/medlm-large": {
      "id": "medlm-large",
      "litellm_id": "medlm-large",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024
    },
    "google/medlm-medium": {
      "id": "medlm-medium",
      "litellm_id": "medlm-medium",
      "provider": "google",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192
    },
    "aws_bedrock/meta.llama2-13b-chat-v1": {
      "id": "meta.llama2-13b-chat-v1",
      "litellm_id": "meta.llama2-13b-chat-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.001
    },
    "aws_bedrock/meta.llama2-70b-chat-v1": {
      "id": "meta.llama2-70b-chat-v1",
      "litellm_id": "meta.llama2-70b-chat-v1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00195,
      "output_cost_per_1k": 0.00256
    },
    "aws_bedrock/meta.llama3-1-405b-instruct-v1:0": {
      "id": "meta.llama3-1-405b-instruct-v1:0",
      "litellm_id": "meta.llama3-1-405b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00532,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-1-70b-instruct-v1:0": {
      "id": "meta.llama3-1-70b-instruct-v1:0",
      "litellm_id": "meta.llama3-1-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00099,
      "output_cost_per_1k": 0.00099,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-1-8b-instruct-v1:0": {
      "id": "meta.llama3-1-8b-instruct-v1:0",
      "litellm_id": "meta.llama3-1-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00022,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-2-11b-instruct-v1:0": {
      "id": "meta.llama3-2-11b-instruct-v1:0",
      "litellm_id": "meta.llama3-2-11b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-2-1b-instruct-v1:0": {
      "id": "meta.llama3-2-1b-instruct-v1:0",
      "litellm_id": "meta.llama3-2-1b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-2-3b-instruct-v1:0": {
      "id": "meta.llama3-2-3b-instruct-v1:0",
      "litellm_id": "meta.llama3-2-3b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-2-90b-instruct-v1:0": {
      "id": "meta.llama3-2-90b-instruct-v1:0",
      "litellm_id": "meta.llama3-2-90b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "bedrock_converse/meta.llama3-3-70b-instruct-v1:0": {
      "id": "meta.llama3-3-70b-instruct-v1:0",
      "litellm_id": "meta.llama3-3-70b-instruct-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/meta.llama3-70b-instruct-v1:0": {
      "id": "meta.llama3-70b-instruct-v1:0",
      "litellm_id": "meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00265,
      "output_cost_per_1k": 0.0035
    },
    "aws_bedrock/meta.llama3-8b-instruct-v1:0": {
      "id": "meta.llama3-8b-instruct-v1:0",
      "litellm_id": "meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006
    },
    "bedrock_converse/meta.llama4-maverick-17b-instruct-v1:0": {
      "id": "meta.llama4-maverick-17b-instruct-v1:0",
      "litellm_id": "meta.llama4-maverick-17b-instruct-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00024,
      "output_cost_per_1k": 0.00097,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/meta.llama4-scout-17b-instruct-v1:0": {
      "id": "meta.llama4-scout-17b-instruct-v1:0",
      "litellm_id": "meta.llama4-scout-17b-instruct-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "function_calling"
      ]
    },
    "meta_llama/Llama-3.3-70B-Instruct": {
      "id": "Llama-3.3-70B-Instruct",
      "litellm_id": "meta_llama/Llama-3.3-70B-Instruct",
      "provider": "meta_llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4028,
      "capabilities": [
        "function_calling"
      ]
    },
    "meta_llama/Llama-3.3-8B-Instruct": {
      "id": "Llama-3.3-8B-Instruct",
      "litellm_id": "meta_llama/Llama-3.3-8B-Instruct",
      "provider": "meta_llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4028,
      "capabilities": [
        "function_calling"
      ]
    },
    "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "litellm_id": "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "meta_llama",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 4028,
      "capabilities": [
        "function_calling"
      ]
    },
    "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8": {
      "id": "Llama-4-Scout-17B-16E-Instruct-FP8",
      "litellm_id": "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
      "provider": "meta_llama",
      "mode": "chat",
      "max_input_tokens": 10000000,
      "max_output_tokens": 4028,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/minimax.minimax-m2": {
      "id": "minimax.minimax-m2",
      "litellm_id": "minimax.minimax-m2",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "system_messages"
      ]
    },
    "bedrock_converse/mistral.magistral-small-2509": {
      "id": "mistral.magistral-small-2509",
      "litellm_id": "mistral.magistral-small-2509",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "system_messages",
        "reasoning"
      ]
    },
    "bedrock_converse/mistral.ministral-3-14b-instruct": {
      "id": "mistral.ministral-3-14b-instruct",
      "litellm_id": "mistral.ministral-3-14b-instruct",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "bedrock_converse/mistral.ministral-3-3b-instruct": {
      "id": "mistral.ministral-3-3b-instruct",
      "litellm_id": "mistral.ministral-3-3b-instruct",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "bedrock_converse/mistral.ministral-3-8b-instruct": {
      "id": "mistral.ministral-3-8b-instruct",
      "litellm_id": "mistral.ministral-3-8b-instruct",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "aws_bedrock/mistral.mistral-7b-instruct-v0:2": {
      "id": "mistral.mistral-7b-instruct-v0:2",
      "litellm_id": "mistral.mistral-7b-instruct-v0:2",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0002
    },
    "aws_bedrock/mistral.mistral-large-2402-v1:0": {
      "id": "mistral.mistral-large-2402-v1:0",
      "litellm_id": "mistral.mistral-large-2402-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/mistral.mistral-large-2407-v1:0": {
      "id": "mistral.mistral-large-2407-v1:0",
      "litellm_id": "mistral.mistral-large-2407-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.009,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/mistral.mistral-large-3-675b-instruct": {
      "id": "mistral.mistral-large-3-675b-instruct",
      "litellm_id": "mistral.mistral-large-3-675b-instruct",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "aws_bedrock/mistral.mistral-small-2402-v1:0": {
      "id": "mistral.mistral-small-2402-v1:0",
      "litellm_id": "mistral.mistral-small-2402-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/mistral.mixtral-8x7b-instruct-v0:1": {
      "id": "mistral.mixtral-8x7b-instruct-v0:1",
      "litellm_id": "mistral.mixtral-8x7b-instruct-v0:1",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0007
    },
    "bedrock_converse/mistral.voxtral-mini-3b-2507": {
      "id": "mistral.voxtral-mini-3b-2507",
      "litellm_id": "mistral.voxtral-mini-3b-2507",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "system_messages",
        "audio_input"
      ]
    },
    "bedrock_converse/mistral.voxtral-small-24b-2507": {
      "id": "mistral.voxtral-small-24b-2507",
      "litellm_id": "mistral.voxtral-small-24b-2507",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "system_messages",
        "audio_input"
      ]
    },
    "mistral/codestral-2405": {
      "id": "codestral-2405",
      "litellm_id": "mistral/codestral-2405",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/codestral-2508": {
      "id": "codestral-2508",
      "litellm_id": "mistral/codestral-2508",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/codestral-latest": {
      "id": "codestral-latest",
      "litellm_id": "mistral/codestral-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/codestral-mamba-latest": {
      "id": "codestral-mamba-latest",
      "litellm_id": "mistral/codestral-mamba-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025
    },
    "mistral/devstral-medium-2507": {
      "id": "devstral-medium-2507",
      "litellm_id": "mistral/devstral-medium-2507",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/devstral-small-2505": {
      "id": "devstral-small-2505",
      "litellm_id": "mistral/devstral-small-2505",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/devstral-small-2507": {
      "id": "devstral-small-2507",
      "litellm_id": "mistral/devstral-small-2507",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/labs-devstral-small-2512": {
      "id": "labs-devstral-small-2512",
      "litellm_id": "mistral/labs-devstral-small-2512",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/devstral-2512": {
      "id": "devstral-2512",
      "litellm_id": "mistral/devstral-2512",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/magistral-medium-2506": {
      "id": "magistral-medium-2506",
      "litellm_id": "mistral/magistral-medium-2506",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "mistral/magistral-medium-2509": {
      "id": "magistral-medium-2509",
      "litellm_id": "mistral/magistral-medium-2509",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "mistral/mistral-ocr-latest": {
      "id": "mistral-ocr-latest",
      "litellm_id": "mistral/mistral-ocr-latest",
      "provider": "mistral",
      "mode": "ocr"
    },
    "mistral/mistral-ocr-2505-completion": {
      "id": "mistral-ocr-2505-completion",
      "litellm_id": "mistral/mistral-ocr-2505-completion",
      "provider": "mistral",
      "mode": "ocr"
    },
    "mistral/magistral-medium-latest": {
      "id": "magistral-medium-latest",
      "litellm_id": "mistral/magistral-medium-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "mistral/magistral-small-2506": {
      "id": "magistral-small-2506",
      "litellm_id": "mistral/magistral-small-2506",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "mistral/magistral-small-latest": {
      "id": "magistral-small-latest",
      "litellm_id": "mistral/magistral-small-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "mistral/mistral-embed": {
      "id": "mistral-embed",
      "litellm_id": "mistral/mistral-embed",
      "provider": "mistral",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0001
    },
    "mistral/codestral-embed": {
      "id": "codestral-embed",
      "litellm_id": "mistral/codestral-embed",
      "provider": "mistral",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00015
    },
    "mistral/codestral-embed-2505": {
      "id": "codestral-embed-2505",
      "litellm_id": "mistral/codestral-embed-2505",
      "provider": "mistral",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00015
    },
    "mistral/mistral-large-2402": {
      "id": "mistral-large-2402",
      "litellm_id": "mistral/mistral-large-2402",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.004,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-large-2407": {
      "id": "mistral-large-2407",
      "litellm_id": "mistral/mistral-large-2407",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.009,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-large-2411": {
      "id": "mistral-large-2411",
      "litellm_id": "mistral/mistral-large-2411",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-large-latest": {
      "id": "mistral-large-latest",
      "litellm_id": "mistral/mistral-large-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-large-3": {
      "id": "mistral-large-3",
      "litellm_id": "mistral/mistral-large-3",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-medium": {
      "id": "mistral-medium",
      "litellm_id": "mistral/mistral-medium",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0027,
      "output_cost_per_1k": 0.0081,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/mistral-medium-2312": {
      "id": "mistral-medium-2312",
      "litellm_id": "mistral/mistral-medium-2312",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0027,
      "output_cost_per_1k": 0.0081,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/mistral-medium-2505": {
      "id": "mistral-medium-2505",
      "litellm_id": "mistral/mistral-medium-2505",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-medium-latest": {
      "id": "mistral-medium-latest",
      "litellm_id": "mistral/mistral-medium-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-small": {
      "id": "mistral-small",
      "litellm_id": "mistral/mistral-small",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-small-latest": {
      "id": "mistral-small-latest",
      "litellm_id": "mistral/mistral-small-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/mistral-tiny": {
      "id": "mistral-tiny",
      "litellm_id": "mistral/mistral-tiny",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/open-codestral-mamba": {
      "id": "open-codestral-mamba",
      "litellm_id": "mistral/open-codestral-mamba",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025
    },
    "mistral/open-mistral-7b": {
      "id": "open-mistral-7b",
      "litellm_id": "mistral/open-mistral-7b",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/open-mistral-nemo": {
      "id": "open-mistral-nemo",
      "litellm_id": "mistral/open-mistral-nemo",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/open-mistral-nemo-2407": {
      "id": "open-mistral-nemo-2407",
      "litellm_id": "mistral/open-mistral-nemo-2407",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "json_mode"
      ]
    },
    "mistral/open-mixtral-8x22b": {
      "id": "open-mixtral-8x22b",
      "litellm_id": "mistral/open-mixtral-8x22b",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 65336,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/open-mixtral-8x7b": {
      "id": "open-mixtral-8x7b",
      "litellm_id": "mistral/open-mixtral-8x7b",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/pixtral-12b-2409": {
      "id": "pixtral-12b-2409",
      "litellm_id": "mistral/pixtral-12b-2409",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/pixtral-large-2411": {
      "id": "pixtral-large-2411",
      "litellm_id": "mistral/pixtral-large-2411",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "mistral/pixtral-large-latest": {
      "id": "pixtral-large-latest",
      "litellm_id": "mistral/pixtral-large-latest",
      "provider": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "bedrock_converse/moonshot.kimi-k2-thinking": {
      "id": "moonshot.kimi-k2-thinking",
      "litellm_id": "moonshot.kimi-k2-thinking",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "system_messages",
        "reasoning"
      ]
    },
    "moonshot/kimi-k2-0711-preview": {
      "id": "kimi-k2-0711-preview",
      "litellm_id": "moonshot/kimi-k2-0711-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "moonshot/kimi-k2-0905-preview": {
      "id": "kimi-k2-0905-preview",
      "litellm_id": "moonshot/kimi-k2-0905-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "moonshot/kimi-k2-turbo-preview": {
      "id": "kimi-k2-turbo-preview",
      "litellm_id": "moonshot/kimi-k2-turbo-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00115,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "moonshot/kimi-latest": {
      "id": "kimi-latest",
      "litellm_id": "moonshot/kimi-latest",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/kimi-latest-128k": {
      "id": "kimi-latest-128k",
      "litellm_id": "moonshot/kimi-latest-128k",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/kimi-latest-32k": {
      "id": "kimi-latest-32k",
      "litellm_id": "moonshot/kimi-latest-32k",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/kimi-latest-8k": {
      "id": "kimi-latest-8k",
      "litellm_id": "moonshot/kimi-latest-8k",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/kimi-thinking-preview": {
      "id": "kimi-thinking-preview",
      "litellm_id": "moonshot/kimi-thinking-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision"
      ]
    },
    "moonshot/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "litellm_id": "moonshot/kimi-k2-thinking",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "moonshot/kimi-k2-thinking-turbo": {
      "id": "kimi-k2-thinking-turbo",
      "litellm_id": "moonshot/kimi-k2-thinking-turbo",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00115,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "moonshot/moonshot-v1-128k": {
      "id": "moonshot-v1-128k",
      "litellm_id": "moonshot/moonshot-v1-128k",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-128k-0430": {
      "id": "moonshot-v1-128k-0430",
      "litellm_id": "moonshot/moonshot-v1-128k-0430",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-128k-vision-preview": {
      "id": "moonshot-v1-128k-vision-preview",
      "litellm_id": "moonshot/moonshot-v1-128k-vision-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-32k": {
      "id": "moonshot-v1-32k",
      "litellm_id": "moonshot/moonshot-v1-32k",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-32k-0430": {
      "id": "moonshot-v1-32k-0430",
      "litellm_id": "moonshot/moonshot-v1-32k-0430",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-32k-vision-preview": {
      "id": "moonshot-v1-32k-vision-preview",
      "litellm_id": "moonshot/moonshot-v1-32k-vision-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-8k": {
      "id": "moonshot-v1-8k",
      "litellm_id": "moonshot/moonshot-v1-8k",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-8k-0430": {
      "id": "moonshot-v1-8k-0430",
      "litellm_id": "moonshot/moonshot-v1-8k-0430",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-8k-vision-preview": {
      "id": "moonshot-v1-8k-vision-preview",
      "litellm_id": "moonshot/moonshot-v1-8k-vision-preview",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "moonshot/moonshot-v1-auto": {
      "id": "moonshot-v1-auto",
      "litellm_id": "moonshot/moonshot-v1-auto",
      "provider": "moonshot",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "morph/morph-v3-fast": {
      "id": "morph-v3-fast",
      "litellm_id": "morph/morph-v3-fast",
      "provider": "morph",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "system_messages"
      ]
    },
    "morph/morph-v3-large": {
      "id": "morph-v3-large",
      "litellm_id": "morph/morph-v3-large",
      "provider": "morph",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0019,
      "capabilities": [
        "system_messages"
      ]
    },
    "vertex_ai-embedding-models/multimodalembedding": {
      "id": "multimodalembedding",
      "litellm_id": "multimodalembedding",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.0008
    },
    "vertex_ai-embedding-models/multimodalembedding@001": {
      "id": "multimodalembedding@001",
      "litellm_id": "multimodalembedding@001",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.0008
    },
    "nscale/Qwen/QwQ-32B": {
      "id": "Qwen/QwQ-32B",
      "litellm_id": "nscale/Qwen/QwQ-32B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.0002
    },
    "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "litellm_id": "nscale/Qwen/Qwen2.5-Coder-32B-Instruct",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.0002
    },
    "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-3B-Instruct",
      "litellm_id": "nscale/Qwen/Qwen2.5-Coder-3B-Instruct",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 3e-05
    },
    "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-7B-Instruct",
      "litellm_id": "nscale/Qwen/Qwen2.5-Coder-7B-Instruct",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 3e-05
    },
    "nscale/black-forest-labs/FLUX.1-schnell": {
      "id": "black-forest-labs/FLUX.1-schnell",
      "litellm_id": "nscale/black-forest-labs/FLUX.1-schnell",
      "provider": "nscale",
      "mode": "image"
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "litellm_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 0.000375,
      "output_cost_per_1k": 0.000375
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "litellm_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 2.5e-05,
      "output_cost_per_1k": 2.5e-05
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "litellm_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 9e-05
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "litellm_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 7e-05
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "litellm_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "litellm_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "nscale/meta-llama/Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "litellm_id": "nscale/meta-llama/Llama-3.1-8B-Instruct",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 3e-05
    },
    "nscale/meta-llama/Llama-3.3-70B-Instruct": {
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "litellm_id": "nscale/meta-llama/Llama-3.3-70B-Instruct",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "litellm_id": "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00029
    },
    "nscale/mistralai/mixtral-8x22b-instruct-v0.1": {
      "id": "mistralai/mixtral-8x22b-instruct-v0.1",
      "litellm_id": "nscale/mistralai/mixtral-8x22b-instruct-v0.1",
      "provider": "nscale",
      "mode": "chat",
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006
    },
    "nscale/stabilityai/stable-diffusion-xl-base-1.0": {
      "id": "stabilityai/stable-diffusion-xl-base-1.0",
      "litellm_id": "nscale/stabilityai/stable-diffusion-xl-base-1.0",
      "provider": "nscale",
      "mode": "image"
    },
    "bedrock_converse/nvidia.nemotron-nano-12b-v2": {
      "id": "nvidia.nemotron-nano-12b-v2",
      "litellm_id": "nvidia.nemotron-nano-12b-v2",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "bedrock_converse/nvidia.nemotron-nano-9b-v2": {
      "id": "nvidia.nemotron-nano-9b-v2",
      "litellm_id": "nvidia.nemotron-nano-9b-v2",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00023,
      "capabilities": [
        "system_messages"
      ]
    },
    "openai/o1": {
      "id": "o1",
      "litellm_id": "o1",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o1-2024-12-17": {
      "id": "o1-2024-12-17",
      "litellm_id": "o1-2024-12-17",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o1-mini": {
      "id": "o1-mini",
      "litellm_id": "o1-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "vision",
        "prompt_caching"
      ]
    },
    "openai/o1-mini-2024-09-12": {
      "id": "o1-mini-2024-09-12",
      "litellm_id": "o1-mini-2024-09-12",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "vision",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2025-10-27"
    },
    "openai/o1-preview": {
      "id": "o1-preview",
      "litellm_id": "o1-preview",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o1-preview-2024-09-12": {
      "id": "o1-preview-2024-09-12",
      "litellm_id": "o1-preview-2024-09-12",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o1-pro": {
      "id": "o1-pro",
      "litellm_id": "o1-pro",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.15,
      "output_cost_per_1k": 0.6,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o1-pro-2025-03-19": {
      "id": "o1-pro-2025-03-19",
      "litellm_id": "o1-pro-2025-03-19",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.15,
      "output_cost_per_1k": 0.6,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o3": {
      "id": "o3",
      "litellm_id": "o3",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o3-2025-04-16": {
      "id": "o3-2025-04-16",
      "litellm_id": "o3-2025-04-16",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o3-deep-research": {
      "id": "o3-deep-research",
      "litellm_id": "o3-deep-research",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.04,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/o3-deep-research-2025-06-26": {
      "id": "o3-deep-research-2025-06-26",
      "litellm_id": "o3-deep-research-2025-06-26",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.04,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/o3-mini": {
      "id": "o3-mini",
      "litellm_id": "o3-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o3-mini-2025-01-31": {
      "id": "o3-mini-2025-01-31",
      "litellm_id": "o3-mini-2025-01-31",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o3-pro": {
      "id": "o3-pro",
      "litellm_id": "o3-pro",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o3-pro-2025-06-10": {
      "id": "o3-pro-2025-06-10",
      "litellm_id": "o3-pro-2025-06-10",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o4-mini": {
      "id": "o4-mini",
      "litellm_id": "o4-mini",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o4-mini-2025-04-16": {
      "id": "o4-mini-2025-04-16",
      "litellm_id": "o4-mini-2025-04-16",
      "provider": "openai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openai/o4-mini-deep-research": {
      "id": "o4-mini-deep-research",
      "litellm_id": "o4-mini-deep-research",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openai/o4-mini-deep-research-2025-06-26": {
      "id": "o4-mini-deep-research-2025-06-26",
      "litellm_id": "o4-mini-deep-research-2025-06-26",
      "provider": "openai",
      "mode": "responses",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "oci/meta.llama-3.1-405b-instruct": {
      "id": "meta.llama-3.1-405b-instruct",
      "litellm_id": "oci/meta.llama-3.1-405b-instruct",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.01068,
      "output_cost_per_1k": 0.01068,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/meta.llama-3.2-90b-vision-instruct": {
      "id": "meta.llama-3.2-90b-vision-instruct",
      "litellm_id": "oci/meta.llama-3.2-90b-vision-instruct",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/meta.llama-3.3-70b-instruct": {
      "id": "meta.llama-3.3-70b-instruct",
      "litellm_id": "oci/meta.llama-3.3-70b-instruct",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
      "id": "meta.llama-4-maverick-17b-128e-instruct-fp8",
      "litellm_id": "oci/meta.llama-4-maverick-17b-128e-instruct-fp8",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 512000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/meta.llama-4-scout-17b-16e-instruct": {
      "id": "meta.llama-4-scout-17b-16e-instruct",
      "litellm_id": "oci/meta.llama-4-scout-17b-16e-instruct",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 192000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/xai.grok-3": {
      "id": "xai.grok-3",
      "litellm_id": "oci/xai.grok-3",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/xai.grok-3-fast": {
      "id": "xai.grok-3-fast",
      "litellm_id": "oci/xai.grok-3-fast",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/xai.grok-3-mini": {
      "id": "xai.grok-3-mini",
      "litellm_id": "oci/xai.grok-3-mini",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/xai.grok-3-mini-fast": {
      "id": "xai.grok-3-mini-fast",
      "litellm_id": "oci/xai.grok-3-mini-fast",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/xai.grok-4": {
      "id": "xai.grok-4",
      "litellm_id": "oci/xai.grok-4",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/cohere.command-latest": {
      "id": "cohere.command-latest",
      "litellm_id": "oci/cohere.command-latest",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00156,
      "output_cost_per_1k": 0.00156,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/cohere.command-a-03-2025": {
      "id": "cohere.command-a-03-2025",
      "litellm_id": "oci/cohere.command-a-03-2025",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00156,
      "output_cost_per_1k": 0.00156,
      "capabilities": [
        "function_calling"
      ]
    },
    "oci/cohere.command-plus-latest": {
      "id": "cohere.command-plus-latest",
      "litellm_id": "oci/cohere.command-plus-latest",
      "provider": "oci",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00156,
      "output_cost_per_1k": 0.00156,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/codegeex4": {
      "id": "codegeex4",
      "litellm_id": "ollama/codegeex4",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192
    },
    "ollama/codegemma": {
      "id": "codegemma",
      "litellm_id": "ollama/codegemma",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192
    },
    "ollama/codellama": {
      "id": "codellama",
      "litellm_id": "ollama/codellama",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/deepseek-coder-v2-base": {
      "id": "deepseek-coder-v2-base",
      "litellm_id": "ollama/deepseek-coder-v2-base",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/deepseek-coder-v2-instruct": {
      "id": "deepseek-coder-v2-instruct",
      "litellm_id": "ollama/deepseek-coder-v2-instruct",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/deepseek-coder-v2-lite-base": {
      "id": "deepseek-coder-v2-lite-base",
      "litellm_id": "ollama/deepseek-coder-v2-lite-base",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/deepseek-coder-v2-lite-instruct": {
      "id": "deepseek-coder-v2-lite-instruct",
      "litellm_id": "ollama/deepseek-coder-v2-lite-instruct",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/deepseek-v3.1:671b-cloud": {
      "id": "deepseek-v3.1:671b-cloud",
      "litellm_id": "ollama/deepseek-v3.1:671b-cloud",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/gpt-oss:120b-cloud": {
      "id": "gpt-oss:120b-cloud",
      "litellm_id": "ollama/gpt-oss:120b-cloud",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/gpt-oss:20b-cloud": {
      "id": "gpt-oss:20b-cloud",
      "litellm_id": "ollama/gpt-oss:20b-cloud",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/internlm2_5-20b-chat": {
      "id": "internlm2_5-20b-chat",
      "litellm_id": "ollama/internlm2_5-20b-chat",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/llama2": {
      "id": "llama2",
      "litellm_id": "ollama/llama2",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/llama2-uncensored": {
      "id": "llama2-uncensored",
      "litellm_id": "ollama/llama2-uncensored",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/llama2:13b": {
      "id": "llama2:13b",
      "litellm_id": "ollama/llama2:13b",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/llama2:70b": {
      "id": "llama2:70b",
      "litellm_id": "ollama/llama2:70b",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/llama2:7b": {
      "id": "llama2:7b",
      "litellm_id": "ollama/llama2:7b",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/llama3": {
      "id": "llama3",
      "litellm_id": "ollama/llama3",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192
    },
    "ollama/llama3.1": {
      "id": "llama3.1",
      "litellm_id": "ollama/llama3.1",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/llama3:70b": {
      "id": "llama3:70b",
      "litellm_id": "ollama/llama3:70b",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192
    },
    "ollama/llama3:8b": {
      "id": "llama3:8b",
      "litellm_id": "ollama/llama3:8b",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192
    },
    "ollama/mistral": {
      "id": "mistral",
      "litellm_id": "ollama/mistral",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/mistral-7B-Instruct-v0.1": {
      "id": "mistral-7B-Instruct-v0.1",
      "litellm_id": "ollama/mistral-7B-Instruct-v0.1",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/mistral-7B-Instruct-v0.2": {
      "id": "mistral-7B-Instruct-v0.2",
      "litellm_id": "ollama/mistral-7B-Instruct-v0.2",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/mistral-large-instruct-2407": {
      "id": "mistral-large-instruct-2407",
      "litellm_id": "ollama/mistral-large-instruct-2407",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/mixtral-8x22B-Instruct-v0.1": {
      "id": "mixtral-8x22B-Instruct-v0.1",
      "litellm_id": "ollama/mixtral-8x22B-Instruct-v0.1",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/mixtral-8x7B-Instruct-v0.1": {
      "id": "mixtral-8x7B-Instruct-v0.1",
      "litellm_id": "ollama/mixtral-8x7B-Instruct-v0.1",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/orca-mini": {
      "id": "orca-mini",
      "litellm_id": "ollama/orca-mini",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "ollama/qwen3-coder:480b-cloud": {
      "id": "qwen3-coder:480b-cloud",
      "litellm_id": "ollama/qwen3-coder:480b-cloud",
      "provider": "ollama",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "capabilities": [
        "function_calling"
      ]
    },
    "ollama/vicuna": {
      "id": "vicuna",
      "litellm_id": "ollama/vicuna",
      "provider": "ollama",
      "mode": "completion",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048
    },
    "openai/omni-moderation-2024-09-26": {
      "id": "omni-moderation-2024-09-26",
      "litellm_id": "omni-moderation-2024-09-26",
      "provider": "openai",
      "mode": "moderation",
      "max_input_tokens": 32768,
      "max_output_tokens": 0
    },
    "openai/omni-moderation-latest": {
      "id": "omni-moderation-latest",
      "litellm_id": "omni-moderation-latest",
      "provider": "openai",
      "mode": "moderation",
      "max_input_tokens": 32768,
      "max_output_tokens": 0
    },
    "openai/omni-moderation-latest-intents": {
      "id": "omni-moderation-latest-intents",
      "litellm_id": "omni-moderation-latest-intents",
      "provider": "openai",
      "mode": "moderation",
      "max_input_tokens": 32768,
      "max_output_tokens": 0
    },
    "bedrock_converse/openai.gpt-oss-120b-1:0": {
      "id": "openai.gpt-oss-120b-1:0",
      "litellm_id": "openai.gpt-oss-120b-1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "bedrock_converse/openai.gpt-oss-20b-1:0": {
      "id": "openai.gpt-oss-20b-1:0",
      "litellm_id": "openai.gpt-oss-20b-1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "bedrock_converse/openai.gpt-oss-safeguard-120b": {
      "id": "openai.gpt-oss-safeguard-120b",
      "litellm_id": "openai.gpt-oss-safeguard-120b",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "system_messages"
      ]
    },
    "bedrock_converse/openai.gpt-oss-safeguard-20b": {
      "id": "openai.gpt-oss-safeguard-20b",
      "litellm_id": "openai.gpt-oss-safeguard-20b",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "system_messages"
      ]
    },
    "openrouter/anthropic/claude-2": {
      "id": "anthropic/claude-2",
      "litellm_id": "openrouter/anthropic/claude-2",
      "provider": "openrouter",
      "mode": "chat",
      "max_output_tokens": 8191,
      "max_input_tokens": 100000,
      "input_cost_per_1k": 0.01102,
      "output_cost_per_1k": 0.03268
    },
    "openrouter/anthropic/claude-3-5-haiku": {
      "id": "anthropic/claude-3-5-haiku",
      "litellm_id": "openrouter/anthropic/claude-3-5-haiku",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3-5-haiku-20241022": {
      "id": "anthropic/claude-3-5-haiku-20241022",
      "litellm_id": "openrouter/anthropic/claude-3-5-haiku-20241022",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3-haiku": {
      "id": "anthropic/claude-3-haiku",
      "litellm_id": "openrouter/anthropic/claude-3-haiku",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3-haiku-20240307": {
      "id": "anthropic/claude-3-haiku-20240307",
      "litellm_id": "openrouter/anthropic/claude-3-haiku-20240307",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3-opus": {
      "id": "anthropic/claude-3-opus",
      "litellm_id": "openrouter/anthropic/claude-3-opus",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3-sonnet": {
      "id": "anthropic/claude-3-sonnet",
      "litellm_id": "openrouter/anthropic/claude-3-sonnet",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
      "id": "anthropic/claude-3.5-sonnet",
      "litellm_id": "openrouter/anthropic/claude-3.5-sonnet",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3.5-sonnet:beta": {
      "id": "anthropic/claude-3.5-sonnet:beta",
      "litellm_id": "openrouter/anthropic/claude-3.5-sonnet:beta",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
      "id": "anthropic/claude-3.7-sonnet",
      "litellm_id": "openrouter/anthropic/claude-3.7-sonnet",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-3.7-sonnet:beta": {
      "id": "anthropic/claude-3.7-sonnet:beta",
      "litellm_id": "openrouter/anthropic/claude-3.7-sonnet:beta",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-instant-v1": {
      "id": "anthropic/claude-instant-v1",
      "litellm_id": "openrouter/anthropic/claude-instant-v1",
      "provider": "openrouter",
      "mode": "chat",
      "max_output_tokens": 8191,
      "max_input_tokens": 100000,
      "input_cost_per_1k": 0.00163,
      "output_cost_per_1k": 0.00551
    },
    "openrouter/anthropic/claude-opus-4": {
      "id": "anthropic/claude-opus-4",
      "litellm_id": "openrouter/anthropic/claude-opus-4",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-opus-4.1": {
      "id": "anthropic/claude-opus-4.1",
      "litellm_id": "openrouter/anthropic/claude-opus-4.1",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "litellm_id": "openrouter/anthropic/claude-sonnet-4",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-opus-4.5": {
      "id": "anthropic/claude-opus-4.5",
      "litellm_id": "openrouter/anthropic/claude-opus-4.5",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
      "id": "anthropic/claude-sonnet-4.5",
      "litellm_id": "openrouter/anthropic/claude-sonnet-4.5",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/anthropic/claude-haiku-4.5": {
      "id": "anthropic/claude-haiku-4.5",
      "litellm_id": "openrouter/anthropic/claude-haiku-4.5",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/bytedance/ui-tars-1.5-7b": {
      "id": "bytedance/ui-tars-1.5-7b",
      "litellm_id": "openrouter/bytedance/ui-tars-1.5-7b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0002
    },
    "openrouter/cognitivecomputations/dolphin-mixtral-8x7b": {
      "id": "cognitivecomputations/dolphin-mixtral-8x7b",
      "litellm_id": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 32769,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "openrouter/cohere/command-r-plus": {
      "id": "cohere/command-r-plus",
      "litellm_id": "openrouter/cohere/command-r-plus",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "openrouter/databricks/dbrx-instruct": {
      "id": "databricks/dbrx-instruct",
      "litellm_id": "openrouter/databricks/dbrx-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 32768,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006
    },
    "openrouter/deepseek/deepseek-chat": {
      "id": "deepseek/deepseek-chat",
      "litellm_id": "openrouter/deepseek/deepseek-chat",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "prompt_caching"
      ]
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
      "id": "deepseek/deepseek-chat-v3-0324",
      "litellm_id": "openrouter/deepseek/deepseek-chat-v3-0324",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "prompt_caching"
      ]
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
      "id": "deepseek/deepseek-chat-v3.1",
      "litellm_id": "openrouter/deepseek/deepseek-chat-v3.1",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/deepseek/deepseek-v3.2": {
      "id": "deepseek/deepseek-v3.2",
      "litellm_id": "openrouter/deepseek/deepseek-v3.2",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/deepseek/deepseek-v3.2-exp": {
      "id": "deepseek/deepseek-v3.2-exp",
      "litellm_id": "openrouter/deepseek/deepseek-v3.2-exp",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "prompt_caching"
      ]
    },
    "openrouter/deepseek/deepseek-coder": {
      "id": "deepseek/deepseek-coder",
      "litellm_id": "openrouter/deepseek/deepseek-coder",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "prompt_caching"
      ]
    },
    "openrouter/deepseek/deepseek-r1": {
      "id": "deepseek/deepseek-r1",
      "litellm_id": "openrouter/deepseek/deepseek-r1",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/deepseek/deepseek-r1-0528": {
      "id": "deepseek/deepseek-r1-0528",
      "litellm_id": "openrouter/deepseek/deepseek-r1-0528",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00215,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/fireworks/firellava-13b": {
      "id": "fireworks/firellava-13b",
      "litellm_id": "openrouter/fireworks/firellava-13b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "openrouter/google/gemini-2.0-flash-001": {
      "id": "google/gemini-2.0-flash-001",
      "litellm_id": "openrouter/google/gemini-2.0-flash-001",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "audio_output"
      ]
    },
    "openrouter/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "litellm_id": "openrouter/google/gemini-2.5-flash",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "audio_output"
      ]
    },
    "openrouter/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "litellm_id": "openrouter/google/gemini-2.5-pro",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "audio_output"
      ]
    },
    "openrouter/google/gemini-3-pro-preview": {
      "id": "google/gemini-3-pro-preview",
      "litellm_id": "openrouter/google/gemini-3-pro-preview",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching",
        "reasoning",
        "web_search",
        "audio_input"
      ]
    },
    "openrouter/google/gemini-pro-1.5": {
      "id": "google/gemini-pro-1.5",
      "litellm_id": "openrouter/google/gemini-pro-1.5",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.0075,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/google/gemini-pro-vision": {
      "id": "google/gemini-pro-vision",
      "litellm_id": "openrouter/google/gemini-pro-vision",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 45875,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000375,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/google/palm-2-chat-bison": {
      "id": "google/palm-2-chat-bison",
      "litellm_id": "openrouter/google/palm-2-chat-bison",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 25804,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "openrouter/google/palm-2-codechat-bison": {
      "id": "google/palm-2-codechat-bison",
      "litellm_id": "openrouter/google/palm-2-codechat-bison",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 20070,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "openrouter/gryphe/mythomax-l2-13b": {
      "id": "gryphe/mythomax-l2-13b",
      "litellm_id": "openrouter/gryphe/mythomax-l2-13b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.001875,
      "output_cost_per_1k": 0.001875
    },
    "openrouter/jondurbin/airoboros-l2-70b-2.1": {
      "id": "jondurbin/airoboros-l2-70b-2.1",
      "litellm_id": "openrouter/jondurbin/airoboros-l2-70b-2.1",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.013875,
      "output_cost_per_1k": 0.013875
    },
    "openrouter/mancer/weaver": {
      "id": "mancer/weaver",
      "litellm_id": "openrouter/mancer/weaver",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8000,
      "input_cost_per_1k": 0.005625,
      "output_cost_per_1k": 0.005625
    },
    "openrouter/meta-llama/codellama-34b-instruct": {
      "id": "meta-llama/codellama-34b-instruct",
      "litellm_id": "openrouter/meta-llama/codellama-34b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "openrouter/meta-llama/llama-2-13b-chat": {
      "id": "meta-llama/llama-2-13b-chat",
      "litellm_id": "openrouter/meta-llama/llama-2-13b-chat",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "openrouter/meta-llama/llama-2-70b-chat": {
      "id": "meta-llama/llama-2-70b-chat",
      "litellm_id": "openrouter/meta-llama/llama-2-70b-chat",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.0015
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
      "id": "meta-llama/llama-3-70b-instruct",
      "litellm_id": "openrouter/meta-llama/llama-3-70b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079
    },
    "openrouter/meta-llama/llama-3-70b-instruct:nitro": {
      "id": "meta-llama/llama-3-70b-instruct:nitro",
      "litellm_id": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "openrouter/meta-llama/llama-3-8b-instruct:extended": {
      "id": "meta-llama/llama-3-8b-instruct:extended",
      "litellm_id": "openrouter/meta-llama/llama-3-8b-instruct:extended",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 16384,
      "input_cost_per_1k": 0.000225,
      "output_cost_per_1k": 0.00225
    },
    "openrouter/meta-llama/llama-3-8b-instruct:free": {
      "id": "meta-llama/llama-3-8b-instruct:free",
      "litellm_id": "openrouter/meta-llama/llama-3-8b-instruct:free",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192
    },
    "openrouter/microsoft/wizardlm-2-8x22b:nitro": {
      "id": "microsoft/wizardlm-2-8x22b:nitro",
      "litellm_id": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 65536,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "openrouter/minimax/minimax-m2": {
      "id": "minimax/minimax-m2",
      "litellm_id": "openrouter/minimax/minimax-m2",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 204800,
      "input_cost_per_1k": 0.000255,
      "output_cost_per_1k": 0.00102,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "openrouter/mistralai/devstral-2512:free": {
      "id": "mistralai/devstral-2512:free",
      "litellm_id": "openrouter/mistralai/devstral-2512:free",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "capabilities": [
        "function_calling"
      ]
    },
    "openrouter/mistralai/devstral-2512": {
      "id": "mistralai/devstral-2512",
      "litellm_id": "openrouter/mistralai/devstral-2512",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "openrouter/mistralai/ministral-3b-2512": {
      "id": "mistralai/ministral-3b-2512",
      "litellm_id": "openrouter/mistralai/ministral-3b-2512",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/mistralai/ministral-8b-2512": {
      "id": "mistralai/ministral-8b-2512",
      "litellm_id": "openrouter/mistralai/ministral-8b-2512",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/mistralai/ministral-14b-2512": {
      "id": "mistralai/ministral-14b-2512",
      "litellm_id": "openrouter/mistralai/ministral-14b-2512",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/mistralai/mistral-large-2512": {
      "id": "mistralai/mistral-large-2512",
      "litellm_id": "openrouter/mistralai/mistral-large-2512",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/mistralai/mistral-7b-instruct": {
      "id": "mistralai/mistral-7b-instruct",
      "litellm_id": "openrouter/mistralai/mistral-7b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00013
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
      "id": "mistralai/mistral-7b-instruct:free",
      "litellm_id": "openrouter/mistralai/mistral-7b-instruct:free",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192
    },
    "openrouter/mistralai/mistral-large": {
      "id": "mistralai/mistral-large",
      "litellm_id": "openrouter/mistralai/mistral-large",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
      "id": "mistralai/mistral-small-3.1-24b-instruct",
      "litellm_id": "openrouter/mistralai/mistral-small-3.1-24b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
      "id": "mistralai/mistral-small-3.2-24b-instruct",
      "litellm_id": "openrouter/mistralai/mistral-small-3.2-24b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
      "id": "mistralai/mixtral-8x22b-instruct",
      "litellm_id": "openrouter/mistralai/mixtral-8x22b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 65536,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00065
    },
    "openrouter/nousresearch/nous-hermes-llama2-13b": {
      "id": "nousresearch/nous-hermes-llama2-13b",
      "litellm_id": "openrouter/nousresearch/nous-hermes-llama2-13b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "openrouter/openai/gpt-3.5-turbo": {
      "id": "openai/gpt-3.5-turbo",
      "litellm_id": "openrouter/openai/gpt-3.5-turbo",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4095,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
      "id": "openai/gpt-3.5-turbo-16k",
      "litellm_id": "openrouter/openai/gpt-3.5-turbo-16k",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 16383,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004
    },
    "openrouter/openai/gpt-4": {
      "id": "openai/gpt-4",
      "litellm_id": "openrouter/openai/gpt-4",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06
    },
    "openrouter/openai/gpt-4-vision-preview": {
      "id": "openai/gpt-4-vision-preview",
      "litellm_id": "openrouter/openai/gpt-4-vision-preview",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 130000,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "openrouter/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "litellm_id": "openrouter/openai/gpt-4.1",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-4.1-2025-04-14": {
      "id": "openai/gpt-4.1-2025-04-14",
      "litellm_id": "openrouter/openai/gpt-4.1-2025-04-14",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "litellm_id": "openrouter/openai/gpt-4.1-mini",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-4.1-mini-2025-04-14": {
      "id": "openai/gpt-4.1-mini-2025-04-14",
      "litellm_id": "openrouter/openai/gpt-4.1-mini-2025-04-14",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-4.1-nano": {
      "id": "openai/gpt-4.1-nano",
      "litellm_id": "openrouter/openai/gpt-4.1-nano",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-4.1-nano-2025-04-14": {
      "id": "openai/gpt-4.1-nano-2025-04-14",
      "litellm_id": "openrouter/openai/gpt-4.1-nano-2025-04-14",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-4o": {
      "id": "openai/gpt-4o",
      "litellm_id": "openrouter/openai/gpt-4o",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
      "id": "openai/gpt-4o-2024-05-13",
      "litellm_id": "openrouter/openai/gpt-4o-2024-05-13",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openrouter/openai/gpt-5-chat": {
      "id": "openai/gpt-5-chat",
      "litellm_id": "openrouter/openai/gpt-5-chat",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-5-codex": {
      "id": "openai/gpt-5-codex",
      "litellm_id": "openrouter/openai/gpt-5-codex",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-5": {
      "id": "openai/gpt-5",
      "litellm_id": "openrouter/openai/gpt-5",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-5-mini": {
      "id": "openai/gpt-5-mini",
      "litellm_id": "openrouter/openai/gpt-5-mini",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-5-nano": {
      "id": "openai/gpt-5-nano",
      "litellm_id": "openrouter/openai/gpt-5-nano",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-5.2": {
      "id": "openai/gpt-5.2",
      "litellm_id": "openrouter/openai/gpt-5.2",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-5.2-chat": {
      "id": "openai/gpt-5.2-chat",
      "litellm_id": "openrouter/openai/gpt-5.2-chat",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "vision",
        "function_calling",
        "prompt_caching"
      ]
    },
    "openrouter/openai/gpt-5.2-pro": {
      "id": "openai/gpt-5.2-pro",
      "litellm_id": "openrouter/openai/gpt-5.2-pro",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "vision",
        "function_calling",
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "litellm_id": "openrouter/openai/gpt-oss-120b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "openrouter/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "litellm_id": "openrouter/openai/gpt-oss-20b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "openrouter/openai/o1": {
      "id": "openai/o1",
      "litellm_id": "openrouter/openai/o1",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "openrouter/openai/o1-mini": {
      "id": "openai/o1-mini",
      "litellm_id": "openrouter/openai/o1-mini",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openrouter/openai/o1-mini-2024-09-12": {
      "id": "openai/o1-mini-2024-09-12",
      "litellm_id": "openrouter/openai/o1-mini-2024-09-12",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openrouter/openai/o1-preview": {
      "id": "openai/o1-preview",
      "litellm_id": "openrouter/openai/o1-preview",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openrouter/openai/o1-preview-2024-09-12": {
      "id": "openai/o1-preview-2024-09-12",
      "litellm_id": "openrouter/openai/o1-preview-2024-09-12",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openrouter/openai/o3-mini": {
      "id": "openai/o3-mini",
      "litellm_id": "openrouter/openai/o3-mini",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "reasoning"
      ]
    },
    "openrouter/openai/o3-mini-high": {
      "id": "openai/o3-mini-high",
      "litellm_id": "openrouter/openai/o3-mini-high",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "reasoning"
      ]
    },
    "openrouter/pygmalionai/mythalion-13b": {
      "id": "pygmalionai/mythalion-13b",
      "litellm_id": "openrouter/pygmalionai/mythalion-13b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.001875,
      "output_cost_per_1k": 0.001875
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
      "id": "qwen/qwen-2.5-coder-32b-instruct",
      "litellm_id": "openrouter/qwen/qwen-2.5-coder-32b-instruct",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 33792,
      "max_output_tokens": 33792,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018
    },
    "openrouter/qwen/qwen-vl-plus": {
      "id": "qwen/qwen-vl-plus",
      "litellm_id": "openrouter/qwen/qwen-vl-plus",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.00063,
      "capabilities": [
        "vision"
      ]
    },
    "openrouter/qwen/qwen3-coder": {
      "id": "qwen/qwen3-coder",
      "litellm_id": "openrouter/qwen/qwen3-coder",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 262100,
      "max_output_tokens": 262100,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00095,
      "capabilities": [
        "function_calling"
      ]
    },
    "openrouter/switchpoint/router": {
      "id": "switchpoint/router",
      "litellm_id": "openrouter/switchpoint/router",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00085,
      "output_cost_per_1k": 0.0034
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
      "id": "undi95/remm-slerp-l2-13b",
      "litellm_id": "openrouter/undi95/remm-slerp-l2-13b",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 6144,
      "input_cost_per_1k": 0.001875,
      "output_cost_per_1k": 0.001875
    },
    "openrouter/x-ai/grok-4": {
      "id": "x-ai/grok-4",
      "litellm_id": "openrouter/x-ai/grok-4",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "openrouter/x-ai/grok-4-fast:free": {
      "id": "x-ai/grok-4-fast:free",
      "litellm_id": "openrouter/x-ai/grok-4-fast:free",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "openrouter/z-ai/glm-4.6": {
      "id": "z-ai/glm-4.6",
      "litellm_id": "openrouter/z-ai/glm-4.6",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 202800,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.00175,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "openrouter/z-ai/glm-4.6:exacto": {
      "id": "z-ai/glm-4.6:exacto",
      "litellm_id": "openrouter/z-ai/glm-4.6:exacto",
      "provider": "openrouter",
      "mode": "chat",
      "max_input_tokens": 202800,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0019,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
      "id": "DeepSeek-R1-Distill-Llama-70B",
      "litellm_id": "ovhcloud/DeepSeek-R1-Distill-Llama-70B",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00067,
      "output_cost_per_1k": 0.00067,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "ovhcloud/Llama-3.1-8B-Instruct": {
      "id": "Llama-3.1-8B-Instruct",
      "litellm_id": "ovhcloud/Llama-3.1-8B-Instruct",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
      "id": "Meta-Llama-3_1-70B-Instruct",
      "litellm_id": "ovhcloud/Meta-Llama-3_1-70B-Instruct",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00067,
      "output_cost_per_1k": 0.00067
    },
    "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
      "id": "Meta-Llama-3_3-70B-Instruct",
      "litellm_id": "ovhcloud/Meta-Llama-3_3-70B-Instruct",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00067,
      "output_cost_per_1k": 0.00067,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "ovhcloud/Mistral-7B-Instruct-v0.3": {
      "id": "Mistral-7B-Instruct-v0.3",
      "litellm_id": "ovhcloud/Mistral-7B-Instruct-v0.3",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 127000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "ovhcloud/Mistral-Nemo-Instruct-2407": {
      "id": "Mistral-Nemo-Instruct-2407",
      "litellm_id": "ovhcloud/Mistral-Nemo-Instruct-2407",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 118000,
      "max_output_tokens": 118000,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
      "id": "Mistral-Small-3.2-24B-Instruct-2506",
      "litellm_id": "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "ovhcloud/Mixtral-8x7B-Instruct-v0.1": {
      "id": "Mixtral-8x7B-Instruct-v0.1",
      "litellm_id": "ovhcloud/Mixtral-8x7B-Instruct-v0.1",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00063,
      "output_cost_per_1k": 0.00063,
      "capabilities": [
        "json_mode"
      ]
    },
    "ovhcloud/Qwen2.5-Coder-32B-Instruct": {
      "id": "Qwen2.5-Coder-32B-Instruct",
      "litellm_id": "ovhcloud/Qwen2.5-Coder-32B-Instruct",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00087,
      "output_cost_per_1k": 0.00087,
      "capabilities": [
        "json_mode"
      ]
    },
    "ovhcloud/Qwen2.5-VL-72B-Instruct": {
      "id": "Qwen2.5-VL-72B-Instruct",
      "litellm_id": "ovhcloud/Qwen2.5-VL-72B-Instruct",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00091,
      "output_cost_per_1k": 0.00091,
      "capabilities": [
        "vision",
        "json_mode"
      ]
    },
    "ovhcloud/Qwen3-32B": {
      "id": "Qwen3-32B",
      "litellm_id": "ovhcloud/Qwen3-32B",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00023,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ]
    },
    "ovhcloud/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "litellm_id": "ovhcloud/gpt-oss-120b",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "json_mode",
        "reasoning"
      ]
    },
    "ovhcloud/gpt-oss-20b": {
      "id": "gpt-oss-20b",
      "litellm_id": "ovhcloud/gpt-oss-20b",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "json_mode",
        "reasoning"
      ]
    },
    "ovhcloud/llava-v1.6-mistral-7b-hf": {
      "id": "llava-v1.6-mistral-7b-hf",
      "litellm_id": "ovhcloud/llava-v1.6-mistral-7b-hf",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00029,
      "capabilities": [
        "vision",
        "json_mode"
      ]
    },
    "ovhcloud/mamba-codestral-7B-v0.1": {
      "id": "mamba-codestral-7B-v0.1",
      "litellm_id": "ovhcloud/mamba-codestral-7B-v0.1",
      "provider": "ovhcloud",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.00019,
      "output_cost_per_1k": 0.00019,
      "capabilities": [
        "json_mode"
      ]
    },
    "palm/chat-bison": {
      "id": "chat-bison",
      "litellm_id": "palm/chat-bison",
      "provider": "palm",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "palm/chat-bison-001": {
      "id": "chat-bison-001",
      "litellm_id": "palm/chat-bison-001",
      "provider": "palm",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "palm/text-bison": {
      "id": "text-bison",
      "litellm_id": "palm/text-bison",
      "provider": "palm",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "palm/text-bison-001": {
      "id": "text-bison-001",
      "litellm_id": "palm/text-bison-001",
      "provider": "palm",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "palm/text-bison-safety-off": {
      "id": "text-bison-safety-off",
      "litellm_id": "palm/text-bison-safety-off",
      "provider": "palm",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "palm/text-bison-safety-recitation-off": {
      "id": "text-bison-safety-recitation-off",
      "litellm_id": "palm/text-bison-safety-recitation-off",
      "provider": "palm",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "parallel_ai/search": {
      "id": "search",
      "litellm_id": "parallel_ai/search",
      "provider": "parallel_ai",
      "mode": "search"
    },
    "parallel_ai/search-pro": {
      "id": "search-pro",
      "litellm_id": "parallel_ai/search-pro",
      "provider": "parallel_ai",
      "mode": "search"
    },
    "perplexity/codellama-34b-instruct": {
      "id": "codellama-34b-instruct",
      "litellm_id": "perplexity/codellama-34b-instruct",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0014
    },
    "perplexity/codellama-70b-instruct": {
      "id": "codellama-70b-instruct",
      "litellm_id": "perplexity/codellama-70b-instruct",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028
    },
    "perplexity/llama-2-70b-chat": {
      "id": "llama-2-70b-chat",
      "litellm_id": "perplexity/llama-2-70b-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028
    },
    "perplexity/llama-3.1-70b-instruct": {
      "id": "llama-3.1-70b-instruct",
      "litellm_id": "perplexity/llama-3.1-70b-instruct",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "perplexity/llama-3.1-8b-instruct": {
      "id": "llama-3.1-8b-instruct",
      "litellm_id": "perplexity/llama-3.1-8b-instruct",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
      "id": "llama-3.1-sonar-huge-128k-online",
      "litellm_id": "perplexity/llama-3.1-sonar-huge-128k-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.005,
      "deprecated": true,
      "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
      "id": "llama-3.1-sonar-large-128k-chat",
      "litellm_id": "perplexity/llama-3.1-sonar-large-128k-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001,
      "deprecated": true,
      "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
      "id": "llama-3.1-sonar-large-128k-online",
      "litellm_id": "perplexity/llama-3.1-sonar-large-128k-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001,
      "deprecated": true,
      "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
      "id": "llama-3.1-sonar-small-128k-chat",
      "litellm_id": "perplexity/llama-3.1-sonar-small-128k-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "deprecated": true,
      "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
      "id": "llama-3.1-sonar-small-128k-online",
      "litellm_id": "perplexity/llama-3.1-sonar-small-128k-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "deprecated": true,
      "deprecation_date": "2025-02-22"
    },
    "perplexity/mistral-7b-instruct": {
      "id": "mistral-7b-instruct",
      "litellm_id": "perplexity/mistral-7b-instruct",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028
    },
    "perplexity/mixtral-8x7b-instruct": {
      "id": "mixtral-8x7b-instruct",
      "litellm_id": "perplexity/mixtral-8x7b-instruct",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028
    },
    "perplexity/pplx-70b-chat": {
      "id": "pplx-70b-chat",
      "litellm_id": "perplexity/pplx-70b-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028
    },
    "perplexity/pplx-70b-online": {
      "id": "pplx-70b-online",
      "litellm_id": "perplexity/pplx-70b-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "output_cost_per_1k": 0.0028
    },
    "perplexity/pplx-7b-chat": {
      "id": "pplx-7b-chat",
      "litellm_id": "perplexity/pplx-7b-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028
    },
    "perplexity/pplx-7b-online": {
      "id": "pplx-7b-online",
      "litellm_id": "perplexity/pplx-7b-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "output_cost_per_1k": 0.00028
    },
    "perplexity/sonar": {
      "id": "sonar",
      "litellm_id": "perplexity/sonar",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "web_search"
      ]
    },
    "perplexity/sonar-deep-research": {
      "id": "sonar-deep-research",
      "litellm_id": "perplexity/sonar-deep-research",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "reasoning",
        "web_search"
      ]
    },
    "perplexity/sonar-medium-chat": {
      "id": "sonar-medium-chat",
      "litellm_id": "perplexity/sonar-medium-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018
    },
    "perplexity/sonar-medium-online": {
      "id": "sonar-medium-online",
      "litellm_id": "perplexity/sonar-medium-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "output_cost_per_1k": 0.0018
    },
    "perplexity/sonar-pro": {
      "id": "sonar-pro",
      "litellm_id": "perplexity/sonar-pro",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "web_search"
      ]
    },
    "perplexity/sonar-reasoning": {
      "id": "sonar-reasoning",
      "litellm_id": "perplexity/sonar-reasoning",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "reasoning",
        "web_search"
      ]
    },
    "perplexity/sonar-reasoning-pro": {
      "id": "sonar-reasoning-pro",
      "litellm_id": "perplexity/sonar-reasoning-pro",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "reasoning",
        "web_search"
      ]
    },
    "perplexity/sonar-small-chat": {
      "id": "sonar-small-chat",
      "litellm_id": "perplexity/sonar-small-chat",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028
    },
    "perplexity/sonar-small-online": {
      "id": "sonar-small-online",
      "litellm_id": "perplexity/sonar-small-online",
      "provider": "perplexity",
      "mode": "chat",
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "output_cost_per_1k": 0.00028
    },
    "publicai/swiss-ai/apertus-8b-instruct": {
      "id": "swiss-ai/apertus-8b-instruct",
      "litellm_id": "publicai/swiss-ai/apertus-8b-instruct",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/swiss-ai/apertus-70b-instruct": {
      "id": "swiss-ai/apertus-70b-instruct",
      "litellm_id": "publicai/swiss-ai/apertus-70b-instruct",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/aisingapore/Gemma-SEA-LION-v4-27B-IT": {
      "id": "aisingapore/Gemma-SEA-LION-v4-27B-IT",
      "litellm_id": "publicai/aisingapore/Gemma-SEA-LION-v4-27B-IT",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/BSC-LT/salamandra-7b-instruct-tools-16k": {
      "id": "BSC-LT/salamandra-7b-instruct-tools-16k",
      "litellm_id": "publicai/BSC-LT/salamandra-7b-instruct-tools-16k",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/BSC-LT/ALIA-40b-instruct_Q8_0": {
      "id": "BSC-LT/ALIA-40b-instruct_Q8_0",
      "litellm_id": "publicai/BSC-LT/ALIA-40b-instruct_Q8_0",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/allenai/Olmo-3-7B-Instruct": {
      "id": "allenai/Olmo-3-7B-Instruct",
      "litellm_id": "publicai/allenai/Olmo-3-7B-Instruct",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/aisingapore/Qwen-SEA-LION-v4-32B-IT": {
      "id": "aisingapore/Qwen-SEA-LION-v4-32B-IT",
      "litellm_id": "publicai/aisingapore/Qwen-SEA-LION-v4-32B-IT",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling"
      ]
    },
    "publicai/allenai/Olmo-3-7B-Think": {
      "id": "allenai/Olmo-3-7B-Think",
      "litellm_id": "publicai/allenai/Olmo-3-7B-Think",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "publicai/allenai/Olmo-3-32B-Think": {
      "id": "allenai/Olmo-3-32B-Think",
      "litellm_id": "publicai/allenai/Olmo-3-32B-Think",
      "provider": "publicai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "bedrock_converse/qwen.qwen3-coder-480b-a35b-v1:0": {
      "id": "qwen.qwen3-coder-480b-a35b-v1:0",
      "litellm_id": "qwen.qwen3-coder-480b-a35b-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "bedrock_converse/qwen.qwen3-235b-a22b-2507-v1:0": {
      "id": "qwen.qwen3-235b-a22b-2507-v1:0",
      "litellm_id": "qwen.qwen3-235b-a22b-2507-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "bedrock_converse/qwen.qwen3-coder-30b-a3b-v1:0": {
      "id": "qwen.qwen3-coder-30b-a3b-v1:0",
      "litellm_id": "qwen.qwen3-coder-30b-a3b-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "bedrock_converse/qwen.qwen3-32b-v1:0": {
      "id": "qwen.qwen3-32b-v1:0",
      "litellm_id": "qwen.qwen3-32b-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "bedrock_converse/qwen.qwen3-next-80b-a3b": {
      "id": "qwen.qwen3-next-80b-a3b",
      "litellm_id": "qwen.qwen3-next-80b-a3b",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "system_messages"
      ]
    },
    "bedrock_converse/qwen.qwen3-vl-235b-a22b": {
      "id": "qwen.qwen3-vl-235b-a22b",
      "litellm_id": "qwen.qwen3-vl-235b-a22b",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00053,
      "output_cost_per_1k": 0.00266,
      "capabilities": [
        "vision",
        "function_calling",
        "system_messages"
      ]
    },
    "recraft/recraftv2": {
      "id": "recraftv2",
      "litellm_id": "recraft/recraftv2",
      "provider": "recraft",
      "mode": "image"
    },
    "recraft/recraftv3": {
      "id": "recraftv3",
      "litellm_id": "recraft/recraftv3",
      "provider": "recraft",
      "mode": "image"
    },
    "replicate/meta/llama-2-13b": {
      "id": "meta/llama-2-13b",
      "litellm_id": "replicate/meta/llama-2-13b",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005
    },
    "replicate/meta/llama-2-13b-chat": {
      "id": "meta/llama-2-13b-chat",
      "litellm_id": "replicate/meta/llama-2-13b-chat",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005
    },
    "replicate/meta/llama-2-70b": {
      "id": "meta/llama-2-70b",
      "litellm_id": "replicate/meta/llama-2-70b",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00275
    },
    "replicate/meta/llama-2-70b-chat": {
      "id": "meta/llama-2-70b-chat",
      "litellm_id": "replicate/meta/llama-2-70b-chat",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00275
    },
    "replicate/meta/llama-2-7b": {
      "id": "meta/llama-2-7b",
      "litellm_id": "replicate/meta/llama-2-7b",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00025
    },
    "replicate/meta/llama-2-7b-chat": {
      "id": "meta/llama-2-7b-chat",
      "litellm_id": "replicate/meta/llama-2-7b-chat",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00025
    },
    "replicate/meta/llama-3-70b": {
      "id": "meta/llama-3-70b",
      "litellm_id": "replicate/meta/llama-3-70b",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00275
    },
    "replicate/meta/llama-3-70b-instruct": {
      "id": "meta/llama-3-70b-instruct",
      "litellm_id": "replicate/meta/llama-3-70b-instruct",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.00275
    },
    "replicate/meta/llama-3-8b": {
      "id": "meta/llama-3-8b",
      "litellm_id": "replicate/meta/llama-3-8b",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00025
    },
    "replicate/meta/llama-3-8b-instruct": {
      "id": "meta/llama-3-8b-instruct",
      "litellm_id": "replicate/meta/llama-3-8b-instruct",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00025
    },
    "replicate/mistralai/mistral-7b-instruct-v0.2": {
      "id": "mistralai/mistral-7b-instruct-v0.2",
      "litellm_id": "replicate/mistralai/mistral-7b-instruct-v0.2",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00025
    },
    "replicate/mistralai/mistral-7b-v0.1": {
      "id": "mistralai/mistral-7b-v0.1",
      "litellm_id": "replicate/mistralai/mistral-7b-v0.1",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00025
    },
    "replicate/mistralai/mixtral-8x7b-instruct-v0.1": {
      "id": "mistralai/mixtral-8x7b-instruct-v0.1",
      "litellm_id": "replicate/mistralai/mixtral-8x7b-instruct-v0.1",
      "provider": "replicate",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.001
    },
    "cohere/rerank-english-v2.0": {
      "id": "rerank-english-v2.0",
      "litellm_id": "rerank-english-v2.0",
      "provider": "cohere",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "cohere/rerank-english-v3.0": {
      "id": "rerank-english-v3.0",
      "litellm_id": "rerank-english-v3.0",
      "provider": "cohere",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "cohere/rerank-multilingual-v2.0": {
      "id": "rerank-multilingual-v2.0",
      "litellm_id": "rerank-multilingual-v2.0",
      "provider": "cohere",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "cohere/rerank-multilingual-v3.0": {
      "id": "rerank-multilingual-v3.0",
      "litellm_id": "rerank-multilingual-v3.0",
      "provider": "cohere",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "cohere/rerank-v3.5": {
      "id": "rerank-v3.5",
      "litellm_id": "rerank-v3.5",
      "provider": "cohere",
      "mode": "rerank",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "nvidia_nim/nvidia/nv-rerankqa-mistral-4b-v3": {
      "id": "nvidia/nv-rerankqa-mistral-4b-v3",
      "litellm_id": "nvidia_nim/nvidia/nv-rerankqa-mistral-4b-v3",
      "provider": "nvidia_nim",
      "mode": "rerank"
    },
    "nvidia_nim/nvidia/llama-3_2-nv-rerankqa-1b-v2": {
      "id": "nvidia/llama-3_2-nv-rerankqa-1b-v2",
      "litellm_id": "nvidia_nim/nvidia/llama-3_2-nv-rerankqa-1b-v2",
      "provider": "nvidia_nim",
      "mode": "rerank"
    },
    "nvidia_nim/ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2": {
      "id": "ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2",
      "litellm_id": "nvidia_nim/ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2",
      "provider": "nvidia_nim",
      "mode": "rerank"
    },
    "aws_sagemaker/meta-textgeneration-llama-2-13b": {
      "id": "meta-textgeneration-llama-2-13b",
      "litellm_id": "sagemaker/meta-textgeneration-llama-2-13b",
      "provider": "aws_sagemaker",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_sagemaker/meta-textgeneration-llama-2-13b-f": {
      "id": "meta-textgeneration-llama-2-13b-f",
      "litellm_id": "sagemaker/meta-textgeneration-llama-2-13b-f",
      "provider": "aws_sagemaker",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_sagemaker/meta-textgeneration-llama-2-70b": {
      "id": "meta-textgeneration-llama-2-70b",
      "litellm_id": "sagemaker/meta-textgeneration-llama-2-70b",
      "provider": "aws_sagemaker",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_sagemaker/meta-textgeneration-llama-2-70b-b-f": {
      "id": "meta-textgeneration-llama-2-70b-b-f",
      "litellm_id": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
      "provider": "aws_sagemaker",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_sagemaker/meta-textgeneration-llama-2-7b": {
      "id": "meta-textgeneration-llama-2-7b",
      "litellm_id": "sagemaker/meta-textgeneration-llama-2-7b",
      "provider": "aws_sagemaker",
      "mode": "completion",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "aws_sagemaker/meta-textgeneration-llama-2-7b-f": {
      "id": "meta-textgeneration-llama-2-7b-f",
      "litellm_id": "sagemaker/meta-textgeneration-llama-2-7b-f",
      "provider": "aws_sagemaker",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "sambanova/DeepSeek-R1": {
      "id": "DeepSeek-R1",
      "litellm_id": "sambanova/DeepSeek-R1",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.007
    },
    "sambanova/DeepSeek-R1-Distill-Llama-70B": {
      "id": "DeepSeek-R1-Distill-Llama-70B",
      "litellm_id": "sambanova/DeepSeek-R1-Distill-Llama-70B",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0014
    },
    "sambanova/DeepSeek-V3-0324": {
      "id": "DeepSeek-V3-0324",
      "litellm_id": "sambanova/DeepSeek-V3-0324",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.0045,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
      "id": "Llama-4-Maverick-17B-128E-Instruct",
      "litellm_id": "sambanova/Llama-4-Maverick-17B-128E-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00063,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "sambanova/Llama-4-Scout-17B-16E-Instruct": {
      "id": "Llama-4-Scout-17B-16E-Instruct",
      "litellm_id": "sambanova/Llama-4-Scout-17B-16E-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "sambanova/Meta-Llama-3.1-405B-Instruct": {
      "id": "Meta-Llama-3.1-405B-Instruct",
      "litellm_id": "sambanova/Meta-Llama-3.1-405B-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "sambanova/Meta-Llama-3.1-8B-Instruct": {
      "id": "Meta-Llama-3.1-8B-Instruct",
      "litellm_id": "sambanova/Meta-Llama-3.1-8B-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "sambanova/Meta-Llama-3.2-1B-Instruct": {
      "id": "Meta-Llama-3.2-1B-Instruct",
      "litellm_id": "sambanova/Meta-Llama-3.2-1B-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 8e-05
    },
    "sambanova/Meta-Llama-3.2-3B-Instruct": {
      "id": "Meta-Llama-3.2-3B-Instruct",
      "litellm_id": "sambanova/Meta-Llama-3.2-3B-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00016
    },
    "sambanova/Meta-Llama-3.3-70B-Instruct": {
      "id": "Meta-Llama-3.3-70B-Instruct",
      "litellm_id": "sambanova/Meta-Llama-3.3-70B-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode"
      ]
    },
    "sambanova/Meta-Llama-Guard-3-8B": {
      "id": "Meta-Llama-Guard-3-8B",
      "litellm_id": "sambanova/Meta-Llama-Guard-3-8B",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0003
    },
    "sambanova/QwQ-32B": {
      "id": "QwQ-32B",
      "litellm_id": "sambanova/QwQ-32B",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.001
    },
    "sambanova/Qwen2-Audio-7B-Instruct": {
      "id": "Qwen2-Audio-7B-Instruct",
      "litellm_id": "sambanova/Qwen2-Audio-7B-Instruct",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.1,
      "capabilities": [
        "audio_input"
      ]
    },
    "sambanova/Qwen3-32B": {
      "id": "Qwen3-32B",
      "litellm_id": "sambanova/Qwen3-32B",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "sambanova/DeepSeek-V3.1": {
      "id": "DeepSeek-V3.1",
      "litellm_id": "sambanova/DeepSeek-V3.1",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.0045,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "sambanova/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "litellm_id": "sambanova/gpt-oss-120b",
      "provider": "sambanova",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.0045,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "snowflake/claude-3-5-sonnet": {
      "id": "claude-3-5-sonnet",
      "litellm_id": "snowflake/claude-3-5-sonnet",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 18000,
      "max_output_tokens": 8192
    },
    "snowflake/deepseek-r1": {
      "id": "deepseek-r1",
      "litellm_id": "snowflake/deepseek-r1",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "capabilities": [
        "reasoning"
      ]
    },
    "snowflake/gemma-7b": {
      "id": "gemma-7b",
      "litellm_id": "snowflake/gemma-7b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192
    },
    "snowflake/jamba-1.5-large": {
      "id": "jamba-1.5-large",
      "litellm_id": "snowflake/jamba-1.5-large",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192
    },
    "snowflake/jamba-1.5-mini": {
      "id": "jamba-1.5-mini",
      "litellm_id": "snowflake/jamba-1.5-mini",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192
    },
    "snowflake/jamba-instruct": {
      "id": "jamba-instruct",
      "litellm_id": "snowflake/jamba-instruct",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192
    },
    "snowflake/llama2-70b-chat": {
      "id": "llama2-70b-chat",
      "litellm_id": "snowflake/llama2-70b-chat",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 8192
    },
    "snowflake/llama3-70b": {
      "id": "llama3-70b",
      "litellm_id": "snowflake/llama3-70b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3-8b": {
      "id": "llama3-8b",
      "litellm_id": "snowflake/llama3-8b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3.1-405b": {
      "id": "llama3.1-405b",
      "litellm_id": "snowflake/llama3.1-405b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3.1-70b": {
      "id": "llama3.1-70b",
      "litellm_id": "snowflake/llama3.1-70b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3.1-8b": {
      "id": "llama3.1-8b",
      "litellm_id": "snowflake/llama3.1-8b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3.2-1b": {
      "id": "llama3.2-1b",
      "litellm_id": "snowflake/llama3.2-1b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3.2-3b": {
      "id": "llama3.2-3b",
      "litellm_id": "snowflake/llama3.2-3b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/llama3.3-70b": {
      "id": "llama3.3-70b",
      "litellm_id": "snowflake/llama3.3-70b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/mistral-7b": {
      "id": "mistral-7b",
      "litellm_id": "snowflake/mistral-7b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192
    },
    "snowflake/mistral-large": {
      "id": "mistral-large",
      "litellm_id": "snowflake/mistral-large",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192
    },
    "snowflake/mistral-large2": {
      "id": "mistral-large2",
      "litellm_id": "snowflake/mistral-large2",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192
    },
    "snowflake/mixtral-8x7b": {
      "id": "mixtral-8x7b",
      "litellm_id": "snowflake/mixtral-8x7b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192
    },
    "snowflake/reka-core": {
      "id": "reka-core",
      "litellm_id": "snowflake/reka-core",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192
    },
    "snowflake/reka-flash": {
      "id": "reka-flash",
      "litellm_id": "snowflake/reka-flash",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 8192
    },
    "snowflake/snowflake-arctic": {
      "id": "snowflake-arctic",
      "litellm_id": "snowflake/snowflake-arctic",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 8192
    },
    "snowflake/snowflake-llama-3.1-405b": {
      "id": "snowflake-llama-3.1-405b",
      "litellm_id": "snowflake/snowflake-llama-3.1-405b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192
    },
    "snowflake/snowflake-llama-3.3-70b": {
      "id": "snowflake-llama-3.3-70b",
      "litellm_id": "snowflake/snowflake-llama-3.3-70b",
      "provider": "snowflake",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192
    },
    "stability/sd3": {
      "id": "sd3",
      "litellm_id": "stability/sd3",
      "provider": "stability",
      "mode": "image"
    },
    "stability/sd3-large": {
      "id": "sd3-large",
      "litellm_id": "stability/sd3-large",
      "provider": "stability",
      "mode": "image"
    },
    "stability/sd3-large-turbo": {
      "id": "sd3-large-turbo",
      "litellm_id": "stability/sd3-large-turbo",
      "provider": "stability",
      "mode": "image"
    },
    "stability/sd3-medium": {
      "id": "sd3-medium",
      "litellm_id": "stability/sd3-medium",
      "provider": "stability",
      "mode": "image"
    },
    "stability/sd3.5-large": {
      "id": "sd3.5-large",
      "litellm_id": "stability/sd3.5-large",
      "provider": "stability",
      "mode": "image"
    },
    "stability/sd3.5-large-turbo": {
      "id": "sd3.5-large-turbo",
      "litellm_id": "stability/sd3.5-large-turbo",
      "provider": "stability",
      "mode": "image"
    },
    "stability/sd3.5-medium": {
      "id": "sd3.5-medium",
      "litellm_id": "stability/sd3.5-medium",
      "provider": "stability",
      "mode": "image"
    },
    "stability/stable-image-ultra": {
      "id": "stable-image-ultra",
      "litellm_id": "stability/stable-image-ultra",
      "provider": "stability",
      "mode": "image"
    },
    "stability/inpaint": {
      "id": "inpaint",
      "litellm_id": "stability/inpaint",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/outpaint": {
      "id": "outpaint",
      "litellm_id": "stability/outpaint",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/erase": {
      "id": "erase",
      "litellm_id": "stability/erase",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/search-and-replace": {
      "id": "search-and-replace",
      "litellm_id": "stability/search-and-replace",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/search-and-recolor": {
      "id": "search-and-recolor",
      "litellm_id": "stability/search-and-recolor",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/remove-background": {
      "id": "remove-background",
      "litellm_id": "stability/remove-background",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/replace-background-and-relight": {
      "id": "replace-background-and-relight",
      "litellm_id": "stability/replace-background-and-relight",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/sketch": {
      "id": "sketch",
      "litellm_id": "stability/sketch",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/structure": {
      "id": "structure",
      "litellm_id": "stability/structure",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/style": {
      "id": "style",
      "litellm_id": "stability/style",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/style-transfer": {
      "id": "style-transfer",
      "litellm_id": "stability/style-transfer",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/fast": {
      "id": "fast",
      "litellm_id": "stability/fast",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/conservative": {
      "id": "conservative",
      "litellm_id": "stability/conservative",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/creative": {
      "id": "creative",
      "litellm_id": "stability/creative",
      "provider": "stability",
      "mode": "image_edit"
    },
    "stability/stable-image-core": {
      "id": "stable-image-core",
      "litellm_id": "stability/stable-image-core",
      "provider": "stability",
      "mode": "image"
    },
    "aws_bedrock/stability.sd3-5-large-v1:0": {
      "id": "stability.sd3-5-large-v1:0",
      "litellm_id": "stability.sd3-5-large-v1:0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.sd3-large-v1:0": {
      "id": "stability.sd3-large-v1:0",
      "litellm_id": "stability.sd3-large-v1:0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-core-v1:0": {
      "id": "stability.stable-image-core-v1:0",
      "litellm_id": "stability.stable-image-core-v1:0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-conservative-upscale-v1:0": {
      "id": "stability.stable-conservative-upscale-v1:0",
      "litellm_id": "stability.stable-conservative-upscale-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-creative-upscale-v1:0": {
      "id": "stability.stable-creative-upscale-v1:0",
      "litellm_id": "stability.stable-creative-upscale-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-fast-upscale-v1:0": {
      "id": "stability.stable-fast-upscale-v1:0",
      "litellm_id": "stability.stable-fast-upscale-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-outpaint-v1:0": {
      "id": "stability.stable-outpaint-v1:0",
      "litellm_id": "stability.stable-outpaint-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-control-sketch-v1:0": {
      "id": "stability.stable-image-control-sketch-v1:0",
      "litellm_id": "stability.stable-image-control-sketch-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-control-structure-v1:0": {
      "id": "stability.stable-image-control-structure-v1:0",
      "litellm_id": "stability.stable-image-control-structure-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-erase-object-v1:0": {
      "id": "stability.stable-image-erase-object-v1:0",
      "litellm_id": "stability.stable-image-erase-object-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-inpaint-v1:0": {
      "id": "stability.stable-image-inpaint-v1:0",
      "litellm_id": "stability.stable-image-inpaint-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-remove-background-v1:0": {
      "id": "stability.stable-image-remove-background-v1:0",
      "litellm_id": "stability.stable-image-remove-background-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-search-recolor-v1:0": {
      "id": "stability.stable-image-search-recolor-v1:0",
      "litellm_id": "stability.stable-image-search-recolor-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-search-replace-v1:0": {
      "id": "stability.stable-image-search-replace-v1:0",
      "litellm_id": "stability.stable-image-search-replace-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-style-guide-v1:0": {
      "id": "stability.stable-image-style-guide-v1:0",
      "litellm_id": "stability.stable-image-style-guide-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-style-transfer-v1:0": {
      "id": "stability.stable-style-transfer-v1:0",
      "litellm_id": "stability.stable-style-transfer-v1:0",
      "provider": "aws_bedrock",
      "mode": "image_edit",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-core-v1:1": {
      "id": "stability.stable-image-core-v1:1",
      "litellm_id": "stability.stable-image-core-v1:1",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-ultra-v1:0": {
      "id": "stability.stable-image-ultra-v1:0",
      "litellm_id": "stability.stable-image-ultra-v1:0",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "aws_bedrock/stability.stable-image-ultra-v1:1": {
      "id": "stability.stable-image-ultra-v1:1",
      "litellm_id": "stability.stable-image-ultra-v1:1",
      "provider": "aws_bedrock",
      "mode": "image",
      "max_input_tokens": 77
    },
    "openai/standard/1024-x-1024/dall-e-3": {
      "id": "standard/1024-x-1024/dall-e-3",
      "litellm_id": "standard/1024-x-1024/dall-e-3",
      "provider": "openai",
      "mode": "image"
    },
    "openai/standard/1024-x-1792/dall-e-3": {
      "id": "standard/1024-x-1792/dall-e-3",
      "litellm_id": "standard/1024-x-1792/dall-e-3",
      "provider": "openai",
      "mode": "image"
    },
    "openai/standard/1792-x-1024/dall-e-3": {
      "id": "standard/1792-x-1024/dall-e-3",
      "litellm_id": "standard/1792-x-1024/dall-e-3",
      "provider": "openai",
      "mode": "image"
    },
    "linkup/search": {
      "id": "search",
      "litellm_id": "linkup/search",
      "provider": "linkup",
      "mode": "search"
    },
    "linkup/search-deep": {
      "id": "search-deep",
      "litellm_id": "linkup/search-deep",
      "provider": "linkup",
      "mode": "search"
    },
    "tavily/search": {
      "id": "search",
      "litellm_id": "tavily/search",
      "provider": "tavily",
      "mode": "search"
    },
    "tavily/search-advanced": {
      "id": "search-advanced",
      "litellm_id": "tavily/search-advanced",
      "provider": "tavily",
      "mode": "search"
    },
    "vertex_ai-text-models/text-bison": {
      "id": "text-bison",
      "litellm_id": "text-bison",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048
    },
    "vertex_ai-text-models/text-bison32k": {
      "id": "text-bison32k",
      "litellm_id": "text-bison32k",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-text-models/text-bison32k@002": {
      "id": "text-bison32k@002",
      "litellm_id": "text-bison32k@002",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.000125
    },
    "vertex_ai-text-models/text-bison@001": {
      "id": "text-bison@001",
      "litellm_id": "text-bison@001",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024
    },
    "vertex_ai-text-models/text-bison@002": {
      "id": "text-bison@002",
      "litellm_id": "text-bison@002",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024
    },
    "text-completion-codestral/codestral-2405": {
      "id": "codestral-2405",
      "litellm_id": "text-completion-codestral/codestral-2405",
      "provider": "text-completion-codestral",
      "mode": "completion",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191
    },
    "text-completion-codestral/codestral-latest": {
      "id": "codestral-latest",
      "litellm_id": "text-completion-codestral/codestral-latest",
      "provider": "text-completion-codestral",
      "mode": "completion",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191
    },
    "vertex_ai-embedding-models/text-embedding-004": {
      "id": "text-embedding-004",
      "litellm_id": "text-embedding-004",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/text-embedding-005": {
      "id": "text-embedding-005",
      "litellm_id": "text-embedding-005",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.0001
    },
    "openai/text-embedding-3-large": {
      "id": "text-embedding-3-large",
      "litellm_id": "text-embedding-3-large",
      "provider": "openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 0.00013
    },
    "openai/text-embedding-3-small": {
      "id": "text-embedding-3-small",
      "litellm_id": "text-embedding-3-small",
      "provider": "openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 2e-05
    },
    "openai/text-embedding-ada-002": {
      "id": "text-embedding-ada-002",
      "litellm_id": "text-embedding-ada-002",
      "provider": "openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 0.0001
    },
    "openai/text-embedding-ada-002-v2": {
      "id": "text-embedding-ada-002-v2",
      "litellm_id": "text-embedding-ada-002-v2",
      "provider": "openai",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/text-embedding-large-exp-03-07": {
      "id": "text-embedding-large-exp-03-07",
      "litellm_id": "text-embedding-large-exp-03-07",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/text-embedding-preview-0409": {
      "id": "text-embedding-preview-0409",
      "litellm_id": "text-embedding-preview-0409",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 6.25e-06
    },
    "openai/text-moderation-007": {
      "id": "text-moderation-007",
      "litellm_id": "text-moderation-007",
      "provider": "openai",
      "mode": "moderation",
      "max_input_tokens": 32768,
      "max_output_tokens": 0
    },
    "openai/text-moderation-latest": {
      "id": "text-moderation-latest",
      "litellm_id": "text-moderation-latest",
      "provider": "openai",
      "mode": "moderation",
      "max_input_tokens": 32768,
      "max_output_tokens": 0
    },
    "openai/text-moderation-stable": {
      "id": "text-moderation-stable",
      "litellm_id": "text-moderation-stable",
      "provider": "openai",
      "mode": "moderation",
      "max_input_tokens": 32768,
      "max_output_tokens": 0
    },
    "vertex_ai-embedding-models/text-multilingual-embedding-002": {
      "id": "text-multilingual-embedding-002",
      "litellm_id": "text-multilingual-embedding-002",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/text-multilingual-embedding-preview-0409": {
      "id": "text-multilingual-embedding-preview-0409",
      "litellm_id": "text-multilingual-embedding-preview-0409",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 6.25e-06
    },
    "vertex_ai-text-models/text-unicorn": {
      "id": "text-unicorn",
      "litellm_id": "text-unicorn",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.028
    },
    "vertex_ai-text-models/text-unicorn@001": {
      "id": "text-unicorn@001",
      "litellm_id": "text-unicorn@001",
      "provider": "vertex_ai-text-models",
      "mode": "completion",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.028
    },
    "vertex_ai-embedding-models/textembedding-gecko": {
      "id": "textembedding-gecko",
      "litellm_id": "textembedding-gecko",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/textembedding-gecko-multilingual": {
      "id": "textembedding-gecko-multilingual",
      "litellm_id": "textembedding-gecko-multilingual",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/textembedding-gecko-multilingual@001": {
      "id": "textembedding-gecko-multilingual@001",
      "litellm_id": "textembedding-gecko-multilingual@001",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/textembedding-gecko@001": {
      "id": "textembedding-gecko@001",
      "litellm_id": "textembedding-gecko@001",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 0.0001
    },
    "vertex_ai-embedding-models/textembedding-gecko@003": {
      "id": "textembedding-gecko@003",
      "litellm_id": "textembedding-gecko@003",
      "provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "max_input_tokens": 3072,
      "input_cost_per_1k": 0.0001
    },
    "together/together-ai-21.1b-41b": {
      "id": "together-ai-21.1b-41b",
      "litellm_id": "together-ai-21.1b-41b",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0008
    },
    "together/together-ai-4.1b-8b": {
      "id": "together-ai-4.1b-8b",
      "litellm_id": "together-ai-4.1b-8b",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "together/together-ai-41.1b-80b": {
      "id": "together-ai-41.1b-80b",
      "litellm_id": "together-ai-41.1b-80b",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "together/together-ai-8.1b-21b": {
      "id": "together-ai-8.1b-21b",
      "litellm_id": "together-ai-8.1b-21b",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 1000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0003
    },
    "together/together-ai-81.1b-110b": {
      "id": "together-ai-81.1b-110b",
      "litellm_id": "together-ai-81.1b-110b",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0018,
      "output_cost_per_1k": 0.0018
    },
    "together/together-ai-embedding-151m-to-350m": {
      "id": "together-ai-embedding-151m-to-350m",
      "litellm_id": "together-ai-embedding-151m-to-350m",
      "provider": "together",
      "mode": "embedding",
      "input_cost_per_1k": 1.6e-05
    },
    "together/together-ai-embedding-up-to-150m": {
      "id": "together-ai-embedding-up-to-150m",
      "litellm_id": "together-ai-embedding-up-to-150m",
      "provider": "together",
      "mode": "embedding",
      "input_cost_per_1k": 8e-06
    },
    "together/baai/bge-base-en-v1.5": {
      "id": "baai/bge-base-en-v1.5",
      "litellm_id": "together_ai/baai/bge-base-en-v1.5",
      "provider": "together",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 8e-06
    },
    "together/BAAI/bge-base-en-v1.5": {
      "id": "BAAI/bge-base-en-v1.5",
      "litellm_id": "together_ai/BAAI/bge-base-en-v1.5",
      "provider": "together",
      "mode": "embedding",
      "max_input_tokens": 512,
      "input_cost_per_1k": 8e-06
    },
    "together/together-ai-up-to-4b": {
      "id": "together-ai-up-to-4b",
      "litellm_id": "together-ai-up-to-4b",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "together/Qwen/Qwen2.5-72B-Instruct-Turbo": {
      "id": "Qwen/Qwen2.5-72B-Instruct-Turbo",
      "litellm_id": "together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/Qwen/Qwen2.5-7B-Instruct-Turbo": {
      "id": "Qwen/Qwen2.5-7B-Instruct-Turbo",
      "litellm_id": "together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
      "litellm_id": "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "litellm_id": "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 256000,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/Qwen/Qwen3-235B-A22B-fp8-tput": {
      "id": "Qwen/Qwen3-235B-A22B-fp8-tput",
      "litellm_id": "together_ai/Qwen/Qwen3-235B-A22B-fp8-tput",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 40000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006
    },
    "together/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "litellm_id": "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/deepseek-ai/DeepSeek-R1": {
      "id": "deepseek-ai/DeepSeek-R1",
      "litellm_id": "together_ai/deepseek-ai/DeepSeek-R1",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.007,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/deepseek-ai/DeepSeek-R1-0528-tput": {
      "id": "deepseek-ai/DeepSeek-R1-0528-tput",
      "litellm_id": "together_ai/deepseek-ai/DeepSeek-R1-0528-tput",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "litellm_id": "together_ai/deepseek-ai/DeepSeek-V3",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "litellm_id": "together_ai/deepseek-ai/DeepSeek-V3.1",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0017,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "reasoning"
      ]
    },
    "together/meta-llama/Llama-3.2-3B-Instruct-Turbo": {
      "id": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "litellm_id": "together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "litellm_id": "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.00088,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
      "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
      "litellm_id": "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "litellm_id": "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "litellm_id": "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "litellm_id": "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "litellm_id": "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.00088,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "litellm_id": "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "together/mistralai/Mistral-7B-Instruct-v0.1": {
      "id": "mistralai/Mistral-7B-Instruct-v0.1",
      "litellm_id": "together_ai/mistralai/Mistral-7B-Instruct-v0.1",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "together/mistralai/Mistral-Small-24B-Instruct-2501": {
      "id": "mistralai/Mistral-Small-24B-Instruct-2501",
      "litellm_id": "together_ai/mistralai/Mistral-Small-24B-Instruct-2501",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "litellm_id": "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "json_mode"
      ]
    },
    "together/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "litellm_id": "together_ai/moonshotai/Kimi-K2-Instruct",
      "provider": "together",
      "mode": "chat",
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "litellm_id": "together_ai/openai/gpt-oss-120b",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "litellm_id": "together_ai/openai/gpt-oss-20b",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/togethercomputer/CodeLlama-34b-Instruct": {
      "id": "togethercomputer/CodeLlama-34b-Instruct",
      "litellm_id": "together_ai/togethercomputer/CodeLlama-34b-Instruct",
      "provider": "together",
      "mode": "chat",
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/zai-org/GLM-4.5-Air-FP8": {
      "id": "zai-org/GLM-4.5-Air-FP8",
      "litellm_id": "together_ai/zai-org/GLM-4.5-Air-FP8",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "litellm_id": "together_ai/zai-org/GLM-4.6",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "parallel_function_calling",
        "reasoning"
      ]
    },
    "together/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "litellm_id": "together_ai/moonshotai/Kimi-K2-Instruct-0905",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 262144,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "litellm_id": "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "together/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "litellm_id": "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking",
      "provider": "together",
      "mode": "chat",
      "max_input_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "openai/tts-1": {
      "id": "tts-1",
      "litellm_id": "tts-1",
      "provider": "openai",
      "mode": "audio_speech"
    },
    "openai/tts-1-hd": {
      "id": "tts-1-hd",
      "litellm_id": "tts-1-hd",
      "provider": "openai",
      "mode": "audio_speech"
    },
    "aws_polly/standard": {
      "id": "standard",
      "litellm_id": "aws_polly/standard",
      "provider": "aws_polly",
      "mode": "audio_speech"
    },
    "aws_polly/neural": {
      "id": "neural",
      "litellm_id": "aws_polly/neural",
      "provider": "aws_polly",
      "mode": "audio_speech"
    },
    "aws_polly/long-form": {
      "id": "long-form",
      "litellm_id": "aws_polly/long-form",
      "provider": "aws_polly",
      "mode": "audio_speech"
    },
    "aws_polly/generative": {
      "id": "generative",
      "litellm_id": "aws_polly/generative",
      "provider": "aws_polly",
      "mode": "audio_speech"
    },
    "bedrock_converse/us.amazon.nova-lite-v1:0": {
      "id": "us.amazon.nova-lite-v1:0",
      "litellm_id": "us.amazon.nova-lite-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/us.amazon.nova-micro-v1:0": {
      "id": "us.amazon.nova-micro-v1:0",
      "litellm_id": "us.amazon.nova-micro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/us.amazon.nova-premier-v1:0": {
      "id": "us.amazon.nova-premier-v1:0",
      "litellm_id": "us.amazon.nova-premier-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.0125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "bedrock_converse/us.amazon.nova-pro-v1:0": {
      "id": "us.amazon.nova-pro-v1:0",
      "litellm_id": "us.amazon.nova-pro-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/us.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0055,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "litellm_id": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "id": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "litellm_id": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching"
      ]
    },
    "bedrock_converse/us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "litellm_id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "aws_bedrock/us.anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "us.anthropic.claude-3-haiku-20240307-v1:0",
      "litellm_id": "us.anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us.anthropic.claude-3-opus-20240229-v1:0": {
      "id": "us.anthropic.claude-3-opus-20240229-v1:0",
      "litellm_id": "us.anthropic.claude-3-opus-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "aws_bedrock/us.anthropic.claude-3-sonnet-20240229-v1:0": {
      "id": "us.anthropic.claude-3-sonnet-20240229-v1:0",
      "litellm_id": "us.anthropic.claude-3-sonnet-20240229-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode"
      ]
    },
    "bedrock_converse/us.anthropic.claude-opus-4-1-20250805-v1:0": {
      "id": "us.anthropic.claude-opus-4-1-20250805-v1:0",
      "litellm_id": "us.anthropic.claude-opus-4-1-20250805-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "litellm_id": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/au.anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "au.anthropic.claude-haiku-4-5-20251001-v1:0",
      "litellm_id": "au.anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0055,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/us.anthropic.claude-opus-4-20250514-v1:0": {
      "id": "us.anthropic.claude-opus-4-20250514-v1:0",
      "litellm_id": "us.anthropic.claude-opus-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/us.anthropic.claude-opus-4-5-20251101-v1:0": {
      "id": "us.anthropic.claude-opus-4-5-20251101-v1:0",
      "litellm_id": "us.anthropic.claude-opus-4-5-20251101-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/global.anthropic.claude-opus-4-5-20251101-v1:0": {
      "id": "global.anthropic.claude-opus-4-5-20251101-v1:0",
      "litellm_id": "global.anthropic.claude-opus-4-5-20251101-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/eu.anthropic.claude-opus-4-5-20251101-v1:0": {
      "id": "eu.anthropic.claude-opus-4-5-20251101-v1:0",
      "litellm_id": "eu.anthropic.claude-opus-4-5-20251101-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/us.anthropic.claude-sonnet-4-20250514-v1:0": {
      "id": "us.anthropic.claude-sonnet-4-20250514-v1:0",
      "litellm_id": "us.anthropic.claude-sonnet-4-20250514-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "bedrock_converse/us.deepseek.r1-v1:0": {
      "id": "us.deepseek.r1-v1:0",
      "litellm_id": "us.deepseek.r1-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning"
      ]
    },
    "aws_bedrock/us.meta.llama3-1-405b-instruct-v1:0": {
      "id": "us.meta.llama3-1-405b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-1-405b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00532,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us.meta.llama3-1-70b-instruct-v1:0": {
      "id": "us.meta.llama3-1-70b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-1-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00099,
      "output_cost_per_1k": 0.00099,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us.meta.llama3-1-8b-instruct-v1:0": {
      "id": "us.meta.llama3-1-8b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-1-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00022,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us.meta.llama3-2-11b-instruct-v1:0": {
      "id": "us.meta.llama3-2-11b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-2-11b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "aws_bedrock/us.meta.llama3-2-1b-instruct-v1:0": {
      "id": "us.meta.llama3-2-1b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-2-1b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us.meta.llama3-2-3b-instruct-v1:0": {
      "id": "us.meta.llama3-2-3b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-2-3b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "aws_bedrock/us.meta.llama3-2-90b-instruct-v1:0": {
      "id": "us.meta.llama3-2-90b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-2-90b-instruct-v1:0",
      "provider": "aws_bedrock",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "bedrock_converse/us.meta.llama3-3-70b-instruct-v1:0": {
      "id": "us.meta.llama3-3-70b-instruct-v1:0",
      "litellm_id": "us.meta.llama3-3-70b-instruct-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/us.meta.llama4-maverick-17b-instruct-v1:0": {
      "id": "us.meta.llama4-maverick-17b-instruct-v1:0",
      "litellm_id": "us.meta.llama4-maverick-17b-instruct-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00024,
      "output_cost_per_1k": 0.00097,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/us.meta.llama4-scout-17b-instruct-v1:0": {
      "id": "us.meta.llama4-scout-17b-instruct-v1:0",
      "litellm_id": "us.meta.llama4-scout-17b-instruct-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "function_calling"
      ]
    },
    "bedrock_converse/us.mistral.pixtral-large-2502-v1:0": {
      "id": "us.mistral.pixtral-large-2502-v1:0",
      "litellm_id": "us.mistral.pixtral-large-2502-v1:0",
      "provider": "bedrock_converse",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "v0/v0-1.0-md": {
      "id": "v0-1.0-md",
      "litellm_id": "v0/v0-1.0-md",
      "provider": "v0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "v0/v0-1.5-lg": {
      "id": "v0-1.5-lg",
      "litellm_id": "v0/v0-1.5-lg",
      "provider": "v0",
      "mode": "chat",
      "max_input_tokens": 512000,
      "max_output_tokens": 512000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "v0/v0-1.5-md": {
      "id": "v0-1.5-md",
      "litellm_id": "v0/v0-1.5-md",
      "provider": "v0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages"
      ]
    },
    "vercel_ai_gateway/alibaba/qwen-3-14b": {
      "id": "alibaba/qwen-3-14b",
      "litellm_id": "vercel_ai_gateway/alibaba/qwen-3-14b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00024
    },
    "vercel_ai_gateway/alibaba/qwen-3-235b": {
      "id": "alibaba/qwen-3-235b",
      "litellm_id": "vercel_ai_gateway/alibaba/qwen-3-235b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006
    },
    "vercel_ai_gateway/alibaba/qwen-3-30b": {
      "id": "alibaba/qwen-3-30b",
      "litellm_id": "vercel_ai_gateway/alibaba/qwen-3-30b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003
    },
    "vercel_ai_gateway/alibaba/qwen-3-32b": {
      "id": "alibaba/qwen-3-32b",
      "litellm_id": "vercel_ai_gateway/alibaba/qwen-3-32b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003
    },
    "vercel_ai_gateway/alibaba/qwen3-coder": {
      "id": "alibaba/qwen3-coder",
      "litellm_id": "vercel_ai_gateway/alibaba/qwen3-coder",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016
    },
    "vercel_ai_gateway/amazon/nova-lite": {
      "id": "amazon/nova-lite",
      "litellm_id": "vercel_ai_gateway/amazon/nova-lite",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024
    },
    "vercel_ai_gateway/amazon/nova-micro": {
      "id": "amazon/nova-micro",
      "litellm_id": "vercel_ai_gateway/amazon/nova-micro",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014
    },
    "vercel_ai_gateway/amazon/nova-pro": {
      "id": "amazon/nova-pro",
      "litellm_id": "vercel_ai_gateway/amazon/nova-pro",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032
    },
    "vercel_ai_gateway/amazon/titan-embed-text-v2": {
      "id": "amazon/titan-embed-text-v2",
      "litellm_id": "vercel_ai_gateway/amazon/titan-embed-text-v2",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 2e-05
    },
    "vercel_ai_gateway/anthropic/claude-3-haiku": {
      "id": "anthropic/claude-3-haiku",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-3-haiku",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125
    },
    "vercel_ai_gateway/anthropic/claude-3-opus": {
      "id": "anthropic/claude-3-opus",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-3-opus",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075
    },
    "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
      "id": "anthropic/claude-3.5-haiku",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-3.5-haiku",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004
    },
    "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
      "id": "anthropic/claude-3.5-sonnet",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-3.5-sonnet",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
      "id": "anthropic/claude-3.7-sonnet",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-3.7-sonnet",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/anthropic/claude-4-opus": {
      "id": "anthropic/claude-4-opus",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-4-opus",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075
    },
    "vercel_ai_gateway/anthropic/claude-4-sonnet": {
      "id": "anthropic/claude-4-sonnet",
      "litellm_id": "vercel_ai_gateway/anthropic/claude-4-sonnet",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/cohere/command-a": {
      "id": "cohere/command-a",
      "litellm_id": "vercel_ai_gateway/cohere/command-a",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "vercel_ai_gateway/cohere/command-r": {
      "id": "cohere/command-r",
      "litellm_id": "vercel_ai_gateway/cohere/command-r",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "vercel_ai_gateway/cohere/command-r-plus": {
      "id": "cohere/command-r-plus",
      "litellm_id": "vercel_ai_gateway/cohere/command-r-plus",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "vercel_ai_gateway/cohere/embed-v4.0": {
      "id": "cohere/embed-v4.0",
      "litellm_id": "vercel_ai_gateway/cohere/embed-v4.0",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00012
    },
    "vercel_ai_gateway/deepseek/deepseek-r1": {
      "id": "deepseek/deepseek-r1",
      "litellm_id": "vercel_ai_gateway/deepseek/deepseek-r1",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219
    },
    "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "litellm_id": "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.00099
    },
    "vercel_ai_gateway/deepseek/deepseek-v3": {
      "id": "deepseek/deepseek-v3",
      "litellm_id": "vercel_ai_gateway/deepseek/deepseek-v3",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "vercel_ai_gateway/google/gemini-2.0-flash": {
      "id": "google/gemini-2.0-flash",
      "litellm_id": "vercel_ai_gateway/google/gemini-2.0-flash",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
      "id": "google/gemini-2.0-flash-lite",
      "litellm_id": "vercel_ai_gateway/google/gemini-2.0-flash-lite",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003
    },
    "vercel_ai_gateway/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "litellm_id": "vercel_ai_gateway/google/gemini-2.5-flash",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025
    },
    "vercel_ai_gateway/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "litellm_id": "vercel_ai_gateway/google/gemini-2.5-pro",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "vercel_ai_gateway/google/gemini-embedding-001": {
      "id": "google/gemini-embedding-001",
      "litellm_id": "vercel_ai_gateway/google/gemini-embedding-001",
      "provider": "vercel_ai_gateway",
      "mode": "embedding",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00015
    },
    "vercel_ai_gateway/google/gemma-2-9b": {
      "id": "google/gemma-2-9b",
      "litellm_id": "vercel_ai_gateway/google/gemma-2-9b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "vercel_ai_gateway/google/text-embedding-005": {
      "id": "google/text-embedding-005",
      "litellm_id": "vercel_ai_gateway/google/text-embedding-005",
      "provider": "vercel_ai_gateway",
      "mode": "embedding",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 2.5e-05
    },
    "vercel_ai_gateway/google/text-multilingual-embedding-002": {
      "id": "google/text-multilingual-embedding-002",
      "litellm_id": "vercel_ai_gateway/google/text-multilingual-embedding-002",
      "provider": "vercel_ai_gateway",
      "mode": "embedding",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 2.5e-05
    },
    "vercel_ai_gateway/inception/mercury-coder-small": {
      "id": "inception/mercury-coder-small",
      "litellm_id": "vercel_ai_gateway/inception/mercury-coder-small",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001
    },
    "vercel_ai_gateway/meta/llama-3-70b": {
      "id": "meta/llama-3-70b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3-70b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079
    },
    "vercel_ai_gateway/meta/llama-3-8b": {
      "id": "meta/llama-3-8b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3-8b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05
    },
    "vercel_ai_gateway/meta/llama-3.1-70b": {
      "id": "meta/llama-3.1-70b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.1-70b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072
    },
    "vercel_ai_gateway/meta/llama-3.1-8b": {
      "id": "meta/llama-3.1-8b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.1-8b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05
    },
    "vercel_ai_gateway/meta/llama-3.2-11b": {
      "id": "meta/llama-3.2-11b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.2-11b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00016,
      "output_cost_per_1k": 0.00016
    },
    "vercel_ai_gateway/meta/llama-3.2-1b": {
      "id": "meta/llama-3.2-1b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.2-1b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "vercel_ai_gateway/meta/llama-3.2-3b": {
      "id": "meta/llama-3.2-3b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.2-3b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "vercel_ai_gateway/meta/llama-3.2-90b": {
      "id": "meta/llama-3.2-90b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.2-90b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072
    },
    "vercel_ai_gateway/meta/llama-3.3-70b": {
      "id": "meta/llama-3.3-70b",
      "litellm_id": "vercel_ai_gateway/meta/llama-3.3-70b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072
    },
    "vercel_ai_gateway/meta/llama-4-maverick": {
      "id": "meta/llama-4-maverick",
      "litellm_id": "vercel_ai_gateway/meta/llama-4-maverick",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006
    },
    "vercel_ai_gateway/meta/llama-4-scout": {
      "id": "meta/llama-4-scout",
      "litellm_id": "vercel_ai_gateway/meta/llama-4-scout",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003
    },
    "vercel_ai_gateway/mistral/codestral": {
      "id": "mistral/codestral",
      "litellm_id": "vercel_ai_gateway/mistral/codestral",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009
    },
    "vercel_ai_gateway/mistral/codestral-embed": {
      "id": "mistral/codestral-embed",
      "litellm_id": "vercel_ai_gateway/mistral/codestral-embed",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00015
    },
    "vercel_ai_gateway/mistral/devstral-small": {
      "id": "mistral/devstral-small",
      "litellm_id": "vercel_ai_gateway/mistral/devstral-small",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028
    },
    "vercel_ai_gateway/mistral/magistral-medium": {
      "id": "mistral/magistral-medium",
      "litellm_id": "vercel_ai_gateway/mistral/magistral-medium",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005
    },
    "vercel_ai_gateway/mistral/magistral-small": {
      "id": "mistral/magistral-small",
      "litellm_id": "vercel_ai_gateway/mistral/magistral-small",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015
    },
    "vercel_ai_gateway/mistral/ministral-3b": {
      "id": "mistral/ministral-3b",
      "litellm_id": "vercel_ai_gateway/mistral/ministral-3b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05
    },
    "vercel_ai_gateway/mistral/ministral-8b": {
      "id": "mistral/ministral-8b",
      "litellm_id": "vercel_ai_gateway/mistral/ministral-8b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "vercel_ai_gateway/mistral/mistral-embed": {
      "id": "mistral/mistral-embed",
      "litellm_id": "vercel_ai_gateway/mistral/mistral-embed",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0001
    },
    "vercel_ai_gateway/mistral/mistral-large": {
      "id": "mistral/mistral-large",
      "litellm_id": "vercel_ai_gateway/mistral/mistral-large",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006
    },
    "vercel_ai_gateway/mistral/mistral-saba-24b": {
      "id": "mistral/mistral-saba-24b",
      "litellm_id": "vercel_ai_gateway/mistral/mistral-saba-24b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00079,
      "output_cost_per_1k": 0.00079
    },
    "vercel_ai_gateway/mistral/mistral-small": {
      "id": "mistral/mistral-small",
      "litellm_id": "vercel_ai_gateway/mistral/mistral-small",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003
    },
    "vercel_ai_gateway/mistral/mixtral-8x22b-instruct": {
      "id": "mistral/mixtral-8x22b-instruct",
      "litellm_id": "vercel_ai_gateway/mistral/mixtral-8x22b-instruct",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "vercel_ai_gateway/mistral/pixtral-12b": {
      "id": "mistral/pixtral-12b",
      "litellm_id": "vercel_ai_gateway/mistral/pixtral-12b",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015
    },
    "vercel_ai_gateway/mistral/pixtral-large": {
      "id": "mistral/pixtral-large",
      "litellm_id": "vercel_ai_gateway/mistral/pixtral-large",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006
    },
    "vercel_ai_gateway/moonshotai/kimi-k2": {
      "id": "moonshotai/kimi-k2",
      "litellm_id": "vercel_ai_gateway/moonshotai/kimi-k2",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0022
    },
    "vercel_ai_gateway/morph/morph-v3-fast": {
      "id": "morph/morph-v3-fast",
      "litellm_id": "vercel_ai_gateway/morph/morph-v3-fast",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0012
    },
    "vercel_ai_gateway/morph/morph-v3-large": {
      "id": "morph/morph-v3-large",
      "litellm_id": "vercel_ai_gateway/morph/morph-v3-large",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0019
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo": {
      "id": "openai/gpt-3.5-turbo",
      "litellm_id": "vercel_ai_gateway/openai/gpt-3.5-turbo",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct": {
      "id": "openai/gpt-3.5-turbo-instruct",
      "litellm_id": "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002
    },
    "vercel_ai_gateway/openai/gpt-4-turbo": {
      "id": "openai/gpt-4-turbo",
      "litellm_id": "vercel_ai_gateway/openai/gpt-4-turbo",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03
    },
    "vercel_ai_gateway/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "litellm_id": "vercel_ai_gateway/openai/gpt-4.1",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "vercel_ai_gateway/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "litellm_id": "vercel_ai_gateway/openai/gpt-4.1-mini",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016
    },
    "vercel_ai_gateway/openai/gpt-4.1-nano": {
      "id": "openai/gpt-4.1-nano",
      "litellm_id": "vercel_ai_gateway/openai/gpt-4.1-nano",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004
    },
    "vercel_ai_gateway/openai/gpt-4o": {
      "id": "openai/gpt-4o",
      "litellm_id": "vercel_ai_gateway/openai/gpt-4o",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01
    },
    "vercel_ai_gateway/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "litellm_id": "vercel_ai_gateway/openai/gpt-4o-mini",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "vercel_ai_gateway/openai/o1": {
      "id": "openai/o1",
      "litellm_id": "vercel_ai_gateway/openai/o1",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06
    },
    "vercel_ai_gateway/openai/o3": {
      "id": "openai/o3",
      "litellm_id": "vercel_ai_gateway/openai/o3",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "vercel_ai_gateway/openai/o3-mini": {
      "id": "openai/o3-mini",
      "litellm_id": "vercel_ai_gateway/openai/o3-mini",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044
    },
    "vercel_ai_gateway/openai/o4-mini": {
      "id": "openai/o4-mini",
      "litellm_id": "vercel_ai_gateway/openai/o4-mini",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044
    },
    "vercel_ai_gateway/openai/text-embedding-3-large": {
      "id": "openai/text-embedding-3-large",
      "litellm_id": "vercel_ai_gateway/openai/text-embedding-3-large",
      "provider": "vercel_ai_gateway",
      "mode": "embedding",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00013
    },
    "vercel_ai_gateway/openai/text-embedding-3-small": {
      "id": "openai/text-embedding-3-small",
      "litellm_id": "vercel_ai_gateway/openai/text-embedding-3-small",
      "provider": "vercel_ai_gateway",
      "mode": "embedding",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 2e-05
    },
    "vercel_ai_gateway/openai/text-embedding-ada-002": {
      "id": "openai/text-embedding-ada-002",
      "litellm_id": "vercel_ai_gateway/openai/text-embedding-ada-002",
      "provider": "vercel_ai_gateway",
      "mode": "embedding",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0001
    },
    "vercel_ai_gateway/perplexity/sonar": {
      "id": "perplexity/sonar",
      "litellm_id": "vercel_ai_gateway/perplexity/sonar",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001
    },
    "vercel_ai_gateway/perplexity/sonar-pro": {
      "id": "perplexity/sonar-pro",
      "litellm_id": "vercel_ai_gateway/perplexity/sonar-pro",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning": {
      "id": "perplexity/sonar-reasoning",
      "litellm_id": "vercel_ai_gateway/perplexity/sonar-reasoning",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
      "id": "perplexity/sonar-reasoning-pro",
      "litellm_id": "vercel_ai_gateway/perplexity/sonar-reasoning-pro",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "vercel_ai_gateway/vercel/v0-1.0-md": {
      "id": "vercel/v0-1.0-md",
      "litellm_id": "vercel_ai_gateway/vercel/v0-1.0-md",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/vercel/v0-1.5-md": {
      "id": "vercel/v0-1.5-md",
      "litellm_id": "vercel_ai_gateway/vercel/v0-1.5-md",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/xai/grok-2": {
      "id": "xai/grok-2",
      "litellm_id": "vercel_ai_gateway/xai/grok-2",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01
    },
    "vercel_ai_gateway/xai/grok-2-vision": {
      "id": "xai/grok-2-vision",
      "litellm_id": "vercel_ai_gateway/xai/grok-2-vision",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01
    },
    "vercel_ai_gateway/xai/grok-3": {
      "id": "xai/grok-3",
      "litellm_id": "vercel_ai_gateway/xai/grok-3",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/xai/grok-3-fast": {
      "id": "xai/grok-3-fast",
      "litellm_id": "vercel_ai_gateway/xai/grok-3-fast",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025
    },
    "vercel_ai_gateway/xai/grok-3-mini": {
      "id": "xai/grok-3-mini",
      "litellm_id": "vercel_ai_gateway/xai/grok-3-mini",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005
    },
    "vercel_ai_gateway/xai/grok-3-mini-fast": {
      "id": "xai/grok-3-mini-fast",
      "litellm_id": "vercel_ai_gateway/xai/grok-3-mini-fast",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004
    },
    "vercel_ai_gateway/xai/grok-4": {
      "id": "xai/grok-4",
      "litellm_id": "vercel_ai_gateway/xai/grok-4",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015
    },
    "vercel_ai_gateway/zai/glm-4.5": {
      "id": "zai/glm-4.5",
      "litellm_id": "vercel_ai_gateway/zai/glm-4.5",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022
    },
    "vercel_ai_gateway/zai/glm-4.5-air": {
      "id": "zai/glm-4.5-air",
      "litellm_id": "vercel_ai_gateway/zai/glm-4.5-air",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011
    },
    "vercel_ai_gateway/zai/glm-4.6": {
      "id": "zai/glm-4.6",
      "litellm_id": "vercel_ai_gateway/zai/glm-4.6",
      "provider": "vercel_ai_gateway",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "google/chirp": {
      "id": "chirp",
      "litellm_id": "vertex_ai/chirp",
      "provider": "google",
      "mode": "audio_speech"
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-5-haiku": {
      "id": "vertex_ai/claude-3-5-haiku",
      "litellm_id": "vertex_ai/claude-3-5-haiku",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-5-haiku@20241022": {
      "id": "vertex_ai/claude-3-5-haiku@20241022",
      "litellm_id": "vertex_ai/claude-3-5-haiku@20241022",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-haiku-4-5@20251001": {
      "id": "vertex_ai/claude-haiku-4-5@20251001",
      "litellm_id": "vertex_ai/claude-haiku-4-5@20251001",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet": {
      "id": "vertex_ai/claude-3-5-sonnet",
      "litellm_id": "vertex_ai/claude-3-5-sonnet",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet-v2": {
      "id": "vertex_ai/claude-3-5-sonnet-v2",
      "litellm_id": "vertex_ai/claude-3-5-sonnet-v2",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet-v2@20241022": {
      "id": "vertex_ai/claude-3-5-sonnet-v2@20241022",
      "litellm_id": "vertex_ai/claude-3-5-sonnet-v2@20241022",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-5-sonnet@20240620": {
      "id": "vertex_ai/claude-3-5-sonnet@20240620",
      "litellm_id": "vertex_ai/claude-3-5-sonnet@20240620",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-7-sonnet@20250219": {
      "id": "vertex_ai/claude-3-7-sonnet@20250219",
      "litellm_id": "vertex_ai/claude-3-7-sonnet@20250219",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ],
      "deprecated": true,
      "deprecation_date": "2025-06-01"
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-haiku": {
      "id": "vertex_ai/claude-3-haiku",
      "litellm_id": "vertex_ai/claude-3-haiku",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-haiku@20240307": {
      "id": "vertex_ai/claude-3-haiku@20240307",
      "litellm_id": "vertex_ai/claude-3-haiku@20240307",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-opus": {
      "id": "vertex_ai/claude-3-opus",
      "litellm_id": "vertex_ai/claude-3-opus",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-opus@20240229": {
      "id": "vertex_ai/claude-3-opus@20240229",
      "litellm_id": "vertex_ai/claude-3-opus@20240229",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-sonnet": {
      "id": "vertex_ai/claude-3-sonnet",
      "litellm_id": "vertex_ai/claude-3-sonnet",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-3-sonnet@20240229": {
      "id": "vertex_ai/claude-3-sonnet@20240229",
      "litellm_id": "vertex_ai/claude-3-sonnet@20240229",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-opus-4": {
      "id": "vertex_ai/claude-opus-4",
      "litellm_id": "vertex_ai/claude-opus-4",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-opus-4-1": {
      "id": "vertex_ai/claude-opus-4-1",
      "litellm_id": "vertex_ai/claude-opus-4-1",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-opus-4-1@20250805": {
      "id": "vertex_ai/claude-opus-4-1@20250805",
      "litellm_id": "vertex_ai/claude-opus-4-1@20250805",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-opus-4-5": {
      "id": "vertex_ai/claude-opus-4-5",
      "litellm_id": "vertex_ai/claude-opus-4-5",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-opus-4-5@20251101": {
      "id": "vertex_ai/claude-opus-4-5@20251101",
      "litellm_id": "vertex_ai/claude-opus-4-5@20251101",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-sonnet-4-5": {
      "id": "vertex_ai/claude-sonnet-4-5",
      "litellm_id": "vertex_ai/claude-sonnet-4-5",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-sonnet-4-5@20250929": {
      "id": "vertex_ai/claude-sonnet-4-5@20250929",
      "litellm_id": "vertex_ai/claude-sonnet-4-5@20250929",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-opus-4@20250514": {
      "id": "vertex_ai/claude-opus-4@20250514",
      "litellm_id": "vertex_ai/claude-opus-4@20250514",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-sonnet-4": {
      "id": "vertex_ai/claude-sonnet-4",
      "litellm_id": "vertex_ai/claude-sonnet-4",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-anthropic_models/vertex_ai/claude-sonnet-4@20250514": {
      "id": "vertex_ai/claude-sonnet-4@20250514",
      "litellm_id": "vertex_ai/claude-sonnet-4@20250514",
      "provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistralai/codestral-2@001": {
      "id": "vertex_ai/mistralai/codestral-2@001",
      "litellm_id": "vertex_ai/mistralai/codestral-2@001",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/codestral-2": {
      "id": "vertex_ai/codestral-2",
      "litellm_id": "vertex_ai/codestral-2",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/codestral-2@001": {
      "id": "vertex_ai/codestral-2@001",
      "litellm_id": "vertex_ai/codestral-2@001",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistralai/codestral-2": {
      "id": "vertex_ai/mistralai/codestral-2",
      "litellm_id": "vertex_ai/mistralai/codestral-2",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/codestral-2501": {
      "id": "vertex_ai/codestral-2501",
      "litellm_id": "vertex_ai/codestral-2501",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/codestral@2405": {
      "id": "vertex_ai/codestral@2405",
      "litellm_id": "vertex_ai/codestral@2405",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/codestral@latest": {
      "id": "vertex_ai/codestral@latest",
      "litellm_id": "vertex_ai/codestral@latest",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-deepseek_models/vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
      "id": "vertex_ai/deepseek-ai/deepseek-v3.1-maas",
      "litellm_id": "vertex_ai/deepseek-ai/deepseek-v3.1-maas",
      "provider": "vertex_ai-deepseek_models",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-deepseek_models/vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
      "id": "vertex_ai/deepseek-ai/deepseek-v3.2-maas",
      "litellm_id": "vertex_ai/deepseek-ai/deepseek-v3.2-maas",
      "provider": "vertex_ai-deepseek_models",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "vertex_ai-deepseek_models/vertex_ai/deepseek-ai/deepseek-r1-0528-maas": {
      "id": "vertex_ai/deepseek-ai/deepseek-r1-0528-maas",
      "litellm_id": "vertex_ai/deepseek-ai/deepseek-r1-0528-maas",
      "provider": "vertex_ai-deepseek_models",
      "mode": "chat",
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "prompt_caching",
        "reasoning"
      ]
    },
    "google/vertex_ai/gemini-2.5-flash-image": {
      "id": "vertex_ai/gemini-2.5-flash-image",
      "litellm_id": "vertex_ai/gemini-2.5-flash-image",
      "provider": "google",
      "mode": "image",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "google/vertex_ai/gemini-3-pro-image-preview": {
      "id": "vertex_ai/gemini-3-pro-image-preview",
      "litellm_id": "vertex_ai/gemini-3-pro-image-preview",
      "provider": "google",
      "mode": "image",
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012
    },
    "vertex_ai-image-models/vertex_ai/imagegeneration@006": {
      "id": "vertex_ai/imagegeneration@006",
      "litellm_id": "vertex_ai/imagegeneration@006",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-3.0-fast-generate-001": {
      "id": "vertex_ai/imagen-3.0-fast-generate-001",
      "litellm_id": "vertex_ai/imagen-3.0-fast-generate-001",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-3.0-generate-001": {
      "id": "vertex_ai/imagen-3.0-generate-001",
      "litellm_id": "vertex_ai/imagen-3.0-generate-001",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-3.0-generate-002": {
      "id": "vertex_ai/imagen-3.0-generate-002",
      "litellm_id": "vertex_ai/imagen-3.0-generate-002",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-3.0-capability-001": {
      "id": "vertex_ai/imagen-3.0-capability-001",
      "litellm_id": "vertex_ai/imagen-3.0-capability-001",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-4.0-fast-generate-001": {
      "id": "vertex_ai/imagen-4.0-fast-generate-001",
      "litellm_id": "vertex_ai/imagen-4.0-fast-generate-001",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-4.0-generate-001": {
      "id": "vertex_ai/imagen-4.0-generate-001",
      "litellm_id": "vertex_ai/imagen-4.0-generate-001",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-image-models/vertex_ai/imagen-4.0-ultra-generate-001": {
      "id": "vertex_ai/imagen-4.0-ultra-generate-001",
      "litellm_id": "vertex_ai/imagen-4.0-ultra-generate-001",
      "provider": "vertex_ai-image-models",
      "mode": "image"
    },
    "vertex_ai-ai21_models/vertex_ai/jamba-1.5": {
      "id": "vertex_ai/jamba-1.5",
      "litellm_id": "vertex_ai/jamba-1.5",
      "provider": "vertex_ai-ai21_models",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "vertex_ai-ai21_models/vertex_ai/jamba-1.5-large": {
      "id": "vertex_ai/jamba-1.5-large",
      "litellm_id": "vertex_ai/jamba-1.5-large",
      "provider": "vertex_ai-ai21_models",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "vertex_ai-ai21_models/vertex_ai/jamba-1.5-large@001": {
      "id": "vertex_ai/jamba-1.5-large@001",
      "litellm_id": "vertex_ai/jamba-1.5-large@001",
      "provider": "vertex_ai-ai21_models",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008
    },
    "vertex_ai-ai21_models/vertex_ai/jamba-1.5-mini": {
      "id": "vertex_ai/jamba-1.5-mini",
      "litellm_id": "vertex_ai/jamba-1.5-mini",
      "provider": "vertex_ai-ai21_models",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "vertex_ai-ai21_models/vertex_ai/jamba-1.5-mini@001": {
      "id": "vertex_ai/jamba-1.5-mini@001",
      "litellm_id": "vertex_ai/jamba-1.5-mini@001",
      "provider": "vertex_ai-ai21_models",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-3.1-405b-instruct-maas": {
      "id": "vertex_ai/meta/llama-3.1-405b-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-3.1-405b-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-3.1-70b-instruct-maas": {
      "id": "vertex_ai/meta/llama-3.1-70b-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-3.1-70b-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-3.1-8b-instruct-maas": {
      "id": "vertex_ai/meta/llama-3.1-8b-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-3.1-8b-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
      "id": "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "capabilities": [
        "vision",
        "system_messages"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
      "id": "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
      "id": "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
      "id": "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 10000000,
      "max_output_tokens": 10000000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
      "id": "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 10000000,
      "max_output_tokens": 10000000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama3-405b-instruct-maas": {
      "id": "vertex_ai/meta/llama3-405b-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama3-405b-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama3-70b-instruct-maas": {
      "id": "vertex_ai/meta/llama3-70b-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama3-70b-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000
    },
    "vertex_ai-llama_models/vertex_ai/meta/llama3-8b-instruct-maas": {
      "id": "vertex_ai/meta/llama3-8b-instruct-maas",
      "litellm_id": "vertex_ai/meta/llama3-8b-instruct-maas",
      "provider": "vertex_ai-llama_models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000
    },
    "vertex_ai-minimax_models/vertex_ai/minimaxai/minimax-m2-maas": {
      "id": "vertex_ai/minimaxai/minimax-m2-maas",
      "litellm_id": "vertex_ai/minimaxai/minimax-m2-maas",
      "provider": "vertex_ai-minimax_models",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 196608,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-moonshot_models/vertex_ai/moonshotai/kimi-k2-thinking-maas": {
      "id": "vertex_ai/moonshotai/kimi-k2-thinking-maas",
      "litellm_id": "vertex_ai/moonshotai/kimi-k2-thinking-maas",
      "provider": "vertex_ai-moonshot_models",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-medium-3": {
      "id": "vertex_ai/mistral-medium-3",
      "litellm_id": "vertex_ai/mistral-medium-3",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-medium-3@001": {
      "id": "vertex_ai/mistral-medium-3@001",
      "litellm_id": "vertex_ai/mistral-medium-3@001",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistralai/mistral-medium-3": {
      "id": "vertex_ai/mistralai/mistral-medium-3",
      "litellm_id": "vertex_ai/mistralai/mistral-medium-3",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistralai/mistral-medium-3@001": {
      "id": "vertex_ai/mistralai/mistral-medium-3@001",
      "litellm_id": "vertex_ai/mistralai/mistral-medium-3@001",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-large-2411": {
      "id": "vertex_ai/mistral-large-2411",
      "litellm_id": "vertex_ai/mistral-large-2411",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-large@2407": {
      "id": "vertex_ai/mistral-large@2407",
      "litellm_id": "vertex_ai/mistral-large@2407",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-large@2411-001": {
      "id": "vertex_ai/mistral-large@2411-001",
      "litellm_id": "vertex_ai/mistral-large@2411-001",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-large@latest": {
      "id": "vertex_ai/mistral-large@latest",
      "litellm_id": "vertex_ai/mistral-large@latest",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-nemo@2407": {
      "id": "vertex_ai/mistral-nemo@2407",
      "litellm_id": "vertex_ai/mistral-nemo@2407",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-nemo@latest": {
      "id": "vertex_ai/mistral-nemo@latest",
      "litellm_id": "vertex_ai/mistral-nemo@latest",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-small-2503": {
      "id": "vertex_ai/mistral-small-2503",
      "litellm_id": "vertex_ai/mistral-small-2503",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "vertex_ai-mistral_models/vertex_ai/mistral-small-2503@001": {
      "id": "vertex_ai/mistral-small-2503@001",
      "litellm_id": "vertex_ai/mistral-small-2503@001",
      "provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling"
      ]
    },
    "google/mistral-ocr-2505": {
      "id": "mistral-ocr-2505",
      "litellm_id": "vertex_ai/mistral-ocr-2505",
      "provider": "google",
      "mode": "ocr"
    },
    "google/deepseek-ai/deepseek-ocr-maas": {
      "id": "deepseek-ai/deepseek-ocr-maas",
      "litellm_id": "vertex_ai/deepseek-ai/deepseek-ocr-maas",
      "provider": "google",
      "mode": "ocr",
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012
    },
    "vertex_ai-openai_models/vertex_ai/openai/gpt-oss-120b-maas": {
      "id": "vertex_ai/openai/gpt-oss-120b-maas",
      "litellm_id": "vertex_ai/openai/gpt-oss-120b-maas",
      "provider": "vertex_ai-openai_models",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "reasoning"
      ]
    },
    "vertex_ai-openai_models/vertex_ai/openai/gpt-oss-20b-maas": {
      "id": "vertex_ai/openai/gpt-oss-20b-maas",
      "litellm_id": "vertex_ai/openai/gpt-oss-20b-maas",
      "provider": "vertex_ai-openai_models",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "reasoning"
      ]
    },
    "vertex_ai-qwen_models/vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
      "id": "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas",
      "litellm_id": "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas",
      "provider": "vertex_ai-qwen_models",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-qwen_models/vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
      "id": "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas",
      "litellm_id": "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas",
      "provider": "vertex_ai-qwen_models",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-qwen_models/vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
      "id": "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas",
      "litellm_id": "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas",
      "provider": "vertex_ai-qwen_models",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-qwen_models/vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
      "id": "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas",
      "litellm_id": "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas",
      "provider": "vertex_ai-qwen_models",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling"
      ]
    },
    "vertex_ai-video-models/vertex_ai/veo-2.0-generate-001": {
      "id": "vertex_ai/veo-2.0-generate-001",
      "litellm_id": "vertex_ai/veo-2.0-generate-001",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.0-fast-generate-preview": {
      "id": "vertex_ai/veo-3.0-fast-generate-preview",
      "litellm_id": "vertex_ai/veo-3.0-fast-generate-preview",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.0-generate-preview": {
      "id": "vertex_ai/veo-3.0-generate-preview",
      "litellm_id": "vertex_ai/veo-3.0-generate-preview",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.0-fast-generate-001": {
      "id": "vertex_ai/veo-3.0-fast-generate-001",
      "litellm_id": "vertex_ai/veo-3.0-fast-generate-001",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.0-generate-001": {
      "id": "vertex_ai/veo-3.0-generate-001",
      "litellm_id": "vertex_ai/veo-3.0-generate-001",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.1-generate-preview": {
      "id": "vertex_ai/veo-3.1-generate-preview",
      "litellm_id": "vertex_ai/veo-3.1-generate-preview",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.1-fast-generate-preview": {
      "id": "vertex_ai/veo-3.1-fast-generate-preview",
      "litellm_id": "vertex_ai/veo-3.1-fast-generate-preview",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.1-generate-001": {
      "id": "vertex_ai/veo-3.1-generate-001",
      "litellm_id": "vertex_ai/veo-3.1-generate-001",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "vertex_ai-video-models/vertex_ai/veo-3.1-fast-generate-001": {
      "id": "vertex_ai/veo-3.1-fast-generate-001",
      "litellm_id": "vertex_ai/veo-3.1-fast-generate-001",
      "provider": "vertex_ai-video-models",
      "mode": "video_generation",
      "max_input_tokens": 1024
    },
    "voyage/rerank-2": {
      "id": "rerank-2",
      "litellm_id": "voyage/rerank-2",
      "provider": "voyage",
      "mode": "rerank",
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 5e-05
    },
    "voyage/rerank-2-lite": {
      "id": "rerank-2-lite",
      "litellm_id": "voyage/rerank-2-lite",
      "provider": "voyage",
      "mode": "rerank",
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 2e-05
    },
    "voyage/rerank-2.5": {
      "id": "rerank-2.5",
      "litellm_id": "voyage/rerank-2.5",
      "provider": "voyage",
      "mode": "rerank",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 5e-05
    },
    "voyage/rerank-2.5-lite": {
      "id": "rerank-2.5-lite",
      "litellm_id": "voyage/rerank-2.5-lite",
      "provider": "voyage",
      "mode": "rerank",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 2e-05
    },
    "voyage/voyage-2": {
      "id": "voyage-2",
      "litellm_id": "voyage/voyage-2",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 4000,
      "input_cost_per_1k": 0.0001
    },
    "voyage/voyage-3": {
      "id": "voyage-3",
      "litellm_id": "voyage/voyage-3",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 6e-05
    },
    "voyage/voyage-3-large": {
      "id": "voyage-3-large",
      "litellm_id": "voyage/voyage-3-large",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.00018
    },
    "voyage/voyage-3-lite": {
      "id": "voyage-3-lite",
      "litellm_id": "voyage/voyage-3-lite",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 2e-05
    },
    "voyage/voyage-3.5": {
      "id": "voyage-3.5",
      "litellm_id": "voyage/voyage-3.5",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 6e-05
    },
    "voyage/voyage-3.5-lite": {
      "id": "voyage-3.5-lite",
      "litellm_id": "voyage/voyage-3.5-lite",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 2e-05
    },
    "voyage/voyage-code-2": {
      "id": "voyage-code-2",
      "litellm_id": "voyage/voyage-code-2",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 16000,
      "input_cost_per_1k": 0.00012
    },
    "voyage/voyage-code-3": {
      "id": "voyage-code-3",
      "litellm_id": "voyage/voyage-code-3",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.00018
    },
    "voyage/voyage-context-3": {
      "id": "voyage-context-3",
      "litellm_id": "voyage/voyage-context-3",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 120000,
      "input_cost_per_1k": 0.00018
    },
    "voyage/voyage-finance-2": {
      "id": "voyage-finance-2",
      "litellm_id": "voyage/voyage-finance-2",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.00012
    },
    "voyage/voyage-large-2": {
      "id": "voyage-large-2",
      "litellm_id": "voyage/voyage-large-2",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 16000,
      "input_cost_per_1k": 0.00012
    },
    "voyage/voyage-law-2": {
      "id": "voyage-law-2",
      "litellm_id": "voyage/voyage-law-2",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 16000,
      "input_cost_per_1k": 0.00012
    },
    "voyage/voyage-lite-01": {
      "id": "voyage-lite-01",
      "litellm_id": "voyage/voyage-lite-01",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 4096,
      "input_cost_per_1k": 0.0001
    },
    "voyage/voyage-lite-02-instruct": {
      "id": "voyage-lite-02-instruct",
      "litellm_id": "voyage/voyage-lite-02-instruct",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 4000,
      "input_cost_per_1k": 0.0001
    },
    "voyage/voyage-multimodal-3": {
      "id": "voyage-multimodal-3",
      "litellm_id": "voyage/voyage-multimodal-3",
      "provider": "voyage",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "input_cost_per_1k": 0.00012
    },
    "wandb/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "litellm_id": "wandb/openai/gpt-oss-120b",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 15.0,
      "output_cost_per_1k": 60.0
    },
    "wandb/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "litellm_id": "wandb/openai/gpt-oss-20b",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5.0,
      "output_cost_per_1k": 20.0
    },
    "wandb/zai-org/GLM-4.5": {
      "id": "zai-org/GLM-4.5",
      "litellm_id": "wandb/zai-org/GLM-4.5",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 55.0,
      "output_cost_per_1k": 200.0
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "litellm_id": "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 10.0,
      "output_cost_per_1k": 10.0
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "litellm_id": "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 100.0,
      "output_cost_per_1k": 150.0
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "litellm_id": "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 10.0,
      "output_cost_per_1k": 10.0
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "litellm_id": "wandb/moonshotai/Kimi-K2-Instruct",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "litellm_id": "wandb/meta-llama/Llama-3.1-8B-Instruct",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 22.0,
      "output_cost_per_1k": 22.0
    },
    "wandb/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "litellm_id": "wandb/deepseek-ai/DeepSeek-V3.1",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 55.0,
      "output_cost_per_1k": 165.0
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "litellm_id": "wandb/deepseek-ai/DeepSeek-R1-0528",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 161000,
      "max_output_tokens": 161000,
      "input_cost_per_1k": 135.0,
      "output_cost_per_1k": 540.0
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "litellm_id": "wandb/deepseek-ai/DeepSeek-V3-0324",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 161000,
      "max_output_tokens": 161000,
      "input_cost_per_1k": 114.0,
      "output_cost_per_1k": 275.0
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "litellm_id": "wandb/meta-llama/Llama-3.3-70B-Instruct",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 71.0,
      "output_cost_per_1k": 71.0
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "litellm_id": "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 17.0,
      "output_cost_per_1k": 66.0
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
      "id": "microsoft/Phi-4-mini-instruct",
      "litellm_id": "wandb/microsoft/Phi-4-mini-instruct",
      "provider": "wandb",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 8.0,
      "output_cost_per_1k": 35.0
    },
    "watsonx/ibm/granite-3-8b-instruct": {
      "id": "ibm/granite-3-8b-instruct",
      "litellm_id": "watsonx/ibm/granite-3-8b-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "watsonx/mistralai/mistral-large": {
      "id": "mistralai/mistral-large",
      "litellm_id": "watsonx/mistralai/mistral-large",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "system_messages",
        "json_mode",
        "prompt_caching"
      ]
    },
    "watsonx/bigscience/mt0-xxl-13b": {
      "id": "bigscience/mt0-xxl-13b",
      "litellm_id": "watsonx/bigscience/mt0-xxl-13b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.5,
      "output_cost_per_1k": 2.0
    },
    "watsonx/core42/jais-13b-chat": {
      "id": "core42/jais-13b-chat",
      "litellm_id": "watsonx/core42/jais-13b-chat",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.5,
      "output_cost_per_1k": 2.0
    },
    "watsonx/google/flan-t5-xl-3b": {
      "id": "google/flan-t5-xl-3b",
      "litellm_id": "watsonx/google/flan-t5-xl-3b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006
    },
    "watsonx/ibm/granite-13b-chat-v2": {
      "id": "ibm/granite-13b-chat-v2",
      "litellm_id": "watsonx/ibm/granite-13b-chat-v2",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006
    },
    "watsonx/ibm/granite-13b-instruct-v2": {
      "id": "ibm/granite-13b-instruct-v2",
      "litellm_id": "watsonx/ibm/granite-13b-instruct-v2",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006
    },
    "watsonx/ibm/granite-3-3-8b-instruct": {
      "id": "ibm/granite-3-3-8b-instruct",
      "litellm_id": "watsonx/ibm/granite-3-3-8b-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/ibm/granite-4-h-small": {
      "id": "ibm/granite-4-h-small",
      "litellm_id": "watsonx/ibm/granite-4-h-small",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 20480,
      "max_output_tokens": 20480,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/ibm/granite-guardian-3-2-2b": {
      "id": "ibm/granite-guardian-3-2-2b",
      "litellm_id": "watsonx/ibm/granite-guardian-3-2-2b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "watsonx/ibm/granite-guardian-3-3-8b": {
      "id": "ibm/granite-guardian-3-3-8b",
      "litellm_id": "watsonx/ibm/granite-guardian-3-3-8b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "watsonx/ibm/granite-ttm-1024-96-r2": {
      "id": "ibm/granite-ttm-1024-96-r2",
      "litellm_id": "watsonx/ibm/granite-ttm-1024-96-r2",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 512,
      "max_output_tokens": 512,
      "input_cost_per_1k": 0.00038,
      "output_cost_per_1k": 0.00038
    },
    "watsonx/ibm/granite-ttm-1536-96-r2": {
      "id": "ibm/granite-ttm-1536-96-r2",
      "litellm_id": "watsonx/ibm/granite-ttm-1536-96-r2",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 512,
      "max_output_tokens": 512,
      "input_cost_per_1k": 0.00038,
      "output_cost_per_1k": 0.00038
    },
    "watsonx/ibm/granite-ttm-512-96-r2": {
      "id": "ibm/granite-ttm-512-96-r2",
      "litellm_id": "watsonx/ibm/granite-ttm-512-96-r2",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 512,
      "max_output_tokens": 512,
      "input_cost_per_1k": 0.00038,
      "output_cost_per_1k": 0.00038
    },
    "watsonx/ibm/granite-vision-3-2-2b": {
      "id": "ibm/granite-vision-3-2-2b",
      "litellm_id": "watsonx/ibm/granite-vision-3-2-2b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "vision"
      ]
    },
    "watsonx/meta-llama/llama-3-2-11b-vision-instruct": {
      "id": "meta-llama/llama-3-2-11b-vision-instruct",
      "litellm_id": "watsonx/meta-llama/llama-3-2-11b-vision-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/meta-llama/llama-3-2-1b-instruct": {
      "id": "meta-llama/llama-3-2-1b-instruct",
      "litellm_id": "watsonx/meta-llama/llama-3-2-1b-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/meta-llama/llama-3-2-3b-instruct": {
      "id": "meta-llama/llama-3-2-3b-instruct",
      "litellm_id": "watsonx/meta-llama/llama-3-2-3b-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/meta-llama/llama-3-2-90b-vision-instruct": {
      "id": "meta-llama/llama-3-2-90b-vision-instruct",
      "litellm_id": "watsonx/meta-llama/llama-3-2-90b-vision-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "vision",
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/meta-llama/llama-3-3-70b-instruct": {
      "id": "meta-llama/llama-3-3-70b-instruct",
      "litellm_id": "watsonx/meta-llama/llama-3-3-70b-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00071,
      "output_cost_per_1k": 0.00071,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/meta-llama/llama-4-maverick-17b": {
      "id": "meta-llama/llama-4-maverick-17b",
      "litellm_id": "watsonx/meta-llama/llama-4-maverick-17b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/meta-llama/llama-guard-3-11b-vision": {
      "id": "meta-llama/llama-guard-3-11b-vision",
      "litellm_id": "watsonx/meta-llama/llama-guard-3-11b-vision",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "vision"
      ]
    },
    "watsonx/mistralai/mistral-medium-2505": {
      "id": "mistralai/mistral-medium-2505",
      "litellm_id": "watsonx/mistralai/mistral-medium-2505",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/mistralai/mistral-small-2503": {
      "id": "mistralai/mistral-small-2503",
      "litellm_id": "watsonx/mistralai/mistral-small-2503",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503": {
      "id": "mistralai/mistral-small-3-1-24b-instruct-2503",
      "litellm_id": "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "parallel_function_calling"
      ]
    },
    "watsonx/mistralai/pixtral-12b-2409": {
      "id": "mistralai/pixtral-12b-2409",
      "litellm_id": "watsonx/mistralai/pixtral-12b-2409",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "vision"
      ]
    },
    "watsonx/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "litellm_id": "watsonx/openai/gpt-oss-120b",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "watsonx/sdaia/allam-1-13b-instruct": {
      "id": "sdaia/allam-1-13b-instruct",
      "litellm_id": "watsonx/sdaia/allam-1-13b-instruct",
      "provider": "watsonx",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0018,
      "output_cost_per_1k": 0.0018
    },
    "watsonx/whisper-large-v3-turbo": {
      "id": "whisper-large-v3-turbo",
      "litellm_id": "watsonx/whisper-large-v3-turbo",
      "provider": "watsonx",
      "mode": "audio_transcription"
    },
    "openai/whisper-1": {
      "id": "whisper-1",
      "litellm_id": "whisper-1",
      "provider": "openai",
      "mode": "audio_transcription"
    },
    "xai/grok-2": {
      "id": "grok-2",
      "litellm_id": "xai/grok-2",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-2-1212": {
      "id": "grok-2-1212",
      "litellm_id": "xai/grok-2-1212",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-2-latest": {
      "id": "grok-2-latest",
      "litellm_id": "xai/grok-2-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-2-vision": {
      "id": "grok-2-vision",
      "litellm_id": "xai/grok-2-vision",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-2-vision-1212": {
      "id": "grok-2-vision-1212",
      "litellm_id": "xai/grok-2-vision-1212",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-2-vision-latest": {
      "id": "grok-2-vision-latest",
      "litellm_id": "xai/grok-2-vision-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "vision",
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-3": {
      "id": "grok-3",
      "litellm_id": "xai/grok-3",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-3-beta": {
      "id": "grok-3-beta",
      "litellm_id": "xai/grok-3-beta",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-3-fast-beta": {
      "id": "grok-3-fast-beta",
      "litellm_id": "xai/grok-3-fast-beta",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-3-fast-latest": {
      "id": "grok-3-fast-latest",
      "litellm_id": "xai/grok-3-fast-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-3-latest": {
      "id": "grok-3-latest",
      "litellm_id": "xai/grok-3-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-3-mini": {
      "id": "grok-3-mini",
      "litellm_id": "xai/grok-3-mini",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "xai/grok-3-mini-beta": {
      "id": "grok-3-mini-beta",
      "litellm_id": "xai/grok-3-mini-beta",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "xai/grok-3-mini-fast": {
      "id": "grok-3-mini-fast",
      "litellm_id": "xai/grok-3-mini-fast",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "xai/grok-3-mini-fast-beta": {
      "id": "grok-3-mini-fast-beta",
      "litellm_id": "xai/grok-3-mini-fast-beta",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "xai/grok-3-mini-fast-latest": {
      "id": "grok-3-mini-fast-latest",
      "litellm_id": "xai/grok-3-mini-fast-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "xai/grok-3-mini-latest": {
      "id": "grok-3-mini-latest",
      "litellm_id": "xai/grok-3-mini-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "web_search"
      ]
    },
    "xai/grok-4": {
      "id": "grok-4",
      "litellm_id": "xai/grok-4",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-4-fast-reasoning": {
      "id": "grok-4-fast-reasoning",
      "litellm_id": "xai/grok-4-fast-reasoning",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "litellm_id": "xai/grok-4-fast-non-reasoning",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-4-0709": {
      "id": "grok-4-0709",
      "litellm_id": "xai/grok-4-0709",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-4-latest": {
      "id": "grok-4-latest",
      "litellm_id": "xai/grok-4-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-4-1-fast": {
      "id": "grok-4-1-fast",
      "litellm_id": "xai/grok-4-1-fast",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "reasoning",
        "web_search",
        "audio_input"
      ]
    },
    "xai/grok-4-1-fast-reasoning": {
      "id": "grok-4-1-fast-reasoning",
      "litellm_id": "xai/grok-4-1-fast-reasoning",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "reasoning",
        "web_search",
        "audio_input"
      ]
    },
    "xai/grok-4-1-fast-reasoning-latest": {
      "id": "grok-4-1-fast-reasoning-latest",
      "litellm_id": "xai/grok-4-1-fast-reasoning-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "reasoning",
        "web_search",
        "audio_input"
      ]
    },
    "xai/grok-4-1-fast-non-reasoning": {
      "id": "grok-4-1-fast-non-reasoning",
      "litellm_id": "xai/grok-4-1-fast-non-reasoning",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "web_search",
        "audio_input"
      ]
    },
    "xai/grok-4-1-fast-non-reasoning-latest": {
      "id": "grok-4-1-fast-non-reasoning-latest",
      "litellm_id": "xai/grok-4-1-fast-non-reasoning-latest",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 2000000.0,
      "max_output_tokens": 2000000.0,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "vision",
        "function_calling",
        "json_mode",
        "web_search",
        "audio_input"
      ]
    },
    "xai/grok-beta": {
      "id": "grok-beta",
      "litellm_id": "xai/grok-beta",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "web_search"
      ]
    },
    "xai/grok-code-fast": {
      "id": "grok-code-fast",
      "litellm_id": "xai/grok-code-fast",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "xai/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "litellm_id": "xai/grok-code-fast-1",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "xai/grok-code-fast-1-0825": {
      "id": "grok-code-fast-1-0825",
      "litellm_id": "xai/grok-code-fast-1-0825",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning"
      ]
    },
    "xai/grok-vision-beta": {
      "id": "grok-vision-beta",
      "litellm_id": "xai/grok-vision-beta",
      "provider": "xai",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "vision",
        "function_calling",
        "web_search"
      ]
    },
    "zai/glm-4.6": {
      "id": "glm-4.6",
      "litellm_id": "zai/glm-4.6",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling"
      ]
    },
    "zai/glm-4.5": {
      "id": "glm-4.5",
      "litellm_id": "zai/glm-4.5",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling"
      ]
    },
    "zai/glm-4.5v": {
      "id": "glm-4.5v",
      "litellm_id": "zai/glm-4.5v",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "vision",
        "function_calling"
      ]
    },
    "zai/glm-4.5-x": {
      "id": "glm-4.5-x",
      "litellm_id": "zai/glm-4.5-x",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0022,
      "output_cost_per_1k": 0.0089,
      "capabilities": [
        "function_calling"
      ]
    },
    "zai/glm-4.5-air": {
      "id": "glm-4.5-air",
      "litellm_id": "zai/glm-4.5-air",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling"
      ]
    },
    "zai/glm-4.5-airx": {
      "id": "glm-4.5-airx",
      "litellm_id": "zai/glm-4.5-airx",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0045,
      "capabilities": [
        "function_calling"
      ]
    },
    "zai/glm-4-32b-0414-128k": {
      "id": "glm-4-32b-0414-128k",
      "litellm_id": "zai/glm-4-32b-0414-128k",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling"
      ]
    },
    "zai/glm-4.5-flash": {
      "id": "glm-4.5-flash",
      "litellm_id": "zai/glm-4.5-flash",
      "provider": "zai",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "capabilities": [
        "function_calling"
      ]
    },
    "google/search_api": {
      "id": "search_api",
      "litellm_id": "vertex_ai/search_api",
      "provider": "google",
      "mode": "vector_store"
    },
    "openai/container": {
      "id": "container",
      "litellm_id": "openai/container",
      "provider": "openai",
      "mode": "chat"
    },
    "openai/sora-2": {
      "id": "sora-2",
      "litellm_id": "openai/sora-2",
      "provider": "openai",
      "mode": "video_generation"
    },
    "openai/sora-2-pro": {
      "id": "sora-2-pro",
      "litellm_id": "openai/sora-2-pro",
      "provider": "openai",
      "mode": "video_generation"
    },
    "azure_openai/sora-2": {
      "id": "sora-2",
      "litellm_id": "azure/sora-2",
      "provider": "azure_openai",
      "mode": "video_generation"
    },
    "azure_openai/sora-2-pro": {
      "id": "sora-2-pro",
      "litellm_id": "azure/sora-2-pro",
      "provider": "azure_openai",
      "mode": "video_generation"
    },
    "azure_openai/sora-2-pro-high-res": {
      "id": "sora-2-pro-high-res",
      "litellm_id": "azure/sora-2-pro-high-res",
      "provider": "azure_openai",
      "mode": "video_generation"
    },
    "runwayml/gen4_turbo": {
      "id": "gen4_turbo",
      "litellm_id": "runwayml/gen4_turbo",
      "provider": "runwayml",
      "mode": "video_generation"
    },
    "runwayml/gen4_aleph": {
      "id": "gen4_aleph",
      "litellm_id": "runwayml/gen4_aleph",
      "provider": "runwayml",
      "mode": "video_generation"
    },
    "runwayml/gen3a_turbo": {
      "id": "gen3a_turbo",
      "litellm_id": "runwayml/gen3a_turbo",
      "provider": "runwayml",
      "mode": "video_generation"
    },
    "runwayml/gen4_image": {
      "id": "gen4_image",
      "litellm_id": "runwayml/gen4_image",
      "provider": "runwayml",
      "mode": "image"
    },
    "runwayml/gen4_image_turbo": {
      "id": "gen4_image_turbo",
      "litellm_id": "runwayml/gen4_image_turbo",
      "provider": "runwayml",
      "mode": "image"
    },
    "runwayml/eleven_multilingual_v2": {
      "id": "eleven_multilingual_v2",
      "litellm_id": "runwayml/eleven_multilingual_v2",
      "provider": "runwayml",
      "mode": "audio_speech"
    },
    "fireworks/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
      "id": "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/flux-kontext-pro": {
      "id": "accounts/fireworks/models/flux-kontext-pro",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-kontext-pro",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05
    },
    "fireworks/accounts/fireworks/models/SSD-1B": {
      "id": "accounts/fireworks/models/SSD-1B",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/SSD-1B",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1.3e-07,
      "output_cost_per_1k": 1.3e-07
    },
    "fireworks/accounts/fireworks/models/chronos-hermes-13b-v2": {
      "id": "accounts/fireworks/models/chronos-hermes-13b-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/chronos-hermes-13b-v2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-llama-13b": {
      "id": "accounts/fireworks/models/code-llama-13b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-13b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-llama-13b-instruct": {
      "id": "accounts/fireworks/models/code-llama-13b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-13b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-llama-13b-python": {
      "id": "accounts/fireworks/models/code-llama-13b-python",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-13b-python",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-llama-34b": {
      "id": "accounts/fireworks/models/code-llama-34b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-34b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/code-llama-34b-instruct": {
      "id": "accounts/fireworks/models/code-llama-34b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-34b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/code-llama-34b-python": {
      "id": "accounts/fireworks/models/code-llama-34b-python",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-34b-python",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/code-llama-70b": {
      "id": "accounts/fireworks/models/code-llama-70b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-70b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/code-llama-70b-instruct": {
      "id": "accounts/fireworks/models/code-llama-70b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-70b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/code-llama-70b-python": {
      "id": "accounts/fireworks/models/code-llama-70b-python",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-70b-python",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/code-llama-7b": {
      "id": "accounts/fireworks/models/code-llama-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-llama-7b-instruct": {
      "id": "accounts/fireworks/models/code-llama-7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-llama-7b-python": {
      "id": "accounts/fireworks/models/code-llama-7b-python",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-llama-7b-python",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/code-qwen-1p5-7b": {
      "id": "accounts/fireworks/models/code-qwen-1p5-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/code-qwen-1p5-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/codegemma-2b": {
      "id": "accounts/fireworks/models/codegemma-2b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/codegemma-2b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/codegemma-7b": {
      "id": "accounts/fireworks/models/codegemma-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/codegemma-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/cogito-671b-v2-p1": {
      "id": "accounts/fireworks/models/cogito-671b-v2-p1",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/cogito-v1-preview-llama-3b": {
      "id": "accounts/fireworks/models/cogito-v1-preview-llama-3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/cogito-v1-preview-llama-70b": {
      "id": "accounts/fireworks/models/cogito-v1-preview-llama-70b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/cogito-v1-preview-llama-8b": {
      "id": "accounts/fireworks/models/cogito-v1-preview-llama-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
      "id": "accounts/fireworks/models/cogito-v1-preview-qwen-14b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
      "id": "accounts/fireworks/models/cogito-v1-preview-qwen-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/flux-kontext-max": {
      "id": "accounts/fireworks/models/flux-kontext-max",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-kontext-max",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 8e-05
    },
    "fireworks/accounts/fireworks/models/dbrx-instruct": {
      "id": "accounts/fireworks/models/dbrx-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/dbrx-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-1b-base": {
      "id": "accounts/fireworks/models/deepseek-coder-1b-base",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-1b-base",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-33b-instruct": {
      "id": "accounts/fireworks/models/deepseek-coder-33b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-33b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-7b-base": {
      "id": "accounts/fireworks/models/deepseek-coder-7b-base",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-7b-base-v1p5": {
      "id": "accounts/fireworks/models/deepseek-coder-7b-base-v1p5",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base-v1p5",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5": {
      "id": "accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-v2-lite-base": {
      "id": "accounts/fireworks/models/deepseek-coder-v2-lite-base",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
      "id": "accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/deepseek-prover-v2": {
      "id": "accounts/fireworks/models/deepseek-prover-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
      "id": "accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
      "id": "accounts/fireworks/models/deepseek-r1-distill-llama-70b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
      "id": "accounts/fireworks/models/deepseek-r1-distill-llama-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
      "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-14b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
      "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
      "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
      "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/deepseek-v2-lite-chat": {
      "id": "accounts/fireworks/models/deepseek-v2-lite-chat",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/deepseek-v2p5": {
      "id": "accounts/fireworks/models/deepseek-v2p5",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/deepseek-v2p5",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/devstral-small-2505": {
      "id": "accounts/fireworks/models/devstral-small-2505",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/devstral-small-2505",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
      "id": "accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
      "id": "accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
      "id": "accounts/fireworks/models/dolphin-2-9-2-qwen2-72b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b": {
      "id": "accounts/fireworks/models/dolphin-2p6-mixtral-8x7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/ernie-4p5-21b-a3b-pt": {
      "id": "accounts/fireworks/models/ernie-4p5-21b-a3b-pt",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/ernie-4p5-21b-a3b-pt",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/ernie-4p5-300b-a47b-pt": {
      "id": "accounts/fireworks/models/ernie-4p5-300b-a47b-pt",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/ernie-4p5-300b-a47b-pt",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/fare-20b": {
      "id": "accounts/fireworks/models/fare-20b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/fare-20b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/firefunction-v1": {
      "id": "accounts/fireworks/models/firefunction-v1",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/firefunction-v1",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/firellava-13b": {
      "id": "accounts/fireworks/models/firellava-13b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/firellava-13b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/firesearch-ocr-v6": {
      "id": "accounts/fireworks/models/firesearch-ocr-v6",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/firesearch-ocr-v6",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/fireworks-asr-large": {
      "id": "accounts/fireworks/models/fireworks-asr-large",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/fireworks-asr-large",
      "provider": "fireworks",
      "mode": "audio_transcription",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "fireworks/accounts/fireworks/models/fireworks-asr-v2": {
      "id": "accounts/fireworks/models/fireworks-asr-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/fireworks-asr-v2",
      "provider": "fireworks",
      "mode": "audio_transcription",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "fireworks/accounts/fireworks/models/flux-1-dev": {
      "id": "accounts/fireworks/models/flux-1-dev",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-1-dev",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/flux-1-dev-controlnet-union": {
      "id": "accounts/fireworks/models/flux-1-dev-controlnet-union",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-1-dev-controlnet-union",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1e-06,
      "output_cost_per_1k": 1e-06
    },
    "fireworks/accounts/fireworks/models/flux-1-dev-fp8": {
      "id": "accounts/fireworks/models/flux-1-dev-fp8",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-1-dev-fp8",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-07,
      "output_cost_per_1k": 5e-07
    },
    "fireworks/accounts/fireworks/models/flux-1-schnell": {
      "id": "accounts/fireworks/models/flux-1-schnell",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-1-schnell",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/flux-1-schnell-fp8": {
      "id": "accounts/fireworks/models/flux-1-schnell-fp8",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/flux-1-schnell-fp8",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3.5e-07,
      "output_cost_per_1k": 3.5e-07
    },
    "fireworks/accounts/fireworks/models/gemma-2b-it": {
      "id": "accounts/fireworks/models/gemma-2b-it",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gemma-2b-it",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/gemma-3-27b-it": {
      "id": "accounts/fireworks/models/gemma-3-27b-it",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/gemma-7b": {
      "id": "accounts/fireworks/models/gemma-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gemma-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/gemma-7b-it": {
      "id": "accounts/fireworks/models/gemma-7b-it",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gemma-7b-it",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/gemma2-9b-it": {
      "id": "accounts/fireworks/models/gemma2-9b-it",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gemma2-9b-it",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/glm-4p5v": {
      "id": "accounts/fireworks/models/glm-4p5v",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/glm-4p5v",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/gpt-oss-safeguard-120b": {
      "id": "accounts/fireworks/models/gpt-oss-safeguard-120b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/gpt-oss-safeguard-20b": {
      "id": "accounts/fireworks/models/gpt-oss-safeguard-20b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/hermes-2-pro-mistral-7b": {
      "id": "accounts/fireworks/models/hermes-2-pro-mistral-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/hermes-2-pro-mistral-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/internvl3-38b": {
      "id": "accounts/fireworks/models/internvl3-38b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/internvl3-38b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/internvl3-78b": {
      "id": "accounts/fireworks/models/internvl3-78b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/internvl3-78b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/internvl3-8b": {
      "id": "accounts/fireworks/models/internvl3-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/internvl3-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/japanese-stable-diffusion-xl": {
      "id": "accounts/fireworks/models/japanese-stable-diffusion-xl",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/japanese-stable-diffusion-xl",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1.3e-07,
      "output_cost_per_1k": 1.3e-07
    },
    "fireworks/accounts/fireworks/models/kat-coder": {
      "id": "accounts/fireworks/models/kat-coder",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/kat-coder",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/kat-dev-32b": {
      "id": "accounts/fireworks/models/kat-dev-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/kat-dev-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/kat-dev-72b-exp": {
      "id": "accounts/fireworks/models/kat-dev-72b-exp",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llama-guard-2-8b": {
      "id": "accounts/fireworks/models/llama-guard-2-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-guard-2-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-guard-3-1b": {
      "id": "accounts/fireworks/models/llama-guard-3-1b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/llama-guard-3-8b": {
      "id": "accounts/fireworks/models/llama-guard-3-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v2-13b": {
      "id": "accounts/fireworks/models/llama-v2-13b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v2-13b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v2-13b-chat": {
      "id": "accounts/fireworks/models/llama-v2-13b-chat",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v2-13b-chat",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v2-70b": {
      "id": "accounts/fireworks/models/llama-v2-70b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v2-70b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/llama-v2-70b-chat": {
      "id": "accounts/fireworks/models/llama-v2-70b-chat",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v2-70b-chat",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llama-v2-7b": {
      "id": "accounts/fireworks/models/llama-v2-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v2-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v2-7b-chat": {
      "id": "accounts/fireworks/models/llama-v2-7b-chat",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v2-7b-chat",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v3-70b-instruct": {
      "id": "accounts/fireworks/models/llama-v3-70b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llama-v3-70b-instruct-hf": {
      "id": "accounts/fireworks/models/llama-v3-70b-instruct-hf",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct-hf",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llama-v3-8b": {
      "id": "accounts/fireworks/models/llama-v3-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v3-8b-instruct-hf": {
      "id": "accounts/fireworks/models/llama-v3-8b-instruct-hf",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3-8b-instruct-hf",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llama-v3p1-405b-instruct-long": {
      "id": "accounts/fireworks/models/llama-v3p1-405b-instruct-long",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct-long",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/llama-v3p1-70b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llama-v3p1-70b-instruct-1b": {
      "id": "accounts/fireworks/models/llama-v3p1-70b-instruct-1b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct-1b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llama-v3p2-1b": {
      "id": "accounts/fireworks/models/llama-v3p2-1b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/llama-v3p2-3b": {
      "id": "accounts/fireworks/models/llama-v3p2-3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct": {
      "id": "accounts/fireworks/models/llama-v3p3-70b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/llamaguard-7b": {
      "id": "accounts/fireworks/models/llamaguard-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llamaguard-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/llava-yi-34b": {
      "id": "accounts/fireworks/models/llava-yi-34b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/llava-yi-34b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/minimax-m1-80k": {
      "id": "accounts/fireworks/models/minimax-m1-80k",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/minimax-m1-80k",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/minimax-m2": {
      "id": "accounts/fireworks/models/minimax-m2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/minimax-m2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/ministral-3-14b-instruct-2512": {
      "id": "accounts/fireworks/models/ministral-3-14b-instruct-2512",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/ministral-3-3b-instruct-2512": {
      "id": "accounts/fireworks/models/ministral-3-3b-instruct-2512",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/ministral-3-8b-instruct-2512": {
      "id": "accounts/fireworks/models/ministral-3-8b-instruct-2512",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-7b": {
      "id": "accounts/fireworks/models/mistral-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-7b-instruct-4k": {
      "id": "accounts/fireworks/models/mistral-7b-instruct-4k",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-4k",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-7b-instruct-v0p2": {
      "id": "accounts/fireworks/models/mistral-7b-instruct-v0p2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v0p2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-7b-instruct-v3": {
      "id": "accounts/fireworks/models/mistral-7b-instruct-v3",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v3",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-7b-v0p2": {
      "id": "accounts/fireworks/models/mistral-7b-v0p2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-7b-v0p2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-large-3-fp8": {
      "id": "accounts/fireworks/models/mistral-large-3-fp8",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/mistral-nemo-base-2407": {
      "id": "accounts/fireworks/models/mistral-nemo-base-2407",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-nemo-instruct-2407": {
      "id": "accounts/fireworks/models/mistral-nemo-instruct-2407",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/mistral-small-24b-instruct-2501": {
      "id": "accounts/fireworks/models/mistral-small-24b-instruct-2501",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mistral-small-24b-instruct-2501",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/mixtral-8x22b": {
      "id": "accounts/fireworks/models/mixtral-8x22b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/mixtral-8x22b-instruct": {
      "id": "accounts/fireworks/models/mixtral-8x22b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012
    },
    "fireworks/accounts/fireworks/models/mixtral-8x7b": {
      "id": "accounts/fireworks/models/mixtral-8x7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/mixtral-8x7b-instruct": {
      "id": "accounts/fireworks/models/mixtral-8x7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
      "id": "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct-hf",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/mythomax-l2-13b": {
      "id": "accounts/fireworks/models/mythomax-l2-13b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/mythomax-l2-13b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/nemotron-nano-v2-12b-vl": {
      "id": "accounts/fireworks/models/nemotron-nano-v2-12b-vl",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nemotron-nano-v2-12b-vl",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/nous-capybara-7b-v1p9": {
      "id": "accounts/fireworks/models/nous-capybara-7b-v1p9",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nous-capybara-7b-v1p9",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo": {
      "id": "accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/nous-hermes-2-yi-34b": {
      "id": "accounts/fireworks/models/nous-hermes-2-yi-34b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nous-hermes-2-yi-34b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/nous-hermes-llama2-13b": {
      "id": "accounts/fireworks/models/nous-hermes-llama2-13b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-13b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/nous-hermes-llama2-70b": {
      "id": "accounts/fireworks/models/nous-hermes-llama2-70b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-70b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/nous-hermes-llama2-7b": {
      "id": "accounts/fireworks/models/nous-hermes-llama2-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
      "id": "accounts/fireworks/models/nvidia-nemotron-nano-12b-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
      "id": "accounts/fireworks/models/nvidia-nemotron-nano-9b-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/openchat-3p5-0106-7b": {
      "id": "accounts/fireworks/models/openchat-3p5-0106-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/openchat-3p5-0106-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/openhermes-2-mistral-7b": {
      "id": "accounts/fireworks/models/openhermes-2-mistral-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/openhermes-2-mistral-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/openhermes-2p5-mistral-7b": {
      "id": "accounts/fireworks/models/openhermes-2p5-mistral-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/openhermes-2p5-mistral-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/openorca-7b": {
      "id": "accounts/fireworks/models/openorca-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/openorca-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/phi-2-3b": {
      "id": "accounts/fireworks/models/phi-2-3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/phi-2-3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/phi-3-mini-128k-instruct": {
      "id": "accounts/fireworks/models/phi-3-mini-128k-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/phi-3-vision-128k-instruct": {
      "id": "accounts/fireworks/models/phi-3-vision-128k-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/phi-3-vision-128k-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32064,
      "max_output_tokens": 32064,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/phind-code-llama-34b-python-v1": {
      "id": "accounts/fireworks/models/phind-code-llama-34b-python-v1",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-python-v1",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/phind-code-llama-34b-v1": {
      "id": "accounts/fireworks/models/phind-code-llama-34b-v1",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v1",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/phind-code-llama-34b-v2": {
      "id": "accounts/fireworks/models/phind-code-llama-34b-v2",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v2",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/playground-v2-1024px-aesthetic": {
      "id": "accounts/fireworks/models/playground-v2-1024px-aesthetic",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/playground-v2-1024px-aesthetic",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1.3e-07,
      "output_cost_per_1k": 1.3e-07
    },
    "fireworks/accounts/fireworks/models/playground-v2-5-1024px-aesthetic": {
      "id": "accounts/fireworks/models/playground-v2-5-1024px-aesthetic",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/playground-v2-5-1024px-aesthetic",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1.3e-07,
      "output_cost_per_1k": 1.3e-07
    },
    "fireworks/accounts/fireworks/models/pythia-12b": {
      "id": "accounts/fireworks/models/pythia-12b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/pythia-12b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen-qwq-32b-preview": {
      "id": "accounts/fireworks/models/qwen-qwq-32b-preview",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen-qwq-32b-preview",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen-v2p5-14b-instruct": {
      "id": "accounts/fireworks/models/qwen-v2p5-14b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen-v2p5-14b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen-v2p5-7b": {
      "id": "accounts/fireworks/models/qwen-v2p5-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen1p5-72b-chat": {
      "id": "accounts/fireworks/models/qwen1p5-72b-chat",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen1p5-72b-chat",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2-7b-instruct": {
      "id": "accounts/fireworks/models/qwen2-7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2-7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2-vl-2b-instruct": {
      "id": "accounts/fireworks/models/qwen2-vl-2b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2-vl-2b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2-vl-72b-instruct": {
      "id": "accounts/fireworks/models/qwen2-vl-72b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2-vl-72b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2-vl-7b-instruct": {
      "id": "accounts/fireworks/models/qwen2-vl-7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2-vl-7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-0p5b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-0p5b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-0p5b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-14b": {
      "id": "accounts/fireworks/models/qwen2p5-14b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-14b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-1p5b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-1p5b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-1p5b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-32b": {
      "id": "accounts/fireworks/models/qwen2p5-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-32b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-32b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-32b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-72b": {
      "id": "accounts/fireworks/models/qwen2p5-72b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-72b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-72b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-72b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-72b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-7b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-0p5b": {
      "id": "accounts/fireworks/models/qwen2p5-coder-0p5b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-coder-0p5b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-14b": {
      "id": "accounts/fireworks/models/qwen2p5-coder-14b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-14b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-coder-14b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-1p5b": {
      "id": "accounts/fireworks/models/qwen2p5-coder-1p5b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-coder-1p5b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-32b": {
      "id": "accounts/fireworks/models/qwen2p5-coder-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
      "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope": {
      "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k": {
      "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-3b": {
      "id": "accounts/fireworks/models/qwen2p5-coder-3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-3b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-coder-3b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-7b": {
      "id": "accounts/fireworks/models/qwen2p5-coder-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-coder-7b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-coder-7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-math-72b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-math-72b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-math-72b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-vl-32b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-vl-3b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-vl-72b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
      "id": "accounts/fireworks/models/qwen2p5-vl-7b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen3-0p6b": {
      "id": "accounts/fireworks/models/qwen3-0p6b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-0p6b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen3-14b": {
      "id": "accounts/fireworks/models/qwen3-14b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-14b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen3-1p7b": {
      "id": "accounts/fireworks/models/qwen3-1p7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
      "id": "accounts/fireworks/models/qwen3-1p7b-fp8-draft",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
      "id": "accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960": {
      "id": "accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen3-235b-a22b": {
      "id": "accounts/fireworks/models/qwen3-235b-a22b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088
    },
    "fireworks/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
      "id": "accounts/fireworks/models/qwen3-235b-a22b-instruct-2507",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088
    },
    "fireworks/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
      "id": "accounts/fireworks/models/qwen3-235b-a22b-thinking-2507",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088
    },
    "fireworks/accounts/fireworks/models/qwen3-30b-a3b": {
      "id": "accounts/fireworks/models/qwen3-30b-a3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "fireworks/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
      "id": "accounts/fireworks/models/qwen3-30b-a3b-instruct-2507",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0005
    },
    "fireworks/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
      "id": "accounts/fireworks/models/qwen3-30b-a3b-thinking-2507",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen3-32b": {
      "id": "accounts/fireworks/models/qwen3-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/qwen3-4b": {
      "id": "accounts/fireworks/models/qwen3-4b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-4b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen3-4b-instruct-2507": {
      "id": "accounts/fireworks/models/qwen3-4b-instruct-2507",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwen3-8b": {
      "id": "accounts/fireworks/models/qwen3-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-8b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "reasoning"
      ]
    },
    "fireworks/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
      "id": "accounts/fireworks/models/qwen3-coder-30b-a3b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "fireworks/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16": {
      "id": "accounts/fireworks/models/qwen3-coder-480b-instruct-bf16",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen3-embedding-0p6b": {
      "id": "accounts/fireworks/models/qwen3-embedding-0p6b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-embedding-0p6b",
      "provider": "fireworks",
      "mode": "embedding",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768
    },
    "fireworks/accounts/fireworks/models/qwen3-embedding-4b": {
      "id": "accounts/fireworks/models/qwen3-embedding-4b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-embedding-4b",
      "provider": "fireworks",
      "mode": "embedding",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960
    },
    "fireworks/accounts/fireworks/models/": {
      "id": "accounts/fireworks/models/",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/",
      "provider": "fireworks",
      "mode": "embedding",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/qwen3-next-80b-a3b-instruct": {
      "id": "accounts/fireworks/models/qwen3-next-80b-a3b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen3-next-80b-a3b-thinking": {
      "id": "accounts/fireworks/models/qwen3-next-80b-a3b-thinking",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-thinking",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen3-reranker-0p6b": {
      "id": "accounts/fireworks/models/qwen3-reranker-0p6b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-reranker-0p6b",
      "provider": "fireworks",
      "mode": "rerank",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960
    },
    "fireworks/accounts/fireworks/models/qwen3-reranker-4b": {
      "id": "accounts/fireworks/models/qwen3-reranker-4b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-reranker-4b",
      "provider": "fireworks",
      "mode": "rerank",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960
    },
    "fireworks/accounts/fireworks/models/qwen3-reranker-8b": {
      "id": "accounts/fireworks/models/qwen3-reranker-8b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-reranker-8b",
      "provider": "fireworks",
      "mode": "rerank",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960
    },
    "fireworks/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
      "id": "accounts/fireworks/models/qwen3-vl-235b-a22b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088
    },
    "fireworks/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
      "id": "accounts/fireworks/models/qwen3-vl-235b-a22b-thinking",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088
    },
    "fireworks/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
      "id": "accounts/fireworks/models/qwen3-vl-30b-a3b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "fireworks/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
      "id": "accounts/fireworks/models/qwen3-vl-30b-a3b-thinking",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006
    },
    "fireworks/accounts/fireworks/models/qwen3-vl-32b-instruct": {
      "id": "accounts/fireworks/models/qwen3-vl-32b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-32b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/qwen3-vl-8b-instruct": {
      "id": "accounts/fireworks/models/qwen3-vl-8b-instruct",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-8b-instruct",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/qwq-32b": {
      "id": "accounts/fireworks/models/qwq-32b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/qwq-32b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/rolm-ocr": {
      "id": "accounts/fireworks/models/rolm-ocr",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/rolm-ocr",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo": {
      "id": "accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/stable-diffusion-xl-1024-v1-0": {
      "id": "accounts/fireworks/models/stable-diffusion-xl-1024-v1-0",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/stable-diffusion-xl-1024-v1-0",
      "provider": "fireworks",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1.3e-07,
      "output_cost_per_1k": 1.3e-07
    },
    "fireworks/accounts/fireworks/models/stablecode-3b": {
      "id": "accounts/fireworks/models/stablecode-3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/stablecode-3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/starcoder-16b": {
      "id": "accounts/fireworks/models/starcoder-16b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/starcoder-16b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/starcoder-7b": {
      "id": "accounts/fireworks/models/starcoder-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/starcoder-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/starcoder2-15b": {
      "id": "accounts/fireworks/models/starcoder2-15b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/starcoder2-15b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/starcoder2-3b": {
      "id": "accounts/fireworks/models/starcoder2-3b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/starcoder2-3b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001
    },
    "fireworks/accounts/fireworks/models/starcoder2-7b": {
      "id": "accounts/fireworks/models/starcoder2-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/starcoder2-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/toppy-m-7b": {
      "id": "accounts/fireworks/models/toppy-m-7b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/toppy-m-7b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/whisper-v3": {
      "id": "accounts/fireworks/models/whisper-v3",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/whisper-v3",
      "provider": "fireworks",
      "mode": "audio_transcription",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "fireworks/accounts/fireworks/models/whisper-v3-turbo": {
      "id": "accounts/fireworks/models/whisper-v3-turbo",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/whisper-v3-turbo",
      "provider": "fireworks",
      "mode": "audio_transcription",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096
    },
    "fireworks/accounts/fireworks/models/yi-34b": {
      "id": "accounts/fireworks/models/yi-34b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/yi-34b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/yi-34b-200k-capybara": {
      "id": "accounts/fireworks/models/yi-34b-200k-capybara",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/yi-34b-chat": {
      "id": "accounts/fireworks/models/yi-34b-chat",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/yi-34b-chat",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009
    },
    "fireworks/accounts/fireworks/models/yi-6b": {
      "id": "accounts/fireworks/models/yi-6b",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/yi-6b",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    },
    "fireworks/accounts/fireworks/models/zephyr-7b-beta": {
      "id": "accounts/fireworks/models/zephyr-7b-beta",
      "litellm_id": "fireworks_ai/accounts/fireworks/models/zephyr-7b-beta",
      "provider": "fireworks",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002
    }
  }
}
