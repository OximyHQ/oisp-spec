{
  "$schema": "https://oisp.dev/schema/v0.1/bundle.schema.json",
  "bundle_version": "1.0.0",
  "domain_index": {
    "127.0.0.1:11434": "ollama",
    "aiplatform.googleapis.com": "google",
    "api-inference.huggingface.co": "huggingface",
    "api.anthropic.com": "anthropic",
    "api.cohere.ai": "cohere",
    "api.cohere.com": "cohere",
    "api.deepseek.com": "deepseek",
    "api.fireworks.ai": "fireworks",
    "api.groq.com": "groq",
    "api.mistral.ai": "mistral",
    "api.openai.com": "openai",
    "api.perplexity.ai": "perplexity",
    "api.replicate.com": "replicate",
    "api.together.xyz": "together",
    "generativelanguage.googleapis.com": "google",
    "localhost:11434": "ollama"
  },
  "domain_patterns": [
    {
      "pattern": "*.openai.azure.com",
      "provider": "azure_openai",
      "regex": "^.*\\.openai\\.azure\\.com$"
    },
    {
      "pattern": "bedrock-runtime.*.amazonaws.com",
      "provider": "aws_bedrock",
      "regex": "^bedrock\\-runtime\\..*\\.amazonaws\\.com$"
    },
    {
      "pattern": "bedrock.*.amazonaws.com",
      "provider": "aws_bedrock",
      "regex": "^bedrock\\..*\\.amazonaws\\.com$"
    },
    {
      "pattern": "localhost:11434",
      "provider": "ollama",
      "regex": "^localhost:11434$"
    },
    {
      "pattern": "127.0.0.1:11434",
      "provider": "ollama",
      "regex": "^127\\.0\\.0\\.1:11434$"
    },
    {
      "pattern": "localhost:1234",
      "provider": "lmstudio",
      "regex": "^localhost:1234$"
    },
    {
      "pattern": "127.0.0.1:1234",
      "provider": "lmstudio",
      "regex": "^127\\.0\\.0\\.1:1234$"
    }
  ],
  "extraction_rules": {
    "anthropic": {
      "auth": {
        "beta_header": "anthropic-beta",
        "header": "x-api-key",
        "key_patterns": [
          {
            "description": "Anthropic API key",
            "pattern": "^sk-ant-[a-zA-Z0-9-]+"
          }
        ],
        "type": "api_key",
        "version_header": "anthropic-version"
      },
      "endpoints": {
        "completions": {
          "method": "POST",
          "path": "/v1/complete",
          "request_extraction": {},
          "request_type": "completion",
          "response_extraction": {},
          "streaming": {}
        },
        "messages": {
          "method": "POST",
          "path": "/v1/messages",
          "request_extraction": {
            "max_tokens": "$.max_tokens",
            "messages": "$.messages",
            "model": "$.model",
            "stream": "$.stream",
            "system": "$.system",
            "temperature": "$.temperature",
            "tool_choice": "$.tool_choice",
            "tools": "$.tools"
          },
          "request_type": "chat",
          "response_extraction": {
            "content": "$.content",
            "model": "$.model",
            "request_id": {
              "header": "request-id"
            },
            "stop_reason": "$.stop_reason",
            "usage": {
              "cache_creation_input_tokens": "$.usage.cache_creation_input_tokens",
              "cache_read_input_tokens": "$.usage.cache_read_input_tokens",
              "input_tokens": "$.usage.input_tokens",
              "output_tokens": "$.usage.output_tokens"
            }
          },
          "streaming": {
            "content_type": "text/event-stream",
            "indicator": {
              "body_field": "stream",
              "value": true
            }
          }
        },
        "messages_count_tokens": {
          "method": "POST",
          "path": "/v1/messages/count_tokens",
          "request_extraction": {},
          "request_type": "utility",
          "response_extraction": {},
          "streaming": {}
        }
      },
      "features": {
        "computer_use": {
          "description": "Allow Claude to control computer interfaces",
          "enabled_via": "anthropic-beta: computer-use-2024-10-22",
          "models": [
            "claude-3-5-sonnet-20241022"
          ],
          "tool_types": [
            "computer_20241022",
            "text_editor_20241022",
            "bash_20241022"
          ]
        },
        "extended_thinking": {
          "description": "Extended reasoning capabilities",
          "enabled_via": "anthropic-beta: extended-thinking-2025-01-24"
        },
        "prompt_caching": {
          "description": "Cache long contexts for repeated use",
          "enabled_via": "anthropic-beta: prompt-caching-2024-07-31",
          "usage_fields": {
            "cache_creation_input_tokens": "$.usage.cache_creation_input_tokens",
            "cache_read_input_tokens": "$.usage.cache_read_input_tokens"
          }
        }
      },
      "model_families": {
        "claude-2": {
          "deprecated": true,
          "display_name": "Claude 2",
          "pattern": "^claude-2"
        },
        "claude-3": {
          "display_name": "Claude 3",
          "pattern": "^claude-3(?!-5)"
        },
        "claude-3.5": {
          "display_name": "Claude 3.5",
          "pattern": "^claude-3-5"
        }
      },
      "response_headers": {
        "ratelimit_requests_limit": "anthropic-ratelimit-requests-limit",
        "ratelimit_requests_remaining": "anthropic-ratelimit-requests-remaining",
        "ratelimit_tokens_limit": "anthropic-ratelimit-tokens-limit",
        "ratelimit_tokens_remaining": "anthropic-ratelimit-tokens-remaining",
        "request_id": "request-id"
      }
    },
    "google": {
      "auth": {
        "methods": {
          "api_key": {
            "description": "Google AI Studio API key",
            "query_param": "key",
            "type": "api_key"
          },
          "oauth": {
            "description": "Google Cloud OAuth for Vertex AI",
            "format": "Bearer {token}",
            "header": "Authorization",
            "type": "oauth2"
          },
          "service_account": {
            "description": "GCP service account for Vertex AI",
            "format": "Bearer {token}",
            "header": "Authorization",
            "type": "service_account"
          }
        }
      },
      "endpoints": {
        "batch_embed_contents": {
          "method": "POST",
          "path": "/v1beta/models/{model}:batchEmbedContents",
          "request_extraction": {},
          "request_type": "embedding",
          "response_extraction": {},
          "streaming": {}
        },
        "count_tokens": {
          "method": "POST",
          "path": "/v1beta/models/{model}:countTokens",
          "request_extraction": {},
          "request_type": "utility",
          "response_extraction": {},
          "streaming": {}
        },
        "embed_content": {
          "method": "POST",
          "path": "/v1beta/models/{model}:embedContent",
          "request_extraction": {},
          "request_type": "embedding",
          "response_extraction": {},
          "streaming": {}
        },
        "generate_content": {
          "method": "POST",
          "path": "/v1beta/models/{model}:generateContent",
          "request_extraction": {
            "contents": "$.contents",
            "generation_config": {
              "max_output_tokens": "$.generationConfig.maxOutputTokens",
              "temperature": "$.generationConfig.temperature",
              "top_k": "$.generationConfig.topK",
              "top_p": "$.generationConfig.topP"
            },
            "model": "{model}",
            "system_instruction": "$.systemInstruction",
            "tools": "$.tools"
          },
          "request_type": "chat",
          "response_extraction": {
            "candidates": "$.candidates",
            "finish_reason": "$.candidates[0].finishReason",
            "usage": {
              "completion_tokens": "$.usageMetadata.candidatesTokenCount",
              "prompt_tokens": "$.usageMetadata.promptTokenCount",
              "total_tokens": "$.usageMetadata.totalTokenCount"
            }
          },
          "streaming": {}
        },
        "stream_generate_content": {
          "method": "POST",
          "path": "/v1beta/models/{model}:streamGenerateContent",
          "request_extraction": {},
          "request_type": "chat",
          "response_extraction": {},
          "streaming": true
        },
        "vertex_generate_content": {
          "method": "POST",
          "path": "/v1/projects/{project}/locations/{location}/publishers/google/models/{model}:generateContent",
          "request_extraction": {},
          "request_type": "chat",
          "response_extraction": {},
          "streaming": {}
        },
        "vertex_stream_generate_content": {
          "method": "POST",
          "path": "/v1/projects/{project}/locations/{location}/publishers/google/models/{model}:streamGenerateContent",
          "request_extraction": {},
          "request_type": "chat",
          "response_extraction": {},
          "streaming": true
        }
      },
      "features": {
        "code_execution": {
          "description": "Execute Python code in sandbox",
          "enabled_via": {
            "tool_type": "code_execution"
          },
          "models": [
            "gemini-2.0-flash",
            "gemini-1.5-pro",
            "gemini-1.5-flash"
          ]
        },
        "context_caching": {
          "api_path": "/v1beta/cachedContents",
          "description": "Cache large contexts for reuse"
        },
        "grounding": {
          "description": "Ground responses with Google Search",
          "enabled_via": {
            "tool_type": "google_search_retrieval"
          },
          "models": [
            "gemini-2.0-flash",
            "gemini-1.5-pro",
            "gemini-1.5-flash"
          ]
        }
      },
      "model_families": {
        "embedding": {
          "display_name": "Embeddings",
          "pattern": "^text-embedding|^embedding"
        },
        "gemini-1.0": {
          "deprecated": true,
          "display_name": "Gemini 1.0",
          "pattern": "^gemini-1\\.0|^gemini-pro"
        },
        "gemini-1.5": {
          "display_name": "Gemini 1.5",
          "pattern": "^gemini-1\\.5"
        },
        "gemini-2.0": {
          "display_name": "Gemini 2.0",
          "pattern": "^gemini-2\\.0"
        }
      },
      "response_headers": {}
    },
    "ollama": {
      "auth": {
        "note": "Ollama runs locally without authentication by default",
        "type": "none"
      },
      "endpoints": {
        "chat": {
          "method": "POST",
          "path": "/api/chat",
          "request_extraction": {
            "messages": "$.messages",
            "model": "$.model",
            "options": {
              "num_predict": "$.options.num_predict",
              "temperature": "$.options.temperature"
            },
            "stream": "$.stream",
            "tools": "$.tools"
          },
          "request_type": "chat",
          "response_extraction": {
            "done": "$.done",
            "message": "$.message",
            "model": "$.model",
            "usage": {
              "completion_tokens": "$.eval_count",
              "prompt_tokens": "$.prompt_eval_count"
            }
          },
          "streaming": {
            "default": true,
            "indicator": {
              "body_field": "stream",
              "value": true
            }
          }
        },
        "embed": {
          "method": "POST",
          "path": "/api/embed",
          "request_extraction": {
            "input": "$.input",
            "model": "$.model"
          },
          "request_type": "embedding",
          "response_extraction": {
            "embeddings": "$.embeddings"
          },
          "streaming": {}
        },
        "embeddings": {
          "method": "POST",
          "path": "/api/embeddings",
          "request_extraction": {
            "model": "$.model",
            "prompt": "$.prompt"
          },
          "request_type": "embedding",
          "response_extraction": {
            "embedding": "$.embedding"
          },
          "streaming": {}
        },
        "generate": {
          "method": "POST",
          "path": "/api/generate",
          "request_extraction": {
            "context": "$.context",
            "model": "$.model",
            "options": {
              "num_predict": "$.options.num_predict",
              "temperature": "$.options.temperature",
              "top_k": "$.options.top_k",
              "top_p": "$.options.top_p"
            },
            "prompt": "$.prompt",
            "stream": "$.stream",
            "system": "$.system",
            "template": "$.template"
          },
          "request_type": "completion",
          "response_extraction": {
            "context": "$.context",
            "done": "$.done",
            "model": "$.model",
            "response": "$.response",
            "timing": {
              "eval_duration": "$.eval_duration",
              "load_duration": "$.load_duration",
              "prompt_eval_duration": "$.prompt_eval_duration",
              "total_duration": "$.total_duration"
            },
            "usage": {
              "completion_tokens": "$.eval_count",
              "prompt_tokens": "$.prompt_eval_count"
            }
          },
          "streaming": {
            "default": true,
            "indicator": {
              "body_field": "stream",
              "value": true
            }
          }
        },
        "list_models": {
          "method": "GET",
          "path": "/api/tags",
          "request_extraction": {},
          "request_type": "management",
          "response_extraction": {},
          "streaming": {}
        },
        "openai_chat_completions": {
          "method": "POST",
          "path": "/v1/chat/completions",
          "request_extraction": {},
          "request_type": "chat",
          "response_extraction": {},
          "streaming": {}
        },
        "openai_completions": {
          "method": "POST",
          "path": "/v1/completions",
          "request_extraction": {},
          "request_type": "completion",
          "response_extraction": {},
          "streaming": {}
        },
        "openai_embeddings": {
          "method": "POST",
          "path": "/v1/embeddings",
          "request_extraction": {},
          "request_type": "embedding",
          "response_extraction": {},
          "streaming": {}
        },
        "pull_model": {
          "method": "POST",
          "path": "/api/pull",
          "request_extraction": {},
          "request_type": "management",
          "response_extraction": {},
          "streaming": {}
        },
        "show_model": {
          "method": "POST",
          "path": "/api/show",
          "request_extraction": {},
          "request_type": "management",
          "response_extraction": {},
          "streaming": {}
        }
      },
      "features": {},
      "model_families": {
        "deepseek": {
          "display_name": "DeepSeek",
          "pattern": "^deepseek"
        },
        "embedding": {
          "display_name": "Embeddings",
          "pattern": "embed|minilm"
        },
        "gemma": {
          "display_name": "Gemma",
          "pattern": "^gemma"
        },
        "llama": {
          "display_name": "Llama",
          "pattern": "^llama|^codellama"
        },
        "mistral": {
          "display_name": "Mistral",
          "pattern": "^mistral|^mixtral"
        },
        "phi": {
          "display_name": "Phi",
          "pattern": "^phi"
        },
        "qwen": {
          "display_name": "Qwen",
          "pattern": "^qwen"
        }
      },
      "response_headers": {}
    },
    "openai": {
      "auth": {
        "format": "Bearer {key}",
        "header": "Authorization",
        "key_patterns": [
          {
            "account_type": "unknown",
            "description": "Legacy API key",
            "pattern": "^sk-[a-zA-Z0-9]{48}$"
          },
          {
            "account_type": "corporate",
            "description": "Project API key",
            "pattern": "^sk-proj-[a-zA-Z0-9]{48}$"
          },
          {
            "account_type": "corporate",
            "description": "Service account key",
            "pattern": "^sk-svcacct-[a-zA-Z0-9]+"
          }
        ],
        "organization_header": "OpenAI-Organization",
        "project_header": "OpenAI-Project",
        "type": "api_key"
      },
      "endpoints": {
        "audio_speech": {
          "method": "POST",
          "path": "/v1/audio/speech",
          "request_extraction": {
            "model": "$.model",
            "voice": "$.voice"
          },
          "request_type": "audio",
          "response_extraction": {},
          "streaming": {}
        },
        "audio_transcriptions": {
          "method": "POST",
          "path": "/v1/audio/transcriptions",
          "request_extraction": {},
          "request_type": "audio",
          "response_extraction": {},
          "streaming": {}
        },
        "chat_completions": {
          "method": "POST",
          "path": "/v1/chat/completions",
          "request_extraction": {
            "max_tokens": "$.max_tokens",
            "messages": "$.messages",
            "model": "$.model",
            "stream": "$.stream",
            "temperature": "$.temperature",
            "tool_choice": "$.tool_choice",
            "tools": "$.tools"
          },
          "request_type": "chat",
          "response_extraction": {
            "choices": "$.choices",
            "finish_reason": "$.choices[0].finish_reason",
            "model": "$.model",
            "request_id": {
              "header": "x-request-id"
            },
            "usage": {
              "completion_tokens": "$.usage.completion_tokens",
              "prompt_tokens": "$.usage.prompt_tokens",
              "total_tokens": "$.usage.total_tokens"
            }
          },
          "streaming": {
            "content_type": "text/event-stream",
            "indicator": {
              "body_field": "stream",
              "value": true
            }
          }
        },
        "completions": {
          "method": "POST",
          "path": "/v1/completions",
          "request_extraction": {
            "model": "$.model",
            "prompt": "$.prompt"
          },
          "request_type": "completion",
          "response_extraction": {},
          "streaming": {}
        },
        "embeddings": {
          "method": "POST",
          "path": "/v1/embeddings",
          "request_extraction": {
            "input": "$.input",
            "model": "$.model"
          },
          "request_type": "embedding",
          "response_extraction": {
            "usage": {
              "prompt_tokens": "$.usage.prompt_tokens",
              "total_tokens": "$.usage.total_tokens"
            }
          },
          "streaming": {}
        },
        "images_generations": {
          "method": "POST",
          "path": "/v1/images/generations",
          "request_extraction": {
            "model": "$.model",
            "prompt": "$.prompt",
            "quality": "$.quality",
            "size": "$.size"
          },
          "request_type": "image",
          "response_extraction": {},
          "streaming": {}
        },
        "moderations": {
          "method": "POST",
          "path": "/v1/moderations",
          "request_extraction": {},
          "request_type": "moderation",
          "response_extraction": {},
          "streaming": {}
        }
      },
      "features": {},
      "model_families": {
        "dall-e": {
          "display_name": "DALL-E",
          "pattern": "^dall-e"
        },
        "embedding": {
          "display_name": "Embeddings",
          "pattern": "^text-embedding"
        },
        "gpt-3.5": {
          "display_name": "GPT-3.5",
          "pattern": "^gpt-3\\.5"
        },
        "gpt-4": {
          "display_name": "GPT-4",
          "pattern": "^gpt-4(?!o)"
        },
        "gpt-4o": {
          "display_name": "GPT-4o",
          "pattern": "^gpt-4o"
        },
        "o1": {
          "display_name": "O1 Reasoning",
          "pattern": "^o1"
        },
        "tts": {
          "display_name": "Text-to-Speech",
          "pattern": "^tts"
        },
        "whisper": {
          "display_name": "Whisper",
          "pattern": "^whisper"
        }
      },
      "response_headers": {
        "model": "openai-model",
        "organization": "openai-organization",
        "processing_ms": "openai-processing-ms",
        "ratelimit_limit": "x-ratelimit-limit-requests",
        "ratelimit_remaining": "x-ratelimit-remaining-requests",
        "ratelimit_reset": "x-ratelimit-reset-requests",
        "request_id": "x-request-id",
        "version": "openai-version"
      }
    }
  },
  "fingerprints": {
    "anthropic": {
      "high_confidence": [
        {
          "domain": "api.anthropic.com",
          "has_model_field": true,
          "model_pattern": "^claude-",
          "path_prefix": "/v1/"
        }
      ],
      "medium_confidence": [
        {
          "domain": "api.anthropic.com",
          "path_prefix": "/v1/"
        }
      ],
      "response_signals": [
        {
          "header": "anthropic-ratelimit-requests-limit"
        },
        {
          "body_field": "$.type",
          "values": [
            "message",
            "message_start",
            "content_block_delta"
          ]
        },
        {
          "body_field": "$.model",
          "pattern": "^claude-"
        },
        {
          "body_field": "$.stop_reason",
          "values": [
            "end_turn",
            "max_tokens",
            "stop_sequence",
            "tool_use"
          ]
        }
      ]
    },
    "google": {
      "high_confidence": [
        {
          "domain": "generativelanguage.googleapis.com",
          "path_contains": ":generateContent"
        },
        {
          "domain": "generativelanguage.googleapis.com",
          "path_contains": ":streamGenerateContent"
        },
        {
          "domain": "aiplatform.googleapis.com",
          "path_contains": "/publishers/google/models/"
        }
      ],
      "medium_confidence": [
        {
          "domain": "generativelanguage.googleapis.com",
          "path_prefix": "/v1beta/models/"
        }
      ],
      "response_signals": [
        {
          "body_field": "$.candidates",
          "is_array": true
        },
        {
          "body_field": "$.usageMetadata.promptTokenCount"
        },
        {
          "body_field": "$.candidates[0].finishReason",
          "values": [
            "STOP",
            "MAX_TOKENS",
            "SAFETY",
            "RECITATION"
          ]
        }
      ]
    },
    "ollama": {
      "high_confidence": [
        {
          "path_prefix": "/api/",
          "port": 11434
        },
        {
          "note": "OpenAI-compatible mode",
          "path_prefix": "/v1/",
          "port": 11434
        }
      ],
      "medium_confidence": [
        {
          "domain_pattern": "localhost:11434"
        },
        {
          "domain_pattern": "127.0.0.1:11434"
        }
      ],
      "response_signals": [
        {
          "body_field": "$.done",
          "type": "boolean"
        },
        {
          "body_field": "$.eval_count",
          "type": "integer"
        },
        {
          "body_field": "$.prompt_eval_count",
          "type": "integer"
        },
        {
          "body_field": "$.total_duration",
          "type": "integer"
        },
        {
          "body_field": "$.model",
          "patterns": [
            "^llama",
            "^mistral",
            "^codellama",
            "^phi",
            "^gemma",
            "^qwen"
          ]
        }
      ]
    },
    "openai": {
      "high_confidence": [
        {
          "domain": "api.openai.com",
          "has_model_field": true,
          "path_prefix": "/v1/"
        }
      ],
      "medium_confidence": [
        {
          "domain": "api.openai.com",
          "path_prefix": "/v1/"
        }
      ],
      "response_signals": [
        {
          "header": "openai-organization"
        },
        {
          "header": "openai-processing-ms"
        },
        {
          "body_field": "$.object",
          "values": [
            "chat.completion",
            "text_completion",
            "embedding",
            "moderation"
          ]
        },
        {
          "body_field": "$.id",
          "pattern": "^chatcmpl-[a-zA-Z0-9]+"
        }
      ]
    }
  },
  "generated_at": "2025-12-29T20:31:51.695511+00:00",
  "model_stats": {
    "providers": 74,
    "total_models": 1924
  },
  "models": {
    "aihubmix/DeepSeek-V3.2-Exp": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "DeepSeek-V3.2-Exp",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 163000,
      "max_output_tokens": 163000,
      "mode": "chat",
      "name": "DeepSeek-V3.2-Exp",
      "open_weights": true,
      "output_cost_per_1k": 0.00041,
      "provider": "aihubmix",
      "release_date": "2025-09-29"
    },
    "aihubmix/DeepSeek-V3.2-Exp-Think": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "DeepSeek-V3.2-Exp-Think",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 131000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "DeepSeek-V3.2-Exp-Think",
      "open_weights": true,
      "output_cost_per_1k": 0.00041,
      "provider": "aihubmix",
      "release_date": "2025-09-29"
    },
    "aihubmix/Kimi-K2-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "Kimi-K2-0905",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "aihubmix",
      "release_date": "2025-09-05"
    },
    "aihubmix/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.0055,
      "provider": "aihubmix",
      "release_date": "2025-09-29"
    },
    "aihubmix/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1",
      "input_cost_per_1k": 0.0165,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.0825,
      "provider": "aihubmix",
      "release_date": "2025-08-05"
    },
    "aihubmix/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5",
      "input_cost_per_1k": 0.0033,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.0165,
      "provider": "aihubmix",
      "release_date": "2025-09-29"
    },
    "aihubmix/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65000,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0003,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 2000000,
      "max_output_tokens": 65000,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.005,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65000,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.012,
      "provider": "aihubmix",
      "release_date": "2025-11-19"
    },
    "aihubmix/glm-4.6": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 204800,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "aihubmix",
      "release_date": "2025-09-30"
    },
    "aihubmix/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "aihubmix",
      "release_date": "2025-04-14"
    },
    "aihubmix/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 mini",
      "output_cost_per_1k": 0.0016,
      "provider": "aihubmix",
      "release_date": "2025-04-14"
    },
    "aihubmix/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "gpt-4.1-nano",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 nano",
      "output_cost_per_1k": 0.0004,
      "provider": "aihubmix",
      "release_date": "2025-04-14"
    },
    "aihubmix/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "aihubmix",
      "release_date": "2024-05-13"
    },
    "aihubmix/gpt-4o-2024-11-20": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o-2024-11-20",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o (2024-11-20)",
      "output_cost_per_1k": 0.01,
      "provider": "aihubmix",
      "release_date": "2024-11-20"
    },
    "aihubmix/gpt-5": {
      "cache_read_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.02,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.01,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5-mini": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "GPT-5-Mini",
      "output_cost_per_1k": 0.006,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5-nano": {
      "cache_read_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5-Nano",
      "output_cost_per_1k": 0.002,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5-pro": {
      "cache_read_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "gpt-5-pro",
      "input_cost_per_1k": 0.007,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Pro",
      "output_cost_per_1k": 0.028,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5.1": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "aihubmix",
      "release_date": "2025-11-15"
    },
    "aihubmix/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "aihubmix",
      "release_date": "2025-11-15"
    },
    "aihubmix/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex Mini",
      "output_cost_per_1k": 0.002,
      "provider": "aihubmix",
      "release_date": "2025-11-15"
    },
    "aihubmix/o4-mini": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "reasoning"
      ],
      "family": "o4-mini",
      "id": "o4-mini",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.006,
      "provider": "aihubmix",
      "release_date": "2025-09-15"
    },
    "aihubmix/qwen3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00112,
      "provider": "aihubmix",
      "release_date": "2025-07-30"
    },
    "aihubmix/qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "aihubmix",
      "release_date": "2025-07-30"
    },
    "aihubmix/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.00082,
      "max_input_tokens": 262144,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "output_cost_per_1k": 0.00329,
      "provider": "aihubmix",
      "release_date": "2025-08-01"
    },
    "alibaba/qvq-max": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qvq-max",
      "id": "qvq-max",
      "input_cost_per_1k": 0.0012,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "QVQ Max",
      "output_cost_per_1k": 0.0048,
      "provider": "alibaba",
      "release_date": "2025-03-25"
    },
    "alibaba/qwen-flash": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen-flash",
      "id": "qwen-flash",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen Flash",
      "output_cost_per_1k": 0.0004,
      "provider": "alibaba",
      "release_date": "2025-07-28"
    },
    "alibaba/qwen-max": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-max",
      "id": "qwen-max",
      "input_cost_per_1k": 0.0016,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen Max",
      "output_cost_per_1k": 0.0064,
      "provider": "alibaba",
      "release_date": "2024-04-03"
    },
    "alibaba/qwen-mt-plus": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen-mt",
      "id": "qwen-mt-plus",
      "input_cost_per_1k": 0.00246,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-MT Plus",
      "output_cost_per_1k": 0.00737,
      "provider": "alibaba",
      "release_date": "2025-01"
    },
    "alibaba/qwen-mt-turbo": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen-mt",
      "id": "qwen-mt-turbo",
      "input_cost_per_1k": 0.00016,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-MT Turbo",
      "output_cost_per_1k": 0.00049,
      "provider": "alibaba",
      "release_date": "2025-01"
    },
    "alibaba/qwen-omni-turbo": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen-omni",
      "id": "qwen-omni-turbo",
      "input_cost_per_1k": 7e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen-Omni Turbo",
      "output_cost_per_1k": 0.00027,
      "provider": "alibaba",
      "release_date": "2025-01-19"
    },
    "alibaba/qwen-omni-turbo-realtime": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen-omni",
      "id": "qwen-omni-turbo-realtime",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen-Omni Turbo Realtime",
      "output_cost_per_1k": 0.00107,
      "provider": "alibaba",
      "release_date": "2025-05-08"
    },
    "alibaba/qwen-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen-plus",
      "id": "qwen-plus",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen Plus",
      "output_cost_per_1k": 0.0012,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.004,
      "release_date": "2024-01-25"
    },
    "alibaba/qwen-plus-character-ja": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-plus",
      "id": "qwen-plus-character-ja",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 8192,
      "max_output_tokens": 512,
      "mode": "chat",
      "name": "Qwen Plus Character (Japanese)",
      "output_cost_per_1k": 0.0014,
      "provider": "alibaba",
      "release_date": "2024-01"
    },
    "alibaba/qwen-turbo": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen-turbo",
      "id": "qwen-turbo",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen Turbo",
      "output_cost_per_1k": 0.0002,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0005,
      "release_date": "2024-11-01"
    },
    "alibaba/qwen-vl-max": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen-vl",
      "id": "qwen-vl-max",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-VL Max",
      "output_cost_per_1k": 0.0032,
      "provider": "alibaba",
      "release_date": "2024-04-08"
    },
    "alibaba/qwen-vl-ocr": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "qwen-vl",
      "id": "qwen-vl-ocr",
      "input_cost_per_1k": 0.00072,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 34096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen-VL OCR",
      "output_cost_per_1k": 0.00072,
      "provider": "alibaba",
      "release_date": "2024-10-28"
    },
    "alibaba/qwen-vl-plus": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen-vl",
      "id": "qwen-vl-plus",
      "input_cost_per_1k": 0.00021,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-VL Plus",
      "output_cost_per_1k": 0.00063,
      "provider": "alibaba",
      "release_date": "2024-01-25"
    },
    "alibaba/qwen2-5-14b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-14b-instruct",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 14B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0014,
      "provider": "alibaba",
      "release_date": "2024-09"
    },
    "alibaba/qwen2-5-32b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-32b-instruct",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "alibaba",
      "release_date": "2024-09"
    },
    "alibaba/qwen2-5-72b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-72b-instruct",
      "input_cost_per_1k": 0.0014,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0056,
      "provider": "alibaba",
      "release_date": "2024-09"
    },
    "alibaba/qwen2-5-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-7b-instruct",
      "input_cost_per_1k": 0.000175,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 7B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0007,
      "provider": "alibaba",
      "release_date": "2024-09"
    },
    "alibaba/qwen2-5-omni-7b": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen2.5-omni",
      "id": "qwen2-5-omni-7b",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen2.5-Omni 7B",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "alibaba",
      "release_date": "2024-12"
    },
    "alibaba/qwen2-5-vl-72b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen2-5-vl-72b-instruct",
      "input_cost_per_1k": 0.0028,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5-VL 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0084,
      "provider": "alibaba",
      "release_date": "2024-09"
    },
    "alibaba/qwen2-5-vl-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen2-5-vl-7b-instruct",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5-VL 7B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00105,
      "provider": "alibaba",
      "release_date": "2024-09"
    },
    "alibaba/qwen3-14b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-14b",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 14B",
      "open_weights": true,
      "output_cost_per_1k": 0.0014,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0042,
      "release_date": "2025-04"
    },
    "alibaba/qwen3-235b-a22b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 235B-A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0084,
      "release_date": "2025-04"
    },
    "alibaba/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-32b",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0084,
      "release_date": "2025-04"
    },
    "alibaba/qwen3-8b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-8b",
      "input_cost_per_1k": 0.00018,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 8B",
      "open_weights": true,
      "output_cost_per_1k": 0.0007,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0021,
      "release_date": "2025-04"
    },
    "alibaba/qwen3-asr-flash": {
      "capabilities": [
        "audio_input"
      ],
      "family": "qwen3",
      "id": "qwen3-asr-flash",
      "input_cost_per_1k": 3.5e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 53248,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen3-ASR Flash",
      "output_cost_per_1k": 3.5e-05,
      "provider": "alibaba",
      "release_date": "2025-09-08"
    },
    "alibaba/qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 0.00045,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00225,
      "provider": "alibaba",
      "release_date": "2025-04"
    },
    "alibaba/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3-Coder 480B-A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0075,
      "provider": "alibaba",
      "release_date": "2025-04"
    },
    "alibaba/qwen3-coder-flash": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder Flash",
      "output_cost_per_1k": 0.0015,
      "provider": "alibaba",
      "release_date": "2025-07-28"
    },
    "alibaba/qwen3-coder-plus": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-plus",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder Plus",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "alibaba",
      "release_date": "2025-07-23"
    },
    "alibaba/qwen3-livetranslate-flash-realtime": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3",
      "id": "qwen3-livetranslate-flash-realtime",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 53248,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen3-LiveTranslate Flash Realtime",
      "output_cost_per_1k": 0.01,
      "provider": "alibaba",
      "release_date": "2025-09-22"
    },
    "alibaba/qwen3-max": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-max",
      "input_cost_per_1k": 0.0012,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Max",
      "output_cost_per_1k": 0.006,
      "provider": "alibaba",
      "release_date": "2025-09-23"
    },
    "alibaba/qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-Next 80B-A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "alibaba",
      "release_date": "2025-09"
    },
    "alibaba/qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-Next 80B-A3B (Thinking)",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "alibaba",
      "release_date": "2025-09"
    },
    "alibaba/qwen3-omni-flash": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen3-omni-flash",
      "input_cost_per_1k": 0.00043,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3-Omni Flash",
      "output_cost_per_1k": 0.00166,
      "provider": "alibaba",
      "release_date": "2025-09-15"
    },
    "alibaba/qwen3-omni-flash-realtime": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen3-omni-flash-realtime",
      "input_cost_per_1k": 0.00052,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3-Omni Flash Realtime",
      "output_cost_per_1k": 0.00199,
      "provider": "alibaba",
      "release_date": "2025-09-15"
    },
    "alibaba/qwen3-vl-235b-a22b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-235b-a22b",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-VL 235B-A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0084,
      "release_date": "2025-04"
    },
    "alibaba/qwen3-vl-30b-a3b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-30b-a3b",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-VL 30B-A3B",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0024,
      "release_date": "2025-04"
    },
    "alibaba/qwen3-vl-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-plus",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-VL Plus",
      "output_cost_per_1k": 0.0016,
      "provider": "alibaba",
      "reasoning_cost_per_1k": 0.0048,
      "release_date": "2025-09-23"
    },
    "alibaba/qwq-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwq-plus",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "QwQ Plus",
      "output_cost_per_1k": 0.0024,
      "provider": "alibaba",
      "release_date": "2025-03-05"
    },
    "alibaba_cn/deepseek-r1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1",
      "input_cost_per_1k": 0.000574,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1",
      "output_cost_per_1k": 0.002294,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1-0528",
      "input_cost_per_1k": 0.000574,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 0528",
      "output_cost_per_1k": 0.002294,
      "provider": "alibaba_cn",
      "release_date": "2025-05-28"
    },
    "alibaba_cn/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.000287,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-distill-llama-8b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-8b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 8B",
      "output_cost_per_1k": 0.0,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-distill-qwen-1-5b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-r1-distill-qwen-1-5b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 1.5B",
      "output_cost_per_1k": 0.0,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-distill-qwen-14b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-r1-distill-qwen-14b",
      "input_cost_per_1k": 0.000144,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 14B",
      "output_cost_per_1k": 0.000431,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-r1-distill-qwen-32b",
      "input_cost_per_1k": 0.000287,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-distill-qwen-7b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-r1-distill-qwen-7b",
      "input_cost_per_1k": 7.2e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 7B",
      "output_cost_per_1k": 0.000144,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-v3": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3",
      "input_cost_per_1k": 0.000287,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3",
      "output_cost_per_1k": 0.001147,
      "provider": "alibaba_cn",
      "release_date": "2024-12-01"
    },
    "alibaba_cn/deepseek-v3-1": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3-1",
      "input_cost_per_1k": 0.000574,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "output_cost_per_1k": 0.001721,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-v3-2-exp": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3-2-exp",
      "input_cost_per_1k": 0.000287,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.2 Exp",
      "output_cost_per_1k": 0.000431,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/moonshot-kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshot-kimi-k2-instruct",
      "input_cost_per_1k": 0.000574,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Moonshot Kimi K2 Instruct",
      "output_cost_per_1k": 0.002294,
      "provider": "alibaba_cn",
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qvq-max": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qvq-max",
      "id": "qvq-max",
      "input_cost_per_1k": 0.001147,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "QVQ Max",
      "output_cost_per_1k": 0.004588,
      "provider": "alibaba_cn",
      "release_date": "2025-03-25"
    },
    "alibaba_cn/qwen-deep-research": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-deep-research",
      "id": "qwen-deep-research",
      "input_cost_per_1k": 0.007742,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen Deep Research",
      "output_cost_per_1k": 0.023367,
      "provider": "alibaba_cn",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen-doc-turbo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-doc",
      "id": "qwen-doc-turbo",
      "input_cost_per_1k": 8.7e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen Doc Turbo",
      "output_cost_per_1k": 0.000144,
      "provider": "alibaba_cn",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen-flash": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen-flash",
      "id": "qwen-flash",
      "input_cost_per_1k": 2.2e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen Flash",
      "output_cost_per_1k": 0.000216,
      "provider": "alibaba_cn",
      "release_date": "2025-07-28"
    },
    "alibaba_cn/qwen-long": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-long",
      "id": "qwen-long",
      "input_cost_per_1k": 7.2e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 10000000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen Long",
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "release_date": "2025-01-25"
    },
    "alibaba_cn/qwen-math-plus": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-math",
      "id": "qwen-math-plus",
      "input_cost_per_1k": 0.000574,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "mode": "chat",
      "name": "Qwen Math Plus",
      "output_cost_per_1k": 0.001721,
      "provider": "alibaba_cn",
      "release_date": "2024-08-16"
    },
    "alibaba_cn/qwen-math-turbo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-math",
      "id": "qwen-math-turbo",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "mode": "chat",
      "name": "Qwen Math Turbo",
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2024-09-19"
    },
    "alibaba_cn/qwen-max": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-max",
      "id": "qwen-max",
      "input_cost_per_1k": 0.000345,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen Max",
      "output_cost_per_1k": 0.001377,
      "provider": "alibaba_cn",
      "release_date": "2024-04-03"
    },
    "alibaba_cn/qwen-mt-plus": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen-mt",
      "id": "qwen-mt-plus",
      "input_cost_per_1k": 0.000259,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-MT Plus",
      "output_cost_per_1k": 0.000775,
      "provider": "alibaba_cn",
      "release_date": "2025-01"
    },
    "alibaba_cn/qwen-mt-turbo": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen-mt",
      "id": "qwen-mt-turbo",
      "input_cost_per_1k": 0.000101,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-MT Turbo",
      "output_cost_per_1k": 0.00028,
      "provider": "alibaba_cn",
      "release_date": "2025-01"
    },
    "alibaba_cn/qwen-omni-turbo": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen-omni",
      "id": "qwen-omni-turbo",
      "input_cost_per_1k": 5.8e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen-Omni Turbo",
      "output_cost_per_1k": 0.00023,
      "provider": "alibaba_cn",
      "release_date": "2025-01-19"
    },
    "alibaba_cn/qwen-omni-turbo-realtime": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen-omni",
      "id": "qwen-omni-turbo-realtime",
      "input_cost_per_1k": 0.00023,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen-Omni Turbo Realtime",
      "output_cost_per_1k": 0.000918,
      "provider": "alibaba_cn",
      "release_date": "2025-05-08"
    },
    "alibaba_cn/qwen-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen-plus",
      "id": "qwen-plus",
      "input_cost_per_1k": 0.000115,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen Plus",
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.001147,
      "release_date": "2024-01-25"
    },
    "alibaba_cn/qwen-plus-character": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen-plus",
      "id": "qwen-plus-character",
      "input_cost_per_1k": 0.000115,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen Plus Character",
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen-turbo": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen-turbo",
      "id": "qwen-turbo",
      "input_cost_per_1k": 4.4e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen Turbo",
      "output_cost_per_1k": 8.7e-05,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.000431,
      "release_date": "2024-11-01"
    },
    "alibaba_cn/qwen-vl-max": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen-vl",
      "id": "qwen-vl-max",
      "input_cost_per_1k": 0.00023,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-VL Max",
      "output_cost_per_1k": 0.000574,
      "provider": "alibaba_cn",
      "release_date": "2024-04-08"
    },
    "alibaba_cn/qwen-vl-ocr": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "qwen-vl",
      "id": "qwen-vl-ocr",
      "input_cost_per_1k": 0.000717,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 34096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen-VL OCR",
      "output_cost_per_1k": 0.000717,
      "provider": "alibaba_cn",
      "release_date": "2024-10-28"
    },
    "alibaba_cn/qwen-vl-plus": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen-vl",
      "id": "qwen-vl-plus",
      "input_cost_per_1k": 0.000115,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen-VL Plus",
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "release_date": "2024-01-25"
    },
    "alibaba_cn/qwen2-5-14b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-14b-instruct",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 14B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000431,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-32b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-32b-instruct",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-72b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-72b-instruct",
      "input_cost_per_1k": 0.000574,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.001721,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen2-5-7b-instruct",
      "input_cost_per_1k": 7.2e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 7B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000144,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-coder-32b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen2-5-coder-32b-instruct",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5-Coder 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2024-11"
    },
    "alibaba_cn/qwen2-5-coder-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen2-5-coder-7b-instruct",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5-Coder 7B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "release_date": "2024-11"
    },
    "alibaba_cn/qwen2-5-math-72b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5-math",
      "id": "qwen2-5-math-72b-instruct",
      "input_cost_per_1k": 0.000574,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "mode": "chat",
      "name": "Qwen2.5-Math 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.001721,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-math-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5-math",
      "id": "qwen2-5-math-7b-instruct",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "mode": "chat",
      "name": "Qwen2.5-Math 7B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-omni-7b": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen2.5-omni",
      "id": "qwen2-5-omni-7b",
      "input_cost_per_1k": 8.7e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen2.5-Omni 7B",
      "open_weights": true,
      "output_cost_per_1k": 0.000345,
      "provider": "alibaba_cn",
      "release_date": "2024-12"
    },
    "alibaba_cn/qwen2-5-vl-72b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen2-5-vl-72b-instruct",
      "input_cost_per_1k": 0.002294,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5-VL 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.006881,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen2-5-vl-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen2-5-vl-7b-instruct",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5-VL 7B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000717,
      "provider": "alibaba_cn",
      "release_date": "2024-09"
    },
    "alibaba_cn/qwen3-14b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-14b",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 14B",
      "open_weights": true,
      "output_cost_per_1k": 0.000574,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.001434,
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-235b-a22b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 235B-A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.001147,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.002868,
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-32b",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.001147,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.002868,
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-8b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-8b",
      "input_cost_per_1k": 7.2e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 8B",
      "open_weights": true,
      "output_cost_per_1k": 0.000287,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.000717,
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-asr-flash": {
      "capabilities": [
        "audio_input"
      ],
      "family": "qwen3",
      "id": "qwen3-asr-flash",
      "input_cost_per_1k": 3.2e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 53248,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen3-ASR Flash",
      "output_cost_per_1k": 3.2e-05,
      "provider": "alibaba_cn",
      "release_date": "2025-09-08"
    },
    "alibaba_cn/qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 0.000216,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.000861,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3-Coder 480B-A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003441,
      "provider": "alibaba_cn",
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-coder-flash": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-flash",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder Flash",
      "output_cost_per_1k": 0.000574,
      "provider": "alibaba_cn",
      "release_date": "2025-07-28"
    },
    "alibaba_cn/qwen3-coder-plus": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-plus",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder Plus",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "alibaba_cn",
      "release_date": "2025-07-23"
    },
    "alibaba_cn/qwen3-max": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-max",
      "input_cost_per_1k": 0.000861,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Max",
      "output_cost_per_1k": 0.003441,
      "provider": "alibaba_cn",
      "release_date": "2025-09-23"
    },
    "alibaba_cn/qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-Next 80B-A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.000574,
      "provider": "alibaba_cn",
      "release_date": "2025-09"
    },
    "alibaba_cn/qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.000144,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-Next 80B-A3B (Thinking)",
      "open_weights": true,
      "output_cost_per_1k": 0.001434,
      "provider": "alibaba_cn",
      "release_date": "2025-09"
    },
    "alibaba_cn/qwen3-omni-flash": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen3-omni-flash",
      "input_cost_per_1k": 5.8e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3-Omni Flash",
      "output_cost_per_1k": 0.00023,
      "provider": "alibaba_cn",
      "release_date": "2025-09-15"
    },
    "alibaba_cn/qwen3-omni-flash-realtime": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen3-omni-flash-realtime",
      "input_cost_per_1k": 0.00023,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3-Omni Flash Realtime",
      "output_cost_per_1k": 0.000918,
      "provider": "alibaba_cn",
      "release_date": "2025-09-15"
    },
    "alibaba_cn/qwen3-vl-235b-a22b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-235b-a22b",
      "input_cost_per_1k": 0.00028671,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-VL 235B-A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.00114682,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.00286705,
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-vl-30b-a3b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-30b-a3b",
      "input_cost_per_1k": 0.000108,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-VL 30B-A3B",
      "open_weights": true,
      "output_cost_per_1k": 0.000431,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.001076,
      "release_date": "2025-04"
    },
    "alibaba_cn/qwen3-vl-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-plus",
      "input_cost_per_1k": 0.00014335,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3-VL Plus",
      "output_cost_per_1k": 0.00143352,
      "provider": "alibaba_cn",
      "reasoning_cost_per_1k": 0.00430058,
      "release_date": "2025-09-23"
    },
    "alibaba_cn/qwq-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwq-32b",
      "input_cost_per_1k": 0.000287,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "QwQ 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.000861,
      "provider": "alibaba_cn",
      "release_date": "2024-12"
    },
    "alibaba_cn/qwq-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwq-plus",
      "input_cost_per_1k": 0.00023,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "QwQ Plus",
      "output_cost_per_1k": 0.000574,
      "provider": "alibaba_cn",
      "release_date": "2025-03-05"
    },
    "alibaba_cn/tongyi-intent-detect-v3": {
      "capabilities": [
        "temperature"
      ],
      "family": "yi",
      "id": "tongyi-intent-detect-v3",
      "input_cost_per_1k": 5.8e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Tongyi Intent Detect V3",
      "output_cost_per_1k": 0.000144,
      "provider": "alibaba_cn",
      "release_date": "2024-01"
    },
    "anthropic/claude-3-5-haiku-20241022": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3-5-haiku-20241022",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5",
      "output_cost_per_1k": 0.004,
      "provider": "anthropic",
      "release_date": "2024-10-22"
    },
    "anthropic/claude-3-5-haiku-latest": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3-5-haiku-latest",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5 (latest)",
      "output_cost_per_1k": 0.004,
      "provider": "anthropic",
      "release_date": "2024-10-22"
    },
    "anthropic/claude-3-5-sonnet-20240620": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-5-sonnet-20240620",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2024-06-20"
    },
    "anthropic/claude-3-5-sonnet-20241022": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-5-sonnet-20241022",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5 v2",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2024-10-22"
    },
    "anthropic/claude-3-7-sonnet-20250219": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-7-sonnet-20250219",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-10-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2025-02-19"
    },
    "anthropic/claude-3-7-sonnet-latest": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-7-sonnet-latest",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-10-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7 (latest)",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2025-02-19"
    },
    "anthropic/claude-3-haiku-20240307": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3-haiku-20240307",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Haiku 3",
      "output_cost_per_1k": 0.00125,
      "provider": "anthropic",
      "release_date": "2024-03-13"
    },
    "anthropic/claude-3-opus-20240229": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-3-opus-20240229",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Opus 3",
      "output_cost_per_1k": 0.075,
      "provider": "anthropic",
      "release_date": "2024-02-29"
    },
    "anthropic/claude-3-sonnet-20240229": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-sonnet-20240229",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Sonnet 3",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2024-03-04"
    },
    "anthropic/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5 (latest)",
      "output_cost_per_1k": 0.005,
      "provider": "anthropic",
      "release_date": "2025-10-15"
    },
    "anthropic/claude-haiku-4-5-20251001": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5-20251001",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "anthropic",
      "release_date": "2025-10-15"
    },
    "anthropic/claude-opus-4-0": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-0",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4 (latest)",
      "output_cost_per_1k": 0.075,
      "provider": "anthropic",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1 (latest)",
      "output_cost_per_1k": 0.075,
      "provider": "anthropic",
      "release_date": "2025-08-05"
    },
    "anthropic/claude-opus-4-1-20250805": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1-20250805",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "anthropic",
      "release_date": "2025-08-05"
    },
    "anthropic/claude-opus-4-20250514": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-20250514",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "anthropic",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-opus-4-5": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5 (latest)",
      "output_cost_per_1k": 0.025,
      "provider": "anthropic",
      "release_date": "2025-11-24"
    },
    "anthropic/claude-opus-4-5-20251101": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-5-20251101",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "anthropic",
      "release_date": "2025-11-01"
    },
    "anthropic/claude-sonnet-4-0": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4 (latest)",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-sonnet-4-20250514": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-20250514",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5 (latest)",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2025-09-29"
    },
    "anthropic/claude-sonnet-4-5-20250929": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5-20250929",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "anthropic",
      "release_date": "2025-09-29"
    },
    "aws_bedrock/ai21.jamba-1-5-large-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "jamba-1.5-large",
      "id": "ai21.jamba-1-5-large-v1:0",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Jamba 1.5 Large",
      "open_weights": true,
      "output_cost_per_1k": 0.008,
      "provider": "aws_bedrock",
      "release_date": "2024-08-15"
    },
    "aws_bedrock/ai21.jamba-1-5-mini-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "jamba-1.5-mini",
      "id": "ai21.jamba-1-5-mini-v1:0",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Jamba 1.5 Mini",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "aws_bedrock",
      "release_date": "2024-08-15"
    },
    "aws_bedrock/amazon.nova-2-lite-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nova",
      "id": "amazon.nova-2-lite-v1:0",
      "input_cost_per_1k": 0.00033,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Nova 2 Lite",
      "output_cost_per_1k": 0.00275,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/amazon.nova-lite-v1:0": {
      "cache_read_cost_per_1k": 1.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nova-lite",
      "id": "amazon.nova-lite-v1:0",
      "input_cost_per_1k": 6e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Nova Lite",
      "output_cost_per_1k": 0.00024,
      "provider": "aws_bedrock",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/amazon.nova-micro-v1:0": {
      "cache_read_cost_per_1k": 8.75e-06,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "nova-micro",
      "id": "amazon.nova-micro-v1:0",
      "input_cost_per_1k": 3.5e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Nova Micro",
      "output_cost_per_1k": 0.00014,
      "provider": "aws_bedrock",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/amazon.nova-premier-v1:0": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nova",
      "id": "amazon.nova-premier-v1:0",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Nova Premier",
      "output_cost_per_1k": 0.0125,
      "provider": "aws_bedrock",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/amazon.nova-pro-v1:0": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nova-pro",
      "id": "amazon.nova-pro-v1:0",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Nova Pro",
      "output_cost_per_1k": 0.0032,
      "provider": "aws_bedrock",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/amazon.titan-text-express-v1": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "titan-text-express",
      "id": "amazon.titan-text-express-v1",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Titan Text G1 - Express",
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/amazon.titan-text-express-v1:0:8k": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "titan-text-express",
      "id": "amazon.titan-text-express-v1:0:8k",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Titan Text G1 - Express",
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/anthropic.claude-3-5-haiku-20241022-v1:0": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5",
      "output_cost_per_1k": 0.004,
      "provider": "aws_bedrock",
      "release_date": "2024-10-22"
    },
    "aws_bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5",
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2024-06-20"
    },
    "aws_bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5 v2",
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2024-10-22"
    },
    "aws_bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2025-02-19"
    },
    "aws_bedrock/anthropic.claude-3-haiku-20240307-v1:0": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic.claude-3-haiku-20240307-v1:0",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-02",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Haiku 3",
      "output_cost_per_1k": 0.00125,
      "provider": "aws_bedrock",
      "release_date": "2024-03-13"
    },
    "aws_bedrock/anthropic.claude-3-opus-20240229-v1:0": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic.claude-3-opus-20240229-v1:0",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Opus 3",
      "output_cost_per_1k": 0.075,
      "provider": "aws_bedrock",
      "release_date": "2024-02-29"
    },
    "aws_bedrock/anthropic.claude-3-sonnet-20240229-v1:0": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Sonnet 3",
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2024-03-04"
    },
    "aws_bedrock/anthropic.claude-haiku-4-5-20251001-v1:0": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic.claude-haiku-4-5-20251001-v1:0",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "aws_bedrock",
      "release_date": "2025-10-15"
    },
    "aws_bedrock/anthropic.claude-instant-v1": {
      "capabilities": [
        "temperature"
      ],
      "family": "claude",
      "id": "anthropic.claude-instant-v1",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 100000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Instant",
      "output_cost_per_1k": 0.0024,
      "provider": "aws_bedrock",
      "release_date": "2023-03-01"
    },
    "aws_bedrock/anthropic.claude-opus-4-1-20250805-v1:0": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic.claude-opus-4-1-20250805-v1:0",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "aws_bedrock",
      "release_date": "2025-08-05"
    },
    "aws_bedrock/anthropic.claude-opus-4-20250514-v1:0": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic.claude-opus-4-20250514-v1:0",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "aws_bedrock",
      "release_date": "2025-05-22"
    },
    "aws_bedrock/anthropic.claude-opus-4-5-20251101-v1:0": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic.claude-opus-4-5-20251101-v1:0",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "aws_bedrock",
      "release_date": "2025-11-24"
    },
    "aws_bedrock/anthropic.claude-sonnet-4-20250514-v1:0": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic.claude-sonnet-4-20250514-v1:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2025-05-22"
    },
    "aws_bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic.claude-sonnet-4-5-20250929-v1:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2025-09-29"
    },
    "aws_bedrock/anthropic.claude-v2": {
      "capabilities": [
        "temperature"
      ],
      "family": "claude",
      "id": "anthropic.claude-v2",
      "input_cost_per_1k": 0.008,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 100000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude 2",
      "output_cost_per_1k": 0.024,
      "provider": "aws_bedrock",
      "release_date": "2023-07-11"
    },
    "aws_bedrock/anthropic.claude-v2:1": {
      "capabilities": [
        "temperature"
      ],
      "family": "claude",
      "id": "anthropic.claude-v2:1",
      "input_cost_per_1k": 0.008,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude 2.1",
      "output_cost_per_1k": 0.024,
      "provider": "aws_bedrock",
      "release_date": "2023-11-21"
    },
    "aws_bedrock/cohere.command-light-text-v14": {
      "capabilities": [
        "temperature"
      ],
      "family": "command-light",
      "id": "cohere.command-light-text-v14",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Command Light",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2023-11-01"
    },
    "aws_bedrock/cohere.command-r-plus-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "command-r-plus",
      "id": "cohere.command-r-plus-v1:0",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Command R+",
      "open_weights": true,
      "output_cost_per_1k": 0.015,
      "provider": "aws_bedrock",
      "release_date": "2024-04-04"
    },
    "aws_bedrock/cohere.command-r-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "command-r",
      "id": "cohere.command-r-v1:0",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Command R",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "aws_bedrock",
      "release_date": "2024-03-11"
    },
    "aws_bedrock/cohere.command-text-v14": {
      "capabilities": [
        "temperature"
      ],
      "family": "command",
      "id": "cohere.command-text-v14",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2023-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Command",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "aws_bedrock",
      "release_date": "2023-11-01"
    },
    "aws_bedrock/deepseek.r1-v1:0": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek.r1-v1:0",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "DeepSeek-R1",
      "output_cost_per_1k": 0.0054,
      "provider": "aws_bedrock",
      "release_date": "2025-01-20"
    },
    "aws_bedrock/deepseek.v3-v1:0": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek.v3-v1:0",
      "input_cost_per_1k": 0.00058,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 81920,
      "mode": "chat",
      "name": "DeepSeek-V3.1",
      "open_weights": true,
      "output_cost_per_1k": 0.00168,
      "provider": "aws_bedrock",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/global.anthropic.claude-opus-4-5-20251101-v1:0": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "global.anthropic.claude-opus-4-5-20251101-v1:0",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5 (Global)",
      "output_cost_per_1k": 0.025,
      "provider": "aws_bedrock",
      "release_date": "2025-11-24"
    },
    "aws_bedrock/google.gemma-3-12b-it": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google.gemma-3-12b-it",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Google Gemma 3 12B",
      "output_cost_per_1k": 0.0001,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/google.gemma-3-27b-it": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google.gemma-3-27b-it",
      "input_cost_per_1k": 0.00012,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 202752,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Google Gemma 3 27B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "aws_bedrock",
      "release_date": "2025-07-27"
    },
    "aws_bedrock/google.gemma-3-4b-it": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google.gemma-3-4b-it",
      "input_cost_per_1k": 4e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 3 4B IT",
      "output_cost_per_1k": 8e-05,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/meta.llama3-1-70b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-1-70b-instruct-v1:0",
      "input_cost_per_1k": 0.00072,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 70B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00072,
      "provider": "aws_bedrock",
      "release_date": "2024-07-23"
    },
    "aws_bedrock/meta.llama3-1-8b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-1-8b-instruct-v1:0",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00022,
      "provider": "aws_bedrock",
      "release_date": "2024-07-23"
    },
    "aws_bedrock/meta.llama3-2-11b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama",
      "id": "meta.llama3-2-11b-instruct-v1:0",
      "input_cost_per_1k": 0.00016,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 11B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00016,
      "provider": "aws_bedrock",
      "release_date": "2024-09-25"
    },
    "aws_bedrock/meta.llama3-2-1b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-2-1b-instruct-v1:0",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 1B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "aws_bedrock",
      "release_date": "2024-09-25"
    },
    "aws_bedrock/meta.llama3-2-3b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-2-3b-instruct-v1:0",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "aws_bedrock",
      "release_date": "2024-09-25"
    },
    "aws_bedrock/meta.llama3-2-90b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama",
      "id": "meta.llama3-2-90b-instruct-v1:0",
      "input_cost_per_1k": 0.00072,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 90B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00072,
      "provider": "aws_bedrock",
      "release_date": "2024-09-25"
    },
    "aws_bedrock/meta.llama3-3-70b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-3-70b-instruct-v1:0",
      "input_cost_per_1k": 0.00072,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.3 70B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00072,
      "provider": "aws_bedrock",
      "release_date": "2024-12-06"
    },
    "aws_bedrock/meta.llama3-70b-instruct-v1:0": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-70b-instruct-v1:0",
      "input_cost_per_1k": 0.00265,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Llama 3 70B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0035,
      "provider": "aws_bedrock",
      "release_date": "2024-07-23"
    },
    "aws_bedrock/meta.llama3-8b-instruct-v1:0": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama",
      "id": "meta.llama3-8b-instruct-v1:0",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2023-03",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Llama 3 8B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2024-07-23"
    },
    "aws_bedrock/meta.llama4-maverick-17b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama",
      "id": "meta.llama4-maverick-17b-instruct-v1:0",
      "input_cost_per_1k": 0.00024,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00097,
      "provider": "aws_bedrock",
      "release_date": "2025-04-05"
    },
    "aws_bedrock/meta.llama4-scout-17b-instruct-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama",
      "id": "meta.llama4-scout-17b-instruct-v1:0",
      "input_cost_per_1k": 0.00017,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 3500000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 4 Scout 17B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00066,
      "provider": "aws_bedrock",
      "release_date": "2025-04-05"
    },
    "aws_bedrock/minimax.minimax-m2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax.minimax-m2",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 204608,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "MiniMax M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "aws_bedrock",
      "release_date": "2025-10-27"
    },
    "aws_bedrock/mistral.ministral-3-14b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral",
      "id": "mistral.ministral-3-14b-instruct",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Ministral 14B 3.0",
      "output_cost_per_1k": 0.0002,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/mistral.ministral-3-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral",
      "id": "mistral.ministral-3-8b-instruct",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Ministral 3 8B",
      "output_cost_per_1k": 0.00015,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/mistral.mistral-7b-instruct-v0:2": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "mistral.mistral-7b-instruct-v0:2",
      "input_cost_per_1k": 0.00011,
      "max_input_tokens": 127000,
      "max_output_tokens": 127000,
      "mode": "chat",
      "name": "Mistral-7B-Instruct-v0.3",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "aws_bedrock",
      "release_date": "2025-04-01"
    },
    "aws_bedrock/mistral.mistral-large-2402-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-large",
      "id": "mistral.mistral-large-2402-v1:0",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mistral Large (24.02)",
      "output_cost_per_1k": 0.0015,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/mistral.mixtral-8x7b-instruct-v0:1": {
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "family": "mixtral-8x7b",
      "id": "mistral.mixtral-8x7b-instruct-v0:1",
      "input_cost_per_1k": 0.0007,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Mixtral-8x7B-Instruct-v0.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0007,
      "provider": "aws_bedrock",
      "release_date": "2025-04-01"
    },
    "aws_bedrock/mistral.voxtral-mini-3b-2507": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature"
      ],
      "family": "mistral",
      "id": "mistral.voxtral-mini-3b-2507",
      "input_cost_per_1k": 4e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Voxtral Mini 3B 2507",
      "output_cost_per_1k": 4e-05,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/mistral.voxtral-small-24b-2507": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral",
      "id": "mistral.voxtral-small-24b-2507",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Voxtral Small 24B 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00035,
      "provider": "aws_bedrock",
      "release_date": "2025-07-01"
    },
    "aws_bedrock/moonshot.kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": null,
      "id": "moonshot.kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "aws_bedrock",
      "release_date": "2025-12-02"
    },
    "aws_bedrock/nvidia.nemotron-nano-12b-v2": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "nemotron",
      "id": "nvidia.nemotron-nano-12b-v2",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "NVIDIA Nemotron Nano 12B v2 VL BF16",
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/nvidia.nemotron-nano-9b-v2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "nemotron",
      "id": "nvidia.nemotron-nano-9b-v2",
      "input_cost_per_1k": 6e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "NVIDIA Nemotron Nano 9B v2",
      "output_cost_per_1k": 0.00023,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/openai.gpt-oss-120b-1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "openai.gpt-oss",
      "id": "openai.gpt-oss-120b-1:0",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "gpt-oss-120b",
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/openai.gpt-oss-20b-1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "openai.gpt-oss",
      "id": "openai.gpt-oss-20b-1:0",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "gpt-oss-20b",
      "output_cost_per_1k": 0.0003,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/openai.gpt-oss-safeguard-120b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "openai.gpt-oss-safeguard",
      "id": "openai.gpt-oss-safeguard-120b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT OSS Safeguard 120B",
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/openai.gpt-oss-safeguard-20b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "openai.gpt-oss-safeguard",
      "id": "openai.gpt-oss-safeguard-20b",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT OSS Safeguard 20B",
      "output_cost_per_1k": 0.0002,
      "provider": "aws_bedrock",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/qwen.qwen3-235b-a22b-2507-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen.qwen3-235b-a22b-2507-v1:0",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00088,
      "provider": "aws_bedrock",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/qwen.qwen3-32b-v1:0": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen.qwen3-32b-v1:0",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 32B (dense)",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/qwen.qwen3-coder-30b-a3b-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen.qwen3-coder-30b-a3b-v1:0",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "output_cost_per_1k": 0.0006,
      "provider": "aws_bedrock",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/qwen.qwen3-coder-480b-a35b-v1:0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen.qwen3-coder-480b-a35b-v1:0",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "aws_bedrock",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/qwen.qwen3-next-80b-a3b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen.qwen3-next-80b-a3b",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "output_cost_per_1k": 0.0014,
      "provider": "aws_bedrock",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/qwen.qwen3-vl-235b-a22b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen.qwen3-vl-235b-a22b",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "output_cost_per_1k": 0.0015,
      "provider": "aws_bedrock",
      "release_date": "2025-10-04"
    },
    "azure_cognitive_services/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-18"
    },
    "azure_cognitive_services/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-18"
    },
    "azure_cognitive_services/claude-opus-4-5": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-24"
    },
    "azure_cognitive_services/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-18"
    },
    "azure_cognitive_services/codestral-2501": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "codestral",
      "id": "codestral-2501",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Codestral 25.01",
      "output_cost_per_1k": 0.0009,
      "provider": "azure_cognitive_services",
      "release_date": "2025-01-01"
    },
    "azure_cognitive_services/codex-mini": {
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "codex",
      "id": "codex-mini",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "Codex Mini",
      "output_cost_per_1k": 0.006,
      "provider": "azure_cognitive_services",
      "release_date": "2025-05-16"
    },
    "azure_cognitive_services/cohere-command-a": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-a",
      "id": "cohere-command-a",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Command A",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-03-13"
    },
    "azure_cognitive_services/cohere-command-r-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r",
      "id": "cohere-command-r-08-2024",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "azure_cognitive_services",
      "release_date": "2024-08-30"
    },
    "azure_cognitive_services/cohere-command-r-plus-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r-plus",
      "id": "cohere-command-r-plus-08-2024",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R+",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2024-08-30"
    },
    "azure_cognitive_services/cohere-embed-v-4-0": {
      "capabilities": [
        "vision"
      ],
      "family": "cohere-embed",
      "id": "cohere-embed-v-4-0",
      "input_cost_per_1k": 0.00012,
      "max_input_tokens": 128000,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "Embed v4",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-15"
    },
    "azure_cognitive_services/cohere-embed-v3-english": {
      "family": "cohere-embed",
      "id": "cohere-embed-v3-english",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "mode": "embedding",
      "name": "Embed v3 English",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2023-11-07"
    },
    "azure_cognitive_services/cohere-embed-v3-multilingual": {
      "family": "cohere-embed",
      "id": "cohere-embed-v3-multilingual",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "mode": "embedding",
      "name": "Embed v3 Multilingual",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2023-11-07"
    },
    "azure_cognitive_services/deepseek-r1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-R1",
      "open_weights": true,
      "output_cost_per_1k": 0.0054,
      "provider": "azure_cognitive_services",
      "release_date": "2025-01-20"
    },
    "azure_cognitive_services/deepseek-r1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1-0528",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-R1-0528",
      "open_weights": true,
      "output_cost_per_1k": 0.0054,
      "provider": "azure_cognitive_services",
      "release_date": "2025-05-28"
    },
    "azure_cognitive_services/deepseek-v3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3-0324",
      "input_cost_per_1k": 0.00114,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "DeepSeek-V3-0324",
      "open_weights": true,
      "output_cost_per_1k": 0.00456,
      "provider": "azure_cognitive_services",
      "release_date": "2025-03-24"
    },
    "azure_cognitive_services/deepseek-v3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.1",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "DeepSeek-V3.1",
      "open_weights": true,
      "output_cost_per_1k": 0.00168,
      "provider": "azure_cognitive_services",
      "release_date": "2025-08-21"
    },
    "azure_cognitive_services/deepseek-v3.2": {
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek-V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.00042,
      "provider": "azure_cognitive_services",
      "release_date": "2025-12-01"
    },
    "azure_cognitive_services/deepseek-v3.2-speciale": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2-speciale",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek-V3.2-Speciale",
      "open_weights": true,
      "output_cost_per_1k": 0.00042,
      "provider": "azure_cognitive_services",
      "release_date": "2025-12-01"
    },
    "azure_cognitive_services/gpt-3.5-turbo-0125": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-0125",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 0125",
      "output_cost_per_1k": 0.0015,
      "provider": "azure_cognitive_services",
      "release_date": "2024-01-25"
    },
    "azure_cognitive_services/gpt-3.5-turbo-0301": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-0301",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 0301",
      "output_cost_per_1k": 0.002,
      "provider": "azure_cognitive_services",
      "release_date": "2023-03-01"
    },
    "azure_cognitive_services/gpt-3.5-turbo-0613": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-0613",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 0613",
      "output_cost_per_1k": 0.004,
      "provider": "azure_cognitive_services",
      "release_date": "2023-06-13"
    },
    "azure_cognitive_services/gpt-3.5-turbo-1106": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-1106",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 1106",
      "output_cost_per_1k": 0.002,
      "provider": "azure_cognitive_services",
      "release_date": "2023-11-06"
    },
    "azure_cognitive_services/gpt-3.5-turbo-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-instruct",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-3.5 Turbo Instruct",
      "output_cost_per_1k": 0.002,
      "provider": "azure_cognitive_services",
      "release_date": "2023-09-21"
    },
    "azure_cognitive_services/gpt-4": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-4",
      "id": "gpt-4",
      "input_cost_per_1k": 0.06,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4",
      "output_cost_per_1k": 0.12,
      "provider": "azure_cognitive_services",
      "release_date": "2023-03-14"
    },
    "azure_cognitive_services/gpt-4-32k": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-4",
      "id": "gpt-4-32k",
      "input_cost_per_1k": 0.06,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4 32K",
      "output_cost_per_1k": 0.12,
      "provider": "azure_cognitive_services",
      "release_date": "2023-03-14"
    },
    "azure_cognitive_services/gpt-4-turbo": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "gpt-4-turbo",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo",
      "output_cost_per_1k": 0.03,
      "provider": "azure_cognitive_services",
      "release_date": "2023-11-06"
    },
    "azure_cognitive_services/gpt-4-turbo-vision": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "gpt-4-turbo-vision",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo Vision",
      "output_cost_per_1k": 0.03,
      "provider": "azure_cognitive_services",
      "release_date": "2023-11-06"
    },
    "azure_cognitive_services/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-14"
    },
    "azure_cognitive_services/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 mini",
      "output_cost_per_1k": 0.0016,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-14"
    },
    "azure_cognitive_services/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "gpt-4.1-nano",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 nano",
      "output_cost_per_1k": 0.0004,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-14"
    },
    "azure_cognitive_services/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2024-05-13"
    },
    "azure_cognitive_services/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o mini",
      "output_cost_per_1k": 0.0006,
      "provider": "azure_cognitive_services",
      "release_date": "2024-07-18"
    },
    "azure_cognitive_services/gpt-5": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-5-chat": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5-chat",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-24",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-09-15"
    },
    "azure_cognitive_services/gpt-5-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "azure_cognitive_services",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-5-nano": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "azure_cognitive_services",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-5-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "gpt-5-pro",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "mode": "chat",
      "name": "GPT-5 Pro",
      "output_cost_per_1k": 0.12,
      "provider": "azure_cognitive_services",
      "release_date": "2025-10-06"
    },
    "azure_cognitive_services/gpt-5.1": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/gpt-5.1-chat": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.1-chat",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "image",
      "name": "GPT-5.1 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1 Codex Mini",
      "output_cost_per_1k": 0.002,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/gpt-5.2-chat": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.2-chat",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.2 Chat",
      "output_cost_per_1k": 0.014,
      "provider": "azure_cognitive_services",
      "release_date": "2025-12-11"
    },
    "azure_cognitive_services/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "azure_cognitive_services",
      "release_date": "2025-02-17"
    },
    "azure_cognitive_services/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "azure_cognitive_services",
      "reasoning_cost_per_1k": 0.0005,
      "release_date": "2025-02-17"
    },
    "azure_cognitive_services/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "azure_cognitive_services",
      "reasoning_cost_per_1k": 0.015,
      "release_date": "2025-07-09"
    },
    "azure_cognitive_services/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "azure_cognitive_services",
      "release_date": "2025-09-19"
    },
    "azure_cognitive_services/grok-4-fast-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast (Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "azure_cognitive_services",
      "release_date": "2025-09-19"
    },
    "azure_cognitive_services/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "azure_cognitive_services",
      "release_date": "2025-08-28"
    },
    "azure_cognitive_services/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "azure_cognitive_services",
      "release_date": "2025-11-06"
    },
    "azure_cognitive_services/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 0.00037,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.2-11B-Vision-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00037,
      "provider": "azure_cognitive_services",
      "release_date": "2024-09-25"
    },
    "azure_cognitive_services/llama-3.2-90b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-90b-vision-instruct",
      "input_cost_per_1k": 0.00204,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.2-90B-Vision-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00204,
      "provider": "azure_cognitive_services",
      "release_date": "2024-09-25"
    },
    "azure_cognitive_services/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.00071,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00071,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-06"
    },
    "azure_cognitive_services/llama-4-maverick-17b-128e-instruct-fp8": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-05"
    },
    "azure_cognitive_services/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00078,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-05"
    },
    "azure_cognitive_services/mai-ds-r1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "mai-ds-r1",
      "id": "mai-ds-r1",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "MAI-DS-R1",
      "output_cost_per_1k": 0.0054,
      "provider": "azure_cognitive_services",
      "release_date": "2025-01-20"
    },
    "azure_cognitive_services/meta-llama-3-70b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama-3-70b-instruct",
      "input_cost_per_1k": 0.00268,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Meta-Llama-3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00354,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-18"
    },
    "azure_cognitive_services/meta-llama-3-8b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama-3-8b-instruct",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Meta-Llama-3-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00061,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-18"
    },
    "azure_cognitive_services/meta-llama-3.1-405b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-405b-instruct",
      "input_cost_per_1k": 0.00533,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-405B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.016,
      "provider": "azure_cognitive_services",
      "release_date": "2024-07-23"
    },
    "azure_cognitive_services/meta-llama-3.1-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-70b-instruct",
      "input_cost_per_1k": 0.00268,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00354,
      "provider": "azure_cognitive_services",
      "release_date": "2024-07-23"
    },
    "azure_cognitive_services/meta-llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00061,
      "provider": "azure_cognitive_services",
      "release_date": "2024-07-23"
    },
    "azure_cognitive_services/ministral-3b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral-3b",
      "id": "ministral-3b",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Ministral 3B",
      "open_weights": true,
      "output_cost_per_1k": 4e-05,
      "provider": "azure_cognitive_services",
      "release_date": "2024-10-22"
    },
    "azure_cognitive_services/mistral-large-2411": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-large",
      "id": "mistral-large-2411",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Large 24.11",
      "output_cost_per_1k": 0.006,
      "provider": "azure_cognitive_services",
      "release_date": "2024-11-01"
    },
    "azure_cognitive_services/mistral-medium-2505": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistral-medium-2505",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral Medium 3",
      "output_cost_per_1k": 0.002,
      "provider": "azure_cognitive_services",
      "release_date": "2025-05-07"
    },
    "azure_cognitive_services/mistral-nemo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistral-nemo",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral Nemo",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "azure_cognitive_services",
      "release_date": "2024-07-18"
    },
    "azure_cognitive_services/mistral-small-2503": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small-2503",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Small 3.1",
      "output_cost_per_1k": 0.0003,
      "provider": "azure_cognitive_services",
      "release_date": "2025-03-01"
    },
    "azure_cognitive_services/model-router": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "model-router",
      "id": "model-router",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Model Router",
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2025-05-19"
    },
    "azure_cognitive_services/o1": {
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "o1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1",
      "output_cost_per_1k": 0.06,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-05"
    },
    "azure_cognitive_services/o1-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "family": "o1-mini",
      "id": "o1-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "o1-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "azure_cognitive_services",
      "release_date": "2024-09-12"
    },
    "azure_cognitive_services/o1-preview": {
      "cache_read_cost_per_1k": 0.00825,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "family": "o1-preview",
      "id": "o1-preview",
      "input_cost_per_1k": 0.0165,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "o1-preview",
      "output_cost_per_1k": 0.066,
      "provider": "azure_cognitive_services",
      "release_date": "2024-09-12"
    },
    "azure_cognitive_services/o3": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "o3",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3",
      "output_cost_per_1k": 0.008,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-16"
    },
    "azure_cognitive_services/o3-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "family": "o3-mini",
      "id": "o3-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-20"
    },
    "azure_cognitive_services/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "azure_cognitive_services",
      "release_date": "2025-04-16"
    },
    "azure_cognitive_services/phi-3-medium-128k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-medium-128k-instruct",
      "input_cost_per_1k": 0.00017,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-medium-instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00068,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-23"
    },
    "azure_cognitive_services/phi-3-medium-4k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-medium-4k-instruct",
      "input_cost_per_1k": 0.00017,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Phi-3-medium-instruct (4k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00068,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-23"
    },
    "azure_cognitive_services/phi-3-mini-128k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-mini-128k-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-mini-instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00052,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-23"
    },
    "azure_cognitive_services/phi-3-mini-4k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-mini-4k-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Phi-3-mini-instruct (4k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00052,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-23"
    },
    "azure_cognitive_services/phi-3-small-128k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-small-128k-instruct",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-small-instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-23"
    },
    "azure_cognitive_services/phi-3-small-8k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-small-8k-instruct",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Phi-3-small-instruct (8k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "azure_cognitive_services",
      "release_date": "2024-04-23"
    },
    "azure_cognitive_services/phi-3.5-mini-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3.5",
      "id": "phi-3.5-mini-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-mini-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00052,
      "provider": "azure_cognitive_services",
      "release_date": "2024-08-20"
    },
    "azure_cognitive_services/phi-3.5-moe-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3.5",
      "id": "phi-3.5-moe-instruct",
      "input_cost_per_1k": 0.00016,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-MoE-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00064,
      "provider": "azure_cognitive_services",
      "release_date": "2024-08-20"
    },
    "azure_cognitive_services/phi-4": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4",
      "input_cost_per_1k": 0.000125,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-11"
    },
    "azure_cognitive_services/phi-4-mini": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-mini",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-11"
    },
    "azure_cognitive_services/phi-4-mini-reasoning": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-mini-reasoning",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini-reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-11"
    },
    "azure_cognitive_services/phi-4-multimodal": {
      "capabilities": [
        "audio_input",
        "temperature",
        "vision"
      ],
      "family": "phi-4",
      "id": "phi-4-multimodal",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-multimodal",
      "open_weights": true,
      "output_cost_per_1k": 0.00032,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-11"
    },
    "azure_cognitive_services/phi-4-reasoning": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-reasoning",
      "input_cost_per_1k": 0.000125,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-11"
    },
    "azure_cognitive_services/phi-4-reasoning-plus": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-reasoning-plus",
      "input_cost_per_1k": 0.000125,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-reasoning-plus",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "azure_cognitive_services",
      "release_date": "2024-12-11"
    },
    "azure_cognitive_services/text-embedding-3-large": {
      "family": "text-embedding-3-large",
      "id": "text-embedding-3-large",
      "input_cost_per_1k": 0.00013,
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "mode": "embedding",
      "name": "text-embedding-3-large",
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2024-01-25"
    },
    "azure_cognitive_services/text-embedding-3-small": {
      "family": "text-embedding-3-small",
      "id": "text-embedding-3-small",
      "input_cost_per_1k": 2e-05,
      "max_input_tokens": 8191,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "text-embedding-3-small",
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2024-01-25"
    },
    "azure_cognitive_services/text-embedding-ada-002": {
      "family": "text-embedding-ada",
      "id": "text-embedding-ada-002",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 8192,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "text-embedding-ada-002",
      "output_cost_per_1k": 0.0,
      "provider": "azure_cognitive_services",
      "release_date": "2022-12-15"
    },
    "azure_openai/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "azure_openai",
      "release_date": "2025-11-18"
    },
    "azure_openai/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "azure_openai",
      "release_date": "2025-11-18"
    },
    "azure_openai/claude-opus-4-5": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "azure_openai",
      "release_date": "2025-11-24"
    },
    "azure_openai/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "azure_openai",
      "release_date": "2025-11-18"
    },
    "azure_openai/codestral-2501": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "codestral",
      "id": "codestral-2501",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Codestral 25.01",
      "output_cost_per_1k": 0.0009,
      "provider": "azure_openai",
      "release_date": "2025-01-01"
    },
    "azure_openai/codex-mini": {
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "codex",
      "id": "codex-mini",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "Codex Mini",
      "output_cost_per_1k": 0.006,
      "provider": "azure_openai",
      "release_date": "2025-05-16"
    },
    "azure_openai/cohere-command-a": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-a",
      "id": "cohere-command-a",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Command A",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-03-13"
    },
    "azure_openai/cohere-command-r-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r",
      "id": "cohere-command-r-08-2024",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "azure_openai",
      "release_date": "2024-08-30"
    },
    "azure_openai/cohere-command-r-plus-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r-plus",
      "id": "cohere-command-r-plus-08-2024",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R+",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2024-08-30"
    },
    "azure_openai/cohere-embed-v-4-0": {
      "capabilities": [
        "vision"
      ],
      "family": "cohere-embed",
      "id": "cohere-embed-v-4-0",
      "input_cost_per_1k": 0.00012,
      "max_input_tokens": 128000,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "Embed v4",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2025-04-15"
    },
    "azure_openai/cohere-embed-v3-english": {
      "family": "cohere-embed",
      "id": "cohere-embed-v3-english",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "mode": "embedding",
      "name": "Embed v3 English",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2023-11-07"
    },
    "azure_openai/cohere-embed-v3-multilingual": {
      "family": "cohere-embed",
      "id": "cohere-embed-v3-multilingual",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "mode": "embedding",
      "name": "Embed v3 Multilingual",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2023-11-07"
    },
    "azure_openai/deepseek-r1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-R1",
      "open_weights": true,
      "output_cost_per_1k": 0.0054,
      "provider": "azure_openai",
      "release_date": "2025-01-20"
    },
    "azure_openai/deepseek-r1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1-0528",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-R1-0528",
      "open_weights": true,
      "output_cost_per_1k": 0.0054,
      "provider": "azure_openai",
      "release_date": "2025-05-28"
    },
    "azure_openai/deepseek-v3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3-0324",
      "input_cost_per_1k": 0.00114,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "DeepSeek-V3-0324",
      "open_weights": true,
      "output_cost_per_1k": 0.00456,
      "provider": "azure_openai",
      "release_date": "2025-03-24"
    },
    "azure_openai/deepseek-v3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.1",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "DeepSeek-V3.1",
      "open_weights": true,
      "output_cost_per_1k": 0.00168,
      "provider": "azure_openai",
      "release_date": "2025-08-21"
    },
    "azure_openai/deepseek-v3.2": {
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek-V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.00042,
      "provider": "azure_openai",
      "release_date": "2025-12-01"
    },
    "azure_openai/deepseek-v3.2-speciale": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2-speciale",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek-V3.2-Speciale",
      "open_weights": true,
      "output_cost_per_1k": 0.00042,
      "provider": "azure_openai",
      "release_date": "2025-12-01"
    },
    "azure_openai/gpt-3.5-turbo-0125": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-0125",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 0125",
      "output_cost_per_1k": 0.0015,
      "provider": "azure_openai",
      "release_date": "2024-01-25"
    },
    "azure_openai/gpt-3.5-turbo-0301": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-0301",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 0301",
      "output_cost_per_1k": 0.002,
      "provider": "azure_openai",
      "release_date": "2023-03-01"
    },
    "azure_openai/gpt-3.5-turbo-0613": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-0613",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 0613",
      "output_cost_per_1k": 0.004,
      "provider": "azure_openai",
      "release_date": "2023-06-13"
    },
    "azure_openai/gpt-3.5-turbo-1106": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-1106",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-3.5 Turbo 1106",
      "output_cost_per_1k": 0.002,
      "provider": "azure_openai",
      "release_date": "2023-11-06"
    },
    "azure_openai/gpt-3.5-turbo-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo-instruct",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2021-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-3.5 Turbo Instruct",
      "output_cost_per_1k": 0.002,
      "provider": "azure_openai",
      "release_date": "2023-09-21"
    },
    "azure_openai/gpt-4": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-4",
      "id": "gpt-4",
      "input_cost_per_1k": 0.06,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4",
      "output_cost_per_1k": 0.12,
      "provider": "azure_openai",
      "release_date": "2023-03-14"
    },
    "azure_openai/gpt-4-32k": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-4",
      "id": "gpt-4-32k",
      "input_cost_per_1k": 0.06,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4 32K",
      "output_cost_per_1k": 0.12,
      "provider": "azure_openai",
      "release_date": "2023-03-14"
    },
    "azure_openai/gpt-4-turbo": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "gpt-4-turbo",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo",
      "output_cost_per_1k": 0.03,
      "provider": "azure_openai",
      "release_date": "2023-11-06"
    },
    "azure_openai/gpt-4-turbo-vision": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "gpt-4-turbo-vision",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo Vision",
      "output_cost_per_1k": 0.03,
      "provider": "azure_openai",
      "release_date": "2023-11-06"
    },
    "azure_openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "azure_openai",
      "release_date": "2025-04-14"
    },
    "azure_openai/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 mini",
      "output_cost_per_1k": 0.0016,
      "provider": "azure_openai",
      "release_date": "2025-04-14"
    },
    "azure_openai/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "gpt-4.1-nano",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 nano",
      "output_cost_per_1k": 0.0004,
      "provider": "azure_openai",
      "release_date": "2025-04-14"
    },
    "azure_openai/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2024-05-13"
    },
    "azure_openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o mini",
      "output_cost_per_1k": 0.0006,
      "provider": "azure_openai",
      "release_date": "2024-07-18"
    },
    "azure_openai/gpt-5": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-08-07"
    },
    "azure_openai/gpt-5-chat": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5-chat",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-24",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-08-07"
    },
    "azure_openai/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-09-15"
    },
    "azure_openai/gpt-5-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "azure_openai",
      "release_date": "2025-08-07"
    },
    "azure_openai/gpt-5-nano": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "azure_openai",
      "release_date": "2025-08-07"
    },
    "azure_openai/gpt-5-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "gpt-5-pro",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "mode": "chat",
      "name": "GPT-5 Pro",
      "output_cost_per_1k": 0.12,
      "provider": "azure_openai",
      "release_date": "2025-10-06"
    },
    "azure_openai/gpt-5.1": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-11-14"
    },
    "azure_openai/gpt-5.1-chat": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.1-chat",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "image",
      "name": "GPT-5.1 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-11-14"
    },
    "azure_openai/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-11-14"
    },
    "azure_openai/gpt-5.1-codex-max": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-max",
      "id": "gpt-5.1-codex-max",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex Max",
      "output_cost_per_1k": 0.01,
      "provider": "azure_openai",
      "release_date": "2025-11-13"
    },
    "azure_openai/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1 Codex Mini",
      "output_cost_per_1k": 0.002,
      "provider": "azure_openai",
      "release_date": "2025-11-14"
    },
    "azure_openai/gpt-5.2": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.2",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.014,
      "provider": "azure_openai",
      "release_date": "2025-12-11"
    },
    "azure_openai/gpt-5.2-chat": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.2-chat",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.2 Chat",
      "output_cost_per_1k": 0.014,
      "provider": "azure_openai",
      "release_date": "2025-12-11"
    },
    "azure_openai/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "azure_openai",
      "release_date": "2025-02-17"
    },
    "azure_openai/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "azure_openai",
      "reasoning_cost_per_1k": 0.0005,
      "release_date": "2025-02-17"
    },
    "azure_openai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "azure_openai",
      "reasoning_cost_per_1k": 0.015,
      "release_date": "2025-07-09"
    },
    "azure_openai/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "azure_openai",
      "release_date": "2025-09-19"
    },
    "azure_openai/grok-4-fast-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast (Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "azure_openai",
      "release_date": "2025-09-19"
    },
    "azure_openai/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "azure_openai",
      "release_date": "2025-08-28"
    },
    "azure_openai/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "azure_openai",
      "release_date": "2025-11-06"
    },
    "azure_openai/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 0.00037,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.2-11B-Vision-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00037,
      "provider": "azure_openai",
      "release_date": "2024-09-25"
    },
    "azure_openai/llama-3.2-90b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-90b-vision-instruct",
      "input_cost_per_1k": 0.00204,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.2-90B-Vision-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00204,
      "provider": "azure_openai",
      "release_date": "2024-09-25"
    },
    "azure_openai/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.00071,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00071,
      "provider": "azure_openai",
      "release_date": "2024-12-06"
    },
    "azure_openai/llama-4-maverick-17b-128e-instruct-fp8": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "azure_openai",
      "release_date": "2025-04-05"
    },
    "azure_openai/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00078,
      "provider": "azure_openai",
      "release_date": "2025-04-05"
    },
    "azure_openai/mai-ds-r1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "mai-ds-r1",
      "id": "mai-ds-r1",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "MAI-DS-R1",
      "output_cost_per_1k": 0.0054,
      "provider": "azure_openai",
      "release_date": "2025-01-20"
    },
    "azure_openai/meta-llama-3-70b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama-3-70b-instruct",
      "input_cost_per_1k": 0.00268,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Meta-Llama-3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00354,
      "provider": "azure_openai",
      "release_date": "2024-04-18"
    },
    "azure_openai/meta-llama-3-8b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama-3-8b-instruct",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Meta-Llama-3-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00061,
      "provider": "azure_openai",
      "release_date": "2024-04-18"
    },
    "azure_openai/meta-llama-3.1-405b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-405b-instruct",
      "input_cost_per_1k": 0.00533,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-405B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.016,
      "provider": "azure_openai",
      "release_date": "2024-07-23"
    },
    "azure_openai/meta-llama-3.1-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-70b-instruct",
      "input_cost_per_1k": 0.00268,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00354,
      "provider": "azure_openai",
      "release_date": "2024-07-23"
    },
    "azure_openai/meta-llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00061,
      "provider": "azure_openai",
      "release_date": "2024-07-23"
    },
    "azure_openai/ministral-3b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral-3b",
      "id": "ministral-3b",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Ministral 3B",
      "open_weights": true,
      "output_cost_per_1k": 4e-05,
      "provider": "azure_openai",
      "release_date": "2024-10-22"
    },
    "azure_openai/mistral-large-2411": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-large",
      "id": "mistral-large-2411",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Large 24.11",
      "output_cost_per_1k": 0.006,
      "provider": "azure_openai",
      "release_date": "2024-11-01"
    },
    "azure_openai/mistral-medium-2505": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistral-medium-2505",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral Medium 3",
      "output_cost_per_1k": 0.002,
      "provider": "azure_openai",
      "release_date": "2025-05-07"
    },
    "azure_openai/mistral-nemo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistral-nemo",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral Nemo",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "azure_openai",
      "release_date": "2024-07-18"
    },
    "azure_openai/mistral-small-2503": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small-2503",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Small 3.1",
      "output_cost_per_1k": 0.0003,
      "provider": "azure_openai",
      "release_date": "2025-03-01"
    },
    "azure_openai/model-router": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "model-router",
      "id": "model-router",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Model Router",
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2025-05-19"
    },
    "azure_openai/o1": {
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "o1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1",
      "output_cost_per_1k": 0.06,
      "provider": "azure_openai",
      "release_date": "2024-12-05"
    },
    "azure_openai/o1-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "family": "o1-mini",
      "id": "o1-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "o1-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "azure_openai",
      "release_date": "2024-09-12"
    },
    "azure_openai/o1-preview": {
      "cache_read_cost_per_1k": 0.00825,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "family": "o1-preview",
      "id": "o1-preview",
      "input_cost_per_1k": 0.0165,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "o1-preview",
      "output_cost_per_1k": 0.066,
      "provider": "azure_openai",
      "release_date": "2024-09-12"
    },
    "azure_openai/o3": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "o3",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3",
      "output_cost_per_1k": 0.008,
      "provider": "azure_openai",
      "release_date": "2025-04-16"
    },
    "azure_openai/o3-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "family": "o3-mini",
      "id": "o3-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "azure_openai",
      "release_date": "2024-12-20"
    },
    "azure_openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "azure_openai",
      "release_date": "2025-04-16"
    },
    "azure_openai/phi-3-medium-128k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-medium-128k-instruct",
      "input_cost_per_1k": 0.00017,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-medium-instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00068,
      "provider": "azure_openai",
      "release_date": "2024-04-23"
    },
    "azure_openai/phi-3-medium-4k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-medium-4k-instruct",
      "input_cost_per_1k": 0.00017,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Phi-3-medium-instruct (4k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00068,
      "provider": "azure_openai",
      "release_date": "2024-04-23"
    },
    "azure_openai/phi-3-mini-128k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-mini-128k-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-mini-instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00052,
      "provider": "azure_openai",
      "release_date": "2024-04-23"
    },
    "azure_openai/phi-3-mini-4k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-mini-4k-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Phi-3-mini-instruct (4k)",
      "open_weights": true,
      "output_cost_per_1k": 0.00052,
      "provider": "azure_openai",
      "release_date": "2024-04-23"
    },
    "azure_openai/phi-3-small-128k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-small-128k-instruct",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-small-instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "azure_openai",
      "release_date": "2024-04-23"
    },
    "azure_openai/phi-3-small-8k-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3",
      "id": "phi-3-small-8k-instruct",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Phi-3-small-instruct (8k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "azure_openai",
      "release_date": "2024-04-23"
    },
    "azure_openai/phi-3.5-mini-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3.5",
      "id": "phi-3.5-mini-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-mini-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00052,
      "provider": "azure_openai",
      "release_date": "2024-08-20"
    },
    "azure_openai/phi-3.5-moe-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-3.5",
      "id": "phi-3.5-moe-instruct",
      "input_cost_per_1k": 0.00016,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-MoE-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00064,
      "provider": "azure_openai",
      "release_date": "2024-08-20"
    },
    "azure_openai/phi-4": {
      "capabilities": [
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4",
      "input_cost_per_1k": 0.000125,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "azure_openai",
      "release_date": "2024-12-11"
    },
    "azure_openai/phi-4-mini": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-mini",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "azure_openai",
      "release_date": "2024-12-11"
    },
    "azure_openai/phi-4-mini-reasoning": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-mini-reasoning",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini-reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "azure_openai",
      "release_date": "2024-12-11"
    },
    "azure_openai/phi-4-multimodal": {
      "capabilities": [
        "audio_input",
        "temperature",
        "vision"
      ],
      "family": "phi-4",
      "id": "phi-4-multimodal",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-multimodal",
      "open_weights": true,
      "output_cost_per_1k": 0.00032,
      "provider": "azure_openai",
      "release_date": "2024-12-11"
    },
    "azure_openai/phi-4-reasoning": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-reasoning",
      "input_cost_per_1k": 0.000125,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "azure_openai",
      "release_date": "2024-12-11"
    },
    "azure_openai/phi-4-reasoning-plus": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "phi-4-reasoning-plus",
      "input_cost_per_1k": 0.000125,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-reasoning-plus",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "azure_openai",
      "release_date": "2024-12-11"
    },
    "azure_openai/text-embedding-3-large": {
      "family": "text-embedding-3-large",
      "id": "text-embedding-3-large",
      "input_cost_per_1k": 0.00013,
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "mode": "embedding",
      "name": "text-embedding-3-large",
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2024-01-25"
    },
    "azure_openai/text-embedding-3-small": {
      "family": "text-embedding-3-small",
      "id": "text-embedding-3-small",
      "input_cost_per_1k": 2e-05,
      "max_input_tokens": 8191,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "text-embedding-3-small",
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2024-01-25"
    },
    "azure_openai/text-embedding-ada-002": {
      "family": "text-embedding-ada",
      "id": "text-embedding-ada-002",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 8192,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "text-embedding-ada-002",
      "output_cost_per_1k": 0.0,
      "provider": "azure_openai",
      "release_date": "2022-12-15"
    },
    "bailing/Ling-1T": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ling-1t",
      "id": "Ling-1T",
      "input_cost_per_1k": 0.00057,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Ling-1T",
      "open_weights": true,
      "output_cost_per_1k": 0.00229,
      "provider": "bailing",
      "release_date": "2025-10"
    },
    "bailing/Ring-1T": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "ring-1t",
      "id": "Ring-1T",
      "input_cost_per_1k": 0.00057,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Ring-1T",
      "open_weights": true,
      "output_cost_per_1k": 0.00229,
      "provider": "bailing",
      "release_date": "2025-10"
    },
    "baseten/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "input_cost_per_1k": 0.00038,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00153,
      "provider": "baseten",
      "release_date": "2025-07-23"
    },
    "baseten/deepseek-ai/DeepSeek-V3.2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3.2",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 163800,
      "max_output_tokens": 131100,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.00045,
      "provider": "baseten",
      "release_date": "2025-12-01"
    },
    "baseten/moonshotai/Kimi-K2-Instruct-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Instruct 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "baseten",
      "release_date": "2025-09-05"
    },
    "baseten/moonshotai/Kimi-K2-Thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "baseten",
      "release_date": "2025-11-06"
    },
    "baseten/zai-org/GLM-4.6": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org/GLM-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "baseten",
      "release_date": "2025-09-16"
    },
    "baseten/zai-org/GLM-4.7": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "zai-org/GLM-4.7",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "baseten",
      "release_date": "2025-12-22"
    },
    "cerebras/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 0.00025,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.00069,
      "provider": "cerebras",
      "release_date": "2025-08-05"
    },
    "cerebras/qwen-3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen",
      "id": "qwen-3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen 3 235B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "cerebras",
      "release_date": "2025-07-22"
    },
    "cerebras/zai-glm-4.6": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-glm-4.6",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 131072,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Z.AI GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cerebras",
      "release_date": "2025-11-05"
    },
    "chutes/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "yi",
      "id": "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Tongyi DeepResearch 30B A3B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/ArliAI/QwQ-32B-ArliAI-RpR-v1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "QwQ 32B ArliAI RpR V1",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/MiniMaxAI/MiniMax-M2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMaxAI/MiniMax-M2",
      "input_cost_per_1k": 0.00026,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 196608,
      "max_output_tokens": 196608,
      "mode": "chat",
      "name": "MiniMax M2",
      "open_weights": true,
      "output_cost_per_1k": 0.00102,
      "provider": "chutes",
      "release_date": "2025-10-27"
    },
    "chutes/NousResearch/DeepHermes-3-Mistral-24B-Preview": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral",
      "id": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "DeepHermes 3 Mistral 24B Preview",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/NousResearch/Hermes-4-14B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "NousResearch/Hermes-4-14B",
      "input_cost_per_1k": 1e-05,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Hermes 4 14B",
      "open_weights": true,
      "output_cost_per_1k": 5e-05,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/NousResearch/Hermes-4-405B-FP8": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "NousResearch/Hermes-4-405B-FP8",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Hermes 4 405B FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/NousResearch/Hermes-4-70B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "NousResearch/Hermes-4-70B",
      "input_cost_per_1k": 0.00011,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Hermes 4 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00038,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/NousResearch/Hermes-4.3-36B": {
      "capabilities": [
        "temperature"
      ],
      "family": "hermes",
      "id": "NousResearch/Hermes-4.3-36B",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Hermes 4.3 36B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "chutes",
      "release_date": "2025-12-11"
    },
    "chutes/OpenGVLab/InternVL3-78B": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "internvl",
      "id": "OpenGVLab/InternVL3-78B",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "InternVL3 78B",
      "open_weights": true,
      "output_cost_per_1k": 0.00039,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen2.5-72B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen2.5 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00026,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen2.5 Coder 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen2.5-VL-32B-Instruct": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen2.5 VL 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00022,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen2.5-VL-72B-Instruct": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "Qwen/Qwen2.5-VL-72B-Instruct",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen2.5 VL 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00013,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen3-14B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-14B",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 14B",
      "open_weights": true,
      "output_cost_per_1k": 0.00022,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen3-235B-A22B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 235B A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00055,
      "provider": "chutes",
      "release_date": "2025-04-28"
    },
    "chutes/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.00011,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "chutes",
      "release_date": "2025-07-25"
    },
    "chutes/Qwen/Qwen3-30B-A3B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-30B-A3B",
      "input_cost_per_1k": 6e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 30B A3B",
      "open_weights": true,
      "output_cost_per_1k": 0.00022,
      "provider": "chutes",
      "release_date": "2025-04-28"
    },
    "chutes/Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 30B A3B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00033,
      "provider": "chutes",
      "release_date": "2025-07-25"
    },
    "chutes/Qwen/Qwen3-32B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-32B",
      "input_cost_per_1k": 8e-05,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.00024,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen3-Coder-30B-A3B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "input_cost_per_1k": 6e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00025,
      "provider": "chutes",
      "release_date": "2025-07-25"
    },
    "chutes/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "input_cost_per_1k": 0.00022,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct (FP8)",
      "output_cost_per_1k": 0.00095,
      "provider": "chutes",
      "release_date": "2025-08-01"
    },
    "chutes/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "chutes",
      "release_date": "2025-09-11"
    },
    "chutes/Qwen/Qwen3-VL-235B-A22B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 VL 235B A22B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/Qwen/Qwen3-VL-235B-A22B-Thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 VL 235B A22B Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/chutesai/Mistral-Small-3.1-24B-Instruct-2503": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Mistral Small 3.1 24B Instruct 2503",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/chutesai/Mistral-Small-3.2-24B-Instruct-2506": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
      "input_cost_per_1k": 6e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Mistral Small 3.2 24B Instruct (2506)",
      "open_weights": true,
      "output_cost_per_1k": 0.00018,
      "provider": "chutes",
      "release_date": "2025-06-20"
    },
    "chutes/deepseek-ai/DeepSeek-R1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek R1",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/deepseek-ai/DeepSeek-R1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek R1 (0528)",
      "output_cost_per_1k": 0.00175,
      "provider": "chutes",
      "release_date": "2025-08-01"
    },
    "chutes/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
      "input_cost_per_1k": 2e-05,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "DeepSeek R1 0528 Qwen3 8B",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "chutes",
      "release_date": "2025-05-29"
    },
    "chutes/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "input_cost_per_1k": 3e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00013,
      "provider": "chutes",
      "release_date": "2025-01-23"
    },
    "chutes/deepseek-ai/DeepSeek-V3": {
      "capabilities": [
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/deepseek-ai/DeepSeek-V3-0324": {
      "capabilities": [
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "input_cost_per_1k": 0.00024,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3 (0324)",
      "output_cost_per_1k": 0.00084,
      "provider": "chutes",
      "release_date": "2025-08-01"
    },
    "chutes/deepseek-ai/DeepSeek-V3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3.1",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "output_cost_per_1k": 0.0008,
      "provider": "chutes",
      "release_date": "2025-08-21"
    },
    "chutes/deepseek-ai/DeepSeek-V3.1-Terminus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "input_cost_per_1k": 0.00023,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "chutes",
      "release_date": "2025-09-22"
    },
    "chutes/deepseek-ai/DeepSeek-V3.2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3.2",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 163840,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.00041,
      "provider": "chutes",
      "release_date": "2025-12-01"
    },
    "chutes/deepseek-ai/DeepSeek-V3.2-Speciale-TEE": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3.2-Speciale-TEE",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.2 Speciale TEE",
      "open_weights": true,
      "output_cost_per_1k": 0.00041,
      "provider": "chutes",
      "release_date": "2025-12-11"
    },
    "chutes/mistralai/Devstral-2-123B-Instruct-2512": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral",
      "id": "mistralai/Devstral-2-123B-Instruct-2512",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Devstral 2 123B Instruct 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "chutes",
      "release_date": "2025-12-11"
    },
    "chutes/moonshotai/Kimi-K2-Instruct-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "input_cost_per_1k": 0.00039,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Instruct 0905",
      "output_cost_per_1k": 0.0019,
      "provider": "chutes",
      "release_date": "2024-09-05"
    },
    "chutes/moonshotai/Kimi-K2-Thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Thinking",
      "input_cost_per_1k": 0.00045,
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.00235,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 4e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "chutes",
      "release_date": "2025-08-05"
    },
    "chutes/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Gpt Oss 20b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/rednote-hilab/dots.ocr": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "dots.ocr",
      "id": "rednote-hilab/dots.ocr",
      "input_cost_per_1k": 1e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Dots.Ocr",
      "open_weights": true,
      "output_cost_per_1k": 1e-05,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/tngtech/DeepSeek-R1T-Chimera": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "tngtech/DeepSeek-R1T-Chimera",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek R1T Chimera",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-04-26"
    },
    "chutes/tngtech/DeepSeek-TNG-R1T2-Chimera": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek TNG R1T2 Chimera",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-07-08"
    },
    "chutes/tngtech/TNG-R1T-Chimera-TEE": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "tng-r1t-chimera-tee",
      "id": "tngtech/TNG-R1T-Chimera-TEE",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "TNG R1T Chimera TEE",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-12-11"
    },
    "chutes/unsloth/Mistral-Nemo-Instruct-2407": {
      "capabilities": [
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "unsloth/Mistral-Nemo-Instruct-2407",
      "input_cost_per_1k": 2e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Mistral Nemo Instruct 2407",
      "open_weights": true,
      "output_cost_per_1k": 4e-05,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/unsloth/Mistral-Small-24B-Instruct-2501": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "unsloth/Mistral-Small-24B-Instruct-2501",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Small 24B Instruct 2501",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/unsloth/gemma-3-12b-it": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "unsloth/gemma-3-12b-it",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Gemma 3 12b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/unsloth/gemma-3-27b-it": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "unsloth/gemma-3-27b-it",
      "input_cost_per_1k": 4e-05,
      "max_input_tokens": 96000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "Gemma 3 27b It",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/unsloth/gemma-3-4b-it": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "unsloth/gemma-3-4b-it",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 96000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "Gemma 3 4b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "chutes",
      "release_date": "2025-11-08"
    },
    "chutes/zai-org/GLM-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai-org/GLM-4.5",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.00155,
      "provider": "chutes",
      "release_date": "2025-10-30"
    },
    "chutes/zai-org/GLM-4.5-Air": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai-org/GLM-4.5-Air",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "chutes",
      "release_date": "2025-07-28"
    },
    "chutes/zai-org/GLM-4.6": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org/GLM-4.6",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 202752,
      "max_output_tokens": 202752,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.00175,
      "provider": "chutes",
      "release_date": "2025-10-30"
    },
    "chutes/zai-org/GLM-4.6-TEE": {
      "capabilities": [
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org/GLM-4.6-TEE",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.6 TEE",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "chutes",
      "release_date": "2025-12-11"
    },
    "chutes/zai-org/GLM-4.6V": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "zai-org/GLM-4.6V",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "GLM 4.6V",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "chutes",
      "release_date": "2025-12-11"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-5-haiku": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-3-5-haiku",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5 (latest)",
      "output_cost_per_1k": 0.004,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-10-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-haiku": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-3-haiku",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Haiku 3",
      "output_cost_per_1k": 0.00125,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-03-13"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-opus": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-3-opus",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Opus 3",
      "output_cost_per_1k": 0.075,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-02-29"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-3-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Sonnet 3",
      "output_cost_per_1k": 0.015,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-03-04"
    },
    "cloudflare_ai_gateway/anthropic/claude-3.5-haiku": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-3.5-haiku",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5 (latest)",
      "output_cost_per_1k": 0.004,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-10-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-3.5-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-3.5-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5 v2",
      "output_cost_per_1k": 0.015,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-10-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-4-5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5 (latest)",
      "output_cost_per_1k": 0.005,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-10-15"
    },
    "cloudflare_ai_gateway/anthropic/claude-opus-4": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4 (latest)",
      "output_cost_per_1k": 0.075,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-05-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1 (latest)",
      "output_cost_per_1k": 0.075,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-08-05"
    },
    "cloudflare_ai_gateway/anthropic/claude-opus-4-5": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5 (latest)",
      "output_cost_per_1k": 0.025,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-24"
    },
    "cloudflare_ai_gateway/anthropic/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4 (latest)",
      "output_cost_per_1k": 0.015,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-05-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4-5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5 (latest)",
      "output_cost_per_1k": 0.015,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-09-29"
    },
    "cloudflare_ai_gateway/openai/gpt-3.5-turbo": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "openai/gpt-3.5-turbo",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2021-09-01",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-3.5-turbo",
      "output_cost_per_1k": 0.0015,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2023-03-01"
    },
    "cloudflare_ai_gateway/openai/gpt-4": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4",
      "id": "openai/gpt-4",
      "input_cost_per_1k": 0.03,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4",
      "output_cost_per_1k": 0.06,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2023-11-06"
    },
    "cloudflare_ai_gateway/openai/gpt-4-turbo": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "openai/gpt-4-turbo",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo",
      "output_cost_per_1k": 0.03,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2023-11-06"
    },
    "cloudflare_ai_gateway/openai/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "openai/gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-05-13"
    },
    "cloudflare_ai_gateway/openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o mini",
      "output_cost_per_1k": 0.0006,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-07-18"
    },
    "cloudflare_ai_gateway/openai/gpt-5.1": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-13"
    },
    "cloudflare_ai_gateway/openai/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-13"
    },
    "cloudflare_ai_gateway/openai/gpt-5.2": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5.2",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.014,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-12-11"
    },
    "cloudflare_ai_gateway/openai/o1": {
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "openai/o1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1",
      "output_cost_per_1k": 0.06,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-12-05"
    },
    "cloudflare_ai_gateway/openai/o3": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "openai/o3",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3",
      "output_cost_per_1k": 0.008,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-16"
    },
    "cloudflare_ai_gateway/openai/o3-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "family": "o3-mini",
      "id": "openai/o3-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2024-12-20"
    },
    "cloudflare_ai_gateway/openai/o3-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o3-pro",
      "id": "openai/o3-pro",
      "input_cost_per_1k": 0.02,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-pro",
      "output_cost_per_1k": 0.08,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-06-10"
    },
    "cloudflare_ai_gateway/openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-16"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/ai4bharat/indictrans2-en-indic-1B": {
      "capabilities": [
        "temperature"
      ],
      "family": "indictrans2",
      "id": "workers-ai/@cf/ai4bharat/indictrans2-en-indic-1B",
      "input_cost_per_1k": 0.00034,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "IndicTrans2 EN-Indic 1B",
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-09-25"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/aisingapore/gemma-sea-lion-v4-27b-it": {
      "capabilities": [
        "temperature"
      ],
      "family": "gemma-sea-lion",
      "id": "workers-ai/@cf/aisingapore/gemma-sea-lion-v4-27b-it",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Gemma SEA-LION v4 27B IT",
      "output_cost_per_1k": 0.00056,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-09-25"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-base-en-v1.5": {
      "capabilities": [
        "temperature"
      ],
      "family": "bge-base",
      "id": "workers-ai/@cf/baai/bge-base-en-v1.5",
      "input_cost_per_1k": 6.7e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "BGE Base EN v1.5",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-large-en-v1.5": {
      "capabilities": [
        "temperature"
      ],
      "family": "bge-large",
      "id": "workers-ai/@cf/baai/bge-large-en-v1.5",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "BGE Large EN v1.5",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-m3": {
      "capabilities": [
        "temperature"
      ],
      "family": "bge-m3",
      "id": "workers-ai/@cf/baai/bge-m3",
      "input_cost_per_1k": 1.2e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "BGE M3",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-reranker-base": {
      "capabilities": [
        "temperature"
      ],
      "family": "bge-reranker",
      "id": "workers-ai/@cf/baai/bge-reranker-base",
      "input_cost_per_1k": 3.1e-06,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "rerank",
      "name": "BGE Reranker Base",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-09"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-small-en-v1.5": {
      "capabilities": [
        "temperature"
      ],
      "family": "bge-small",
      "id": "workers-ai/@cf/baai/bge-small-en-v1.5",
      "input_cost_per_1k": 2e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "BGE Small EN v1.5",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepgram/aura-2-en": {
      "capabilities": [
        "temperature"
      ],
      "family": "aura-2",
      "id": "workers-ai/@cf/deepgram/aura-2-en",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Deepgram Aura 2 (EN)",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepgram/aura-2-es": {
      "capabilities": [
        "temperature"
      ],
      "family": "aura-2",
      "id": "workers-ai/@cf/deepgram/aura-2-es",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Deepgram Aura 2 (ES)",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepgram/nova-3": {
      "capabilities": [
        "temperature"
      ],
      "family": "nova",
      "id": "workers-ai/@cf/deepgram/nova-3",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Deepgram Nova 3",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "temperature"
      ],
      "family": "deepseek-r1-distill-qwen",
      "id": "workers-ai/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "output_cost_per_1k": 0.00488,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/facebook/bart-large-cnn": {
      "capabilities": [
        "temperature"
      ],
      "family": "bart",
      "id": "workers-ai/@cf/facebook/bart-large-cnn",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "BART Large CNN",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-09"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/google/gemma-3-12b-it": {
      "capabilities": [
        "temperature"
      ],
      "family": "gemma-3",
      "id": "workers-ai/@cf/google/gemma-3-12b-it",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Gemma 3 12B IT",
      "output_cost_per_1k": 0.00056,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/huggingface/distilbert-sst-2-int8": {
      "capabilities": [
        "temperature"
      ],
      "family": "distilbert",
      "id": "workers-ai/@cf/huggingface/distilbert-sst-2-int8",
      "input_cost_per_1k": 2.6e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DistilBERT SST-2 INT8",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/ibm-granite/granite-4.0-h-micro": {
      "capabilities": [
        "temperature"
      ],
      "family": "granite-4",
      "id": "workers-ai/@cf/ibm-granite/granite-4.0-h-micro",
      "input_cost_per_1k": 1.7e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "IBM Granite 4.0 H Micro",
      "output_cost_per_1k": 0.00011,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-10-15"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-2-7b-chat-fp16": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-2",
      "id": "workers-ai/@cf/meta/llama-2-7b-chat-fp16",
      "input_cost_per_1k": 0.00056,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 2 7B Chat FP16",
      "output_cost_per_1k": 0.00667,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3-8b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "workers-ai/@cf/meta/llama-3-8b-instruct",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3 8B Instruct",
      "output_cost_per_1k": 0.00083,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3-8b-instruct-awq": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "workers-ai/@cf/meta/llama-3-8b-instruct-awq",
      "input_cost_per_1k": 0.00012,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3 8B Instruct AWQ",
      "output_cost_per_1k": 0.00027,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.1-8b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "workers-ai/@cf/meta/llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct",
      "output_cost_per_1k": 0.00083,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.1-8b-instruct-awq": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "workers-ai/@cf/meta/llama-3.1-8b-instruct-awq",
      "input_cost_per_1k": 0.00012,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct AWQ",
      "output_cost_per_1k": 0.00027,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.1-8b-instruct-fp8": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "workers-ai/@cf/meta/llama-3.1-8b-instruct-fp8",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct FP8",
      "output_cost_per_1k": 0.00029,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.2-vision",
      "id": "workers-ai/@cf/meta/llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 4.9e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.2 11B Vision Instruct",
      "output_cost_per_1k": 0.00068,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.2-1b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "workers-ai/@cf/meta/llama-3.2-1b-instruct",
      "input_cost_per_1k": 2.7e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.2 1B Instruct",
      "output_cost_per_1k": 0.0002,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.2-3b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "workers-ai/@cf/meta/llama-3.2-3b-instruct",
      "input_cost_per_1k": 5.1e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.2 3B Instruct",
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.3-70b-instruct-fp8-fast": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "workers-ai/@cf/meta/llama-3.3-70b-instruct-fp8-fast",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.3 70B Instruct FP8 Fast",
      "output_cost_per_1k": 0.00225,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-4-scout",
      "id": "workers-ai/@cf/meta/llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "output_cost_per_1k": 0.00085,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-16"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-guard-3-8b": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-guard",
      "id": "workers-ai/@cf/meta/llama-guard-3-8b",
      "input_cost_per_1k": 0.00048,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama Guard 3 8B",
      "output_cost_per_1k": 3e-05,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/m2m100-1.2b": {
      "capabilities": [
        "temperature"
      ],
      "family": "m2m100",
      "id": "workers-ai/@cf/meta/m2m100-1.2b",
      "input_cost_per_1k": 0.00034,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "M2M100 1.2B",
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/mistral/mistral-7b-instruct-v0.1": {
      "capabilities": [
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "workers-ai/@cf/mistral/mistral-7b-instruct-v0.1",
      "input_cost_per_1k": 0.00011,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral 7B Instruct v0.1",
      "output_cost_per_1k": 0.00019,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/mistralai/mistral-small-3.1-24b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "mistral-small",
      "id": "workers-ai/@cf/mistralai/mistral-small-3.1-24b-instruct",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral Small 3.1 24B Instruct",
      "output_cost_per_1k": 0.00056,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/myshell-ai/melotts": {
      "capabilities": [
        "temperature"
      ],
      "family": "melotts",
      "id": "workers-ai/@cf/myshell-ai/melotts",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "MyShell MeloTTS",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/openai/gpt-oss-120b": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "workers-ai/@cf/openai/gpt-oss-120b",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "output_cost_per_1k": 0.00075,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-08-05"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/openai/gpt-oss-20b": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "workers-ai/@cf/openai/gpt-oss-20b",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "output_cost_per_1k": 0.0003,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-08-05"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/pfnet/plamo-embedding-1b": {
      "capabilities": [
        "temperature"
      ],
      "family": "plamo-embedding",
      "id": "workers-ai/@cf/pfnet/plamo-embedding-1b",
      "input_cost_per_1k": 1.9e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "embedding",
      "name": "PLaMo Embedding 1B",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-09-25"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/pipecat-ai/smart-turn-v2": {
      "capabilities": [
        "temperature"
      ],
      "family": "smart-turn",
      "id": "workers-ai/@cf/pipecat-ai/smart-turn-v2",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Pipecat Smart Turn v2",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "workers-ai/@cf/qwen/qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.00066,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen 2.5 Coder 32B Instruct",
      "output_cost_per_1k": 0.001,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwen3-30b-a3b-fp8": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen3",
      "id": "workers-ai/@cf/qwen/qwen3-30b-a3b-fp8",
      "input_cost_per_1k": 5.1e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 30B A3B FP8",
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwen3-embedding-0.6b": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen3-embedding",
      "id": "workers-ai/@cf/qwen/qwen3-embedding-0.6b",
      "input_cost_per_1k": 1.2e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "embedding",
      "name": "Qwen3 Embedding 0.6B",
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwq-32b": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwq",
      "id": "workers-ai/@cf/qwen/qwq-32b",
      "input_cost_per_1k": 0.00066,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "QwQ 32B",
      "output_cost_per_1k": 0.001,
      "provider": "cloudflare_ai_gateway",
      "release_date": "2025-04-11"
    },
    "cloudflare_workers_ai/aura-1": {
      "capabilities": [
        "audio_output"
      ],
      "family": "aura",
      "id": "aura-1",
      "input_cost_per_1k": 1.5e-05,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "audio_speech",
      "name": "@cf/deepgram/aura-1",
      "open_weights": true,
      "output_cost_per_1k": 1.5e-05,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-08-27"
    },
    "cloudflare_workers_ai/bart-large-cnn": {
      "family": "bart-large-cnn",
      "id": "bart-large-cnn",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/facebook/bart-large-cnn",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2022-03-02"
    },
    "cloudflare_workers_ai/deepseek-coder-6.7b-base-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "deepseek-coder",
      "id": "deepseek-coder-6.7b-base-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/deepseek-coder-6.7b-base-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-11-05"
    },
    "cloudflare_workers_ai/deepseek-coder-6.7b-instruct-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "deepseek-coder",
      "id": "deepseek-coder-6.7b-instruct-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-11-05"
    },
    "cloudflare_workers_ai/deepseek-math-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "deepseek",
      "id": "deepseek-math-7b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@cf/deepseek-ai/deepseek-math-7b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-05"
    },
    "cloudflare_workers_ai/deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-r1-distill-qwen-32b",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 80000,
      "max_output_tokens": 80000,
      "mode": "chat",
      "name": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
      "open_weights": true,
      "output_cost_per_1k": 0.00488,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-01-20"
    },
    "cloudflare_workers_ai/discolm-german-7b-v1-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "discolm-german",
      "id": "discolm-german-7b-v1-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@cf/thebloke/discolm-german-7b-v1-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-01-18"
    },
    "cloudflare_workers_ai/dreamshaper-8-lcm": {
      "capabilities": [
        "image_output",
        "vision"
      ],
      "family": "dreamshaper-8-lcm",
      "id": "dreamshaper-8-lcm",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/lykon/dreamshaper-8-lcm",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-06"
    },
    "cloudflare_workers_ai/falcon-7b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "falcon-7b",
      "id": "falcon-7b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@cf/tiiuae/falcon-7b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-04-25"
    },
    "cloudflare_workers_ai/flux-1-schnell": {
      "capabilities": [
        "image_output"
      ],
      "family": "flux-1",
      "id": "flux-1-schnell",
      "input_cost_per_1k": 5e-08,
      "max_input_tokens": 2048,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/black-forest-labs/flux-1-schnell",
      "open_weights": true,
      "output_cost_per_1k": 1.1e-07,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-31"
    },
    "cloudflare_workers_ai/gemma-2b-it-lora": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gemma-2",
      "id": "gemma-2b-it-lora",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@cf/google/gemma-2b-it-lora",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-04-02"
    },
    "cloudflare_workers_ai/gemma-3-12b-it": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gemma-3",
      "id": "gemma-3-12b-it",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 80000,
      "max_output_tokens": 80000,
      "mode": "chat",
      "name": "@cf/google/gemma-3-12b-it",
      "open_weights": true,
      "output_cost_per_1k": 0.00056,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-03-01"
    },
    "cloudflare_workers_ai/gemma-7b-it": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gemma",
      "id": "gemma-7b-it",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@hf/google/gemma-7b-it",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-13"
    },
    "cloudflare_workers_ai/gemma-7b-it-lora": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gemma",
      "id": "gemma-7b-it-lora",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 3500,
      "max_output_tokens": 3500,
      "mode": "chat",
      "name": "@cf/google/gemma-7b-it-lora",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-04-02"
    },
    "cloudflare_workers_ai/gemma-sea-lion-v4-27b-it": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gemma",
      "id": "gemma-sea-lion-v4-27b-it",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/aisingapore/gemma-sea-lion-v4-27b-it",
      "output_cost_per_1k": 0.00056,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-09-23"
    },
    "cloudflare_workers_ai/gpt-oss-120b": {
      "capabilities": [
        "reasoning"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "@cf/openai/gpt-oss-120b",
      "open_weights": true,
      "output_cost_per_1k": 0.00075,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-08-04"
    },
    "cloudflare_workers_ai/gpt-oss-20b": {
      "capabilities": [
        "reasoning"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-20b",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "@cf/openai/gpt-oss-20b",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-08-04"
    },
    "cloudflare_workers_ai/granite-4.0-h-micro": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "granite",
      "id": "granite-4.0-h-micro",
      "input_cost_per_1k": 1.7e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/ibm-granite/granite-4.0-h-micro",
      "output_cost_per_1k": 0.00011,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-10-07"
    },
    "cloudflare_workers_ai/hermes-2-pro-mistral-7b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "hermes-2-pro-mistral-7b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "mode": "chat",
      "name": "@hf/nousresearch/hermes-2-pro-mistral-7b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-03-11"
    },
    "cloudflare_workers_ai/llama-2-13b-chat-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "llama-2",
      "id": "llama-2-13b-chat-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/llama-2-13b-chat-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-09-19"
    },
    "cloudflare_workers_ai/llama-2-7b-chat-fp16": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-2",
      "id": "llama-2-7b-chat-fp16",
      "input_cost_per_1k": 0.00056,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@cf/meta/llama-2-7b-chat-fp16",
      "open_weights": true,
      "output_cost_per_1k": 0.00667,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-07-26"
    },
    "cloudflare_workers_ai/llama-2-7b-chat-hf-lora": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-2",
      "id": "llama-2-7b-chat-hf-lora",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@cf/meta-llama/llama-2-7b-chat-hf-lora",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-07-13"
    },
    "cloudflare_workers_ai/llama-2-7b-chat-int8": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-2",
      "id": "llama-2-7b-chat-int8",
      "input_cost_per_1k": 0.000556,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@cf/meta/llama-2-7b-chat-int8",
      "open_weights": true,
      "output_cost_per_1k": 0.006667,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-09-25"
    },
    "cloudflare_workers_ai/llama-3-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3",
      "id": "llama-3-8b-instruct",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 7968,
      "max_output_tokens": 7968,
      "mode": "chat",
      "name": "@cf/meta/llama-3-8b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00083,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-04-17"
    },
    "cloudflare_workers_ai/llama-3-8b-instruct-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3",
      "id": "llama-3-8b-instruct-awq",
      "input_cost_per_1k": 0.00012,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@cf/meta/llama-3-8b-instruct-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.00027,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-05-09"
    },
    "cloudflare_workers_ai/llama-3.1-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-70b-instruct",
      "input_cost_per_1k": 0.000293,
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.1-70b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002253,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-16"
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 7968,
      "max_output_tokens": 7968,
      "mode": "chat",
      "name": "@cf/meta/llama-3.1-8b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00083,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-18"
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct-awq",
      "input_cost_per_1k": 0.00012,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@cf/meta/llama-3.1-8b-instruct-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.00027,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-25"
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct-fast": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct-fast",
      "input_cost_per_1k": 4.5e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.1-8b-instruct-fast",
      "open_weights": true,
      "output_cost_per_1k": 0.000384,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-18"
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct-fp8": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct-fp8",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.1-8b-instruct-fp8",
      "open_weights": true,
      "output_cost_per_1k": 0.00029,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-25"
    },
    "cloudflare_workers_ai/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 4.9e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.2-11b-vision-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00068,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-09-18"
    },
    "cloudflare_workers_ai/llama-3.2-1b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-1b-instruct",
      "input_cost_per_1k": 2.7e-05,
      "max_input_tokens": 60000,
      "max_output_tokens": 60000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.2-1b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-09-18"
    },
    "cloudflare_workers_ai/llama-3.2-3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-3b-instruct",
      "input_cost_per_1k": 5.1e-05,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.2-3b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-09-18"
    },
    "cloudflare_workers_ai/llama-3.3-70b-instruct-fp8-fast": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-instruct-fp8-fast",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "mode": "chat",
      "name": "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
      "open_weights": true,
      "output_cost_per_1k": 0.00225,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-12-06"
    },
    "cloudflare_workers_ai/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-4-scout",
      "id": "llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "@cf/meta/llama-4-scout-17b-16e-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00085,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-04-02"
    },
    "cloudflare_workers_ai/llama-guard-3-8b": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama",
      "id": "llama-guard-3-8b",
      "input_cost_per_1k": 0.00048,
      "max_input_tokens": 131072,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/meta/llama-guard-3-8b",
      "open_weights": true,
      "output_cost_per_1k": 3e-05,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-22"
    },
    "cloudflare_workers_ai/llamaguard-7b-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "llama",
      "id": "llamaguard-7b-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/llamaguard-7b-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-11"
    },
    "cloudflare_workers_ai/llava-1.5-7b-hf": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "llava-1.5-7b-hf",
      "id": "llava-1.5-7b-hf",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/llava-hf/llava-1.5-7b-hf",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-05"
    },
    "cloudflare_workers_ai/lucid-origin": {
      "capabilities": [
        "image_output"
      ],
      "family": "lucid-origin",
      "id": "lucid-origin",
      "input_cost_per_1k": 7e-06,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/leonardo/lucid-origin",
      "output_cost_per_1k": 7e-06,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-08-25"
    },
    "cloudflare_workers_ai/m2m100-1.2b": {
      "family": "m2m100-1.2b",
      "id": "m2m100-1.2b",
      "input_cost_per_1k": 0.00034,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/meta/m2m100-1.2b",
      "open_weights": true,
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_workers_ai",
      "release_date": "2022-03-02"
    },
    "cloudflare_workers_ai/melotts": {
      "capabilities": [
        "audio_output",
        "vision"
      ],
      "family": "melotts",
      "id": "melotts",
      "input_cost_per_1k": 2e-07,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "audio_speech",
      "name": "@cf/myshell-ai/melotts",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-07-19"
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.1": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "mistral-7b-instruct-v0.1",
      "input_cost_per_1k": 0.00011,
      "max_input_tokens": 2824,
      "max_output_tokens": 2824,
      "mode": "chat",
      "name": "@cf/mistral/mistral-7b-instruct-v0.1",
      "open_weights": true,
      "output_cost_per_1k": 0.00019,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-09-27"
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.1-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "mistral-7b",
      "id": "mistral-7b-instruct-v0.1-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-09-27"
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "mistral-7b-instruct-v0.2",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 3072,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/mistral/mistral-7b-instruct-v0.2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-11"
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.2-lora": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "mistral-7b-instruct-v0.2-lora",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 15000,
      "max_output_tokens": 15000,
      "mode": "chat",
      "name": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-04-01"
    },
    "cloudflare_workers_ai/mistral-small-3.1-24b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-small",
      "id": "mistral-small-3.1-24b-instruct",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "@cf/mistralai/mistral-small-3.1-24b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00056,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-03-11"
    },
    "cloudflare_workers_ai/neural-chat-7b-v3-1-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "neural-chat-7b-v3",
      "id": "neural-chat-7b-v3-1-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/neural-chat-7b-v3-1-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-11-15"
    },
    "cloudflare_workers_ai/nova-3": {
      "capabilities": [
        "audio_input"
      ],
      "family": "nova",
      "id": "nova-3",
      "input_cost_per_1k": 5.2e-06,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/deepgram/nova-3",
      "open_weights": true,
      "output_cost_per_1k": 5.2e-06,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-06-05"
    },
    "cloudflare_workers_ai/openchat-3.5-0106": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "openchat",
      "id": "openchat-3.5-0106",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "@cf/openchat/openchat-3.5-0106",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-01-07"
    },
    "cloudflare_workers_ai/openhermes-2.5-mistral-7b-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "mistral-7b",
      "id": "openhermes-2.5-mistral-7b-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-11-02"
    },
    "cloudflare_workers_ai/phi-2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "phi",
      "id": "phi-2",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "@cf/microsoft/phi-2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-13"
    },
    "cloudflare_workers_ai/phoenix-1.0": {
      "capabilities": [
        "image_output"
      ],
      "family": "phoenix",
      "id": "phoenix-1.0",
      "input_cost_per_1k": 5.8e-06,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/leonardo/phoenix-1.0",
      "output_cost_per_1k": 5.8e-06,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-08-25"
    },
    "cloudflare_workers_ai/qwen1.5-0.5b-chat": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "qwen",
      "id": "qwen1.5-0.5b-chat",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "@cf/qwen/qwen1.5-0.5b-chat",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-01-31"
    },
    "cloudflare_workers_ai/qwen1.5-1.8b-chat": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "qwen",
      "id": "qwen1.5-1.8b-chat",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "@cf/qwen/qwen1.5-1.8b-chat",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-01-30"
    },
    "cloudflare_workers_ai/qwen1.5-14b-chat-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "qwen",
      "id": "qwen1.5-14b-chat-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 7500,
      "max_output_tokens": 7500,
      "mode": "chat",
      "name": "@cf/qwen/qwen1.5-14b-chat-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-03"
    },
    "cloudflare_workers_ai/qwen1.5-7b-chat-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "qwen",
      "id": "qwen1.5-7b-chat-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 20000,
      "max_output_tokens": 20000,
      "mode": "chat",
      "name": "@cf/qwen/qwen1.5-7b-chat-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-03"
    },
    "cloudflare_workers_ai/qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.00066,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "@cf/qwen/qwen2.5-coder-32b-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-11-06"
    },
    "cloudflare_workers_ai/qwen3-30b-a3b-fp8": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-30b-a3b-fp8",
      "input_cost_per_1k": 5.1e-05,
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/qwen/qwen3-30b-a3b-fp8",
      "open_weights": true,
      "output_cost_per_1k": 0.00034,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-04-30"
    },
    "cloudflare_workers_ai/qwq-32b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwq-32b",
      "input_cost_per_1k": 0.00066,
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "mode": "chat",
      "name": "@cf/qwen/qwq-32b",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "cloudflare_workers_ai",
      "release_date": "2025-03-05"
    },
    "cloudflare_workers_ai/resnet-50": {
      "capabilities": [
        "vision"
      ],
      "family": "resnet",
      "id": "resnet-50",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/microsoft/resnet-50",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2022-03-16"
    },
    "cloudflare_workers_ai/sqlcoder-7b-2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "sqlcoder",
      "id": "sqlcoder-7b-2",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 10000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "@cf/defog/sqlcoder-7b-2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-05"
    },
    "cloudflare_workers_ai/stable-diffusion-v1-5-img2img": {
      "capabilities": [
        "image_output"
      ],
      "family": "stable-diffusion",
      "id": "stable-diffusion-v1-5-img2img",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/runwayml/stable-diffusion-v1-5-img2img",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-27"
    },
    "cloudflare_workers_ai/stable-diffusion-v1-5-inpainting": {
      "capabilities": [
        "image_output"
      ],
      "family": "stable-diffusion",
      "id": "stable-diffusion-v1-5-inpainting",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/runwayml/stable-diffusion-v1-5-inpainting",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-27"
    },
    "cloudflare_workers_ai/stable-diffusion-xl-base-1.0": {
      "capabilities": [
        "image_output"
      ],
      "family": "stable-diffusion",
      "id": "stable-diffusion-xl-base-1.0",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/stabilityai/stable-diffusion-xl-base-1.0",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-07-25"
    },
    "cloudflare_workers_ai/stable-diffusion-xl-lightning": {
      "capabilities": [
        "image_output"
      ],
      "family": "stable-diffusion",
      "id": "stable-diffusion-xl-lightning",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "@cf/bytedance/stable-diffusion-xl-lightning",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-20"
    },
    "cloudflare_workers_ai/starling-lm-7b-beta": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "starling-lm",
      "id": "starling-lm-7b-beta",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/nexusflow/starling-lm-7b-beta",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-03-19"
    },
    "cloudflare_workers_ai/tinyllama-1.1b-chat-v1.0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "llama",
      "id": "tinyllama-1.1b-chat-v1.0",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-30"
    },
    "cloudflare_workers_ai/uform-gen2-qwen-500m": {
      "capabilities": [
        "vision"
      ],
      "family": "qwen",
      "id": "uform-gen2-qwen-500m",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "@cf/unum/uform-gen2-qwen-500m",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-02-15"
    },
    "cloudflare_workers_ai/una-cybertron-7b-v2-bf16": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "una-cybertron",
      "id": "una-cybertron-7b-v2-bf16",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 15000,
      "max_output_tokens": 15000,
      "mode": "chat",
      "name": "@cf/fblgit/una-cybertron-7b-v2-bf16",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-12-02"
    },
    "cloudflare_workers_ai/whisper": {
      "capabilities": [
        "audio_input"
      ],
      "family": "whisper",
      "id": "whisper",
      "input_cost_per_1k": 4.5e-07,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "audio_transcription",
      "name": "@cf/openai/whisper",
      "open_weights": true,
      "output_cost_per_1k": 4.5e-07,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-11-07"
    },
    "cloudflare_workers_ai/whisper-large-v3-turbo": {
      "capabilities": [
        "audio_input"
      ],
      "family": "whisper-large",
      "id": "whisper-large-v3-turbo",
      "input_cost_per_1k": 5.1e-07,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "audio_transcription",
      "name": "@cf/openai/whisper-large-v3-turbo",
      "open_weights": true,
      "output_cost_per_1k": 5.1e-07,
      "provider": "cloudflare_workers_ai",
      "release_date": "2024-10-01"
    },
    "cloudflare_workers_ai/whisper-tiny-en": {
      "capabilities": [
        "audio_input"
      ],
      "family": "whisper",
      "id": "whisper-tiny-en",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "audio_transcription",
      "name": "@cf/openai/whisper-tiny-en",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2022-09-26"
    },
    "cloudflare_workers_ai/zephyr-7b-beta-awq": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "zephyr",
      "id": "zephyr-7b-beta-awq",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "@hf/thebloke/zephyr-7b-beta-awq",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cloudflare_workers_ai",
      "release_date": "2023-10-27"
    },
    "cohere/command-a-03-2025": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-a",
      "id": "command-a-03-2025",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Command A",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "cohere",
      "release_date": "2025-03-13"
    },
    "cohere/command-a-reasoning-08-2025": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-a",
      "id": "command-a-reasoning-08-2025",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Command A Reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "cohere",
      "release_date": "2025-08-21"
    },
    "cohere/command-a-translate-08-2025": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "command-a",
      "id": "command-a-translate-08-2025",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Command A Translate",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "cohere",
      "release_date": "2025-08-28"
    },
    "cohere/command-a-vision-07-2025": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "command-a",
      "id": "command-a-vision-07-2025",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Command A Vision",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "cohere",
      "release_date": "2025-07-31"
    },
    "cohere/command-r-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r",
      "id": "command-r-08-2024",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "cohere",
      "release_date": "2024-08-30"
    },
    "cohere/command-r-plus-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r-plus",
      "id": "command-r-plus-08-2024",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R+",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "cohere",
      "release_date": "2024-08-30"
    },
    "cohere/command-r7b-12-2024": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "command-r",
      "id": "command-r7b-12-2024",
      "input_cost_per_1k": 3.75e-05,
      "knowledge_cutoff": "2024-06-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Command R7B",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "cohere",
      "release_date": "2024-02-27"
    },
    "cortecs/claude-4-5-sonnet": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-4-5-sonnet",
      "input_cost_per_1k": 0.003259,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "mode": "chat",
      "name": "Claude 4.5 Sonnet",
      "output_cost_per_1k": 0.016296,
      "provider": "cortecs",
      "release_date": "2025-09-29"
    },
    "cortecs/claude-sonnet-4": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4",
      "input_cost_per_1k": 0.003307,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.016536,
      "provider": "cortecs",
      "release_date": "2025-05-22"
    },
    "cortecs/deepseek-v3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3-0324",
      "input_cost_per_1k": 0.000551,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek V3 0324",
      "open_weights": true,
      "output_cost_per_1k": 0.001654,
      "provider": "cortecs",
      "release_date": "2025-03-24"
    },
    "cortecs/devstral-2512": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": null,
      "id": "devstral-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Devstral 2 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cortecs",
      "release_date": "2025-12-09"
    },
    "cortecs/devstral-small-2512": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "devstral-small-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Devstral Small 2 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cortecs",
      "release_date": "2025-12-09"
    },
    "cortecs/gemini-2.5-pro": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.001654,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.011024,
      "provider": "cortecs",
      "release_date": "2025-03-20"
    },
    "cortecs/gpt-4.1": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.002354,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT 4.1",
      "output_cost_per_1k": 0.009417,
      "provider": "cortecs",
      "release_date": "2025-04-14"
    },
    "cortecs/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT Oss 120b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cortecs",
      "release_date": "2025-08-05"
    },
    "cortecs/intellect-3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "intellect-3",
      "input_cost_per_1k": 0.000219,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "INTELLECT 3",
      "open_weights": true,
      "output_cost_per_1k": 0.001202,
      "provider": "cortecs",
      "release_date": "2025-11-26"
    },
    "cortecs/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-instruct",
      "input_cost_per_1k": 0.000551,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002646,
      "provider": "cortecs",
      "release_date": "2025-07-11"
    },
    "cortecs/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.000656,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002731,
      "provider": "cortecs",
      "release_date": "2025-12-08"
    },
    "cortecs/llama-3.1-405b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-405b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Llama 3.1 405B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "cortecs",
      "release_date": "2024-07-23"
    },
    "cortecs/nova-pro-v1": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "nova-pro",
      "id": "nova-pro-v1",
      "input_cost_per_1k": 0.001016,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 300000,
      "max_output_tokens": 5000,
      "mode": "chat",
      "name": "Nova Pro 1.0",
      "output_cost_per_1k": 0.004061,
      "provider": "cortecs",
      "release_date": "2024-12-03"
    },
    "cortecs/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-32b",
      "input_cost_per_1k": 9.9e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.00033,
      "provider": "cortecs",
      "release_date": "2025-04-29"
    },
    "cortecs/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.000441,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.001984,
      "provider": "cortecs",
      "release_date": "2025-07-25"
    },
    "cortecs/qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": null,
      "id": "qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.000164,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.001311,
      "provider": "cortecs",
      "release_date": "2025-09-11"
    },
    "deepinfra/MiniMaxAI/MiniMax-M2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMaxAI/MiniMax-M2",
      "input_cost_per_1k": 0.000254,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "MiniMax M2",
      "open_weights": true,
      "output_cost_per_1k": 0.00102,
      "provider": "deepinfra",
      "release_date": "2025-11-13"
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0016,
      "provider": "deepinfra",
      "release_date": "2025-07-23"
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct Turbo",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "deepinfra",
      "release_date": "2025-07-23"
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "deepinfra",
      "release_date": "2025-07-11"
    },
    "deepinfra/moonshotai/Kimi-K2-Thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Thinking",
      "input_cost_per_1k": 0.00047,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "deepinfra",
      "release_date": "2025-11-06"
    },
    "deepinfra/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.00024,
      "provider": "deepinfra",
      "release_date": "2025-08-05"
    },
    "deepinfra/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 3e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.00014,
      "provider": "deepinfra",
      "release_date": "2025-08-05"
    },
    "deepinfra/zai-org/GLM-4.5": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "glm-4.5",
      "id": "zai-org/GLM-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "deepinfra",
      "release_date": "2025-07-28"
    },
    "deepinfra/zai-org/GLM-4.7": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "zai-org/GLM-4.7",
      "input_cost_per_1k": 0.00043,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 202752,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.00175,
      "provider": "deepinfra",
      "release_date": "2025-12-22"
    },
    "deepseek/deepseek-chat": {
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "deepseek-chat",
      "id": "deepseek-chat",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek Chat",
      "output_cost_per_1k": 0.00042,
      "provider": "deepseek",
      "release_date": "2024-12-26"
    },
    "deepseek/deepseek-reasoner": {
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "deepseek",
      "id": "deepseek-reasoner",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek Reasoner",
      "output_cost_per_1k": 0.00042,
      "provider": "deepseek",
      "release_date": "2025-01-20"
    },
    "fastrouter/anthropic/claude-opus-4.1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "fastrouter",
      "release_date": "2025-08-05"
    },
    "fastrouter/anthropic/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "fastrouter",
      "release_date": "2025-05-22"
    },
    "fastrouter/deepseek-ai/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-ai/deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 3e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00014,
      "provider": "fastrouter",
      "release_date": "2025-01-23"
    },
    "fastrouter/google/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "fastrouter",
      "release_date": "2025-06-17"
    },
    "fastrouter/google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "fastrouter",
      "release_date": "2025-06-17"
    },
    "fastrouter/moonshotai/kimi-k2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "fastrouter",
      "release_date": "2025-07-11"
    },
    "fastrouter/openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "openai/gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "fastrouter",
      "release_date": "2025-04-14"
    },
    "fastrouter/openai/gpt-5": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "fastrouter",
      "release_date": "2025-08-07"
    },
    "fastrouter/openai/gpt-5-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "openai/gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "fastrouter",
      "release_date": "2025-08-07"
    },
    "fastrouter/openai/gpt-5-nano": {
      "cache_read_cost_per_1k": 5e-06,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "openai/gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "fastrouter",
      "release_date": "2025-08-07"
    },
    "fastrouter/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "fastrouter",
      "release_date": "2025-08-05"
    },
    "fastrouter/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "fastrouter",
      "release_date": "2025-08-05"
    },
    "fastrouter/qwen/qwen3-coder": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "fastrouter",
      "release_date": "2025-07-23"
    },
    "fastrouter/x-ai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "fastrouter",
      "release_date": "2025-07-09"
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "accounts/fireworks/models/deepseek-r1-0528",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 160000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Deepseek R1 05/28",
      "open_weights": true,
      "output_cost_per_1k": 0.008,
      "provider": "fireworks",
      "release_date": "2025-05-28"
    },
    "fireworks/accounts/fireworks/models/deepseek-v3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "accounts/fireworks/models/deepseek-v3-0324",
      "input_cost_per_1k": 0.0009,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 160000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Deepseek V3 03-24",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "fireworks",
      "release_date": "2025-03-24"
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "accounts/fireworks/models/deepseek-v3p1",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "open_weights": true,
      "output_cost_per_1k": 0.00168,
      "provider": "fireworks",
      "release_date": "2025-08-21"
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p2": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "accounts/fireworks/models/deepseek-v3p2",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 160000,
      "max_output_tokens": 160000,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.00168,
      "provider": "fireworks",
      "release_date": "2025-12-01"
    },
    "fireworks/accounts/fireworks/models/glm-4p5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4",
      "id": "accounts/fireworks/models/glm-4p5",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "fireworks",
      "release_date": "2025-07-29"
    },
    "fireworks/accounts/fireworks/models/glm-4p5-air": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4-air",
      "id": "accounts/fireworks/models/glm-4p5-air",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.00088,
      "provider": "fireworks",
      "release_date": "2025-08-01"
    },
    "fireworks/accounts/fireworks/models/glm-4p6": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4",
      "id": "accounts/fireworks/models/glm-4p6",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 198000,
      "max_output_tokens": 198000,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "fireworks",
      "release_date": "2025-10-01"
    },
    "fireworks/accounts/fireworks/models/glm-4p7": {
      "cache_read_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4",
      "id": "accounts/fireworks/models/glm-4p7",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 198000,
      "max_output_tokens": 198000,
      "mode": "chat",
      "name": "GLM 4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "fireworks",
      "release_date": "2025-12-22"
    },
    "fireworks/accounts/fireworks/models/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "accounts/fireworks/models/gpt-oss-120b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "fireworks",
      "release_date": "2025-08-05"
    },
    "fireworks/accounts/fireworks/models/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "accounts/fireworks/models/gpt-oss-20b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "fireworks",
      "release_date": "2025-08-05"
    },
    "fireworks/accounts/fireworks/models/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "accounts/fireworks/models/kimi-k2-instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "fireworks",
      "release_date": "2025-07-11"
    },
    "fireworks/accounts/fireworks/models/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "accounts/fireworks/models/kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "fireworks",
      "release_date": "2025-11-06"
    },
    "fireworks/accounts/fireworks/models/minimax-m2": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "accounts/fireworks/models/minimax-m2",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 192000,
      "max_output_tokens": 192000,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "fireworks",
      "release_date": "2025-10-27"
    },
    "fireworks/accounts/fireworks/models/minimax-m2p1": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "accounts/fireworks/models/minimax-m2p1",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "mode": "chat",
      "name": "MiniMax-M2.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "fireworks",
      "release_date": "2025-12-23"
    },
    "fireworks/accounts/fireworks/models/qwen3-235b-a22b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "accounts/fireworks/models/qwen3-235b-a22b",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 235B-A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.00088,
      "provider": "fireworks",
      "release_date": "2025-04-29"
    },
    "fireworks/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.00045,
      "max_input_tokens": 256000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "fireworks",
      "release_date": "2025-07-22"
    },
    "friendli/LGAI-EXAONE/EXAONE-4.0.1-32B": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "exaone",
      "id": "LGAI-EXAONE/EXAONE-4.0.1-32B",
      "input_cost_per_1k": 0.0006,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "EXAONE 4.0.1 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "friendli",
      "release_date": "2025-07-31"
    },
    "friendli/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "friendli",
      "release_date": "2025-07-29"
    },
    "friendli/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-07-29"
    },
    "friendli/Qwen/Qwen3-30B-A3B": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-30B-A3B",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Qwen3 30B A3B",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-06-16"
    },
    "friendli/Qwen/Qwen3-32B": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-32B",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Qwen3 32B",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-06-16"
    },
    "friendli/deepseek-ai/DeepSeek-R1-0528": {
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek R1 0528",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-07-11"
    },
    "friendli/meta-llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "friendli",
      "release_date": "2024-08-01"
    },
    "friendli/meta-llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.0006,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Llama 3.3 70B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "friendli",
      "release_date": "2024-08-01"
    },
    "friendli/meta-llama/Llama-4-Maverick-17B-128E-Instruct": {
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "llama-4",
      "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B 128E Instruct",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-06-16"
    },
    "friendli/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "llama-4",
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-06-16"
    },
    "friendli/zai-org/GLM-4.6": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4",
      "id": "zai-org/GLM-4.6",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "provider": "friendli",
      "release_date": "2025-10-31"
    },
    "github_copilot/claude-3.5-sonnet": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "deprecated": true,
      "family": "claude-sonnet",
      "id": "claude-3.5-sonnet",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 90000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2024-10-22"
    },
    "github_copilot/claude-3.7-sonnet": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "deprecated": true,
      "family": "claude-sonnet",
      "id": "claude-3.7-sonnet",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-02-19"
    },
    "github_copilot/claude-3.7-sonnet-thought": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "deprecated": true,
      "family": "claude-sonnet",
      "id": "claude-3.7-sonnet-thought",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Claude Sonnet 3.7 Thinking",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-02-19"
    },
    "github_copilot/claude-haiku-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4.5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-10-15"
    },
    "github_copilot/claude-opus-4": {
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "deprecated": true,
      "family": "claude-opus",
      "id": "claude-opus-4",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 80000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-05-22"
    },
    "github_copilot/claude-opus-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4.5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-11-24"
    },
    "github_copilot/claude-opus-41": {
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-41",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 80000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-08-05"
    },
    "github_copilot/claude-sonnet-4": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-05-22"
    },
    "github_copilot/claude-sonnet-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4.5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-09-29"
    },
    "github_copilot/gemini-2.0-flash-001": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "deprecated": true,
      "family": "gemini-flash",
      "id": "gemini-2.0-flash-001",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2024-12-11"
    },
    "github_copilot/gemini-2.5-pro": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-03-20"
    },
    "github_copilot/gemini-3-flash-preview": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-3-flash-preview",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 3 Flash",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-12-17"
    },
    "github_copilot/gemini-3-pro-preview": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-11-18"
    },
    "github_copilot/gpt-4.1": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-04-14"
    },
    "github_copilot/gpt-4o": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2024-05-13"
    },
    "github_copilot/gpt-5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-08-07"
    },
    "github_copilot/gpt-5-codex": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-09-15"
    },
    "github_copilot/gpt-5-mini": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "GPT-5-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-08-13"
    },
    "github_copilot/gpt-5.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-11-13"
    },
    "github_copilot/gpt-5.1-codex": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1-Codex",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-11-13"
    },
    "github_copilot/gpt-5.1-codex-max": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-max",
      "id": "gpt-5.1-codex-max",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1-Codex-max",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-12-04"
    },
    "github_copilot/gpt-5.1-codex-mini": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "GPT-5.1-Codex-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-11-13"
    },
    "github_copilot/gpt-5.2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.2",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-12-11"
    },
    "github_copilot/grok-code-fast-1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-code-fast-1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-08-27"
    },
    "github_copilot/o3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "deprecated": true,
      "family": "o3",
      "id": "o3",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "o3 (Preview)",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-04-16"
    },
    "github_copilot/o3-mini": {
      "capabilities": [
        "reasoning"
      ],
      "deprecated": true,
      "family": "o3-mini",
      "id": "o3-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2024-12-20"
    },
    "github_copilot/o4-mini": {
      "capabilities": [
        "reasoning"
      ],
      "deprecated": true,
      "family": "o4-mini",
      "id": "o4-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "o4-mini (Preview)",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-04-16"
    },
    "github_copilot/oswe-vscode-prime": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "oswe-vscode-prime",
      "id": "oswe-vscode-prime",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Raptor Mini (Preview)",
      "output_cost_per_1k": 0.0,
      "provider": "github_copilot",
      "release_date": "2025-11-10"
    },
    "github_models/ai21-labs/ai21-jamba-1.5-large": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "jamba-1.5-large",
      "id": "ai21-labs/ai21-jamba-1.5-large",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "AI21 Jamba 1.5 Large",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-29"
    },
    "github_models/ai21-labs/ai21-jamba-1.5-mini": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "jamba-1.5-mini",
      "id": "ai21-labs/ai21-jamba-1.5-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "AI21 Jamba 1.5 Mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-29"
    },
    "github_models/cohere/cohere-command-a": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-a",
      "id": "cohere/cohere-command-a",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cohere Command A",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-11-01"
    },
    "github_models/cohere/cohere-command-r": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r",
      "id": "cohere/cohere-command-r",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cohere Command R",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-03-11"
    },
    "github_models/cohere/cohere-command-r-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r",
      "id": "cohere/cohere-command-r-08-2024",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cohere Command R 08-2024",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-01"
    },
    "github_models/cohere/cohere-command-r-plus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r-plus",
      "id": "cohere/cohere-command-r-plus",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cohere Command R+",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-04"
    },
    "github_models/cohere/cohere-command-r-plus-08-2024": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "command-r-plus",
      "id": "cohere/cohere-command-r-plus-08-2024",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cohere Command R+ 08-2024",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-01"
    },
    "github_models/core42/jais-30b-chat": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "jais",
      "id": "core42/jais-30b-chat",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-03",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "JAIS 30b Chat",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2023-08-30"
    },
    "github_models/deepseek/deepseek-r1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek/deepseek-r1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek-R1",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-20"
    },
    "github_models/deepseek/deepseek-r1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek/deepseek-r1-0528",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek-R1-0528",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-05-28"
    },
    "github_models/deepseek/deepseek-v3-0324": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3-0324",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek-V3-0324",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-03-24"
    },
    "github_models/meta/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "meta/llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.2-11B-Vision-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-09-25"
    },
    "github_models/meta/llama-3.2-90b-vision-instruct": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "meta/llama-3.2-90b-vision-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.2-90B-Vision-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-09-25"
    },
    "github_models/meta/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta/llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-06"
    },
    "github_models/meta/llama-4-maverick-17b-128e-instruct-fp8": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "meta/llama-4-maverick-17b-128e-instruct-fp8",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-31"
    },
    "github_models/meta/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "meta/llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-31"
    },
    "github_models/meta/meta-llama-3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta/meta-llama-3-70b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Meta-Llama-3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-18"
    },
    "github_models/meta/meta-llama-3-8b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta/meta-llama-3-8b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Meta-Llama-3-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-18"
    },
    "github_models/meta/meta-llama-3.1-405b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta/meta-llama-3.1-405b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-405B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-07-23"
    },
    "github_models/meta/meta-llama-3.1-70b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta/meta-llama-3.1-70b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-07-23"
    },
    "github_models/meta/meta-llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta/meta-llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-07-23"
    },
    "github_models/microsoft/mai-ds-r1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mai-ds-r1",
      "id": "microsoft/mai-ds-r1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "MAI-DS-R1",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-20"
    },
    "github_models/microsoft/phi-3-medium-128k-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3",
      "id": "microsoft/phi-3-medium-128k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-medium instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-23"
    },
    "github_models/microsoft/phi-3-medium-4k-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3",
      "id": "microsoft/phi-3-medium-4k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Phi-3-medium instruct (4k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-23"
    },
    "github_models/microsoft/phi-3-mini-128k-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3",
      "id": "microsoft/phi-3-mini-128k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-mini instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-23"
    },
    "github_models/microsoft/phi-3-mini-4k-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3",
      "id": "microsoft/phi-3-mini-4k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Phi-3-mini instruct (4k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-23"
    },
    "github_models/microsoft/phi-3-small-128k-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3",
      "id": "microsoft/phi-3-small-128k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3-small instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-23"
    },
    "github_models/microsoft/phi-3-small-8k-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3",
      "id": "microsoft/phi-3-small-8k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Phi-3-small instruct (8k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-04-23"
    },
    "github_models/microsoft/phi-3.5-mini-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3.5",
      "id": "microsoft/phi-3.5-mini-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-mini instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-20"
    },
    "github_models/microsoft/phi-3.5-moe-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-3.5",
      "id": "microsoft/phi-3.5-moe-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-MoE instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-20"
    },
    "github_models/microsoft/phi-3.5-vision-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "phi-3.5",
      "id": "microsoft/phi-3.5-vision-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-3.5-vision instruct (128k)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-08-20"
    },
    "github_models/microsoft/phi-4": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "microsoft/phi-4",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-11"
    },
    "github_models/microsoft/phi-4-mini-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "microsoft/phi-4-mini-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-11"
    },
    "github_models/microsoft/phi-4-mini-reasoning": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "microsoft/phi-4-mini-reasoning",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini-reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-11"
    },
    "github_models/microsoft/phi-4-multimodal-instruct": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "phi-4",
      "id": "microsoft/phi-4-multimodal-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-multimodal-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-11"
    },
    "github_models/microsoft/phi-4-reasoning": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "microsoft/phi-4-reasoning",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-Reasoning",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-11"
    },
    "github_models/mistral-ai/codestral-2501": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "codestral",
      "id": "mistral-ai/codestral-2501",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Codestral 25.01",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-01"
    },
    "github_models/mistral-ai/ministral-3b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "ministral-3b",
      "id": "mistral-ai/ministral-3b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Ministral 3B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-10-22"
    },
    "github_models/mistral-ai/mistral-large-2411": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mistral-large",
      "id": "mistral-ai/mistral-large-2411",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Large 24.11",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-11-01"
    },
    "github_models/mistral-ai/mistral-medium-2505": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistral-ai/mistral-medium-2505",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Medium 3 (25.05)",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-05-01"
    },
    "github_models/mistral-ai/mistral-nemo": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistral-ai/mistral-nemo",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Mistral Nemo",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-07-18"
    },
    "github_models/mistral-ai/mistral-small-2503": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-ai/mistral-small-2503",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Small 3.1",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-03-01"
    },
    "github_models/openai/gpt-4.1": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "openai/gpt-4.1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-04-14"
    },
    "github_models/openai/gpt-4.1-mini": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "openai/gpt-4.1-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4.1-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-04-14"
    },
    "github_models/openai/gpt-4.1-nano": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "openai/gpt-4.1-nano",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4.1-nano",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-04-14"
    },
    "github_models/openai/gpt-4o": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "openai/gpt-4o",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-05-13"
    },
    "github_models/openai/gpt-4o-mini": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-07-18"
    },
    "github_models/openai/o1": {
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "openai/o1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o1",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-09-12"
    },
    "github_models/openai/o1-mini": {
      "capabilities": [
        "reasoning"
      ],
      "family": "o1-mini",
      "id": "openai/o1-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "OpenAI o1-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-09-12"
    },
    "github_models/openai/o1-preview": {
      "capabilities": [
        "reasoning"
      ],
      "family": "o1-preview",
      "id": "openai/o1-preview",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI o1-preview",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-09-12"
    },
    "github_models/openai/o3": {
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "openai/o3",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o3",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-31"
    },
    "github_models/openai/o3-mini": {
      "capabilities": [
        "reasoning"
      ],
      "family": "o3-mini",
      "id": "openai/o3-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o3-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-31"
    },
    "github_models/openai/o4-mini": {
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o4-mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2025-01-31"
    },
    "github_models/xai/grok-3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "xai/grok-3",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-09"
    },
    "github_models/xai/grok-3-mini": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "xai/grok-3-mini",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0,
      "provider": "github_models",
      "release_date": "2024-12-09"
    },
    "google/gemini-1.5-flash": {
      "cache_read_cost_per_1k": 1.875e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-1.5-flash",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 1.5 Flash",
      "output_cost_per_1k": 0.0003,
      "provider": "google",
      "release_date": "2024-05-14"
    },
    "google/gemini-1.5-flash-8b": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-1.5-flash-8b",
      "input_cost_per_1k": 3.75e-05,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 1.5 Flash-8B",
      "output_cost_per_1k": 0.00015,
      "provider": "google",
      "release_date": "2024-10-03"
    },
    "google/gemini-1.5-pro": {
      "cache_read_cost_per_1k": 0.0003125,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-1.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 1.5 Pro",
      "output_cost_per_1k": 0.005,
      "provider": "google",
      "release_date": "2024-02-15"
    },
    "google/gemini-2.0-flash": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.0-flash",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash",
      "output_cost_per_1k": 0.0004,
      "provider": "google",
      "release_date": "2024-12-11"
    },
    "google/gemini-2.0-flash-lite": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.0-flash-lite",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash Lite",
      "output_cost_per_1k": 0.0003,
      "provider": "google",
      "release_date": "2024-12-11"
    },
    "google/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "google",
      "release_date": "2025-03-20"
    },
    "google/gemini-2.5-flash-image": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "image_output",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-flash-image",
      "id": "gemini-2.5-flash-image",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "image",
      "name": "Gemini 2.5 Flash Image",
      "output_cost_per_1k": 0.03,
      "provider": "google",
      "release_date": "2025-08-26"
    },
    "google/gemini-2.5-flash-image-preview": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "image_output",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-flash-image",
      "id": "gemini-2.5-flash-image-preview",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "image",
      "name": "Gemini 2.5 Flash Image (Preview)",
      "output_cost_per_1k": 0.03,
      "provider": "google",
      "release_date": "2025-08-26"
    },
    "google/gemini-2.5-flash-lite": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite",
      "output_cost_per_1k": 0.0004,
      "provider": "google",
      "release_date": "2025-06-17"
    },
    "google/gemini-2.5-flash-lite-preview-06-17": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite-preview-06-17",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite Preview 06-17",
      "output_cost_per_1k": 0.0004,
      "provider": "google",
      "release_date": "2025-06-17"
    },
    "google/gemini-2.5-flash-lite-preview-09-2025": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite-preview-09-2025",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "output_cost_per_1k": 0.0004,
      "provider": "google",
      "release_date": "2025-09-25"
    },
    "google/gemini-2.5-flash-preview-04-17": {
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash-preview-04-17",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 04-17",
      "output_cost_per_1k": 0.0006,
      "provider": "google",
      "release_date": "2025-04-17"
    },
    "google/gemini-2.5-flash-preview-05-20": {
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash-preview-05-20",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 05-20",
      "output_cost_per_1k": 0.0006,
      "provider": "google",
      "release_date": "2025-05-20"
    },
    "google/gemini-2.5-flash-preview-09-2025": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash-preview-09-2025",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "output_cost_per_1k": 0.0025,
      "provider": "google",
      "release_date": "2025-09-25"
    },
    "google/gemini-2.5-flash-preview-tts": {
      "capabilities": [
        "audio_output"
      ],
      "family": "gemini-flash-tts",
      "id": "gemini-2.5-flash-preview-tts",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 8000,
      "max_output_tokens": 16000,
      "mode": "audio_speech",
      "name": "Gemini 2.5 Flash Preview TTS",
      "output_cost_per_1k": 0.01,
      "provider": "google",
      "release_date": "2025-05-01"
    },
    "google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "google",
      "release_date": "2025-03-20"
    },
    "google/gemini-2.5-pro-preview-05-06": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro-preview-05-06",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro Preview 05-06",
      "output_cost_per_1k": 0.01,
      "provider": "google",
      "release_date": "2025-05-06"
    },
    "google/gemini-2.5-pro-preview-06-05": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro-preview-06-05",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro Preview 06-05",
      "output_cost_per_1k": 0.01,
      "provider": "google",
      "release_date": "2025-06-05"
    },
    "google/gemini-2.5-pro-preview-tts": {
      "capabilities": [
        "audio_output"
      ],
      "family": "gemini-flash-tts",
      "id": "gemini-2.5-pro-preview-tts",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 8000,
      "max_output_tokens": 16000,
      "mode": "audio_speech",
      "name": "Gemini 2.5 Pro Preview TTS",
      "output_cost_per_1k": 0.02,
      "provider": "google",
      "release_date": "2025-05-01"
    },
    "google/gemini-3-flash-preview": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-3-flash-preview",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Flash Preview",
      "output_cost_per_1k": 0.003,
      "provider": "google",
      "release_date": "2025-12-17"
    },
    "google/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.012,
      "provider": "google",
      "release_date": "2025-11-18"
    },
    "google/gemini-embedding-001": {
      "family": "gemini",
      "id": "gemini-embedding-001",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 2048,
      "max_output_tokens": 3072,
      "mode": "embedding",
      "name": "Gemini Embedding 001",
      "output_cost_per_1k": 0.0,
      "provider": "google",
      "release_date": "2025-05-20"
    },
    "google/gemini-flash-latest": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-flash-latest",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini Flash Latest",
      "output_cost_per_1k": 0.0025,
      "provider": "google",
      "release_date": "2025-09-25"
    },
    "google/gemini-flash-lite-latest": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-flash-lite-latest",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini Flash-Lite Latest",
      "output_cost_per_1k": 0.0004,
      "provider": "google",
      "release_date": "2025-09-25"
    },
    "google/gemini-live-2.5-flash": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-live-2.5-flash",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Gemini Live 2.5 Flash",
      "output_cost_per_1k": 0.002,
      "provider": "google",
      "release_date": "2025-09-01"
    },
    "google/gemini-live-2.5-flash-preview-native-audio": {
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "video_input"
      ],
      "family": "gemini-flash",
      "id": "gemini-live-2.5-flash-preview-native-audio",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini Live 2.5 Flash Preview Native Audio",
      "output_cost_per_1k": 0.002,
      "provider": "google",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-2.0-flash": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.0-flash",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash",
      "output_cost_per_1k": 0.0004,
      "provider": "google_vertex",
      "release_date": "2024-12-11"
    },
    "google_vertex/gemini-2.0-flash-lite": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.0-flash-lite",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash Lite",
      "output_cost_per_1k": 0.0003,
      "provider": "google_vertex",
      "release_date": "2024-12-11"
    },
    "google_vertex/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "google_vertex",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-2.5-flash-lite": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite",
      "output_cost_per_1k": 0.0004,
      "provider": "google_vertex",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-2.5-flash-lite-preview-06-17": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite-preview-06-17",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite Preview 06-17",
      "output_cost_per_1k": 0.0004,
      "provider": "google_vertex",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-2.5-flash-lite-preview-09-2025": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite-preview-09-2025",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "output_cost_per_1k": 0.0004,
      "provider": "google_vertex",
      "release_date": "2025-09-25"
    },
    "google_vertex/gemini-2.5-flash-preview-04-17": {
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash-preview-04-17",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 04-17",
      "output_cost_per_1k": 0.0006,
      "provider": "google_vertex",
      "release_date": "2025-04-17"
    },
    "google_vertex/gemini-2.5-flash-preview-05-20": {
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash-preview-05-20",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 05-20",
      "output_cost_per_1k": 0.0006,
      "provider": "google_vertex",
      "release_date": "2025-05-20"
    },
    "google_vertex/gemini-2.5-flash-preview-09-2025": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash-preview-09-2025",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "output_cost_per_1k": 0.0025,
      "provider": "google_vertex",
      "release_date": "2025-09-25"
    },
    "google_vertex/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "google_vertex",
      "release_date": "2025-03-20"
    },
    "google_vertex/gemini-2.5-pro-preview-05-06": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro-preview-05-06",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro Preview 05-06",
      "output_cost_per_1k": 0.01,
      "provider": "google_vertex",
      "release_date": "2025-05-06"
    },
    "google_vertex/gemini-2.5-pro-preview-06-05": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro-preview-06-05",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro Preview 06-05",
      "output_cost_per_1k": 0.01,
      "provider": "google_vertex",
      "release_date": "2025-06-05"
    },
    "google_vertex/gemini-3-flash-preview": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-3-flash-preview",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Flash Preview",
      "output_cost_per_1k": 0.003,
      "provider": "google_vertex",
      "release_date": "2025-12-17"
    },
    "google_vertex/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.012,
      "provider": "google_vertex",
      "release_date": "2025-11-18"
    },
    "google_vertex/gemini-embedding-001": {
      "family": "gemini",
      "id": "gemini-embedding-001",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 2048,
      "max_output_tokens": 3072,
      "mode": "embedding",
      "name": "Gemini Embedding 001",
      "output_cost_per_1k": 0.0,
      "provider": "google_vertex",
      "release_date": "2025-05-20"
    },
    "google_vertex/gemini-flash-latest": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-flash-latest",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini Flash Latest",
      "output_cost_per_1k": 0.0025,
      "provider": "google_vertex",
      "release_date": "2025-09-25"
    },
    "google_vertex/gemini-flash-lite-latest": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-flash-lite-latest",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini Flash-Lite Latest",
      "output_cost_per_1k": 0.0004,
      "provider": "google_vertex",
      "release_date": "2025-09-25"
    },
    "google_vertex/openai/gpt-oss-120b-maas": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b-maas",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.00036,
      "provider": "google_vertex",
      "release_date": "2025-08-05"
    },
    "google_vertex/openai/gpt-oss-20b-maas": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b-maas",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.00025,
      "provider": "google_vertex",
      "release_date": "2025-08-05"
    },
    "google_vertex_anthropic/claude-3-5-haiku@20241022": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3-5-haiku@20241022",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5",
      "output_cost_per_1k": 0.004,
      "provider": "google_vertex_anthropic",
      "release_date": "2024-10-22"
    },
    "google_vertex_anthropic/claude-3-5-sonnet@20241022": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-5-sonnet@20241022",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5 v2",
      "output_cost_per_1k": 0.015,
      "provider": "google_vertex_anthropic",
      "release_date": "2024-10-22"
    },
    "google_vertex_anthropic/claude-3-7-sonnet@20250219": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3-7-sonnet@20250219",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-10-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.015,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-02-19"
    },
    "google_vertex_anthropic/claude-haiku-4-5@20251001": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5@20251001",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-10-15"
    },
    "google_vertex_anthropic/claude-opus-4-1@20250805": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1@20250805",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-08-05"
    },
    "google_vertex_anthropic/claude-opus-4-5@20251101": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-5@20251101",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-11-24"
    },
    "google_vertex_anthropic/claude-opus-4@20250514": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4@20250514",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-05-22"
    },
    "google_vertex_anthropic/claude-sonnet-4-5@20250929": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5@20250929",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-09-29"
    },
    "google_vertex_anthropic/claude-sonnet-4@20250514": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4@20250514",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "google_vertex_anthropic",
      "release_date": "2025-05-22"
    },
    "groq/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "deprecated": true,
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.00075,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00099,
      "provider": "groq",
      "release_date": "2025-01-20"
    },
    "groq/gemma2-9b-it": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "gemma-2",
      "id": "gemma2-9b-it",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma 2 9B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "groq",
      "release_date": "2024-06-27"
    },
    "groq/llama-3.1-8b-instant": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instant",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3.1 8B Instant",
      "open_weights": true,
      "output_cost_per_1k": 8e-05,
      "provider": "groq",
      "release_date": "2024-07-23"
    },
    "groq/llama-3.3-70b-versatile": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-versatile",
      "input_cost_per_1k": 0.00059,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama 3.3 70B Versatile",
      "open_weights": true,
      "output_cost_per_1k": 0.00079,
      "provider": "groq",
      "release_date": "2024-12-06"
    },
    "groq/llama-guard-3-8b": {
      "capabilities": [
        "temperature"
      ],
      "deprecated": true,
      "family": "llama",
      "id": "llama-guard-3-8b",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama Guard 3 8B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "groq",
      "release_date": "2024-07-23"
    },
    "groq/llama3-70b-8192": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "llama",
      "id": "llama3-70b-8192",
      "input_cost_per_1k": 0.00059,
      "knowledge_cutoff": "2023-03",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00079,
      "provider": "groq",
      "release_date": "2024-04-18"
    },
    "groq/llama3-8b-8192": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "llama",
      "id": "llama3-8b-8192",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2023-03",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3 8B",
      "open_weights": true,
      "output_cost_per_1k": 8e-05,
      "provider": "groq",
      "release_date": "2024-04-18"
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "groq",
      "release_date": "2025-04-05"
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.00011,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Scout 17B",
      "open_weights": true,
      "output_cost_per_1k": 0.00034,
      "provider": "groq",
      "release_date": "2025-04-05"
    },
    "groq/meta-llama/llama-guard-4-12b": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "llama",
      "id": "meta-llama/llama-guard-4-12b",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 131072,
      "max_output_tokens": 128,
      "mode": "chat",
      "name": "Llama Guard 4 12B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "groq",
      "release_date": "2025-04-05"
    },
    "groq/mistral-saba-24b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "mistral",
      "id": "mistral-saba-24b",
      "input_cost_per_1k": 0.00079,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral Saba 24B",
      "output_cost_per_1k": 0.00079,
      "provider": "groq",
      "release_date": "2025-02-06"
    },
    "groq/moonshotai/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "groq",
      "release_date": "2025-07-14"
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-instruct-0905",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Instruct 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "groq",
      "release_date": "2025-09-05"
    },
    "groq/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.00075,
      "provider": "groq",
      "release_date": "2025-08-05"
    },
    "groq/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "groq",
      "release_date": "2025-08-05"
    },
    "groq/qwen-qwq-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwen-qwq-32b",
      "input_cost_per_1k": 0.00029,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen QwQ 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.00039,
      "provider": "groq",
      "release_date": "2024-11-27"
    },
    "groq/qwen/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-32b",
      "input_cost_per_1k": 0.00029,
      "knowledge_cutoff": "2024-11-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.00059,
      "provider": "groq",
      "release_date": "2024-12-23"
    },
    "helicone/chatgpt-4o-latest": {
      "cache_read_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "chatgpt-4o",
      "id": "chatgpt-4o-latest",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "OpenAI ChatGPT-4o",
      "output_cost_per_1k": 0.02,
      "provider": "helicone",
      "release_date": "2024-08-14"
    },
    "helicone/claude-3-haiku-20240307": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3-haiku-20240307",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Anthropic: Claude 3 Haiku",
      "output_cost_per_1k": 0.00125,
      "provider": "helicone",
      "release_date": "2024-03-07"
    },
    "helicone/claude-3.5-haiku": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3.5-haiku",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Anthropic: Claude 3.5 Haiku",
      "output_cost_per_1k": 0.004,
      "provider": "helicone",
      "release_date": "2024-10-22"
    },
    "helicone/claude-3.5-sonnet-v2": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3.5-sonnet-v2",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Anthropic: Claude 3.5 Sonnet v2",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2024-10-22"
    },
    "helicone/claude-3.7-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-3.7-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-02",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Anthropic: Claude 3.7 Sonnet",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2025-02-19"
    },
    "helicone/claude-4.5-haiku": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-4.5-haiku",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Anthropic: Claude 4.5 Haiku",
      "output_cost_per_1k": 0.005,
      "provider": "helicone",
      "release_date": "2025-10-01"
    },
    "helicone/claude-4.5-opus": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-4.5-opus",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Anthropic: Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "helicone",
      "release_date": "2025-11-24"
    },
    "helicone/claude-4.5-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-4.5-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Anthropic: Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2025-09-29"
    },
    "helicone/claude-haiku-4-5-20251001": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5-20251001",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Anthropic: Claude 4.5 Haiku (20251001)",
      "output_cost_per_1k": 0.005,
      "provider": "helicone",
      "release_date": "2025-10-01"
    },
    "helicone/claude-opus-4": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Anthropic: Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "helicone",
      "release_date": "2025-05-14"
    },
    "helicone/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Anthropic: Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "helicone",
      "release_date": "2025-08-05"
    },
    "helicone/claude-opus-4-1-20250805": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1-20250805",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Anthropic: Claude Opus 4.1 (20250805)",
      "output_cost_per_1k": 0.075,
      "provider": "helicone",
      "release_date": "2025-08-05"
    },
    "helicone/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Anthropic: Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2025-05-14"
    },
    "helicone/claude-sonnet-4-5-20250929": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5-20250929",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Anthropic: Claude Sonnet 4.5 (20250929)",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2025-09-29"
    },
    "helicone/codex-mini-latest": {
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "codex",
      "id": "codex-mini-latest",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI Codex Mini Latest",
      "output_cost_per_1k": 0.006,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 3e-05,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "output_cost_per_1k": 0.00013,
      "provider": "helicone",
      "release_date": "2025-01-20"
    },
    "helicone/deepseek-reasoner": {
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "temperature"
      ],
      "family": "deepseek",
      "id": "deepseek-reasoner",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "DeepSeek Reasoner",
      "output_cost_per_1k": 0.00168,
      "provider": "helicone",
      "release_date": "2025-01-20"
    },
    "helicone/deepseek-tng-r1t2-chimera": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-tng-r1t2-chimera",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 130000,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek TNG R1T2 Chimera",
      "output_cost_per_1k": 0.0012,
      "provider": "helicone",
      "release_date": "2025-07-02"
    },
    "helicone/deepseek-v3": {
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3",
      "output_cost_per_1k": 0.00168,
      "provider": "helicone",
      "release_date": "2024-12-26"
    },
    "helicone/deepseek-v3.1-terminus": {
      "cache_read_cost_per_1k": 0.000216,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.1-terminus",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus",
      "output_cost_per_1k": 0.001,
      "provider": "helicone",
      "release_date": "2025-09-22"
    },
    "helicone/deepseek-v3.2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "output_cost_per_1k": 0.00041,
      "provider": "helicone",
      "release_date": "2025-09-22"
    },
    "helicone/ernie-4.5-21b-a3b-thinking": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "ernie-4",
      "id": "ernie-4.5-21b-a3b-thinking",
      "input_cost_per_1k": 7e-05,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Baidu Ernie 4.5 21B A3B Thinking",
      "output_cost_per_1k": 0.00028,
      "provider": "helicone",
      "release_date": "2025-03-16"
    },
    "helicone/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "mode": "chat",
      "name": "Google Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "helicone",
      "release_date": "2025-06-17"
    },
    "helicone/gemini-2.5-flash-lite": {
      "cache_read_cost_per_1k": 2.5e-05,
      "cache_write_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "gemini-2.5-flash-lite",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "mode": "chat",
      "name": "Google Gemini 2.5 Flash Lite",
      "output_cost_per_1k": 0.0004,
      "provider": "helicone",
      "release_date": "2025-07-22"
    },
    "helicone/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.0003125,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Google Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2025-06-17"
    },
    "helicone/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Google Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.012,
      "provider": "helicone",
      "release_date": "2025-11-18"
    },
    "helicone/gemma-3-12b-it": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "gemma-3-12b-it",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Google Gemma 3 12B",
      "output_cost_per_1k": 0.0001,
      "provider": "helicone",
      "release_date": "2024-12-01"
    },
    "helicone/gemma2-9b-it": {
      "capabilities": [
        "temperature"
      ],
      "family": "gemma-2",
      "id": "gemma2-9b-it",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Google Gemma 2",
      "output_cost_per_1k": 3e-05,
      "provider": "helicone",
      "release_date": "2024-06-25"
    },
    "helicone/glm-4.6": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.00045,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Zai GLM-4.6",
      "output_cost_per_1k": 0.0015,
      "provider": "helicone",
      "release_date": "2024-07-18"
    },
    "helicone/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "helicone",
      "release_date": "2025-04-14"
    },
    "helicone/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI GPT-4.1 Mini",
      "output_cost_per_1k": 0.0016,
      "provider": "helicone",
      "release_date": "2025-04-14"
    },
    "helicone/gpt-4.1-mini-2025-04-14": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "gpt-4.1-mini-2025-04-14",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI GPT-4.1 Mini",
      "output_cost_per_1k": 0.0016,
      "provider": "helicone",
      "release_date": "2025-04-14"
    },
    "helicone/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "gpt-4.1-nano",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI GPT-4.1 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "helicone",
      "release_date": "2025-04-14"
    },
    "helicone/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "OpenAI GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2024-05-13"
    },
    "helicone/gpt-4o-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "OpenAI GPT-4o-mini",
      "output_cost_per_1k": 0.0006,
      "provider": "helicone",
      "release_date": "2024-07-18"
    },
    "helicone/gpt-5": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "OpenAI GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5-chat-latest": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5-chat-latest",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "OpenAI GPT-5 Chat Latest",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2024-09-30"
    },
    "helicone/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "OpenAI: GPT-5 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "OpenAI GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5-nano": {
      "cache_read_cost_per_1k": 5e-06,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "OpenAI GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5-pro": {
      "family": "gpt-5-pro",
      "id": "gpt-5-pro",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI: GPT-5 Pro",
      "output_cost_per_1k": 0.12,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5.1": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "OpenAI GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5.1-chat-latest": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.1-chat-latest",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "image",
      "name": "OpenAI GPT-5.1 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "OpenAI: GPT-5.1 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "OpenAI: GPT-5.1 Codex Mini",
      "output_cost_per_1k": 0.002,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "OpenAI GPT-OSS 120b",
      "output_cost_per_1k": 0.00016,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-20b",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "OpenAI GPT-OSS 20b",
      "output_cost_per_1k": 0.0002,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "xAI Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "xAI Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "xAI Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2024-07-09"
    },
    "helicone/grok-4-1-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "image_output",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-1-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "image",
      "name": "xAI Grok 4.1 Fast Non-Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "helicone",
      "release_date": "2025-11-17"
    },
    "helicone/grok-4-1-fast-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-1-fast-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "mode": "chat",
      "name": "xAI Grok 4.1 Fast Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "helicone",
      "release_date": "2025-11-17"
    },
    "helicone/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "mode": "chat",
      "name": "xAI Grok 4 Fast Non-Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "helicone",
      "release_date": "2025-09-19"
    },
    "helicone/grok-4-fast-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "mode": "chat",
      "name": "xAI: Grok 4 Fast Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "helicone",
      "release_date": "2025-09-01"
    },
    "helicone/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "xAI Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "helicone",
      "release_date": "2024-08-25"
    },
    "helicone/hermes-2-pro-llama-3-8b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3",
      "id": "hermes-2-pro-llama-3-8b",
      "input_cost_per_1k": 0.00014,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Hermes 2 Pro Llama 3 8B",
      "output_cost_per_1k": 0.00014,
      "provider": "helicone",
      "release_date": "2024-05-27"
    },
    "helicone/kimi-k2-0711": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0711",
      "input_cost_per_1k": 0.00057,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 (07/11)",
      "output_cost_per_1k": 0.0023,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/kimi-k2-0905": {
      "cache_read_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0905",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 (09/05)",
      "output_cost_per_1k": 0.002,
      "provider": "helicone",
      "release_date": "2025-09-05"
    },
    "helicone/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.00048,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 256000,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "output_cost_per_1k": 0.002,
      "provider": "helicone",
      "release_date": "2025-11-06"
    },
    "helicone/llama-3.1-8b-instant": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instant",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 32678,
      "mode": "chat",
      "name": "Meta Llama 3.1 8B Instant",
      "output_cost_per_1k": 8e-05,
      "provider": "helicone",
      "release_date": "2024-07-01"
    },
    "helicone/llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct",
      "input_cost_per_1k": 2e-05,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Meta Llama 3.1 8B Instruct",
      "output_cost_per_1k": 5e-05,
      "provider": "helicone",
      "release_date": "2024-07-23"
    },
    "helicone/llama-3.1-8b-instruct-turbo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct-turbo",
      "input_cost_per_1k": 2e-05,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Meta Llama 3.1 8B Instruct Turbo",
      "output_cost_per_1k": 3e-05,
      "provider": "helicone",
      "release_date": "2024-07-23"
    },
    "helicone/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 16400,
      "mode": "chat",
      "name": "Meta Llama 3.3 70B Instruct",
      "output_cost_per_1k": 0.00039,
      "provider": "helicone",
      "release_date": "2024-12-06"
    },
    "helicone/llama-3.3-70b-versatile": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-versatile",
      "input_cost_per_1k": 0.00059,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 32678,
      "mode": "chat",
      "name": "Meta Llama 3.3 70B Versatile",
      "output_cost_per_1k": 0.00079,
      "provider": "helicone",
      "release_date": "2024-12-06"
    },
    "helicone/llama-4-maverick": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "llama-4-maverick",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Meta Llama 4 Maverick 17B 128E",
      "output_cost_per_1k": 0.0006,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/llama-4-scout": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "llama-4-scout",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Meta Llama 4 Scout 17B 16E",
      "output_cost_per_1k": 0.0003,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/llama-guard-4": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "llama",
      "id": "llama-guard-4",
      "input_cost_per_1k": 0.00021,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "Meta Llama Guard 4 12B",
      "output_cost_per_1k": 0.00021,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/llama-prompt-guard-2-22m": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama",
      "id": "llama-prompt-guard-2-22m",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 512,
      "max_output_tokens": 2,
      "mode": "chat",
      "name": "Meta Llama Prompt Guard 2 22M",
      "output_cost_per_1k": 1e-05,
      "provider": "helicone",
      "release_date": "2024-10-01"
    },
    "helicone/llama-prompt-guard-2-86m": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama",
      "id": "llama-prompt-guard-2-86m",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 512,
      "max_output_tokens": 2,
      "mode": "chat",
      "name": "Meta Llama Prompt Guard 2 86M",
      "output_cost_per_1k": 1e-05,
      "provider": "helicone",
      "release_date": "2024-10-01"
    },
    "helicone/mistral-large-2411": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-large",
      "id": "mistral-large-2411",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral-Large",
      "output_cost_per_1k": 0.006,
      "provider": "helicone",
      "release_date": "2024-07-24"
    },
    "helicone/mistral-nemo": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "mistral-nemo",
      "id": "mistral-nemo",
      "input_cost_per_1k": 0.02,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 16400,
      "mode": "chat",
      "name": "Mistral Nemo",
      "output_cost_per_1k": 0.04,
      "provider": "helicone",
      "release_date": "2024-07-18"
    },
    "helicone/mistral-small": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small",
      "input_cost_per_1k": 0.075,
      "knowledge_cutoff": "2024-02",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral Small",
      "output_cost_per_1k": 0.2,
      "provider": "helicone",
      "release_date": "2024-02-26"
    },
    "helicone/o1": {
      "cache_read_cost_per_1k": 0.0075,
      "family": "o1",
      "id": "o1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI: o1",
      "output_cost_per_1k": 0.06,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/o1-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "family": "o1-mini",
      "id": "o1-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "OpenAI: o1-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/o3": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "o3",
      "id": "o3",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o3",
      "output_cost_per_1k": 0.008,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/o3-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling"
      ],
      "family": "o3-mini",
      "id": "o3-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o3 Mini",
      "output_cost_per_1k": 0.0044,
      "provider": "helicone",
      "release_date": "2023-10-01"
    },
    "helicone/o3-pro": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "o3-pro",
      "id": "o3-pro",
      "input_cost_per_1k": 0.02,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o3 Pro",
      "output_cost_per_1k": 0.08,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/o4-mini": {
      "cache_read_cost_per_1k": 0.000275,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "o4-mini",
      "id": "o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "OpenAI o4 Mini",
      "output_cost_per_1k": 0.0044,
      "provider": "helicone",
      "release_date": "2024-06-01"
    },
    "helicone/qwen2.5-coder-7b-fast": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen2.5-coder-7b-fast",
      "input_cost_per_1k": 3e-05,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 Coder 7B fast",
      "output_cost_per_1k": 9e-05,
      "provider": "helicone",
      "release_date": "2024-09-15"
    },
    "helicone/qwen3-235b-a22b-thinking": {
      "capabilities": [
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-thinking",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 81920,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking",
      "output_cost_per_1k": 0.0029,
      "provider": "helicone",
      "release_date": "2025-07-25"
    },
    "helicone/qwen3-30b-a3b": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen3",
      "id": "qwen3-30b-a3b",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 41000,
      "max_output_tokens": 41000,
      "mode": "chat",
      "name": "Qwen3 30B A3B",
      "output_cost_per_1k": 0.00029,
      "provider": "helicone",
      "release_date": "2025-06-01"
    },
    "helicone/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-32b",
      "input_cost_per_1k": 0.00029,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 32B",
      "output_cost_per_1k": 0.00059,
      "provider": "helicone",
      "release_date": "2025-04-28"
    },
    "helicone/qwen3-coder": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct Turbo",
      "output_cost_per_1k": 0.00095,
      "provider": "helicone",
      "release_date": "2025-07-23"
    },
    "helicone/qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "output_cost_per_1k": 0.0003,
      "provider": "helicone",
      "release_date": "2025-07-31"
    },
    "helicone/qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3",
      "id": "qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.00014,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 262000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Instruct",
      "output_cost_per_1k": 0.0014,
      "provider": "helicone",
      "release_date": "2025-01-01"
    },
    "helicone/qwen3-vl-235b-a22b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-235b-a22b-instruct",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 256000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 VL 235B A22B Instruct",
      "output_cost_per_1k": 0.0015,
      "provider": "helicone",
      "release_date": "2025-09-23"
    },
    "helicone/sonar": {
      "capabilities": [
        "temperature"
      ],
      "family": "sonar",
      "id": "sonar",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Perplexity Sonar",
      "output_cost_per_1k": 0.001,
      "provider": "helicone",
      "release_date": "2025-01-27"
    },
    "helicone/sonar-deep-research": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "sonar-deep-research",
      "id": "sonar-deep-research",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Perplexity Sonar Deep Research",
      "output_cost_per_1k": 0.008,
      "provider": "helicone",
      "release_date": "2025-01-27"
    },
    "helicone/sonar-pro": {
      "capabilities": [
        "temperature"
      ],
      "family": "sonar-pro",
      "id": "sonar-pro",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Perplexity Sonar Pro",
      "output_cost_per_1k": 0.015,
      "provider": "helicone",
      "release_date": "2025-01-27"
    },
    "helicone/sonar-reasoning": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "sonar-reasoning",
      "id": "sonar-reasoning",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Perplexity Sonar Reasoning",
      "output_cost_per_1k": 0.005,
      "provider": "helicone",
      "release_date": "2025-01-27"
    },
    "helicone/sonar-reasoning-pro": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "sonar-reasoning",
      "id": "sonar-reasoning-pro",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Perplexity Sonar Reasoning Pro",
      "output_cost_per_1k": 0.008,
      "provider": "helicone",
      "release_date": "2025-01-27"
    },
    "huggingface/MiniMaxAI/MiniMax-M2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMaxAI/MiniMax-M2",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 204800,
      "max_output_tokens": 204800,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "huggingface",
      "release_date": "2025-10-27"
    },
    "huggingface/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "huggingface",
      "release_date": "2025-07-25"
    },
    "huggingface/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3-Coder-480B-A35B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "huggingface",
      "release_date": "2025-07-23"
    },
    "huggingface/Qwen/Qwen3-Embedding-4B": {
      "family": "qwen3",
      "id": "Qwen/Qwen3-Embedding-4B",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 32000,
      "max_output_tokens": 2048,
      "mode": "embedding",
      "name": "Qwen 3 Embedding 4B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "huggingface",
      "release_date": "2025-01-01"
    },
    "huggingface/Qwen/Qwen3-Embedding-8B": {
      "family": "qwen3",
      "id": "Qwen/Qwen3-Embedding-8B",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "embedding",
      "name": "Qwen 3 Embedding 4B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "huggingface",
      "release_date": "2025-01-01"
    },
    "huggingface/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3-Next-80B-A3B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "huggingface",
      "release_date": "2025-09-11"
    },
    "huggingface/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3-Next-80B-A3B-Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "huggingface",
      "release_date": "2025-09-11"
    },
    "huggingface/deepseek-ai/DeepSeek-R1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-R1-0528",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "huggingface",
      "release_date": "2025-05-28"
    },
    "huggingface/deepseek-ai/Deepseek-V3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/Deepseek-V3-0324",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek-V3-0324",
      "open_weights": true,
      "output_cost_per_1k": 0.00125,
      "provider": "huggingface",
      "release_date": "2025-03-24"
    },
    "huggingface/moonshotai/Kimi-K2-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi-K2-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "huggingface",
      "release_date": "2025-07-14"
    },
    "huggingface/moonshotai/Kimi-K2-Instruct-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi-K2-Instruct-0905",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "huggingface",
      "release_date": "2025-09-04"
    },
    "huggingface/zai-org/GLM-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai-org/GLM-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "huggingface",
      "release_date": "2025-07-28"
    },
    "huggingface/zai-org/GLM-4.5-Air": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai-org/GLM-4.5-Air",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM-4.5-Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "huggingface",
      "release_date": "2025-07-28"
    },
    "huggingface/zai-org/GLM-4.6": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org/GLM-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "huggingface",
      "release_date": "2025-09-30"
    },
    "iflowcn/deepseek-r1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-r1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "DeepSeek-R1",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-01-20"
    },
    "iflowcn/deepseek-v3": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "DeepSeek-V3",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2024-12-26"
    },
    "iflowcn/deepseek-v3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "DeepSeek-V3.1-Terminus",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-01-01"
    },
    "iflowcn/deepseek-v3.2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "DeepSeek-V3.2-Exp",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-01-01"
    },
    "iflowcn/deepseek-v3.2-chat": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2-chat",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "DeepSeek-V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-12-01"
    },
    "iflowcn/glm-4.6": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GLM-4.6",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2024-12-01"
    },
    "iflowcn/kimi-k2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Kimi-K2",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2024-12-01"
    },
    "iflowcn/kimi-k2-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0905",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Kimi-K2-0905",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-09-05"
    },
    "iflowcn/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Kimi-K2-Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-11-06"
    },
    "iflowcn/minimax-m2": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax-m2",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 204800,
      "max_output_tokens": 131100,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-11-13"
    },
    "iflowcn/qwen3-235b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3-235B-A22B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2024-12-01"
    },
    "iflowcn/qwen3-235b-a22b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Qwen3-235B-A22B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-07-01"
    },
    "iflowcn/qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Qwen3-235B-A22B-Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-07-01"
    },
    "iflowcn/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-32b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3-32B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2024-12-01"
    },
    "iflowcn/qwen3-coder": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Qwen3-Coder-480B-A35B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-07-01"
    },
    "iflowcn/qwen3-coder-plus": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-plus",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Qwen3-Coder-Plus",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-07-01"
    },
    "iflowcn/qwen3-max": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-max",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3-Max",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-01-01"
    },
    "iflowcn/qwen3-max-preview": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-max-preview",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3-Max-Preview",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-01-01"
    },
    "iflowcn/qwen3-vl-plus": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-plus",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3-VL-Plus",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2025-01-01"
    },
    "iflowcn/tstars2.0": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "tstars2.0",
      "id": "tstars2.0",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "TStars-2.0",
      "output_cost_per_1k": 0.0,
      "provider": "iflowcn",
      "release_date": "2024-01-01"
    },
    "inception/mercury": {
      "cache_read_cost_per_1k": 0.00025,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mercury",
      "id": "mercury",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mercury",
      "output_cost_per_1k": 0.001,
      "provider": "inception",
      "release_date": "2025-06-26"
    },
    "inception/mercury-coder": {
      "cache_read_cost_per_1k": 0.00025,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mercury-coder",
      "id": "mercury-coder",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mercury Coder",
      "output_cost_per_1k": 0.001,
      "provider": "inception",
      "release_date": "2025-02-26"
    },
    "inference/google/gemma-3": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google/gemma-3",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 125000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Google Gemma 3",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/meta/llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta/llama-3.1-8b-instruct",
      "input_cost_per_1k": 2.5e-05,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 2.5e-05,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/meta/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "meta/llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 5.5e-05,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 11B Vision Instruct",
      "open_weights": true,
      "output_cost_per_1k": 5.5e-05,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/meta/llama-3.2-1b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "meta/llama-3.2-1b-instruct",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 1B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 1e-05,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/meta/llama-3.2-3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "meta/llama-3.2-3b-instruct",
      "input_cost_per_1k": 2e-05,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 2e-05,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/mistral/mistral-nemo-12b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistral/mistral-nemo-12b-instruct",
      "input_cost_per_1k": 3.8e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mistral Nemo 12B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/osmosis/osmosis-structure-0.6b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "osmosis-structure-0.6b",
      "id": "osmosis/osmosis-structure-0.6b",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 4000,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Osmosis Structure 0.6B",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/qwen/qwen-2.5-7b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen",
      "id": "qwen/qwen-2.5-7b-vision-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 125000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen 2.5 7B Vision Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "inference/qwen/qwen3-embedding-4b": {
      "family": "qwen3",
      "id": "qwen/qwen3-embedding-4b",
      "input_cost_per_1k": 1e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 32000,
      "max_output_tokens": 2048,
      "mode": "embedding",
      "name": "Qwen 3 Embedding 4B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "inference",
      "release_date": "2025-01-01"
    },
    "io_net/Intel/Qwen3-Coder-480B-A35B-Instruct-int4-mixed-ar": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.00044,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Intel/Qwen3-Coder-480B-A35B-Instruct-int4-mixed-ar",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 106000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen 3 Coder 480B",
      "open_weights": true,
      "output_cost_per_1k": 0.00095,
      "provider": "io_net",
      "release_date": "2025-01-15"
    },
    "io_net/Qwen/Qwen2.5-VL-32B-Instruct": {
      "cache_read_cost_per_1k": 2.5e-05,
      "cache_write_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen 2.5 VL 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00022,
      "provider": "io_net",
      "release_date": "2024-11-01"
    },
    "io_net/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "cache_read_cost_per_1k": 5.5e-05,
      "cache_write_cost_per_1k": 0.00022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.00011,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen 3 235B Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "io_net",
      "release_date": "2025-07-01"
    },
    "io_net/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen 3 Next 80B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "io_net",
      "release_date": "2025-01-10"
    },
    "io_net/deepseek-ai/DeepSeek-R1-0528": {
      "cache_read_cost_per_1k": 0.001,
      "cache_write_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "DeepSeek R1",
      "open_weights": true,
      "output_cost_per_1k": 0.00875,
      "provider": "io_net",
      "release_date": "2025-01-20"
    },
    "io_net/meta-llama/Llama-3.2-90B-Vision-Instruct": {
      "cache_read_cost_per_1k": 0.000175,
      "cache_write_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "meta-llama/Llama-3.2-90B-Vision-Instruct",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 90B Vision Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "io_net",
      "release_date": "2024-09-25"
    },
    "io_net/meta-llama/Llama-3.3-70B-Instruct": {
      "cache_read_cost_per_1k": 6.5e-05,
      "cache_write_cost_per_1k": 0.00026,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.3 70B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00038,
      "provider": "io_net",
      "release_date": "2024-12-06"
    },
    "io_net/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 430000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 4 Maverick 17B 128E Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "io_net",
      "release_date": "2025-01-15"
    },
    "io_net/mistralai/Devstral-Small-2505": {
      "cache_read_cost_per_1k": 2.5e-05,
      "cache_write_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-small",
      "id": "mistralai/Devstral-Small-2505",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Devstral Small 2505",
      "output_cost_per_1k": 0.00022,
      "provider": "io_net",
      "release_date": "2025-05-01"
    },
    "io_net/mistralai/Magistral-Small-2506": {
      "cache_read_cost_per_1k": 0.00025,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "magistral-small",
      "id": "mistralai/Magistral-Small-2506",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Magistral Small 2506",
      "output_cost_per_1k": 0.0015,
      "provider": "io_net",
      "release_date": "2025-06-01"
    },
    "io_net/mistralai/Mistral-Large-Instruct-2411": {
      "cache_read_cost_per_1k": 0.001,
      "cache_write_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-large",
      "id": "mistralai/Mistral-Large-Instruct-2411",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mistral Large Instruct 2411",
      "output_cost_per_1k": 0.006,
      "provider": "io_net",
      "release_date": "2024-11-01"
    },
    "io_net/mistralai/Mistral-Nemo-Instruct-2407": {
      "cache_read_cost_per_1k": 1e-05,
      "cache_write_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistralai/Mistral-Nemo-Instruct-2407",
      "input_cost_per_1k": 2e-05,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mistral Nemo Instruct 2407",
      "open_weights": true,
      "output_cost_per_1k": 4e-05,
      "provider": "io_net",
      "release_date": "2024-07-01"
    },
    "io_net/moonshotai/Kimi-K2-Instruct-0905": {
      "cache_read_cost_per_1k": 0.000195,
      "cache_write_cost_per_1k": 0.00078,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "input_cost_per_1k": 0.00039,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "output_cost_per_1k": 0.0019,
      "provider": "io_net",
      "release_date": "2024-09-05"
    },
    "io_net/moonshotai/Kimi-K2-Thinking": {
      "cache_read_cost_per_1k": 0.000275,
      "cache_write_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Thinking",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "output_cost_per_1k": 0.00225,
      "provider": "io_net",
      "release_date": "2024-11-01"
    },
    "io_net/openai/gpt-oss-120b": {
      "cache_read_cost_per_1k": 2e-05,
      "cache_write_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "io_net",
      "release_date": "2024-12-01"
    },
    "io_net/openai/gpt-oss-20b": {
      "cache_read_cost_per_1k": 1.5e-05,
      "cache_write_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 3e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.00014,
      "provider": "io_net",
      "release_date": "2024-12-01"
    },
    "io_net/zai-org/GLM-4.6": {
      "cache_read_cost_per_1k": 0.0002,
      "cache_write_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org/GLM-4.6",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GLM 4.6",
      "output_cost_per_1k": 0.00175,
      "provider": "io_net",
      "release_date": "2024-11-15"
    },
    "kimi_for_coding/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "kimi_for_coding",
      "release_date": "2025-11"
    },
    "llama/cerebras-llama-4-maverick-17b-128e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "cerebras-llama-4-maverick-17b-128e-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cerebras-Llama-4-Maverick-17B-128E-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2025-04-05"
    },
    "llama/cerebras-llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "cerebras-llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Cerebras-Llama-4-Scout-17B-16E-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2025-04-05"
    },
    "llama/groq-llama-4-maverick-17b-128e-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "groq-llama-4-maverick-17b-128e-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Groq-Llama-4-Maverick-17B-128E-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2025-04-05"
    },
    "llama/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2024-12-06"
    },
    "llama/llama-3.3-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-8b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-3.3-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2024-12-06"
    },
    "llama/llama-4-maverick-17b-128e-instruct-fp8": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2025-04-05"
    },
    "llama/llama-4-scout-17b-16e-instruct-fp8": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "llama-4-scout-17b-16e-instruct-fp8",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-4-Scout-17B-16E-Instruct-FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "llama",
      "release_date": "2025-04-05"
    },
    "lmstudio/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "lmstudio",
      "release_date": "2025-08-05"
    },
    "lmstudio/qwen/qwen3-30b-a3b-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-30b-a3b-2507",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 30B A3B 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "lmstudio",
      "release_date": "2025-07-30"
    },
    "lmstudio/qwen/qwen3-coder-30b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder-30b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder 30B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "lmstudio",
      "release_date": "2025-07-23"
    },
    "lucidquery/lucidnova-rf1-100b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "nova",
      "id": "lucidnova-rf1-100b",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-09-16",
      "max_input_tokens": 120000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "LucidNova RF1 100B",
      "output_cost_per_1k": 0.005,
      "provider": "lucidquery",
      "release_date": "2024-12-28"
    },
    "lucidquery/lucidquery-nexus-coder": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "lucidquery-nexus-coder",
      "id": "lucidquery-nexus-coder",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-08-01",
      "max_input_tokens": 250000,
      "max_output_tokens": 60000,
      "mode": "chat",
      "name": "LucidQuery Nexus Coder",
      "output_cost_per_1k": 0.005,
      "provider": "lucidquery",
      "release_date": "2025-09-01"
    },
    "minimax/MiniMax-M2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMax-M2",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "minimax",
      "release_date": "2025-10-27"
    },
    "minimax/MiniMax-M2.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMax-M2.1",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "MiniMax-M2.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "minimax",
      "release_date": "2025-12-23"
    },
    "minimax_cn/MiniMax-M2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMax-M2",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "minimax_cn",
      "release_date": "2025-10-27"
    },
    "minimax_cn/MiniMax-M2.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "MiniMax-M2.1",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "MiniMax-M2.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "minimax_cn",
      "release_date": "2025-12-23"
    },
    "mistral/codestral-latest": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "codestral",
      "id": "codestral-latest",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Codestral",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "mistral",
      "release_date": "2024-05-29"
    },
    "mistral/devstral-2512": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-medium",
      "id": "devstral-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Devstral 2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "mistral",
      "release_date": "2025-12-09"
    },
    "mistral/devstral-medium-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-medium",
      "id": "devstral-medium-2507",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Devstral Medium",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "mistral",
      "release_date": "2025-07-10"
    },
    "mistral/devstral-medium-latest": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-medium",
      "id": "devstral-medium-latest",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Devstral 2",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "mistral",
      "release_date": "2025-12-02"
    },
    "mistral/devstral-small-2505": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-small",
      "id": "devstral-small-2505",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Devstral Small 2505",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "mistral",
      "release_date": "2025-05-07"
    },
    "mistral/devstral-small-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-small",
      "id": "devstral-small-2507",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Devstral Small",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "mistral",
      "release_date": "2025-07-10"
    },
    "mistral/labs-devstral-small-2512": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "devstral-small",
      "id": "labs-devstral-small-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Devstral Small 2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "mistral",
      "release_date": "2025-12-09"
    },
    "mistral/magistral-medium-latest": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "magistral-medium",
      "id": "magistral-medium-latest",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Magistral Medium",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "mistral",
      "release_date": "2025-03-17"
    },
    "mistral/magistral-small": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "magistral-small",
      "id": "magistral-small",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Magistral Small",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "mistral",
      "release_date": "2025-03-17"
    },
    "mistral/ministral-3b-latest": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral-3b",
      "id": "ministral-3b-latest",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Ministral 3B",
      "open_weights": true,
      "output_cost_per_1k": 4e-05,
      "provider": "mistral",
      "release_date": "2024-10-01"
    },
    "mistral/ministral-8b-latest": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral-8b",
      "id": "ministral-8b-latest",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Ministral 8B",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "mistral",
      "release_date": "2024-10-01"
    },
    "mistral/mistral-embed": {
      "family": "mistral-embed",
      "id": "mistral-embed",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 8000,
      "max_output_tokens": 3072,
      "mode": "embedding",
      "name": "Mistral Embed",
      "output_cost_per_1k": 0.0,
      "provider": "mistral",
      "release_date": "2023-12-11"
    },
    "mistral/mistral-large-2411": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-large",
      "id": "mistral-large-2411",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral Large 2.1",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "mistral",
      "release_date": "2024-11-01"
    },
    "mistral/mistral-large-2512": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-large",
      "id": "mistral-large-2512",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Mistral Large 3",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "mistral",
      "release_date": "2024-11-01"
    },
    "mistral/mistral-large-latest": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-large",
      "id": "mistral-large-latest",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Mistral Large",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "mistral",
      "release_date": "2024-11-01"
    },
    "mistral/mistral-medium-2505": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistral-medium-2505",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Mistral Medium 3",
      "output_cost_per_1k": 0.002,
      "provider": "mistral",
      "release_date": "2025-05-07"
    },
    "mistral/mistral-medium-2508": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistral-medium-2508",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Mistral Medium 3.1",
      "output_cost_per_1k": 0.002,
      "provider": "mistral",
      "release_date": "2025-08-12"
    },
    "mistral/mistral-medium-latest": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistral-medium-latest",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral Medium",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "mistral",
      "release_date": "2025-05-07"
    },
    "mistral/mistral-nemo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistral-nemo",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral Nemo",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "mistral",
      "release_date": "2024-07-01"
    },
    "mistral/mistral-small-2506": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small-2506",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral Small 3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "mistral",
      "release_date": "2025-06-20"
    },
    "mistral/mistral-small-latest": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small-latest",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral Small",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "mistral",
      "release_date": "2024-09-01"
    },
    "mistral/open-mistral-7b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "open-mistral-7b",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Mistral 7B",
      "open_weights": true,
      "output_cost_per_1k": 0.00025,
      "provider": "mistral",
      "release_date": "2023-09-27"
    },
    "mistral/open-mixtral-8x22b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mixtral-8x22b",
      "id": "open-mixtral-8x22b",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Mixtral 8x22B",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "mistral",
      "release_date": "2024-04-17"
    },
    "mistral/open-mixtral-8x7b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mixtral-8x7b",
      "id": "open-mixtral-8x7b",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Mixtral 8x7B",
      "open_weights": true,
      "output_cost_per_1k": 0.0007,
      "provider": "mistral",
      "release_date": "2023-12-11"
    },
    "mistral/pixtral-12b": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "pixtral",
      "id": "pixtral-12b",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Pixtral 12B",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "mistral",
      "release_date": "2024-09-01"
    },
    "mistral/pixtral-large-latest": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "pixtral-large",
      "id": "pixtral-large-latest",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Pixtral Large",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "mistral",
      "release_date": "2024-11-01"
    },
    "modelscope/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-04-28"
    },
    "modelscope/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-07-25"
    },
    "modelscope/Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3 30B A3B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-07-30"
    },
    "modelscope/Qwen/Qwen3-30B-A3B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 30B A3B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-07-30"
    },
    "modelscope/Qwen/Qwen3-Coder-30B-A3B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-07-31"
    },
    "modelscope/ZhipuAI/GLM-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "ZhipuAI/GLM-4.5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-07-28"
    },
    "modelscope/ZhipuAI/GLM-4.6": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "ZhipuAI/GLM-4.6",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 202752,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "modelscope",
      "release_date": "2025-09-30"
    },
    "moonshotai/kimi-k2-0711-preview": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0711-preview",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 0711",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "moonshotai",
      "release_date": "2025-07-14"
    },
    "moonshotai/kimi-k2-0905-preview": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0905-preview",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "moonshotai",
      "release_date": "2025-09-05"
    },
    "moonshotai/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "moonshotai",
      "release_date": "2025-11-06"
    },
    "moonshotai/kimi-k2-thinking-turbo": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking-turbo",
      "input_cost_per_1k": 0.00115,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking Turbo",
      "open_weights": true,
      "output_cost_per_1k": 0.008,
      "provider": "moonshotai",
      "release_date": "2025-11-06"
    },
    "moonshotai/kimi-k2-turbo-preview": {
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-turbo-preview",
      "input_cost_per_1k": 0.0024,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Turbo",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "moonshotai",
      "release_date": "2025-09-05"
    },
    "moonshotai_cn/kimi-k2-0711-preview": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0711-preview",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 0711",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "moonshotai_cn",
      "release_date": "2025-07-14"
    },
    "moonshotai_cn/kimi-k2-0905-preview": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-0905-preview",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "moonshotai_cn",
      "release_date": "2025-09-05"
    },
    "moonshotai_cn/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "moonshotai_cn",
      "release_date": "2025-11-06"
    },
    "moonshotai_cn/kimi-k2-thinking-turbo": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking-turbo",
      "input_cost_per_1k": 0.00115,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking Turbo",
      "open_weights": true,
      "output_cost_per_1k": 0.008,
      "provider": "moonshotai_cn",
      "release_date": "2025-11-06"
    },
    "moonshotai_cn/kimi-k2-turbo-preview": {
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-turbo-preview",
      "input_cost_per_1k": 0.0024,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Turbo",
      "open_weights": true,
      "output_cost_per_1k": 0.01,
      "provider": "moonshotai_cn",
      "release_date": "2025-09-05"
    },
    "morph/auto": {
      "family": "auto",
      "id": "auto",
      "input_cost_per_1k": 0.00085,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Auto",
      "output_cost_per_1k": 0.00155,
      "provider": "morph",
      "release_date": "2024-06-01"
    },
    "morph/morph-v3-fast": {
      "family": "morph-v3-fast",
      "id": "morph-v3-fast",
      "input_cost_per_1k": 0.0008,
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Morph v3 Fast",
      "output_cost_per_1k": 0.0012,
      "provider": "morph",
      "release_date": "2024-08-15"
    },
    "morph/morph-v3-large": {
      "family": "morph-v3-large",
      "id": "morph-v3-large",
      "input_cost_per_1k": 0.0009,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Morph v3 Large",
      "output_cost_per_1k": 0.0019,
      "provider": "morph",
      "release_date": "2024-08-15"
    },
    "nano_gpt/deepseek/deepseek-r1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek",
      "id": "deepseek/deepseek-r1",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Deepseek R1",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-01-20"
    },
    "nano_gpt/deepseek/deepseek-v3.2:thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek",
      "id": "deepseek/deepseek-v3.2:thinking",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Deepseek V3.2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-12-01"
    },
    "nano_gpt/meta-llama/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama",
      "id": "meta-llama/llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3.3 70b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2024-12-06"
    },
    "nano_gpt/meta-llama/llama-4-maverick": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama",
      "id": "meta-llama/llama-4-maverick",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Maverick",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-04-05"
    },
    "nano_gpt/minimax/minimax-m2.1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax/minimax-m2.1",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Minimax M2.1",
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-12-23"
    },
    "nano_gpt/mistralai/devstral-2-123b-instruct-2512": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "mistral",
      "id": "mistralai/devstral-2-123b-instruct-2512",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Devstral 2 123b Instruct 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-12-11"
    },
    "nano_gpt/mistralai/ministral-14b-instruct-2512": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "mistral",
      "id": "mistralai/ministral-14b-instruct-2512",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Ministral 14b Instruct 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-12-01"
    },
    "nano_gpt/mistralai/mistral-large-3-675b-instruct-2512": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "mistral",
      "id": "mistralai/mistral-large-3-675b-instruct-2512",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Mistral Large 3 675b Instruct 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-12-02"
    },
    "nano_gpt/moonshotai/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi",
      "id": "moonshotai/kimi-k2-instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2024-07-18"
    },
    "nano_gpt/moonshotai/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi",
      "id": "moonshotai/kimi-k2-thinking",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2024-11-01"
    },
    "nano_gpt/nousresearch/hermes-4-405b:thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "nousresearch/hermes-4-405b:thinking",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Hermes 4 405b Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2024-08-13"
    },
    "nano_gpt/nvidia/llama-3_3-nemotron-super-49b-v1_5": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama",
      "id": "nvidia/llama-3_3-nemotron-super-49b-v1_5",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3 3 Nemotron Super 49B V1 5",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-08-08"
    },
    "nano_gpt/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "gpt",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT Oss 120b",
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-06-23"
    },
    "nano_gpt/qwen/qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-07-01"
    },
    "nano_gpt/qwen/qwen3-coder": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen",
      "id": "qwen/qwen3-coder",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 106000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 Coder",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-01-15"
    },
    "nano_gpt/z-ai/glm-4.6": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm",
      "id": "z-ai/glm-4.6",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2024-11-15"
    },
    "nano_gpt/z-ai/glm-4.6:thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm",
      "id": "z-ai/glm-4.6:thinking",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.6 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-04-07"
    },
    "nano_gpt/zai-org/glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm",
      "id": "zai-org/glm-4.5-air",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-07-28"
    },
    "nano_gpt/zai-org/glm-4.5-air:thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm",
      "id": "zai-org/glm-4.5-air:thinking",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.5 Air Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-04-07"
    },
    "nano_gpt/zai-org/glm-4.7": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm",
      "id": "zai-org/glm-4.7",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-12-22"
    },
    "nano_gpt/zai-org/glm-4.7:thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm",
      "id": "zai-org/glm-4.7:thinking",
      "input_cost_per_1k": 0.001,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.7 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "nano_gpt",
      "release_date": "2025-04-07"
    },
    "nebius/NousResearch/hermes-4-405b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "NousResearch/hermes-4-405b",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Hermes-4 405B",
      "output_cost_per_1k": 0.003,
      "provider": "nebius",
      "release_date": "2024-08-01"
    },
    "nebius/NousResearch/hermes-4-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "NousResearch/hermes-4-70b",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Hermes 4 70B",
      "output_cost_per_1k": 0.0004,
      "provider": "nebius",
      "release_date": "2024-08-01"
    },
    "nebius/deepseek-ai/deepseek-v3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/deepseek-v3",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3",
      "output_cost_per_1k": 0.0015,
      "provider": "nebius",
      "release_date": "2024-05-07"
    },
    "nebius/meta-llama/llama-3.3-70b-instruct-base": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama/llama-3.3-70b-instruct-base",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct (Base)",
      "output_cost_per_1k": 0.0004,
      "provider": "nebius",
      "release_date": "2024-08-22"
    },
    "nebius/meta-llama/llama-3.3-70b-instruct-fast": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama/llama-3.3-70b-instruct-fast",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct (Fast)",
      "output_cost_per_1k": 0.00075,
      "provider": "nebius",
      "release_date": "2024-08-22"
    },
    "nebius/meta-llama/llama-3_1-405b-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama/llama-3_1-405b-instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-03",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3.1 405B Instruct",
      "output_cost_per_1k": 0.003,
      "provider": "nebius",
      "release_date": "2024-07-23"
    },
    "nebius/moonshotai/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-instruct",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "output_cost_per_1k": 0.0024,
      "provider": "nebius",
      "release_date": "2025-01-01"
    },
    "nebius/nvidia/llama-3_1-nemotron-ultra-253b-v1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3",
      "id": "nvidia/llama-3_1-nemotron-ultra-253b-v1",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3.1 Nemotron Ultra 253B v1",
      "output_cost_per_1k": 0.0018,
      "provider": "nebius",
      "release_date": "2024-07-01"
    },
    "nebius/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "output_cost_per_1k": 0.0006,
      "provider": "nebius",
      "release_date": "2024-01-01"
    },
    "nebius/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "output_cost_per_1k": 0.0002,
      "provider": "nebius",
      "release_date": "2024-01-01"
    },
    "nebius/qwen/qwen3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "output_cost_per_1k": 0.0006,
      "provider": "nebius",
      "release_date": "2025-07-25"
    },
    "nebius/qwen/qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "output_cost_per_1k": 0.0008,
      "provider": "nebius",
      "release_date": "2025-07-25"
    },
    "nebius/qwen/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "output_cost_per_1k": 0.0018,
      "provider": "nebius",
      "release_date": "2025-07-23"
    },
    "nebius/zai-org/glm-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai-org/glm-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.5",
      "output_cost_per_1k": 0.0022,
      "provider": "nebius",
      "release_date": "2024-06-01"
    },
    "nebius/zai-org/glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai-org/glm-4.5-air",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "output_cost_per_1k": 0.0012,
      "provider": "nebius",
      "release_date": "2024-06-01"
    },
    "nvidia/black-forest-labs/flux.1-dev": {
      "capabilities": [
        "image_output",
        "temperature"
      ],
      "family": "flux",
      "id": "black-forest-labs/flux.1-dev",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 4096,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "FLUX.1-dev",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-08-01"
    },
    "nvidia/deepseek-ai/deepseek-coder-6.7b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "deepseek-ai/deepseek-coder-6.7b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Deepseek Coder 6.7b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2023-10-29"
    },
    "nvidia/deepseek-ai/deepseek-r1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": null,
      "id": "deepseek-ai/deepseek-r1",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Deepseek R1",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-01-20"
    },
    "nvidia/deepseek-ai/deepseek-r1-0528": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": null,
      "id": "deepseek-ai/deepseek-r1-0528",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Deepseek R1 0528",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-05-28"
    },
    "nvidia/deepseek-ai/deepseek-v3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/deepseek-v3.1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-08-20"
    },
    "nvidia/deepseek-ai/deepseek-v3.1-terminus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/deepseek-v3.1-terminus",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-09-22"
    },
    "nvidia/google/codegemma-1.1-7b": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "google/codegemma-1.1-7b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Codegemma 1.1 7b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-04-30"
    },
    "nvidia/google/codegemma-7b": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "google/codegemma-7b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Codegemma 7b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-03-21"
    },
    "nvidia/google/gemma-2-27b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "google/gemma-2-27b-it",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 2 27b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-06-24"
    },
    "nvidia/google/gemma-2-2b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "google/gemma-2-2b-it",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 2 2b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-07-16"
    },
    "nvidia/google/gemma-3-12b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "google/gemma-3-12b-it",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 3 12b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-01"
    },
    "nvidia/google/gemma-3-1b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "google/gemma-3-1b-it",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 3 1b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-10"
    },
    "nvidia/google/gemma-3-27b-it": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google/gemma-3-27b-it",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma-3-27B-IT",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-12-01"
    },
    "nvidia/google/gemma-3n-e2b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "google/gemma-3n-e2b-it",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 3n E2b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-06-12"
    },
    "nvidia/google/gemma-3n-e4b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "google/gemma-3n-e4b-it",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Gemma 3n E4b It",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-06-03"
    },
    "nvidia/meta/codellama-70b": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "meta/codellama-70b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Codellama 70b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-01-29"
    },
    "nvidia/meta/llama-3.1-405b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "meta/llama-3.1-405b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 405b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-07-16"
    },
    "nvidia/meta/llama-3.1-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "meta/llama-3.1-70b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 70b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-07-16"
    },
    "nvidia/meta/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "meta/llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 11b Vision Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-09-18"
    },
    "nvidia/meta/llama-3.2-1b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "meta/llama-3.2-1b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.2 1b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-09-18"
    },
    "nvidia/meta/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "meta/llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.3 70b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-11-26"
    },
    "nvidia/meta/llama-4-maverick-17b-128e-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "meta/llama-4-maverick-17b-128e-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-02",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 4 Maverick 17b 128e Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-04-01"
    },
    "nvidia/meta/llama-4-scout-17b-16e-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "meta/llama-4-scout-17b-16e-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-02",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 4 Scout 17b 16e Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-04-02"
    },
    "nvidia/meta/llama3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "meta/llama3-70b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama3 70b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-04-17"
    },
    "nvidia/meta/llama3-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "meta/llama3-8b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama3 8b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-04-17"
    },
    "nvidia/microsoft/phi-3-medium-128k-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "microsoft/phi-3-medium-128k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3 Medium 128k Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-05-07"
    },
    "nvidia/microsoft/phi-3-medium-4k-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "microsoft/phi-3-medium-4k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 4000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3 Medium 4k Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-05-07"
    },
    "nvidia/microsoft/phi-3-small-128k-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "microsoft/phi-3-small-128k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3 Small 128k Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-05-07"
    },
    "nvidia/microsoft/phi-3-small-8k-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "microsoft/phi-3-small-8k-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 8000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3 Small 8k Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-05-07"
    },
    "nvidia/microsoft/phi-3-vision-128k-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "microsoft/phi-3-vision-128k-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3 Vision 128k Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-05-19"
    },
    "nvidia/microsoft/phi-3.5-moe-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "microsoft/phi-3.5-moe-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3.5 Moe Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-08-17"
    },
    "nvidia/microsoft/phi-3.5-vision-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": null,
      "id": "microsoft/phi-3.5-vision-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi 3.5 Vision Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-08-16"
    },
    "nvidia/microsoft/phi-4-mini-instruct": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "phi-4",
      "id": "microsoft/phi-4-mini-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Phi-4-Mini",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-12-01"
    },
    "nvidia/minimaxai/minimax-m2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimaxai/minimax-m2",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-10-27"
    },
    "nvidia/mistralai/codestral-22b-instruct-v0.1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "mistralai/codestral-22b-instruct-v0.1",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Codestral 22b Instruct V0.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-05-29"
    },
    "nvidia/mistralai/devstral-2-123b-instruct-2512": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "devstral",
      "id": "mistralai/devstral-2-123b-instruct-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Devstral-2-123B-Instruct-2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-12-08"
    },
    "nvidia/mistralai/mamba-codestral-7b-v0.1": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "mistralai/mamba-codestral-7b-v0.1",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mamba Codestral 7b V0.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-07-16"
    },
    "nvidia/mistralai/ministral-14b-instruct-2512": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "ministral",
      "id": "mistralai/ministral-14b-instruct-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Ministral 3 14B Instruct 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-12-01"
    },
    "nvidia/mistralai/mistral-large-2-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "mistralai/mistral-large-2-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mistral Large 2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-07-24"
    },
    "nvidia/mistralai/mistral-large-3-675b-instruct-2512": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "mistral-large",
      "id": "mistralai/mistral-large-3-675b-instruct-2512",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Mistral Large 3 675B Instruct 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-12-02"
    },
    "nvidia/mistralai/mistral-small-3.1-24b-instruct-2503": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "mistralai/mistral-small-3.1-24b-instruct-2503",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Mistral Small 3.1 24b Instruct 2503",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-11"
    },
    "nvidia/moonshotai/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-01-01"
    },
    "nvidia/moonshotai/kimi-k2-instruct-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-instruct-0905",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-09-05"
    },
    "nvidia/moonshotai/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-thinking",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-11"
    },
    "nvidia/nvidia/cosmos-nemotron-34b": {
      "capabilities": [
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nemotron",
      "id": "nvidia/cosmos-nemotron-34b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Cosmos Nemotron 34B",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-01-01"
    },
    "nvidia/nvidia/llama-3.1-nemotron-51b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "nvidia/llama-3.1-nemotron-51b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 Nemotron 51b Instruct",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-09-22"
    },
    "nvidia/nvidia/llama-3.1-nemotron-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "nvidia/llama-3.1-nemotron-70b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.1 Nemotron 70b Instruct",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-10-12"
    },
    "nvidia/nvidia/llama-3.1-nemotron-ultra-253b-v1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama-3.1-Nemotron-Ultra-253B-v1",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-07-01"
    },
    "nvidia/nvidia/llama-3.3-nemotron-super-49b-v1": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "nvidia/llama-3.3-nemotron-super-49b-v1",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.3 Nemotron Super 49b V1",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-16"
    },
    "nvidia/nvidia/llama-3.3-nemotron-super-49b-v1.5": {
      "capabilities": [
        "temperature"
      ],
      "family": null,
      "id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama 3.3 Nemotron Super 49b V1.5",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-16"
    },
    "nvidia/nvidia/llama-embed-nemotron-8b": {
      "family": "llama",
      "id": "nvidia/llama-embed-nemotron-8b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "mode": "embedding",
      "name": "Llama Embed Nemotron 8B",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-18"
    },
    "nvidia/nvidia/llama3-chatqa-1.5-70b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "nvidia/llama3-chatqa-1.5-70b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama3 Chatqa 1.5 70b",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-04-28"
    },
    "nvidia/nvidia/nemoretriever-ocr-v1": {
      "capabilities": [
        "vision"
      ],
      "family": "nemoretriever-ocr",
      "id": "nvidia/nemoretriever-ocr-v1",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "NeMo Retriever OCR v1",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-01-01"
    },
    "nvidia/nvidia/nemotron-3-nano-30b-a3b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "nemotron",
      "id": "nvidia/nemotron-3-nano-30b-a3b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "nemotron-3-nano-30b-a3b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-12"
    },
    "nvidia/nvidia/nemotron-4-340b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "nvidia/nemotron-4-340b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Nemotron 4 340b Instruct",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-06-13"
    },
    "nvidia/nvidia/nvidia-nemotron-nano-9b-v2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "nemotron",
      "id": "nvidia/nvidia-nemotron-nano-9b-v2",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "nvidia-nemotron-nano-9b-v2",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-08-18"
    },
    "nvidia/nvidia/parakeet-tdt-0.6b-v2": {
      "capabilities": [
        "audio_input"
      ],
      "family": "parakeet-tdt-0.6b",
      "id": "nvidia/parakeet-tdt-0.6b-v2",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Parakeet TDT 0.6B v2",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-01-01"
    },
    "nvidia/openai/gpt-oss-120b": {
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-OSS-120B",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-08-04"
    },
    "nvidia/openai/whisper-large-v3": {
      "capabilities": [
        "audio_input"
      ],
      "family": "whisper-large",
      "id": "openai/whisper-large-v3",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "mode": "audio_transcription",
      "name": "Whisper Large v3",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2023-09-01"
    },
    "nvidia/qwen/qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "qwen/qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen2.5 Coder 32b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-11-06"
    },
    "nvidia/qwen/qwen2.5-coder-7b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": null,
      "id": "qwen/qwen2.5-coder-7b-instruct",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwen2.5 Coder 7b Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-09-17"
    },
    "nvidia/qwen/qwen3-235b-a22b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3-235B-A22B",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-12-01"
    },
    "nvidia/qwen/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-07-23"
    },
    "nvidia/qwen/qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3-Next-80B-A3B-Instruct",
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-12-01"
    },
    "nvidia/qwen/qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Qwen3-Next-80B-A3B-Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2024-12-01"
    },
    "nvidia/qwen/qwq-32b": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": null,
      "id": "qwen/qwq-32b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Qwq 32b",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "nvidia",
      "release_date": "2025-03-05"
    },
    "ollama/cogito-2.1:671b-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "cogito-2.1:671b-cloud",
      "id": "cogito-2.1:671b-cloud",
      "max_input_tokens": 160000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Cogito 2.1 671B",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-11-19"
    },
    "ollama/deepseek-v3.1:671b-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.1:671b-cloud",
      "max_input_tokens": 160000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek-V3.1 671B",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-08-21"
    },
    "ollama/gemini-3-pro-preview:latest": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview:latest",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "provider": "ollama",
      "release_date": "2025-11-18"
    },
    "ollama/glm-4.6:cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6:cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-09-29"
    },
    "ollama/gpt-oss:120b-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss:120b",
      "id": "gpt-oss:120b-cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-OSS 120B",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-08-05"
    },
    "ollama/gpt-oss:20b-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss:20b",
      "id": "gpt-oss:20b-cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-OSS 20B",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-08-05"
    },
    "ollama/kimi-k2-thinking:cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking:cloud",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-11-06"
    },
    "ollama/kimi-k2:1t-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2:1t-cloud",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Kimi K2",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-09-05"
    },
    "ollama/minimax-m2:cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax-m2:cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "MiniMax M2",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-10-27"
    },
    "ollama/qwen3-coder:480b-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder:480b-cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 Coder 480B",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-07-22"
    },
    "ollama/qwen3-vl-235b-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-235b-cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3-VL 235B Instruct",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-09-22"
    },
    "ollama/qwen3-vl-235b-instruct-cloud": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen3-vl-235b-instruct-cloud",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3-VL 235B Instruct",
      "open_weights": true,
      "provider": "ollama",
      "release_date": "2025-09-22"
    },
    "openai/codex-mini-latest": {
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "codex",
      "id": "codex-mini-latest",
      "input_cost_per_1k": 0.0015,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "Codex Mini",
      "output_cost_per_1k": 0.006,
      "provider": "openai",
      "release_date": "2025-05-16"
    },
    "openai/gpt-3.5-turbo": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "temperature"
      ],
      "family": "gpt-3.5-turbo",
      "id": "gpt-3.5-turbo",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2021-09-01",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-3.5-turbo",
      "output_cost_per_1k": 0.0015,
      "provider": "openai",
      "release_date": "2023-03-01"
    },
    "openai/gpt-4": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4",
      "id": "gpt-4",
      "input_cost_per_1k": 0.03,
      "knowledge_cutoff": "2023-11",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4",
      "output_cost_per_1k": 0.06,
      "provider": "openai",
      "release_date": "2023-11-06"
    },
    "openai/gpt-4-turbo": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "gpt-4-turbo",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo",
      "output_cost_per_1k": 0.03,
      "provider": "openai",
      "release_date": "2023-11-06"
    },
    "openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "openai",
      "release_date": "2025-04-14"
    },
    "openai/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 mini",
      "output_cost_per_1k": 0.0016,
      "provider": "openai",
      "release_date": "2025-04-14"
    },
    "openai/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "gpt-4.1-nano",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 nano",
      "output_cost_per_1k": 0.0004,
      "provider": "openai",
      "release_date": "2025-04-14"
    },
    "openai/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2024-05-13"
    },
    "openai/gpt-4o-2024-05-13": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o-2024-05-13",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4o (2024-05-13)",
      "output_cost_per_1k": 0.015,
      "provider": "openai",
      "release_date": "2024-05-13"
    },
    "openai/gpt-4o-2024-08-06": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o-2024-08-06",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o (2024-08-06)",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2024-08-06"
    },
    "openai/gpt-4o-2024-11-20": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "gpt-4o-2024-11-20",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o (2024-11-20)",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2024-11-20"
    },
    "openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o mini",
      "output_cost_per_1k": 0.0006,
      "provider": "openai",
      "release_date": "2024-07-18"
    },
    "openai/gpt-5": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-08-07"
    },
    "openai/gpt-5-chat-latest": {
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5-chat-latest",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Chat (latest)",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-08-07"
    },
    "openai/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-09-15"
    },
    "openai/gpt-5-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "openai",
      "release_date": "2025-08-07"
    },
    "openai/gpt-5-nano": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "openai",
      "release_date": "2025-08-07"
    },
    "openai/gpt-5-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "gpt-5-pro",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "mode": "chat",
      "name": "GPT-5 Pro",
      "output_cost_per_1k": 0.12,
      "provider": "openai",
      "release_date": "2025-10-06"
    },
    "openai/gpt-5.1": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-11-13"
    },
    "openai/gpt-5.1-chat-latest": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.1-chat-latest",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.1 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-11-13"
    },
    "openai/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-11-13"
    },
    "openai/gpt-5.1-codex-max": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex-max",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex Max",
      "output_cost_per_1k": 0.01,
      "provider": "openai",
      "release_date": "2025-11-13"
    },
    "openai/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "image_output",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5.1 Codex mini",
      "output_cost_per_1k": 0.002,
      "provider": "openai",
      "release_date": "2025-11-13"
    },
    "openai/gpt-5.2": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.2",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.014,
      "provider": "openai",
      "release_date": "2025-12-11"
    },
    "openai/gpt-5.2-chat-latest": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "gpt-5.2-chat-latest",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.2 Chat",
      "output_cost_per_1k": 0.014,
      "provider": "openai",
      "release_date": "2025-12-11"
    },
    "openai/gpt-5.2-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "gpt-5.2-pro",
      "input_cost_per_1k": 0.021,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2 Pro",
      "output_cost_per_1k": 0.168,
      "provider": "openai",
      "release_date": "2025-12-11"
    },
    "openai/o1": {
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "o1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1",
      "output_cost_per_1k": 0.06,
      "provider": "openai",
      "release_date": "2024-12-05"
    },
    "openai/o1-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "json_mode",
        "reasoning"
      ],
      "family": "o1-mini",
      "id": "o1-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "o1-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "openai",
      "release_date": "2024-09-12"
    },
    "openai/o1-preview": {
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "o1-preview",
      "id": "o1-preview",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "o1-preview",
      "output_cost_per_1k": 0.06,
      "provider": "openai",
      "release_date": "2024-09-12"
    },
    "openai/o1-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o1-pro",
      "id": "o1-pro",
      "input_cost_per_1k": 0.15,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1-pro",
      "output_cost_per_1k": 0.6,
      "provider": "openai",
      "release_date": "2025-03-19"
    },
    "openai/o3": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "o3",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3",
      "output_cost_per_1k": 0.008,
      "provider": "openai",
      "release_date": "2025-04-16"
    },
    "openai/o3-deep-research": {
      "cache_read_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "o3-deep-research",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-deep-research",
      "output_cost_per_1k": 0.04,
      "provider": "openai",
      "release_date": "2024-06-26"
    },
    "openai/o3-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "family": "o3-mini",
      "id": "o3-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "openai",
      "release_date": "2024-12-20"
    },
    "openai/o3-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o3-pro",
      "id": "o3-pro",
      "input_cost_per_1k": 0.02,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-pro",
      "output_cost_per_1k": 0.08,
      "provider": "openai",
      "release_date": "2025-06-10"
    },
    "openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "openai",
      "release_date": "2025-04-16"
    },
    "openai/o4-mini-deep-research": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "o4-mini-deep-research",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini-deep-research",
      "output_cost_per_1k": 0.008,
      "provider": "openai",
      "release_date": "2024-06-26"
    },
    "openai/text-embedding-3-large": {
      "family": "text-embedding-3-large",
      "id": "text-embedding-3-large",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "mode": "embedding",
      "name": "text-embedding-3-large",
      "output_cost_per_1k": 0.0,
      "provider": "openai",
      "release_date": "2024-01-25"
    },
    "openai/text-embedding-3-small": {
      "family": "text-embedding-3-small",
      "id": "text-embedding-3-small",
      "input_cost_per_1k": 2e-05,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 8191,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "text-embedding-3-small",
      "output_cost_per_1k": 0.0,
      "provider": "openai",
      "release_date": "2024-01-25"
    },
    "openai/text-embedding-ada-002": {
      "family": "text-embedding-ada",
      "id": "text-embedding-ada-002",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2022-12",
      "max_input_tokens": 8192,
      "max_output_tokens": 1536,
      "mode": "embedding",
      "name": "text-embedding-ada-002",
      "output_cost_per_1k": 0.0,
      "provider": "openai",
      "release_date": "2022-12-15"
    },
    "opencode/alpha-gd4": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "alpha-gd4",
      "id": "alpha-gd4",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Alpha GD4",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "opencode",
      "release_date": "2025-01-01"
    },
    "opencode/alpha-glm-4.7": {
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "alpha-glm",
      "id": "alpha-glm-4.7",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Alpha GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "opencode",
      "release_date": "2025-12-22"
    },
    "opencode/big-pickle": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "big-pickle",
      "id": "big-pickle",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Big Pickle",
      "output_cost_per_1k": 0.0,
      "provider": "opencode",
      "release_date": "2025-10-17"
    },
    "opencode/claude-3-5-haiku": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-3-5-haiku",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5",
      "output_cost_per_1k": 0.004,
      "provider": "opencode",
      "release_date": "2024-10-22"
    },
    "opencode/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "claude-haiku-4-5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "opencode",
      "release_date": "2025-10-15"
    },
    "opencode/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "opencode",
      "release_date": "2025-08-05"
    },
    "opencode/claude-opus-4-5": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-4-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "opencode",
      "release_date": "2025-11-01"
    },
    "opencode/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "opencode",
      "release_date": "2025-05-22"
    },
    "opencode/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "claude-sonnet-4-5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "opencode",
      "release_date": "2025-09-29"
    },
    "opencode/gemini-3-flash": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-3-flash",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Flash",
      "output_cost_per_1k": 0.003,
      "provider": "opencode",
      "release_date": "2025-12-17"
    },
    "opencode/gemini-3-pro": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Pro",
      "output_cost_per_1k": 0.012,
      "provider": "opencode",
      "release_date": "2025-11-18"
    },
    "opencode/glm-4.6": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "opencode",
      "release_date": "2025-09-30"
    },
    "opencode/glm-4.7-free": {
      "cache_read_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-free",
      "id": "glm-4.7-free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "opencode",
      "release_date": "2025-12-22"
    },
    "opencode/gpt-5": {
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.00107,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.0085,
      "provider": "opencode",
      "release_date": "2025-08-07"
    },
    "opencode/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5-codex",
      "input_cost_per_1k": 0.00107,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Codex",
      "output_cost_per_1k": 0.0085,
      "provider": "opencode",
      "release_date": "2025-08-07"
    },
    "opencode/gpt-5-nano": {
      "cache_read_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0,
      "provider": "opencode",
      "release_date": "2025-08-07"
    },
    "opencode/gpt-5.1": {
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.1",
      "input_cost_per_1k": 0.00107,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.0085,
      "provider": "opencode",
      "release_date": "2025-11-12"
    },
    "opencode/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex",
      "input_cost_per_1k": 0.00107,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex",
      "output_cost_per_1k": 0.0085,
      "provider": "opencode",
      "release_date": "2025-11-12"
    },
    "opencode/gpt-5.1-codex-max": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "gpt-5.1-codex-max",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1 Codex Max",
      "output_cost_per_1k": 0.01,
      "provider": "opencode",
      "release_date": "2025-11-12"
    },
    "opencode/gpt-5.2": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5.2",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.014,
      "provider": "opencode",
      "release_date": "2025-11-12"
    },
    "opencode/grok-code": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-code",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0,
      "provider": "opencode",
      "release_date": "2025-08-20"
    },
    "opencode/kimi-k2": {
      "cache_read_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "opencode",
      "release_date": "2025-09-05"
    },
    "opencode/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "opencode",
      "release_date": "2025-09-05"
    },
    "opencode/minimax-m2.1-free": {
      "cache_read_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax-free",
      "id": "minimax-m2.1-free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "MiniMax M2.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "opencode",
      "release_date": "2025-12-23"
    },
    "opencode/qwen3-coder": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder",
      "input_cost_per_1k": 0.00045,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen3 Coder",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "opencode",
      "release_date": "2025-07-23"
    },
    "openrouter/anthropic/claude-3.5-haiku": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-3.5-haiku",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5",
      "output_cost_per_1k": 0.004,
      "provider": "openrouter",
      "release_date": "2024-10-22"
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-3.7-sonnet",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.075,
      "provider": "openrouter",
      "release_date": "2025-02-19"
    },
    "openrouter/anthropic/claude-haiku-4.5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-4.5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "openrouter",
      "release_date": "2025-10-15"
    },
    "openrouter/anthropic/claude-opus-4": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "openrouter",
      "release_date": "2025-05-22"
    },
    "openrouter/anthropic/claude-opus-4.1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "openrouter",
      "release_date": "2025-08-05"
    },
    "openrouter/anthropic/claude-opus-4.5": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-05-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "openrouter",
      "release_date": "2025-11-24"
    },
    "openrouter/anthropic/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "openrouter",
      "release_date": "2025-05-22"
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4.5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "openrouter",
      "release_date": "2025-09-29"
    },
    "openrouter/cognitivecomputations/dolphin3.0-mistral-24b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral",
      "id": "cognitivecomputations/dolphin3.0-mistral-24b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Dolphin3.0 Mistral 24B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-02-13"
    },
    "openrouter/cognitivecomputations/dolphin3.0-r1-mistral-24b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mistral",
      "id": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Dolphin3.0 R1 Mistral 24B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-02-13"
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
      "capabilities": [
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-chat-v3-0324",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3 0324",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-24"
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-chat-v3.1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-V3.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "openrouter",
      "release_date": "2025-08-21"
    },
    "openrouter/deepseek/deepseek-r1-0528-qwen3-8b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Deepseek R1 0528 Qwen3 8B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-05-29"
    },
    "openrouter/deepseek/deepseek-r1-0528:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek/deepseek-r1-0528:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "R1 0528 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-05-28"
    },
    "openrouter/deepseek/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-01-23"
    },
    "openrouter/deepseek/deepseek-r1-distill-qwen-14b": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek/deepseek-r1-distill-qwen-14b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 64000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 14B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-01-29"
    },
    "openrouter/deepseek/deepseek-r1:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek/deepseek-r1:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "R1 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-01-20"
    },
    "openrouter/deepseek/deepseek-v3-base:free": {
      "capabilities": [
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3-base:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3 Base (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-29"
    },
    "openrouter/deepseek/deepseek-v3.1-terminus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.1-terminus",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "openrouter",
      "release_date": "2025-09-22"
    },
    "openrouter/deepseek/deepseek-v3.1-terminus:exacto": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.1-terminus:exacto",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus (exacto)",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "openrouter",
      "release_date": "2025-09-22"
    },
    "openrouter/deepseek/deepseek-v3.2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.2",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "openrouter",
      "release_date": "2025-12-01"
    },
    "openrouter/deepseek/deepseek-v3.2-speciale": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.2-speciale",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "DeepSeek V3.2 Speciale",
      "open_weights": true,
      "output_cost_per_1k": 0.00041,
      "provider": "openrouter",
      "release_date": "2025-12-01"
    },
    "openrouter/featherless/qwerky-72b": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwerky",
      "id": "featherless/qwerky-72b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwerky 72B",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-20"
    },
    "openrouter/google/gemini-2.0-flash-001": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.0-flash-001",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash",
      "output_cost_per_1k": 0.0004,
      "provider": "openrouter",
      "release_date": "2024-12-11"
    },
    "openrouter/google/gemini-2.0-flash-exp:free": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.0-flash-exp:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 1048576,
      "max_output_tokens": 1048576,
      "mode": "chat",
      "name": "Gemini 2.0 Flash Experimental (free)",
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-12-11"
    },
    "openrouter/google/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "openrouter",
      "release_date": "2025-07-17"
    },
    "openrouter/google/gemini-2.5-flash-lite": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.5-flash-lite",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite",
      "output_cost_per_1k": 0.0004,
      "provider": "openrouter",
      "release_date": "2025-06-17"
    },
    "openrouter/google/gemini-2.5-flash-lite-preview-09-2025": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.5-flash-lite-preview-09-2025",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "output_cost_per_1k": 0.0004,
      "provider": "openrouter",
      "release_date": "2025-09-25"
    },
    "openrouter/google/gemini-2.5-flash-preview-09-2025": {
      "cache_read_cost_per_1k": 3.1e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash-preview-09-2025",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "output_cost_per_1k": 0.0025,
      "provider": "openrouter",
      "release_date": "2025-09-25"
    },
    "openrouter/google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-03-20"
    },
    "openrouter/google/gemini-2.5-pro-preview-05-06": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro-preview-05-06",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro Preview 05-06",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-05-06"
    },
    "openrouter/google/gemini-2.5-pro-preview-06-05": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro-preview-06-05",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro Preview 06-05",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-06-05"
    },
    "openrouter/google/gemini-3-flash-preview": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-3-flash-preview",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Flash Preview",
      "output_cost_per_1k": 0.003,
      "provider": "openrouter",
      "release_date": "2025-12-17"
    },
    "openrouter/google/gemini-3-pro-preview": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1050000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.012,
      "provider": "openrouter",
      "release_date": "2025-11-18"
    },
    "openrouter/google/gemma-2-9b-it:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gemma-2",
      "id": "google/gemma-2-9b-it:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma 2 9B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-06-28"
    },
    "openrouter/google/gemma-3-12b-it": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google/gemma-3-12b-it",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 96000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma 3 12B IT",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-13"
    },
    "openrouter/google/gemma-3-27b-it": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google/gemma-3-27b-it",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 96000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma 3 27B IT",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-12"
    },
    "openrouter/google/gemma-3n-e4b-it": {
      "capabilities": [
        "audio_input",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google/gemma-3n-e4b-it",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma 3n E4B IT",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-05-20"
    },
    "openrouter/google/gemma-3n-e4b-it:free": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google/gemma-3n-e4b-it:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma 3n 4B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-05-20"
    },
    "openrouter/kwaipilot/kat-coder-pro:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kat-coder-pro",
      "id": "kwaipilot/kat-coder-pro:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 256000,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Kat Coder Pro (free)",
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-11-10"
    },
    "openrouter/meta-llama/llama-3.2-11b-vision-instruct": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "llama-3.2",
      "id": "meta-llama/llama-3.2-11b-vision-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 3.2 11B Vision Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-09-25"
    },
    "openrouter/meta-llama/llama-3.3-70b-instruct:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama/llama-3.3-70b-instruct:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Llama 3.3 70B Instruct (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-12-06"
    },
    "openrouter/meta-llama/llama-4-scout:free": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "meta-llama/llama-4-scout:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Llama 4 Scout (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-05"
    },
    "openrouter/microsoft/mai-ds-r1:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mai-ds-r1",
      "id": "microsoft/mai-ds-r1:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "MAI DS R1 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-21"
    },
    "openrouter/minimax/minimax-01": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "minimax",
      "id": "minimax/minimax-01",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "mode": "chat",
      "name": "MiniMax-01",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "openrouter",
      "release_date": "2025-01-15"
    },
    "openrouter/minimax/minimax-m1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax/minimax-m1",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 1000000,
      "max_output_tokens": 40000,
      "mode": "chat",
      "name": "MiniMax M1",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "openrouter",
      "release_date": "2025-06-17"
    },
    "openrouter/minimax/minimax-m2": {
      "cache_read_cost_per_1k": 0.00028,
      "cache_write_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax/minimax-m2",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 196600,
      "max_output_tokens": 118000,
      "mode": "chat",
      "name": "MiniMax M2",
      "open_weights": true,
      "output_cost_per_1k": 0.00115,
      "provider": "openrouter",
      "release_date": "2025-10-23"
    },
    "openrouter/minimax/minimax-m2.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax/minimax-m2.1",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "MiniMax M2.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "openrouter",
      "release_date": "2025-12-23"
    },
    "openrouter/mistralai/codestral-2508": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "codestral",
      "id": "mistralai/codestral-2508",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Codestral 2508",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "openrouter",
      "release_date": "2025-08-01"
    },
    "openrouter/mistralai/devstral-2512": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral",
      "id": "mistralai/devstral-2512",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Devstral 2 2512",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "openrouter",
      "release_date": "2025-09-12"
    },
    "openrouter/mistralai/devstral-2512:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral",
      "id": "mistralai/devstral-2512:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-12",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Devstral 2 2512 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-09-12"
    },
    "openrouter/mistralai/devstral-medium-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-medium",
      "id": "mistralai/devstral-medium-2507",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Devstral Medium",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "openrouter",
      "release_date": "2025-07-10"
    },
    "openrouter/mistralai/devstral-small-2505": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-small",
      "id": "mistralai/devstral-small-2505",
      "input_cost_per_1k": 6e-05,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Devstral Small",
      "open_weights": true,
      "output_cost_per_1k": 0.00012,
      "provider": "openrouter",
      "release_date": "2025-05-07"
    },
    "openrouter/mistralai/devstral-small-2505:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-small",
      "id": "mistralai/devstral-small-2505:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Devstral Small 2505 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-05-21"
    },
    "openrouter/mistralai/devstral-small-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "devstral-small",
      "id": "mistralai/devstral-small-2507",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Devstral Small 1.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "openrouter",
      "release_date": "2025-07-10"
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "mistralai/mistral-7b-instruct:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Mistral 7B Instruct (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-05-27"
    },
    "openrouter/mistralai/mistral-medium-3": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistralai/mistral-medium-3",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Mistral Medium 3",
      "output_cost_per_1k": 0.002,
      "provider": "openrouter",
      "release_date": "2025-05-07"
    },
    "openrouter/mistralai/mistral-medium-3.1": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-medium",
      "id": "mistralai/mistral-medium-3.1",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Mistral Medium 3.1",
      "output_cost_per_1k": 0.002,
      "provider": "openrouter",
      "release_date": "2025-08-12"
    },
    "openrouter/mistralai/mistral-nemo:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistralai/mistral-nemo:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Mistral Nemo (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-07-19"
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistralai/mistral-small-3.1-24b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Mistral Small 3.1 24B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-17"
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistralai/mistral-small-3.2-24b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 96000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Mistral Small 3.2 24B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-06-20"
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct:free": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistralai/mistral-small-3.2-24b-instruct:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 96000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "Mistral Small 3.2 24B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-06-20"
    },
    "openrouter/moonshotai/kimi-dev-72b:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi",
      "id": "moonshotai/kimi-dev-72b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Kimi Dev 72b (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-06-16"
    },
    "openrouter/moonshotai/kimi-k2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "openrouter",
      "release_date": "2025-07-11"
    },
    "openrouter/moonshotai/kimi-k2-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-0905",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Instruct 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "openrouter",
      "release_date": "2025-09-05"
    },
    "openrouter/moonshotai/kimi-k2-0905:exacto": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-0905:exacto",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Instruct 0905 (exacto)",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "openrouter",
      "release_date": "2025-09-05"
    },
    "openrouter/moonshotai/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "openrouter",
      "release_date": "2025-11-06"
    },
    "openrouter/moonshotai/kimi-k2:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 32800,
      "max_output_tokens": 32800,
      "mode": "chat",
      "name": "Kimi K2 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-07-11"
    },
    "openrouter/nousresearch/deephermes-3-llama-3-8b-preview": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3",
      "id": "nousresearch/deephermes-3-llama-3-8b-preview",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepHermes 3 Llama 3 8B Preview",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-02-28"
    },
    "openrouter/nousresearch/hermes-4-405b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "nousresearch/hermes-4-405b",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Hermes 4 405B",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "openrouter",
      "release_date": "2025-08-25"
    },
    "openrouter/nousresearch/hermes-4-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "hermes",
      "id": "nousresearch/hermes-4-70b",
      "input_cost_per_1k": 0.00013,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Hermes 4 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "openrouter",
      "release_date": "2025-08-25"
    },
    "openrouter/nvidia/nemotron-nano-9b-v2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "nemotron",
      "id": "nvidia/nemotron-nano-9b-v2",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "nvidia-nemotron-nano-9b-v2",
      "open_weights": true,
      "output_cost_per_1k": 0.00016,
      "provider": "openrouter",
      "release_date": "2025-08-18"
    },
    "openrouter/openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "openai/gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "openrouter",
      "release_date": "2025-04-14"
    },
    "openrouter/openai/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "openai/gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 Mini",
      "output_cost_per_1k": 0.0016,
      "provider": "openrouter",
      "release_date": "2025-04-14"
    },
    "openrouter/openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o-mini",
      "output_cost_per_1k": 0.0006,
      "provider": "openrouter",
      "release_date": "2024-07-18"
    },
    "openrouter/openai/gpt-5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-chat": {
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "openai/gpt-5-chat",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Chat (latest)",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-09-15"
    },
    "openrouter/openai/gpt-5-image": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "image_output",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5-image",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5 Image",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-10-14"
    },
    "openrouter/openai/gpt-5-mini": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "openai/gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "openrouter",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-nano": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "openai/gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "openrouter",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-pro": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "openai/gpt-5-pro",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "mode": "chat",
      "name": "GPT-5 Pro",
      "output_cost_per_1k": 0.12,
      "provider": "openrouter",
      "release_date": "2025-10-06"
    },
    "openrouter/openai/gpt-5.1": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5.1",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5.1-chat": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "openai/gpt-5.1-chat",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.1 Chat",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5.1-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1-Codex",
      "output_cost_per_1k": 0.01,
      "provider": "openrouter",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "openai/gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "GPT-5.1-Codex-Mini",
      "output_cost_per_1k": 0.002,
      "provider": "openrouter",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5.2": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5.2",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.014,
      "provider": "openrouter",
      "release_date": "2025-12-11"
    },
    "openrouter/openai/gpt-5.2-chat-latest": {
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "openai/gpt-5.2-chat-latest",
      "input_cost_per_1k": 0.00175,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.2 Chat",
      "output_cost_per_1k": 0.014,
      "provider": "openrouter",
      "release_date": "2025-12-11"
    },
    "openrouter/openai/gpt-5.2-pro": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "openai/gpt-5.2-pro",
      "input_cost_per_1k": 0.021,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.2 Pro",
      "output_cost_per_1k": 0.168,
      "provider": "openrouter",
      "release_date": "2025-12-11"
    },
    "openrouter/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 7.2e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.00028,
      "provider": "openrouter",
      "release_date": "2025-08-05"
    },
    "openrouter/openai/gpt-oss-120b:exacto": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b:exacto",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B (exacto)",
      "open_weights": true,
      "output_cost_per_1k": 0.00024,
      "provider": "openrouter",
      "release_date": "2025-08-05"
    },
    "openrouter/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "openrouter",
      "release_date": "2025-08-05"
    },
    "openrouter/openai/gpt-oss-safeguard-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-safeguard-20b",
      "input_cost_per_1k": 7.5e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "GPT OSS Safeguard 20B",
      "output_cost_per_1k": 0.0003,
      "provider": "openrouter",
      "release_date": "2025-10-29"
    },
    "openrouter/openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4 Mini",
      "output_cost_per_1k": 0.0044,
      "provider": "openrouter",
      "release_date": "2025-04-16"
    },
    "openrouter/openrouter/sherlock-dash-alpha": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "sherlock",
      "id": "openrouter/sherlock-dash-alpha",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 1840000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Sherlock Dash Alpha",
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-11-15"
    },
    "openrouter/openrouter/sherlock-think-alpha": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "sherlock",
      "id": "openrouter/sherlock-think-alpha",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 1840000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Sherlock Think Alpha",
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-11-15"
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen",
      "id": "qwen/qwen-2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 Coder 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2024-11-11"
    },
    "openrouter/qwen/qwen2.5-vl-32b-instruct:free": {
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen/qwen2.5-vl-32b-instruct:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 VL 32B Instruct (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-24"
    },
    "openrouter/qwen/qwen2.5-vl-72b-instruct": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen/qwen2.5-vl-72b-instruct",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen2.5 VL 72B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-02-01"
    },
    "openrouter/qwen/qwen2.5-vl-72b-instruct:free": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen/qwen2.5-vl-72b-instruct:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-02",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen2.5 VL 72B Instruct (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-02-01"
    },
    "openrouter/qwen/qwen3-14b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-14b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 14B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-235b-a22b-07-25": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b-07-25",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00085,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-235b-a22b-07-25:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b-07-25:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507 (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 7.8e-05,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 81920,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.000312,
      "provider": "openrouter",
      "release_date": "2025-07-25"
    },
    "openrouter/qwen/qwen3-235b-a22b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-235b-a22b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-30b-a3b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-30b-a3b-instruct-2507",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen3 30B A3B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "openrouter",
      "release_date": "2025-07-29"
    },
    "openrouter/qwen/qwen3-30b-a3b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-30b-a3b-thinking-2507",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen3 30B A3B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "openrouter",
      "release_date": "2025-07-29"
    },
    "openrouter/qwen/qwen3-30b-a3b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-30b-a3b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 30B A3B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-32b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-32b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 32B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-8b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-8b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "Qwen3 8B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-28"
    },
    "openrouter/qwen/qwen3-coder": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "openrouter",
      "release_date": "2025-07-23"
    },
    "openrouter/qwen/qwen3-coder-flash": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder Flash",
      "output_cost_per_1k": 0.0015,
      "provider": "openrouter",
      "release_date": "2025-07-23"
    },
    "openrouter/qwen/qwen3-coder:exacto": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder:exacto",
      "input_cost_per_1k": 0.00038,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 Coder (exacto)",
      "open_weights": true,
      "output_cost_per_1k": 0.00153,
      "provider": "openrouter",
      "release_date": "2025-07-23"
    },
    "openrouter/qwen/qwen3-coder:free": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-07-23"
    },
    "openrouter/qwen/qwen3-max": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-max",
      "input_cost_per_1k": 0.0012,
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 Max",
      "output_cost_per_1k": 0.006,
      "provider": "openrouter",
      "release_date": "2025-09-05"
    },
    "openrouter/qwen/qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.00014,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0014,
      "provider": "openrouter",
      "release_date": "2025-09-11"
    },
    "openrouter/qwen/qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen/qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.00014,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0014,
      "provider": "openrouter",
      "release_date": "2025-09-11"
    },
    "openrouter/qwen/qwq-32b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwen/qwq-32b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "QwQ 32B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-05"
    },
    "openrouter/rekaai/reka-flash-3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "reka-flash",
      "id": "rekaai/reka-flash-3",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Reka Flash 3",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-03-12"
    },
    "openrouter/sarvamai/sarvam-m:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "sarvam-m",
      "id": "sarvamai/sarvam-m:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Sarvam-M (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-05-25"
    },
    "openrouter/thudm/glm-z1-32b:free": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-z1",
      "id": "thudm/glm-z1-32b:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM Z1 32B (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-04-17"
    },
    "openrouter/tngtech/deepseek-r1t2-chimera:free": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "tngtech/deepseek-r1t2-chimera:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek R1T2 Chimera (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-07-08"
    },
    "openrouter/x-ai/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "x-ai/grok-3",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "openrouter",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-3-beta": {
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "x-ai/grok-3-beta",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Beta",
      "output_cost_per_1k": 0.015,
      "provider": "openrouter",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "x-ai/grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "openrouter",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-3-mini-beta": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "x-ai/grok-3-mini-beta",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini Beta",
      "output_cost_per_1k": 0.0005,
      "provider": "openrouter",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "openrouter",
      "release_date": "2025-07-09"
    },
    "openrouter/x-ai/grok-4-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "openrouter",
      "release_date": "2025-08-19"
    },
    "openrouter/x-ai/grok-4.1-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4.1-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4.1 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "openrouter",
      "release_date": "2025-11-19"
    },
    "openrouter/x-ai/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "x-ai/grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "openrouter",
      "release_date": "2025-08-26"
    },
    "openrouter/z-ai/glm-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "z-ai/glm-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "openrouter",
      "release_date": "2025-07-28"
    },
    "openrouter/z-ai/glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "z-ai/glm-4.5-air",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "openrouter",
      "release_date": "2025-07-28"
    },
    "openrouter/z-ai/glm-4.5-air:free": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "z-ai/glm-4.5-air:free",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5 Air (free)",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "openrouter",
      "release_date": "2025-07-28"
    },
    "openrouter/z-ai/glm-4.5v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "z-ai/glm-4.5v",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GLM 4.5V",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "openrouter",
      "release_date": "2025-08-11"
    },
    "openrouter/z-ai/glm-4.6": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "z-ai/glm-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "openrouter",
      "release_date": "2025-09-30"
    },
    "openrouter/z-ai/glm-4.6:exacto": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "z-ai/glm-4.6:exacto",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GLM 4.6 (exacto)",
      "open_weights": true,
      "output_cost_per_1k": 0.0019,
      "provider": "openrouter",
      "release_date": "2025-09-30"
    },
    "openrouter/z-ai/glm-4.7": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "z-ai/glm-4.7",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "openrouter",
      "release_date": "2025-12-22"
    },
    "ovhcloud/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.00074,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "DeepSeek-R1-Distill-Llama-70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00074,
      "provider": "ovhcloud",
      "release_date": "2025-01-30"
    },
    "ovhcloud/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "gpt-oss-120b",
      "open_weights": true,
      "output_cost_per_1k": 0.00047,
      "provider": "ovhcloud",
      "release_date": "2025-08-28"
    },
    "ovhcloud/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-20b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "gpt-oss-20b",
      "open_weights": true,
      "output_cost_per_1k": 0.00018,
      "provider": "ovhcloud",
      "release_date": "2025-08-28"
    },
    "ovhcloud/llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.00011,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Llama-3.1-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "ovhcloud",
      "release_date": "2025-06-11"
    },
    "ovhcloud/llava-next-mistral-7b": {
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "mistral-7b",
      "id": "llava-next-mistral-7b",
      "input_cost_per_1k": 0.00032,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "llava-next-mistral-7b",
      "open_weights": true,
      "output_cost_per_1k": 0.00032,
      "provider": "ovhcloud",
      "release_date": "2025-01-08"
    },
    "ovhcloud/meta-llama-3_1-70b-instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama-3_1-70b-instruct",
      "input_cost_per_1k": 0.00074,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Meta-Llama-3_1-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00074,
      "provider": "ovhcloud",
      "release_date": "2025-04-01"
    },
    "ovhcloud/meta-llama-3_3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3",
      "id": "meta-llama-3_3-70b-instruct",
      "input_cost_per_1k": 0.00074,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Meta-Llama-3_3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00074,
      "provider": "ovhcloud",
      "release_date": "2025-04-01"
    },
    "ovhcloud/mistral-7b-instruct-v0.3": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "mistral-7b",
      "id": "mistral-7b-instruct-v0.3",
      "input_cost_per_1k": 0.00011,
      "max_input_tokens": 127000,
      "max_output_tokens": 127000,
      "mode": "chat",
      "name": "Mistral-7B-Instruct-v0.3",
      "open_weights": true,
      "output_cost_per_1k": 0.00011,
      "provider": "ovhcloud",
      "release_date": "2025-04-01"
    },
    "ovhcloud/mistral-nemo-instruct-2407": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "mistral-nemo",
      "id": "mistral-nemo-instruct-2407",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 118000,
      "max_output_tokens": 118000,
      "mode": "chat",
      "name": "Mistral-Nemo-Instruct-2407",
      "open_weights": true,
      "output_cost_per_1k": 0.00014,
      "provider": "ovhcloud",
      "release_date": "2024-11-20"
    },
    "ovhcloud/mistral-small-3.2-24b-instruct-2506": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small-3.2-24b-instruct-2506",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Mistral-Small-3.2-24B-Instruct-2506",
      "open_weights": true,
      "output_cost_per_1k": 0.00031,
      "provider": "ovhcloud",
      "release_date": "2025-07-16"
    },
    "ovhcloud/mixtral-8x7b-instruct-v0.1": {
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "family": "mixtral-8x7b",
      "id": "mixtral-8x7b-instruct-v0.1",
      "input_cost_per_1k": 0.0007,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Mixtral-8x7B-Instruct-v0.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0007,
      "provider": "ovhcloud",
      "release_date": "2025-04-01"
    },
    "ovhcloud/qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.00096,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen2.5-Coder-32B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00096,
      "provider": "ovhcloud",
      "release_date": "2025-03-24"
    },
    "ovhcloud/qwen2.5-vl-72b-instruct": {
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen2.5-vl-72b-instruct",
      "input_cost_per_1k": 0.00101,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen2.5-VL-72B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00101,
      "provider": "ovhcloud",
      "release_date": "2025-03-31"
    },
    "ovhcloud/qwen3-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-32b",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3-32B",
      "open_weights": true,
      "output_cost_per_1k": 0.00025,
      "provider": "ovhcloud",
      "release_date": "2025-07-16"
    },
    "ovhcloud/qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Qwen3-Coder-30B-A3B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00026,
      "provider": "ovhcloud",
      "release_date": "2025-10-28"
    },
    "perplexity/sonar": {
      "capabilities": [
        "temperature"
      ],
      "family": "sonar",
      "id": "sonar",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-09-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Sonar",
      "output_cost_per_1k": 0.001,
      "provider": "perplexity",
      "release_date": "2024-01-01"
    },
    "perplexity/sonar-pro": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "sonar-pro",
      "id": "sonar-pro",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-09-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Sonar Pro",
      "output_cost_per_1k": 0.015,
      "provider": "perplexity",
      "release_date": "2024-01-01"
    },
    "perplexity/sonar-reasoning-pro": {
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "sonar-reasoning",
      "id": "sonar-reasoning-pro",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-09-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Sonar Reasoning Pro",
      "output_cost_per_1k": 0.008,
      "provider": "perplexity",
      "release_date": "2024-01-01"
    },
    "poe/anthropic/claude-haiku-3": {
      "cache_read_cost_per_1k": 2.1e-05,
      "cache_write_cost_per_1k": 0.00026,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-3",
      "input_cost_per_1k": 0.00021,
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude-Haiku-3",
      "output_cost_per_1k": 0.0011,
      "provider": "poe",
      "release_date": "2024-03-09"
    },
    "poe/anthropic/claude-haiku-3.5": {
      "cache_read_cost_per_1k": 6.8e-05,
      "cache_write_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-3.5",
      "input_cost_per_1k": 0.00068,
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude-Haiku-3.5",
      "output_cost_per_1k": 0.0034,
      "provider": "poe",
      "release_date": "2024-10-01"
    },
    "poe/anthropic/claude-haiku-3.5-search": {
      "cache_read_cost_per_1k": 6.8e-05,
      "cache_write_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-3.5-search",
      "input_cost_per_1k": 0.00068,
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude-Haiku-3.5-Search",
      "output_cost_per_1k": 0.0034,
      "provider": "poe",
      "release_date": "2025-05-15"
    },
    "poe/anthropic/claude-haiku-4.5": {
      "cache_read_cost_per_1k": 8.5e-05,
      "cache_write_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-4.5",
      "input_cost_per_1k": 0.00085,
      "max_input_tokens": 192000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.0043,
      "provider": "poe",
      "release_date": "2025-10-15"
    },
    "poe/anthropic/claude-opus-3": {
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-3",
      "input_cost_per_1k": 0.013,
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude-Opus-3",
      "output_cost_per_1k": 0.064,
      "provider": "poe",
      "release_date": "2024-03-04"
    },
    "poe/anthropic/claude-opus-4": {
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4",
      "input_cost_per_1k": 0.013,
      "max_input_tokens": 192512,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.064,
      "provider": "poe",
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-opus-4-reasoning": {
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4-reasoning",
      "input_cost_per_1k": 0.013,
      "max_input_tokens": 196608,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Claude Opus 4 Reasoning",
      "output_cost_per_1k": 0.064,
      "provider": "poe",
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-opus-4-search": {
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4-search",
      "input_cost_per_1k": 0.013,
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Claude Opus 4 Search",
      "output_cost_per_1k": 0.064,
      "provider": "poe",
      "release_date": "2025-06-20"
    },
    "poe/anthropic/claude-opus-4.1": {
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.1",
      "input_cost_per_1k": 0.013,
      "max_input_tokens": 196608,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.064,
      "provider": "poe",
      "release_date": "2025-08-05"
    },
    "poe/anthropic/claude-opus-4.5": {
      "cache_read_cost_per_1k": 0.00043,
      "cache_write_cost_per_1k": 0.0053,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.5",
      "input_cost_per_1k": 0.0043,
      "max_input_tokens": 196608,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "claude-opus-4.5",
      "output_cost_per_1k": 0.021,
      "provider": "poe",
      "release_date": "2025-11-21"
    },
    "poe/anthropic/claude-sonnet-3.5": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-3.5",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude-Sonnet-3.5",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2024-06-05"
    },
    "poe/anthropic/claude-sonnet-3.5-june": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-3.5-june",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude-Sonnet-3.5-June",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2024-11-18"
    },
    "poe/anthropic/claude-sonnet-3.7": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-3.7",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 196608,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-02-19"
    },
    "poe/anthropic/claude-sonnet-3.7-reasoning": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-3.7-reasoning",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7 Reasoning",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-02-19"
    },
    "poe/anthropic/claude-sonnet-3.7-search": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-3.7-search",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7 Search",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-05-15"
    },
    "poe/anthropic/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 983040,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-sonnet-4-reasoning": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4-reasoning",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 983040,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4 Reasoning",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-sonnet-4-search": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4-search",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 983040,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Claude Sonnet 4 Search",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-06-20"
    },
    "poe/anthropic/claude-sonnet-4.5": {
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4.5",
      "input_cost_per_1k": 0.0026,
      "max_input_tokens": 983040,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-09-26"
    },
    "poe/elevenlabs/elevenlabs-music": {
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "family": "elevenlabs-music",
      "id": "elevenlabs/elevenlabs-music",
      "max_input_tokens": 2000,
      "max_output_tokens": 0,
      "mode": "audio_speech",
      "name": "ElevenLabs-Music",
      "provider": "poe",
      "release_date": "2025-08-29"
    },
    "poe/elevenlabs/elevenlabs-v2.5-turbo": {
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "family": "elevenlabs-v2.5-turbo",
      "id": "elevenlabs/elevenlabs-v2.5-turbo",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "mode": "audio_speech",
      "name": "ElevenLabs-v2.5-Turbo",
      "provider": "poe",
      "release_date": "2024-10-28"
    },
    "poe/elevenlabs/elevenlabs-v3": {
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "family": "elevenlabs",
      "id": "elevenlabs/elevenlabs-v3",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "mode": "audio_speech",
      "name": "ElevenLabs-v3",
      "provider": "poe",
      "release_date": "2025-06-05"
    },
    "poe/google/gemini-2.0-flash": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.0-flash",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 990000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini-2.0-Flash",
      "output_cost_per_1k": 0.00042,
      "provider": "poe",
      "release_date": "2024-12-11"
    },
    "poe/google/gemini-2.0-flash-lite": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.0-flash-lite",
      "input_cost_per_1k": 5.2e-05,
      "max_input_tokens": 990000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini-2.0-Flash-Lite",
      "output_cost_per_1k": 0.00021,
      "provider": "poe",
      "release_date": "2025-02-05"
    },
    "poe/google/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 5.2e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash",
      "input_cost_per_1k": 0.00021,
      "max_input_tokens": 1065535,
      "max_output_tokens": 65535,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0018,
      "provider": "poe",
      "release_date": "2025-04-26"
    },
    "poe/google/gemini-2.5-flash-lite": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.5-flash-lite",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 1024000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite",
      "output_cost_per_1k": 0.00028,
      "provider": "poe",
      "release_date": "2025-06-19"
    },
    "poe/google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00022,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro",
      "input_cost_per_1k": 0.00087,
      "max_input_tokens": 1065535,
      "max_output_tokens": 65535,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.007,
      "provider": "poe",
      "release_date": "2025-02-05"
    },
    "poe/google/gemini-3-pro": {
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-3-pro",
      "input_cost_per_1k": 0.0016,
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini-3-Pro",
      "output_cost_per_1k": 0.0096,
      "provider": "poe",
      "release_date": "2025-10-22"
    },
    "poe/google/gemini-deep-research": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "family": null,
      "id": "google/gemini-deep-research",
      "input_cost_per_1k": 0.0016,
      "max_input_tokens": 1048576,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "gemini-deep-research",
      "output_cost_per_1k": 0.0096,
      "provider": "poe",
      "release_date": "2025-12-11"
    },
    "poe/google/imagen-3": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "imagen",
      "id": "google/imagen-3",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Imagen-3",
      "provider": "poe",
      "release_date": "2024-10-15"
    },
    "poe/google/imagen-3-fast": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "imagen-3-fast",
      "id": "google/imagen-3-fast",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Imagen-3-Fast",
      "provider": "poe",
      "release_date": "2024-10-17"
    },
    "poe/google/imagen-4": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "imagen",
      "id": "google/imagen-4",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Imagen-4",
      "provider": "poe",
      "release_date": "2025-05-22"
    },
    "poe/google/imagen-4-fast": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "imagen-4-fast",
      "id": "google/imagen-4-fast",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Imagen-4-Fast",
      "provider": "poe",
      "release_date": "2025-06-25"
    },
    "poe/google/imagen-4-ultra": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "imagen-4-ultra",
      "id": "google/imagen-4-ultra",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Imagen-4-Ultra",
      "provider": "poe",
      "release_date": "2025-05-24"
    },
    "poe/google/lyria": {
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "family": "lyria",
      "id": "google/lyria",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "audio_speech",
      "name": "Lyria",
      "provider": "poe",
      "release_date": "2025-06-04"
    },
    "poe/google/nano-banana": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "nano-banana",
      "id": "google/nano-banana",
      "input_cost_per_1k": 0.00021,
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Nano-Banana",
      "output_cost_per_1k": 0.0018,
      "provider": "poe",
      "release_date": "2025-08-21"
    },
    "poe/google/nano-banana-pro": {
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "nano-banana-pro",
      "id": "google/nano-banana-pro",
      "input_cost_per_1k": 0.0016,
      "max_input_tokens": 65536,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Nano-Banana-Pro",
      "output_cost_per_1k": 0.0096,
      "provider": "poe",
      "release_date": "2025-11-19"
    },
    "poe/google/veo-2": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "veo",
      "id": "google/veo-2",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Veo-2",
      "provider": "poe",
      "release_date": "2024-12-02"
    },
    "poe/google/veo-3": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "veo",
      "id": "google/veo-3",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Veo-3",
      "provider": "poe",
      "release_date": "2025-05-21"
    },
    "poe/google/veo-3-fast": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "veo-3-fast",
      "id": "google/veo-3-fast",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Veo-3-Fast",
      "provider": "poe",
      "release_date": "2025-10-13"
    },
    "poe/google/veo-3.1": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "veo",
      "id": "google/veo-3.1",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Veo-3.1",
      "provider": "poe",
      "release_date": "2025-10-15"
    },
    "poe/google/veo-3.1-fast": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "veo-3.1-fast",
      "id": "google/veo-3.1-fast",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Veo-3.1-Fast",
      "provider": "poe",
      "release_date": "2025-10-15"
    },
    "poe/ideogramai/ideogram": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "ideogram",
      "id": "ideogramai/ideogram",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Ideogram",
      "provider": "poe",
      "release_date": "2024-04-03"
    },
    "poe/ideogramai/ideogram-v2": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "ideogram",
      "id": "ideogramai/ideogram-v2",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Ideogram-v2",
      "provider": "poe",
      "release_date": "2024-08-21"
    },
    "poe/ideogramai/ideogram-v2a": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "ideogram",
      "id": "ideogramai/ideogram-v2a",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Ideogram-v2a",
      "provider": "poe",
      "release_date": "2025-02-27"
    },
    "poe/ideogramai/ideogram-v2a-turbo": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "ideogram",
      "id": "ideogramai/ideogram-v2a-turbo",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "Ideogram-v2a-Turbo",
      "provider": "poe",
      "release_date": "2025-02-27"
    },
    "poe/lumalabs/dream-machine": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "dream-machine",
      "id": "lumalabs/dream-machine",
      "max_input_tokens": 5000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Dream-Machine",
      "provider": "poe",
      "release_date": "2024-09-18"
    },
    "poe/lumalabs/ray2": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "ray2",
      "id": "lumalabs/ray2",
      "max_input_tokens": 5000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Ray2",
      "provider": "poe",
      "release_date": "2025-02-20"
    },
    "poe/novita/glm-4.6": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "glm-4.6",
      "id": "novita/glm-4.6",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "GLM-4.6",
      "provider": "poe",
      "release_date": "2025-09-30"
    },
    "poe/novita/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "kimi-k2",
      "id": "novita/kimi-k2-thinking",
      "max_input_tokens": 256000,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "kimi-k2-thinking",
      "provider": "poe",
      "release_date": "2025-11-07"
    },
    "poe/openai/chatgpt-4o-latest": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "chatgpt-4o",
      "id": "openai/chatgpt-4o-latest",
      "input_cost_per_1k": 0.0045,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "ChatGPT-4o-Latest",
      "output_cost_per_1k": 0.014,
      "provider": "poe",
      "release_date": "2024-08-14"
    },
    "poe/openai/dall-e-3": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "dall-e-3",
      "id": "openai/dall-e-3",
      "max_input_tokens": 800,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "DALL-E-3",
      "provider": "poe",
      "release_date": "2023-11-06"
    },
    "poe/openai/gpt-3.5-turbo": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-3.5-turbo",
      "id": "openai/gpt-3.5-turbo",
      "input_cost_per_1k": 0.00045,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "GPT-3.5-Turbo",
      "output_cost_per_1k": 0.0014,
      "provider": "poe",
      "release_date": "2023-09-13"
    },
    "poe/openai/gpt-3.5-turbo-instruct": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-3.5-turbo",
      "id": "openai/gpt-3.5-turbo-instruct",
      "input_cost_per_1k": 0.0014,
      "max_input_tokens": 3500,
      "max_output_tokens": 1024,
      "mode": "chat",
      "name": "GPT-3.5-Turbo-Instruct",
      "output_cost_per_1k": 0.0018,
      "provider": "poe",
      "release_date": "2023-09-20"
    },
    "poe/openai/gpt-3.5-turbo-raw": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-3.5-turbo",
      "id": "openai/gpt-3.5-turbo-raw",
      "input_cost_per_1k": 0.00045,
      "max_input_tokens": 4524,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "GPT-3.5-Turbo-Raw",
      "output_cost_per_1k": 0.0014,
      "provider": "poe",
      "release_date": "2023-09-27"
    },
    "poe/openai/gpt-4-classic": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4",
      "id": "openai/gpt-4-classic",
      "input_cost_per_1k": 0.027,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4-Classic",
      "output_cost_per_1k": 0.054,
      "provider": "poe",
      "release_date": "2024-03-25"
    },
    "poe/openai/gpt-4-classic-0314": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4",
      "id": "openai/gpt-4-classic-0314",
      "input_cost_per_1k": 0.027,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4-Classic-0314",
      "output_cost_per_1k": 0.054,
      "provider": "poe",
      "release_date": "2024-08-26"
    },
    "poe/openai/gpt-4-turbo": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "openai/gpt-4-turbo",
      "input_cost_per_1k": 0.009,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4-Turbo",
      "output_cost_per_1k": 0.027,
      "provider": "poe",
      "release_date": "2023-09-13"
    },
    "poe/openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "openai/gpt-4.1",
      "input_cost_per_1k": 0.0018,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.0072,
      "provider": "poe",
      "release_date": "2025-04-14"
    },
    "poe/openai/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 9e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "openai/gpt-4.1-mini",
      "input_cost_per_1k": 0.00036,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1-mini",
      "output_cost_per_1k": 0.0014,
      "provider": "poe",
      "release_date": "2025-04-15"
    },
    "poe/openai/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "openai/gpt-4.1-nano",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1-nano",
      "output_cost_per_1k": 0.00036,
      "provider": "poe",
      "release_date": "2025-04-15"
    },
    "poe/openai/gpt-4o": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "openai/gpt-4o",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4o",
      "provider": "poe",
      "release_date": "2024-05-13"
    },
    "poe/openai/gpt-4o-aug": {
      "cache_read_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "openai/gpt-4o-aug",
      "input_cost_per_1k": 0.0022,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4o-Aug",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2024-11-21"
    },
    "poe/openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 6.8e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4o-mini",
      "output_cost_per_1k": 0.00054,
      "provider": "poe",
      "release_date": "2024-07-18"
    },
    "poe/openai/gpt-4o-mini-search": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini-search",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4o-mini-Search",
      "output_cost_per_1k": 0.00054,
      "provider": "poe",
      "release_date": "2025-03-11"
    },
    "poe/openai/gpt-4o-search": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "openai/gpt-4o-search",
      "input_cost_per_1k": 0.0022,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-4o-Search",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-03-11"
    },
    "poe/openai/gpt-5": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-08-05"
    },
    "poe/openai/gpt-5-chat": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-5-chat",
      "id": "openai/gpt-5-chat",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5-Chat",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-08-07"
    },
    "poe/openai/gpt-5-codex": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5-codex",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-09-23"
    },
    "poe/openai/gpt-5-mini": {
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "openai/gpt-5-mini",
      "input_cost_per_1k": 0.00022,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-mini",
      "output_cost_per_1k": 0.0018,
      "provider": "poe",
      "release_date": "2025-06-25"
    },
    "poe/openai/gpt-5-nano": {
      "cache_read_cost_per_1k": 4.5e-06,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "openai/gpt-5-nano",
      "input_cost_per_1k": 4.5e-05,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-nano",
      "output_cost_per_1k": 0.00036,
      "provider": "poe",
      "release_date": "2025-08-05"
    },
    "poe/openai/gpt-5-pro": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-pro",
      "id": "openai/gpt-5-pro",
      "input_cost_per_1k": 0.014,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Pro",
      "output_cost_per_1k": 0.11,
      "provider": "poe",
      "release_date": "2025-10-06"
    },
    "poe/openai/gpt-5.1": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5.1",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-5.1-codex": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5.1-codex",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1-Codex",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-5.1-codex-max": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": null,
      "id": "openai/gpt-5.1-codex-max",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "gpt-5.1-codex-max",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-12-08"
    },
    "poe/openai/gpt-5.1-codex-mini": {
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex-mini",
      "id": "openai/gpt-5.1-codex-mini",
      "input_cost_per_1k": 0.00022,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5.1-Codex-Mini",
      "output_cost_per_1k": 0.0018,
      "provider": "poe",
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-5.1-instant": {
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5.1-instant",
      "input_cost_per_1k": 0.0011,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-5.1-Instant",
      "output_cost_per_1k": 0.009,
      "provider": "poe",
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-5.2": {
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": null,
      "id": "openai/gpt-5.2",
      "input_cost_per_1k": 0.0016,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "gpt-5.2",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-12-08"
    },
    "poe/openai/gpt-5.2-instant": {
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": null,
      "id": "openai/gpt-5.2-instant",
      "input_cost_per_1k": 0.0016,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "gpt-5.2-instant",
      "output_cost_per_1k": 0.013,
      "provider": "poe",
      "release_date": "2025-12-11"
    },
    "poe/openai/gpt-5.2-pro": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": null,
      "id": "openai/gpt-5.2-pro",
      "input_cost_per_1k": 0.019,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "gpt-5.2-pro",
      "output_cost_per_1k": 0.15,
      "provider": "poe",
      "release_date": "2025-12-11"
    },
    "poe/openai/gpt-image-1": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "gpt-image",
      "id": "openai/gpt-image-1",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "GPT-Image-1",
      "provider": "poe",
      "release_date": "2025-03-31"
    },
    "poe/openai/gpt-image-1-mini": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "gpt-image",
      "id": "openai/gpt-image-1-mini",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "GPT-Image-1-Mini",
      "provider": "poe",
      "release_date": "2025-08-26"
    },
    "poe/openai/o1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "openai/o1",
      "input_cost_per_1k": 0.014,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1",
      "output_cost_per_1k": 0.054,
      "provider": "poe",
      "release_date": "2024-12-18"
    },
    "poe/openai/o1-pro": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o1-pro",
      "id": "openai/o1-pro",
      "input_cost_per_1k": 0.14,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1-pro",
      "output_cost_per_1k": 0.54,
      "provider": "poe",
      "release_date": "2025-03-19"
    },
    "poe/openai/o3": {
      "cache_read_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "openai/o3",
      "input_cost_per_1k": 0.0018,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3",
      "output_cost_per_1k": 0.0072,
      "provider": "poe",
      "release_date": "2025-04-16"
    },
    "poe/openai/o3-deep-research": {
      "cache_read_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "openai/o3-deep-research",
      "input_cost_per_1k": 0.009,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-deep-research",
      "output_cost_per_1k": 0.036,
      "provider": "poe",
      "release_date": "2025-06-27"
    },
    "poe/openai/o3-mini": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3-mini",
      "id": "openai/o3-mini",
      "input_cost_per_1k": 0.00099,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.004,
      "provider": "poe",
      "release_date": "2025-01-31"
    },
    "poe/openai/o3-mini-high": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3-mini",
      "id": "openai/o3-mini-high",
      "input_cost_per_1k": 0.00099,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini-high",
      "output_cost_per_1k": 0.004,
      "provider": "poe",
      "release_date": "2025-01-31"
    },
    "poe/openai/o3-pro": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o3-pro",
      "id": "openai/o3-pro",
      "input_cost_per_1k": 0.018,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-pro",
      "output_cost_per_1k": 0.072,
      "provider": "poe",
      "release_date": "2025-06-10"
    },
    "poe/openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini",
      "input_cost_per_1k": 0.00099,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.004,
      "provider": "poe",
      "release_date": "2025-04-16"
    },
    "poe/openai/o4-mini-deep-research": {
      "cache_read_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini-deep-research",
      "input_cost_per_1k": 0.0018,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini-deep-research",
      "output_cost_per_1k": 0.0072,
      "provider": "poe",
      "release_date": "2025-06-27"
    },
    "poe/openai/sora-2": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "sora",
      "id": "openai/sora-2",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Sora-2",
      "provider": "poe",
      "release_date": "2025-10-06"
    },
    "poe/openai/sora-2-pro": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "sora-2-pro",
      "id": "openai/sora-2-pro",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Sora-2-Pro",
      "provider": "poe",
      "release_date": "2025-10-06"
    },
    "poe/poetools/claude-code": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": null,
      "id": "poetools/claude-code",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "claude-code",
      "provider": "poe",
      "release_date": "2025-11-27"
    },
    "poe/runwayml/runway": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "runway",
      "id": "runwayml/runway",
      "max_input_tokens": 256,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Runway",
      "provider": "poe",
      "release_date": "2024-10-11"
    },
    "poe/runwayml/runway-gen-4-turbo": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "runway-gen-4-turbo",
      "id": "runwayml/runway-gen-4-turbo",
      "max_input_tokens": 256,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Runway-Gen-4-Turbo",
      "provider": "poe",
      "release_date": "2025-05-09"
    },
    "poe/stabilityai/stablediffusionxl": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "stablediffusionxl",
      "id": "stabilityai/stablediffusionxl",
      "max_input_tokens": 200,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "StableDiffusionXL",
      "provider": "poe",
      "release_date": "2023-07-09"
    },
    "poe/topazlabs-co/topazlabs": {
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "family": "topazlabs",
      "id": "topazlabs-co/topazlabs",
      "max_input_tokens": 204,
      "max_output_tokens": 0,
      "mode": "image",
      "name": "TopazLabs",
      "provider": "poe",
      "release_date": "2024-12-03"
    },
    "poe/trytako/tako": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "tako",
      "id": "trytako/tako",
      "max_input_tokens": 2048,
      "max_output_tokens": 0,
      "mode": "chat",
      "name": "Tako",
      "provider": "poe",
      "release_date": "2024-08-15"
    },
    "poe/xai/grok-2": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "grok-2",
      "id": "xai/grok-2",
      "input_cost_per_1k": 0.002,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok-2",
      "output_cost_per_1k": 0.01,
      "provider": "poe",
      "release_date": "2025-01-14"
    },
    "poe/xai/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "grok-3",
      "id": "xai/grok-3",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "poe",
      "release_date": "2025-04-11"
    },
    "poe/xai/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "grok-3",
      "id": "xai/grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "poe",
      "release_date": "2025-04-11"
    },
    "poe/xai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 256000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "poe",
      "release_date": "2025-07-10"
    },
    "poe/xai/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 2000000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Grok-4-Fast-Non-Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "poe",
      "release_date": "2025-09-16"
    },
    "poe/xai/grok-4-fast-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4-fast-reasoning",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 2000000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Grok 4 Fast Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "poe",
      "release_date": "2025-09-16"
    },
    "poe/xai/grok-4.1-fast-non-reasoning": {
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4.1-fast-non-reasoning",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok-4.1-Fast-Non-Reasoning",
      "provider": "poe",
      "release_date": "2025-11-19"
    },
    "poe/xai/grok-4.1-fast-reasoning": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4.1-fast-reasoning",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok-4.1-Fast-Reasoning",
      "provider": "poe",
      "release_date": "2025-11-19"
    },
    "poe/xai/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "grok",
      "id": "xai/grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 256000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "poe",
      "release_date": "2025-08-22"
    },
    "requesty/anthropic/claude-3-7-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-3-7-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.015,
      "provider": "requesty",
      "release_date": "2025-02-19"
    },
    "requesty/anthropic/claude-haiku-4-5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-4-5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-01",
      "max_input_tokens": 200000,
      "max_output_tokens": 62000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "requesty",
      "release_date": "2025-10-15"
    },
    "requesty/anthropic/claude-opus-4": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "requesty",
      "release_date": "2025-05-22"
    },
    "requesty/anthropic/claude-opus-4-1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4-1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "requesty",
      "release_date": "2025-08-05"
    },
    "requesty/anthropic/claude-opus-4-5": {
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4-5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "requesty",
      "release_date": "2025-11-24"
    },
    "requesty/anthropic/claude-sonnet-4": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "requesty",
      "release_date": "2025-05-22"
    },
    "requesty/anthropic/claude-sonnet-4-5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4-5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "requesty",
      "release_date": "2025-09-29"
    },
    "requesty/google/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.00055,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "requesty",
      "release_date": "2025-06-17"
    },
    "requesty/google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "cache_write_cost_per_1k": 0.002375,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "requesty",
      "release_date": "2025-06-17"
    },
    "requesty/google/gemini-3-flash-preview": {
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": null,
      "id": "google/gemini-3-flash-preview",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Flash",
      "output_cost_per_1k": 0.003,
      "provider": "requesty",
      "release_date": "2025-12-17"
    },
    "requesty/google/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.0002,
      "cache_write_cost_per_1k": 0.0045,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Pro",
      "output_cost_per_1k": 0.012,
      "provider": "requesty",
      "release_date": "2025-11-18"
    },
    "requesty/openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "openai/gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "requesty",
      "release_date": "2025-04-14"
    },
    "requesty/openai/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "openai/gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 Mini",
      "output_cost_per_1k": 0.0016,
      "provider": "requesty",
      "release_date": "2025-04-14"
    },
    "requesty/openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o Mini",
      "output_cost_per_1k": 0.0006,
      "provider": "requesty",
      "release_date": "2024-07-18"
    },
    "requesty/openai/gpt-5": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "video_input",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "image",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "requesty",
      "release_date": "2025-08-07"
    },
    "requesty/openai/gpt-5-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "openai/gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "requesty",
      "release_date": "2025-08-07"
    },
    "requesty/openai/gpt-5-nano": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "openai/gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 16000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "requesty",
      "release_date": "2025-08-07"
    },
    "requesty/openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4 Mini",
      "output_cost_per_1k": 0.0044,
      "provider": "requesty",
      "release_date": "2025-04-16"
    },
    "requesty/xai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "requesty",
      "release_date": "2025-09-09"
    },
    "requesty/xai/grok-4-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "xai/grok-4-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 2000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "requesty",
      "release_date": "2025-09-19"
    },
    "sap_ai_core/anthropic--claude-3-haiku": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic--claude-3-haiku",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "anthropic--claude-3-haiku",
      "output_cost_per_1k": 0.00125,
      "provider": "sap_ai_core",
      "release_date": "2024-03-13"
    },
    "sap_ai_core/anthropic--claude-3-opus": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic--claude-3-opus",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "anthropic--claude-3-opus",
      "output_cost_per_1k": 0.075,
      "provider": "sap_ai_core",
      "release_date": "2024-02-29"
    },
    "sap_ai_core/anthropic--claude-3-sonnet": {
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic--claude-3-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "anthropic--claude-3-sonnet",
      "output_cost_per_1k": 0.015,
      "provider": "sap_ai_core",
      "release_date": "2024-03-04"
    },
    "sap_ai_core/anthropic--claude-3.5-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic--claude-3.5-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "anthropic--claude-3.5-sonnet",
      "output_cost_per_1k": 0.015,
      "provider": "sap_ai_core",
      "release_date": "2024-10-22"
    },
    "sap_ai_core/anthropic--claude-3.7-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic--claude-3.7-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-10-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "anthropic--claude-3.7-sonnet",
      "output_cost_per_1k": 0.015,
      "provider": "sap_ai_core",
      "release_date": "2025-02-24"
    },
    "sap_ai_core/anthropic--claude-4-opus": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic--claude-4-opus",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-01-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "anthropic--claude-4-opus",
      "output_cost_per_1k": 0.075,
      "provider": "sap_ai_core",
      "release_date": "2025-05-22"
    },
    "sap_ai_core/anthropic--claude-4-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic--claude-4-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-01-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "anthropic--claude-4-sonnet",
      "output_cost_per_1k": 0.015,
      "provider": "sap_ai_core",
      "release_date": "2025-05-22"
    },
    "sap_ai_core/anthropic--claude-4.5-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic--claude-4.5-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-01-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "anthropic--claude-4.5-sonnet",
      "output_cost_per_1k": 0.015,
      "provider": "sap_ai_core",
      "release_date": "2025-09-29"
    },
    "sap_ai_core/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "gemini-2.5-flash",
      "output_cost_per_1k": 0.0025,
      "provider": "sap_ai_core",
      "release_date": "2025-03-25"
    },
    "sap_ai_core/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "gemini-2.5-pro",
      "output_cost_per_1k": 0.01,
      "provider": "sap_ai_core",
      "release_date": "2025-03-25"
    },
    "sap_ai_core/gpt-5": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "gpt-5",
      "output_cost_per_1k": 0.01,
      "provider": "sap_ai_core",
      "release_date": "2025-08-07"
    },
    "sap_ai_core/gpt-5-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "gpt-5-mini",
      "output_cost_per_1k": 0.002,
      "provider": "sap_ai_core",
      "release_date": "2025-08-07"
    },
    "sap_ai_core/gpt-5-nano": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "gpt-5-nano",
      "output_cost_per_1k": 0.0004,
      "provider": "sap_ai_core",
      "release_date": "2025-08-07"
    },
    "scaleway/bge-multilingual-gemma2": {
      "family": "gemma-2",
      "id": "bge-multilingual-gemma2",
      "input_cost_per_1k": 0.00013,
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "mode": "chat",
      "name": "BGE Multilingual Gemma2",
      "output_cost_per_1k": 0.0,
      "provider": "scaleway",
      "release_date": "2024-07-26"
    },
    "scaleway/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.0009,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "scaleway",
      "release_date": "2025-01-20"
    },
    "scaleway/gemma-3-27b-it": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "gemma-3-27b-it",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 40000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemma-3-27B-IT",
      "output_cost_per_1k": 0.0005,
      "provider": "scaleway",
      "release_date": "2024-12-01"
    },
    "scaleway/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT-OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "scaleway",
      "release_date": "2024-01-01"
    },
    "scaleway/llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "llama-3.1-8b-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Llama 3.1 8B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "scaleway",
      "release_date": "2025-01-01"
    },
    "scaleway/llama-3.3-70b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b-instruct",
      "input_cost_per_1k": 0.0009,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 100000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "scaleway",
      "release_date": "2024-12-06"
    },
    "scaleway/mistral-nemo-instruct-2407": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-nemo",
      "id": "mistral-nemo-instruct-2407",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Mistral Nemo Instruct 2407",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "scaleway",
      "release_date": "2024-07-25"
    },
    "scaleway/mistral-small-3.2-24b-instruct-2506": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral-small-3.2-24b-instruct-2506",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Mistral Small 3.2 24B Instruct (2506)",
      "open_weights": true,
      "output_cost_per_1k": 0.00035,
      "provider": "scaleway",
      "release_date": "2025-06-20"
    },
    "scaleway/pixtral-12b-2409": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "pixtral",
      "id": "pixtral-12b-2409",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Pixtral 12B 2409",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "scaleway",
      "release_date": "2024-09-25"
    },
    "scaleway/qwen3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 0.00075,
      "max_input_tokens": 260000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00225,
      "provider": "scaleway",
      "release_date": "2025-07-01"
    },
    "scaleway/qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "scaleway",
      "release_date": "2025-04"
    },
    "scaleway/voxtral-small-24b-2507": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "voxtral-small",
      "id": "voxtral-small-24b-2507",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Voxtral Small 24B 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00035,
      "provider": "scaleway",
      "release_date": "2025-07-01"
    },
    "scaleway/whisper-large-v3": {
      "capabilities": [
        "audio_input"
      ],
      "family": "whisper-large",
      "id": "whisper-large-v3",
      "input_cost_per_1k": 3e-06,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "mode": "audio_transcription",
      "name": "Whisper Large v3",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "scaleway",
      "release_date": "2023-09-01"
    },
    "siliconflow/baidu-ernie-4.5-300b-a47b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "ernie-4",
      "id": "baidu-ernie-4.5-300b-a47b",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "baidu/ERNIE-4.5-300B-A47B",
      "output_cost_per_1k": 0.0011,
      "provider": "siliconflow",
      "release_date": "2025-07-02"
    },
    "siliconflow/bytedance-seed-seed-oss-36b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "bytedance-seed-seed-oss",
      "id": "bytedance-seed-seed-oss-36b-instruct",
      "input_cost_per_1k": 0.00021,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "ByteDance-Seed/Seed-OSS-36B-Instruct",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-09-04"
    },
    "siliconflow/deepseek-ai-deepseek-r1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai-deepseek-r1",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1",
      "output_cost_per_1k": 0.00218,
      "provider": "siliconflow",
      "release_date": "2025-05-28"
    },
    "siliconflow/deepseek-ai-deepseek-r1-distill-qwen-14b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-ai-deepseek-r1-distill-qwen-14b",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "output_cost_per_1k": 0.0001,
      "provider": "siliconflow",
      "release_date": "2025-01-20"
    },
    "siliconflow/deepseek-ai-deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-ai-deepseek-r1-distill-qwen-32b",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow",
      "release_date": "2025-01-20"
    },
    "siliconflow/deepseek-ai-deepseek-r1-distill-qwen-7b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-ai-deepseek-r1-distill-qwen-7b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "output_cost_per_1k": 5e-05,
      "provider": "siliconflow",
      "release_date": "2025-01-20"
    },
    "siliconflow/deepseek-ai-deepseek-v3": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3",
      "input_cost_per_1k": 0.00025,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow",
      "release_date": "2024-12-26"
    },
    "siliconflow/deepseek-ai-deepseek-v3.1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3.1",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3.1",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow",
      "release_date": "2025-08-25"
    },
    "siliconflow/deepseek-ai-deepseek-v3.1-terminus": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3.1-terminus",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow",
      "release_date": "2025-09-29"
    },
    "siliconflow/deepseek-ai-deepseek-v3.2-exp": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3.2-exp",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3.2-Exp",
      "output_cost_per_1k": 0.00041,
      "provider": "siliconflow",
      "release_date": "2025-10-10"
    },
    "siliconflow/deepseek-ai-deepseek-vl2": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "deepseek",
      "id": "deepseek-ai-deepseek-vl2",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 4000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "deepseek-ai/deepseek-vl2",
      "output_cost_per_1k": 0.00015,
      "provider": "siliconflow",
      "release_date": "2024-12-13"
    },
    "siliconflow/inclusionai-ling-flash-2.0": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "inclusionai-ling-flash",
      "id": "inclusionai-ling-flash-2.0",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "inclusionAI/Ling-flash-2.0",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-09-18"
    },
    "siliconflow/inclusionai-ling-mini-2.0": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "inclusionai-ling-mini",
      "id": "inclusionai-ling-mini-2.0",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "inclusionAI/Ling-mini-2.0",
      "output_cost_per_1k": 0.00028,
      "provider": "siliconflow",
      "release_date": "2025-09-10"
    },
    "siliconflow/inclusionai-ring-flash-2.0": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "inclusionai-ring-flash",
      "id": "inclusionai-ring-flash-2.0",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "inclusionAI/Ring-flash-2.0",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-09-29"
    },
    "siliconflow/meta-llama-meta-llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-meta-llama-3.1-8b-instruct",
      "input_cost_per_1k": 6e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "output_cost_per_1k": 6e-05,
      "provider": "siliconflow",
      "release_date": "2025-04-23"
    },
    "siliconflow/minimaxai-minimax-m1-80k": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimaxai-minimax-m1-80k",
      "input_cost_per_1k": 0.00055,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "MiniMaxAI/MiniMax-M1-80k",
      "output_cost_per_1k": 0.0022,
      "provider": "siliconflow",
      "release_date": "2025-06-17"
    },
    "siliconflow/minimaxai-minimax-m2": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimaxai-minimax-m2",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 197000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "MiniMaxAI/MiniMax-M2",
      "output_cost_per_1k": 0.0012,
      "provider": "siliconflow",
      "release_date": "2025-10-28"
    },
    "siliconflow/moonshotai-kimi-dev-72b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi",
      "id": "moonshotai-kimi-dev-72b",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "moonshotai/Kimi-Dev-72B",
      "output_cost_per_1k": 0.00115,
      "provider": "siliconflow",
      "release_date": "2025-06-19"
    },
    "siliconflow/moonshotai-kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai-kimi-k2-instruct",
      "input_cost_per_1k": 0.00058,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "moonshotai/Kimi-K2-Instruct",
      "output_cost_per_1k": 0.00229,
      "provider": "siliconflow",
      "release_date": "2025-07-13"
    },
    "siliconflow/moonshotai-kimi-k2-instruct-0905": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai-kimi-k2-instruct-0905",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "moonshotai/Kimi-K2-Instruct-0905",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow",
      "release_date": "2025-09-08"
    },
    "siliconflow/moonshotai-kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai-kimi-k2-thinking",
      "input_cost_per_1k": 0.00055,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "moonshotai/Kimi-K2-Thinking",
      "output_cost_per_1k": 0.0025,
      "provider": "siliconflow",
      "release_date": "2025-11-07"
    },
    "siliconflow/nex-agi-deepseek-v3.1-nex-n1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "nex-agi-deepseek-v3.1-nex-n1",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow",
      "release_date": "2025-01-01"
    },
    "siliconflow/openai-gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "openai-gpt-oss",
      "id": "openai-gpt-oss-120b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "openai/gpt-oss-120b",
      "output_cost_per_1k": 0.00045,
      "provider": "siliconflow",
      "release_date": "2025-08-13"
    },
    "siliconflow/openai-gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "openai-gpt-oss",
      "id": "openai-gpt-oss-20b",
      "input_cost_per_1k": 4e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "openai/gpt-oss-20b",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow",
      "release_date": "2025-08-13"
    },
    "siliconflow/qwen-qwen2.5-14b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-14b-instruct",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-14B-Instruct",
      "output_cost_per_1k": 0.0001,
      "provider": "siliconflow",
      "release_date": "2024-09-18"
    },
    "siliconflow/qwen-qwen2.5-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-32b-instruct",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-32B-Instruct",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow",
      "release_date": "2024-09-19"
    },
    "siliconflow/qwen-qwen2.5-72b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-72b-instruct",
      "input_cost_per_1k": 0.00059,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-72B-Instruct",
      "output_cost_per_1k": 0.00059,
      "provider": "siliconflow",
      "release_date": "2024-09-18"
    },
    "siliconflow/qwen-qwen2.5-72b-instruct-128k": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-72b-instruct-128k",
      "input_cost_per_1k": 0.00059,
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-72B-Instruct-128K",
      "output_cost_per_1k": 0.00059,
      "provider": "siliconflow",
      "release_date": "2024-09-18"
    },
    "siliconflow/qwen-qwen2.5-7b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-7b-instruct",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-7B-Instruct",
      "output_cost_per_1k": 5e-05,
      "provider": "siliconflow",
      "release_date": "2024-09-18"
    },
    "siliconflow/qwen-qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen-qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow",
      "release_date": "2024-11-11"
    },
    "siliconflow/qwen-qwen2.5-vl-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen-qwen2.5-vl-32b-instruct",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-VL-32B-Instruct",
      "output_cost_per_1k": 0.00027,
      "provider": "siliconflow",
      "release_date": "2025-03-24"
    },
    "siliconflow/qwen-qwen2.5-vl-72b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen-qwen2.5-vl-72b-instruct",
      "input_cost_per_1k": 0.00059,
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-VL-72B-Instruct",
      "output_cost_per_1k": 0.00059,
      "provider": "siliconflow",
      "release_date": "2025-01-28"
    },
    "siliconflow/qwen-qwen2.5-vl-7b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen-qwen2.5-vl-7b-instruct",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-VL-7B-Instruct",
      "output_cost_per_1k": 5e-05,
      "provider": "siliconflow",
      "release_date": "2025-01-28"
    },
    "siliconflow/qwen-qwen3-14b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-14b",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-14B",
      "output_cost_per_1k": 0.00028,
      "provider": "siliconflow",
      "release_date": "2025-04-30"
    },
    "siliconflow/qwen-qwen3-235b-a22b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-235b-a22b",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-235B-A22B",
      "output_cost_per_1k": 0.00142,
      "provider": "siliconflow",
      "release_date": "2025-04-30"
    },
    "siliconflow/qwen-qwen3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "output_cost_per_1k": 0.0006,
      "provider": "siliconflow",
      "release_date": "2025-07-23"
    },
    "siliconflow/qwen-qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.00013,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "output_cost_per_1k": 0.0006,
      "provider": "siliconflow",
      "release_date": "2025-07-28"
    },
    "siliconflow/qwen-qwen3-30b-a3b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-30b-a3b",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-30B-A3B",
      "output_cost_per_1k": 0.00045,
      "provider": "siliconflow",
      "release_date": "2025-04-30"
    },
    "siliconflow/qwen-qwen3-30b-a3b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-30b-a3b-instruct-2507",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "output_cost_per_1k": 0.0003,
      "provider": "siliconflow",
      "release_date": "2025-07-30"
    },
    "siliconflow/qwen-qwen3-30b-a3b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-30b-a3b-thinking-2507",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "output_cost_per_1k": 0.0003,
      "provider": "siliconflow",
      "release_date": "2025-07-31"
    },
    "siliconflow/qwen-qwen3-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-32b",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-32B",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-04-30"
    },
    "siliconflow/qwen-qwen3-8b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-8b",
      "input_cost_per_1k": 6e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-8B",
      "output_cost_per_1k": 6e-05,
      "provider": "siliconflow",
      "release_date": "2025-04-30"
    },
    "siliconflow/qwen-qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen-qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "output_cost_per_1k": 0.00028,
      "provider": "siliconflow",
      "release_date": "2025-08-01"
    },
    "siliconflow/qwen-qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen-qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.00025,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow",
      "release_date": "2025-07-31"
    },
    "siliconflow/qwen-qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "output_cost_per_1k": 0.0014,
      "provider": "siliconflow",
      "release_date": "2025-09-18"
    },
    "siliconflow/qwen-qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-09-25"
    },
    "siliconflow/qwen-qwen3-omni-30b-a3b-captioner": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen-qwen3-omni-30b-a3b-captioner",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Captioner",
      "output_cost_per_1k": 0.0004,
      "provider": "siliconflow",
      "release_date": "2025-10-04"
    },
    "siliconflow/qwen-qwen3-omni-30b-a3b-instruct": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen-qwen3-omni-30b-a3b-instruct",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "output_cost_per_1k": 0.0004,
      "provider": "siliconflow",
      "release_date": "2025-10-04"
    },
    "siliconflow/qwen-qwen3-omni-30b-a3b-thinking": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen-qwen3-omni-30b-a3b-thinking",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "output_cost_per_1k": 0.0004,
      "provider": "siliconflow",
      "release_date": "2025-10-04"
    },
    "siliconflow/qwen-qwen3-vl-235b-a22b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-235b-a22b-instruct",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "output_cost_per_1k": 0.0015,
      "provider": "siliconflow",
      "release_date": "2025-10-04"
    },
    "siliconflow/qwen-qwen3-vl-235b-a22b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-235b-a22b-thinking",
      "input_cost_per_1k": 0.00045,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "output_cost_per_1k": 0.0035,
      "provider": "siliconflow",
      "release_date": "2025-10-04"
    },
    "siliconflow/qwen-qwen3-vl-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-30b-a3b-instruct",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow",
      "release_date": "2025-10-05"
    },
    "siliconflow/qwen-qwen3-vl-30b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-30b-a3b-thinking",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow",
      "release_date": "2025-10-11"
    },
    "siliconflow/qwen-qwen3-vl-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-32b-instruct",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-32B-Instruct",
      "output_cost_per_1k": 0.0006,
      "provider": "siliconflow",
      "release_date": "2025-10-21"
    },
    "siliconflow/qwen-qwen3-vl-32b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-32b-thinking",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-32B-Thinking",
      "output_cost_per_1k": 0.0015,
      "provider": "siliconflow",
      "release_date": "2025-10-21"
    },
    "siliconflow/qwen-qwen3-vl-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-8b-instruct",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-8B-Instruct",
      "output_cost_per_1k": 0.00068,
      "provider": "siliconflow",
      "release_date": "2025-10-15"
    },
    "siliconflow/qwen-qwen3-vl-8b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-8b-thinking",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-8B-Thinking",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow",
      "release_date": "2025-10-15"
    },
    "siliconflow/qwen-qwq-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwen-qwq-32b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/QwQ-32B",
      "output_cost_per_1k": 0.00058,
      "provider": "siliconflow",
      "release_date": "2025-03-06"
    },
    "siliconflow/stepfun-ai-step3": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "stepfun-ai-step3",
      "id": "stepfun-ai-step3",
      "input_cost_per_1k": 0.00057,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "stepfun-ai/step3",
      "output_cost_per_1k": 0.00142,
      "provider": "siliconflow",
      "release_date": "2025-08-06"
    },
    "siliconflow/tencent-hunyuan-a13b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "hunyuan",
      "id": "tencent-hunyuan-a13b-instruct",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "tencent/Hunyuan-A13B-Instruct",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-06-30"
    },
    "siliconflow/tencent-hunyuan-mt-7b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "hunyuan",
      "id": "tencent-hunyuan-mt-7b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "mode": "chat",
      "name": "tencent/Hunyuan-MT-7B",
      "output_cost_per_1k": 0.0,
      "provider": "siliconflow",
      "release_date": "2025-09-18"
    },
    "siliconflow/thudm-glm-4-32b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4",
      "id": "thudm-glm-4-32b-0414",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "mode": "chat",
      "name": "THUDM/GLM-4-32B-0414",
      "output_cost_per_1k": 0.00027,
      "provider": "siliconflow",
      "release_date": "2025-04-18"
    },
    "siliconflow/thudm-glm-4-9b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4",
      "id": "thudm-glm-4-9b-0414",
      "input_cost_per_1k": 8.6e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "mode": "chat",
      "name": "THUDM/GLM-4-9B-0414",
      "output_cost_per_1k": 8.6e-05,
      "provider": "siliconflow",
      "release_date": "2025-04-18"
    },
    "siliconflow/thudm-glm-4.1v-9b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "glm-4v",
      "id": "thudm-glm-4.1v-9b-thinking",
      "input_cost_per_1k": 3.5e-05,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "THUDM/GLM-4.1V-9B-Thinking",
      "output_cost_per_1k": 0.00014,
      "provider": "siliconflow",
      "release_date": "2025-07-04"
    },
    "siliconflow/thudm-glm-z1-32b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm-z1",
      "id": "thudm-glm-z1-32b-0414",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "THUDM/GLM-Z1-32B-0414",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow",
      "release_date": "2025-04-18"
    },
    "siliconflow/thudm-glm-z1-9b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm-z1",
      "id": "thudm-glm-z1-9b-0414",
      "input_cost_per_1k": 8.6e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "THUDM/GLM-Z1-9B-0414",
      "output_cost_per_1k": 8.6e-05,
      "provider": "siliconflow",
      "release_date": "2025-04-18"
    },
    "siliconflow/z-ai-glm-4.5": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "z-ai-glm-4.5",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "z-ai/GLM-4.5",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow",
      "release_date": "2025-07-28"
    },
    "siliconflow/z-ai-glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "z-ai-glm-4.5-air",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "z-ai/GLM-4.5-Air",
      "output_cost_per_1k": 0.00086,
      "provider": "siliconflow",
      "release_date": "2025-07-28"
    },
    "siliconflow/zai-org-glm-4.5": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai-org-glm-4.5",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "zai-org/GLM-4.5",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow",
      "release_date": "2025-07-28"
    },
    "siliconflow/zai-org-glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai-org-glm-4.5-air",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "zai-org/GLM-4.5-Air",
      "output_cost_per_1k": 0.00086,
      "provider": "siliconflow",
      "release_date": "2025-07-28"
    },
    "siliconflow/zai-org-glm-4.5v": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "zai-org-glm-4.5v",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "zai-org/GLM-4.5V",
      "output_cost_per_1k": 0.00086,
      "provider": "siliconflow",
      "release_date": "2025-08-13"
    },
    "siliconflow/zai-org-glm-4.6": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org-glm-4.6",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 205000,
      "max_output_tokens": 205000,
      "mode": "chat",
      "name": "zai-org/GLM-4.6",
      "output_cost_per_1k": 0.0019,
      "provider": "siliconflow",
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/baidu-ernie-4.5-300b-a47b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "ernie-4",
      "id": "baidu-ernie-4.5-300b-a47b",
      "input_cost_per_1k": 0.00028,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "baidu/ERNIE-4.5-300B-A47B",
      "output_cost_per_1k": 0.0011,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-02"
    },
    "siliconflow_cn/bytedance-seed-seed-oss-36b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "bytedance-seed-seed-oss",
      "id": "bytedance-seed-seed-oss-36b-instruct",
      "input_cost_per_1k": 0.00021,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "ByteDance-Seed/Seed-OSS-36B-Instruct",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-04"
    },
    "siliconflow_cn/deepseek-ai-deepseek-r1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai-deepseek-r1",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1",
      "output_cost_per_1k": 0.00218,
      "provider": "siliconflow_cn",
      "release_date": "2025-05-28"
    },
    "siliconflow_cn/deepseek-ai-deepseek-r1-distill-qwen-14b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-ai-deepseek-r1-distill-qwen-14b",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "output_cost_per_1k": 0.0001,
      "provider": "siliconflow_cn",
      "release_date": "2025-01-20"
    },
    "siliconflow_cn/deepseek-ai-deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-ai-deepseek-r1-distill-qwen-32b",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow_cn",
      "release_date": "2025-01-20"
    },
    "siliconflow_cn/deepseek-ai-deepseek-r1-distill-qwen-7b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-ai-deepseek-r1-distill-qwen-7b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "output_cost_per_1k": 5e-05,
      "provider": "siliconflow_cn",
      "release_date": "2025-01-20"
    },
    "siliconflow_cn/deepseek-ai-deepseek-v3": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3",
      "input_cost_per_1k": 0.00025,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow_cn",
      "release_date": "2024-12-26"
    },
    "siliconflow_cn/deepseek-ai-deepseek-v3.1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3.1",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3.1",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow_cn",
      "release_date": "2025-08-25"
    },
    "siliconflow_cn/deepseek-ai-deepseek-v3.1-terminus": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3.1-terminus",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-29"
    },
    "siliconflow_cn/deepseek-ai-deepseek-v3.2-exp": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai-deepseek-v3.2-exp",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "mode": "chat",
      "name": "deepseek-ai/DeepSeek-V3.2-Exp",
      "output_cost_per_1k": 0.00041,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-10"
    },
    "siliconflow_cn/deepseek-ai-deepseek-vl2": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "deepseek",
      "id": "deepseek-ai-deepseek-vl2",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 4000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "deepseek-ai/deepseek-vl2",
      "output_cost_per_1k": 0.00015,
      "provider": "siliconflow_cn",
      "release_date": "2024-12-13"
    },
    "siliconflow_cn/inclusionai-ling-flash-2.0": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "inclusionai-ling-flash",
      "id": "inclusionai-ling-flash-2.0",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "inclusionAI/Ling-flash-2.0",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-18"
    },
    "siliconflow_cn/inclusionai-ling-mini-2.0": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "inclusionai-ling-mini",
      "id": "inclusionai-ling-mini-2.0",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "inclusionAI/Ling-mini-2.0",
      "output_cost_per_1k": 0.00028,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-10"
    },
    "siliconflow_cn/inclusionai-ring-flash-2.0": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "inclusionai-ring-flash",
      "id": "inclusionai-ring-flash-2.0",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "inclusionAI/Ring-flash-2.0",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-29"
    },
    "siliconflow_cn/meta-llama-meta-llama-3.1-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama-meta-llama-3.1-8b-instruct",
      "input_cost_per_1k": 6e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "output_cost_per_1k": 6e-05,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-23"
    },
    "siliconflow_cn/minimaxai-minimax-m1-80k": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimaxai-minimax-m1-80k",
      "input_cost_per_1k": 0.00055,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "MiniMaxAI/MiniMax-M1-80k",
      "output_cost_per_1k": 0.0022,
      "provider": "siliconflow_cn",
      "release_date": "2025-06-17"
    },
    "siliconflow_cn/minimaxai-minimax-m2": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimaxai-minimax-m2",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 197000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "MiniMaxAI/MiniMax-M2",
      "output_cost_per_1k": 0.0012,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-28"
    },
    "siliconflow_cn/moonshotai-kimi-dev-72b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi",
      "id": "moonshotai-kimi-dev-72b",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "moonshotai/Kimi-Dev-72B",
      "output_cost_per_1k": 0.00115,
      "provider": "siliconflow_cn",
      "release_date": "2025-06-19"
    },
    "siliconflow_cn/moonshotai-kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai-kimi-k2-instruct",
      "input_cost_per_1k": 0.00058,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "moonshotai/Kimi-K2-Instruct",
      "output_cost_per_1k": 0.00229,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-13"
    },
    "siliconflow_cn/moonshotai-kimi-k2-instruct-0905": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai-kimi-k2-instruct-0905",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "moonshotai/Kimi-K2-Instruct-0905",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-08"
    },
    "siliconflow_cn/moonshotai-kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai-kimi-k2-thinking",
      "input_cost_per_1k": 0.00055,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "moonshotai/Kimi-K2-Thinking",
      "output_cost_per_1k": 0.0025,
      "provider": "siliconflow_cn",
      "release_date": "2025-11-07"
    },
    "siliconflow_cn/nex-agi-deepseek-v3.1-nex-n1": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "nex-agi-deepseek-v3.1-nex-n1",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow_cn",
      "release_date": "2025-01-01"
    },
    "siliconflow_cn/openai-gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "openai-gpt-oss",
      "id": "openai-gpt-oss-120b",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "openai/gpt-oss-120b",
      "output_cost_per_1k": 0.00045,
      "provider": "siliconflow_cn",
      "release_date": "2025-08-13"
    },
    "siliconflow_cn/openai-gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "openai-gpt-oss",
      "id": "openai-gpt-oss-20b",
      "input_cost_per_1k": 4e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "openai/gpt-oss-20b",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow_cn",
      "release_date": "2025-08-13"
    },
    "siliconflow_cn/qwen-qwen2.5-14b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-14b-instruct",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-14B-Instruct",
      "output_cost_per_1k": 0.0001,
      "provider": "siliconflow_cn",
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/qwen-qwen2.5-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-32b-instruct",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-32B-Instruct",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow_cn",
      "release_date": "2024-09-19"
    },
    "siliconflow_cn/qwen-qwen2.5-72b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-72b-instruct",
      "input_cost_per_1k": 0.00059,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-72B-Instruct",
      "output_cost_per_1k": 0.00059,
      "provider": "siliconflow_cn",
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/qwen-qwen2.5-72b-instruct-128k": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-72b-instruct-128k",
      "input_cost_per_1k": 0.00059,
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-72B-Instruct-128K",
      "output_cost_per_1k": 0.00059,
      "provider": "siliconflow_cn",
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/qwen-qwen2.5-7b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5",
      "id": "qwen-qwen2.5-7b-instruct",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-7B-Instruct",
      "output_cost_per_1k": 5e-05,
      "provider": "siliconflow_cn",
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/qwen-qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen-qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "output_cost_per_1k": 0.00018,
      "provider": "siliconflow_cn",
      "release_date": "2024-11-11"
    },
    "siliconflow_cn/qwen-qwen2.5-vl-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen-qwen2.5-vl-32b-instruct",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-VL-32B-Instruct",
      "output_cost_per_1k": 0.00027,
      "provider": "siliconflow_cn",
      "release_date": "2025-03-24"
    },
    "siliconflow_cn/qwen-qwen2.5-vl-72b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen-qwen2.5-vl-72b-instruct",
      "input_cost_per_1k": 0.00059,
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-VL-72B-Instruct",
      "output_cost_per_1k": 0.00059,
      "provider": "siliconflow_cn",
      "release_date": "2025-01-28"
    },
    "siliconflow_cn/qwen-qwen2.5-vl-7b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen2.5-vl",
      "id": "qwen-qwen2.5-vl-7b-instruct",
      "input_cost_per_1k": 5e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "mode": "chat",
      "name": "Qwen/Qwen2.5-VL-7B-Instruct",
      "output_cost_per_1k": 5e-05,
      "provider": "siliconflow_cn",
      "release_date": "2025-01-28"
    },
    "siliconflow_cn/qwen-qwen3-14b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-14b",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-14B",
      "output_cost_per_1k": 0.00028,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/qwen-qwen3-235b-a22b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-235b-a22b",
      "input_cost_per_1k": 0.00035,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-235B-A22B",
      "output_cost_per_1k": 0.00142,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/qwen-qwen3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "output_cost_per_1k": 0.0006,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-23"
    },
    "siliconflow_cn/qwen-qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.00013,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "output_cost_per_1k": 0.0006,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/qwen-qwen3-30b-a3b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-30b-a3b",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-30B-A3B",
      "output_cost_per_1k": 0.00045,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/qwen-qwen3-30b-a3b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-30b-a3b-instruct-2507",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "output_cost_per_1k": 0.0003,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-30"
    },
    "siliconflow_cn/qwen-qwen3-30b-a3b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-30b-a3b-thinking-2507",
      "input_cost_per_1k": 9e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "output_cost_per_1k": 0.0003,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-31"
    },
    "siliconflow_cn/qwen-qwen3-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-32b",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-32B",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/qwen-qwen3-8b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-8b",
      "input_cost_per_1k": 6e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/Qwen3-8B",
      "output_cost_per_1k": 6e-05,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/qwen-qwen3-coder-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen-qwen3-coder-30b-a3b-instruct",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "output_cost_per_1k": 0.00028,
      "provider": "siliconflow_cn",
      "release_date": "2025-08-01"
    },
    "siliconflow_cn/qwen-qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen-qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.00025,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-31"
    },
    "siliconflow_cn/qwen-qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "output_cost_per_1k": 0.0014,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-18"
    },
    "siliconflow_cn/qwen-qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen-qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-25"
    },
    "siliconflow_cn/qwen-qwen3-omni-30b-a3b-captioner": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen-qwen3-omni-30b-a3b-captioner",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Captioner",
      "output_cost_per_1k": 0.0004,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/qwen-qwen3-omni-30b-a3b-instruct": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen-qwen3-omni-30b-a3b-instruct",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "output_cost_per_1k": 0.0004,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/qwen-qwen3-omni-30b-a3b-thinking": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-omni",
      "id": "qwen-qwen3-omni-30b-a3b-thinking",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "output_cost_per_1k": 0.0004,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/qwen-qwen3-vl-235b-a22b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-235b-a22b-instruct",
      "input_cost_per_1k": 0.0003,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "output_cost_per_1k": 0.0015,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/qwen-qwen3-vl-235b-a22b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-235b-a22b-thinking",
      "input_cost_per_1k": 0.00045,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "output_cost_per_1k": 0.0035,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/qwen-qwen3-vl-30b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-30b-a3b-instruct",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-05"
    },
    "siliconflow_cn/qwen-qwen3-vl-30b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-30b-a3b-thinking",
      "input_cost_per_1k": 0.00029,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "output_cost_per_1k": 0.001,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-11"
    },
    "siliconflow_cn/qwen-qwen3-vl-32b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-32b-instruct",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-32B-Instruct",
      "output_cost_per_1k": 0.0006,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-21"
    },
    "siliconflow_cn/qwen-qwen3-vl-32b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-32b-thinking",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-32B-Thinking",
      "output_cost_per_1k": 0.0015,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-21"
    },
    "siliconflow_cn/qwen-qwen3-vl-8b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-8b-instruct",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-8B-Instruct",
      "output_cost_per_1k": 0.00068,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-15"
    },
    "siliconflow_cn/qwen-qwen3-vl-8b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "qwen-qwen3-vl-8b-thinking",
      "input_cost_per_1k": 0.00018,
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "mode": "chat",
      "name": "Qwen/Qwen3-VL-8B-Thinking",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-15"
    },
    "siliconflow_cn/qwen-qwq-32b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwq",
      "id": "qwen-qwq-32b",
      "input_cost_per_1k": 0.00015,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "Qwen/QwQ-32B",
      "output_cost_per_1k": 0.00058,
      "provider": "siliconflow_cn",
      "release_date": "2025-03-06"
    },
    "siliconflow_cn/stepfun-ai-step3": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "stepfun-ai-step3",
      "id": "stepfun-ai-step3",
      "input_cost_per_1k": 0.00057,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "stepfun-ai/step3",
      "output_cost_per_1k": 0.00142,
      "provider": "siliconflow_cn",
      "release_date": "2025-08-06"
    },
    "siliconflow_cn/tencent-hunyuan-a13b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "hunyuan",
      "id": "tencent-hunyuan-a13b-instruct",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "tencent/Hunyuan-A13B-Instruct",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-06-30"
    },
    "siliconflow_cn/tencent-hunyuan-mt-7b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "hunyuan",
      "id": "tencent-hunyuan-mt-7b",
      "input_cost_per_1k": 0.0,
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "mode": "chat",
      "name": "tencent/Hunyuan-MT-7B",
      "output_cost_per_1k": 0.0,
      "provider": "siliconflow_cn",
      "release_date": "2025-09-18"
    },
    "siliconflow_cn/thudm-glm-4-32b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4",
      "id": "thudm-glm-4-32b-0414",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "mode": "chat",
      "name": "THUDM/GLM-4-32B-0414",
      "output_cost_per_1k": 0.00027,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/thudm-glm-4-9b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4",
      "id": "thudm-glm-4-9b-0414",
      "input_cost_per_1k": 8.6e-05,
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "mode": "chat",
      "name": "THUDM/GLM-4-9B-0414",
      "output_cost_per_1k": 8.6e-05,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/thudm-glm-4.1v-9b-thinking": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "glm-4v",
      "id": "thudm-glm-4.1v-9b-thinking",
      "input_cost_per_1k": 3.5e-05,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "THUDM/GLM-4.1V-9B-Thinking",
      "output_cost_per_1k": 0.00014,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-04"
    },
    "siliconflow_cn/thudm-glm-z1-32b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm-z1",
      "id": "thudm-glm-z1-32b-0414",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "THUDM/GLM-Z1-32B-0414",
      "output_cost_per_1k": 0.00057,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/thudm-glm-z1-9b-0414": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "glm-z1",
      "id": "thudm-glm-z1-9b-0414",
      "input_cost_per_1k": 8.6e-05,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "THUDM/GLM-Z1-9B-0414",
      "output_cost_per_1k": 8.6e-05,
      "provider": "siliconflow_cn",
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/z-ai-glm-4.5": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "z-ai-glm-4.5",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "z-ai/GLM-4.5",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/z-ai-glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "z-ai-glm-4.5-air",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "z-ai/GLM-4.5-Air",
      "output_cost_per_1k": 0.00086,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/zai-org-glm-4.5": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai-org-glm-4.5",
      "input_cost_per_1k": 0.0004,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "zai-org/GLM-4.5",
      "output_cost_per_1k": 0.002,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/zai-org-glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai-org-glm-4.5-air",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "zai-org/GLM-4.5-Air",
      "output_cost_per_1k": 0.00086,
      "provider": "siliconflow_cn",
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/zai-org-glm-4.5v": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "zai-org-glm-4.5v",
      "input_cost_per_1k": 0.00014,
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "mode": "chat",
      "name": "zai-org/GLM-4.5V",
      "output_cost_per_1k": 0.00086,
      "provider": "siliconflow_cn",
      "release_date": "2025-08-13"
    },
    "siliconflow_cn/zai-org-glm-4.6": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org-glm-4.6",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 205000,
      "max_output_tokens": 205000,
      "mode": "chat",
      "name": "zai-org/GLM-4.6",
      "output_cost_per_1k": 0.0019,
      "provider": "siliconflow_cn",
      "release_date": "2025-10-04"
    },
    "submodel/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "output_cost_per_1k": 0.0008,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/deepseek-ai/DeepSeek-R1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_1k": 0.0005,
      "max_input_tokens": 75000,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek R1 0528",
      "output_cost_per_1k": 0.00215,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/deepseek-ai/DeepSeek-V3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 75000,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3 0324",
      "output_cost_per_1k": 0.0008,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/deepseek-ai/DeepSeek-V3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3.1",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 75000,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "output_cost_per_1k": 0.0008,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "submodel",
      "release_date": "2025-08-23"
    },
    "submodel/zai-org/GLM-4.5-Air": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai-org/GLM-4.5-Air",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "submodel",
      "release_date": "2025-07-28"
    },
    "submodel/zai-org/GLM-4.5-FP8": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai-org/GLM-4.5-FP8",
      "input_cost_per_1k": 0.0002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM 4.5 FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "submodel",
      "release_date": "2025-07-28"
    },
    "synthetic/hf:MiniMaxAI/MiniMax-M2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "hf:MiniMaxAI/MiniMax-M2",
      "input_cost_per_1k": 0.00055,
      "max_input_tokens": 196608,
      "max_output_tokens": 131000,
      "mode": "chat",
      "name": "MiniMax-M2",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "synthetic",
      "release_date": "2025-10-27"
    },
    "synthetic/hf:Qwen/Qwen2.5-Coder-32B-Instruct": {
      "capabilities": [
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen2.5-Coder-32B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0008,
      "provider": "synthetic",
      "release_date": "2024-11-11"
    },
    "synthetic/hf:Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen 3 235B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "synthetic",
      "release_date": "2025-04-28"
    },
    "synthetic/hf:Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.00065,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen3 235B A22B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "synthetic",
      "release_date": "2025-07-25"
    },
    "synthetic/hf:Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Qwen 3 Coder 480B",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "synthetic",
      "release_date": "2025-07-23"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-R1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "hf:deepseek-ai/DeepSeek-R1",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek R1",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "synthetic",
      "release_date": "2025-01-20"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-R1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "hf:deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek R1 (0528)",
      "output_cost_per_1k": 0.008,
      "provider": "synthetic",
      "release_date": "2025-08-01"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "hf:deepseek-ai/DeepSeek-V3",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek V3",
      "open_weights": true,
      "output_cost_per_1k": 0.00125,
      "provider": "synthetic",
      "release_date": "2025-01-20"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "hf:deepseek-ai/DeepSeek-V3-0324",
      "input_cost_per_1k": 0.0012,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek V3 (0324)",
      "output_cost_per_1k": 0.0012,
      "provider": "synthetic",
      "release_date": "2025-08-01"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3.1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "hf:deepseek-ai/DeepSeek-V3.1",
      "input_cost_per_1k": 0.00056,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "output_cost_per_1k": 0.00168,
      "provider": "synthetic",
      "release_date": "2025-08-21"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3.1-Terminus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "hf:deepseek-ai/DeepSeek-V3.1-Terminus",
      "input_cost_per_1k": 0.0012,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus",
      "output_cost_per_1k": 0.0012,
      "provider": "synthetic",
      "release_date": "2025-09-22"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3.2": {
      "cache_read_cost_per_1k": 0.00027,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "hf:deepseek-ai/DeepSeek-V3.2",
      "input_cost_per_1k": 0.00027,
      "max_input_tokens": 162816,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.0004,
      "provider": "synthetic",
      "release_date": "2025-12-01"
    },
    "synthetic/hf:meta-llama/Llama-3.1-405B-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "hf:meta-llama/Llama-3.1-405B-Instruct",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.1-405B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "synthetic",
      "release_date": "2024-07-23"
    },
    "synthetic/hf:meta-llama/Llama-3.1-70B-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "hf:meta-llama/Llama-3.1-70B-Instruct",
      "input_cost_per_1k": 0.0009,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.1-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "synthetic",
      "release_date": "2024-07-23"
    },
    "synthetic/hf:meta-llama/Llama-3.1-8B-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "hf:meta-llama/Llama-3.1-8B-Instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.1-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "synthetic",
      "release_date": "2024-07-23"
    },
    "synthetic/hf:meta-llama/Llama-3.3-70B-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "hf:meta-llama/Llama-3.3-70B-Instruct",
      "input_cost_per_1k": 0.0009,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "synthetic",
      "release_date": "2024-12-06"
    },
    "synthetic/hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 524000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.00088,
      "provider": "synthetic",
      "release_date": "2025-04-05"
    },
    "synthetic/hf:meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 328000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-4-Scout-17B-16E-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "synthetic",
      "release_date": "2025-04-05"
    },
    "synthetic/hf:moonshotai/Kimi-K2-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "hf:moonshotai/Kimi-K2-Instruct",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2",
      "open_weights": true,
      "output_cost_per_1k": 0.0025,
      "provider": "synthetic",
      "release_date": "2025-07-11"
    },
    "synthetic/hf:moonshotai/Kimi-K2-Instruct-0905": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "hf:moonshotai/Kimi-K2-Instruct-0905",
      "input_cost_per_1k": 0.0012,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2 0905",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "synthetic",
      "release_date": "2025-09-05"
    },
    "synthetic/hf:moonshotai/Kimi-K2-Thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "hf:moonshotai/Kimi-K2-Thinking",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "synthetic",
      "release_date": "2025-11-07"
    },
    "synthetic/hf:openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "hf:openai/gpt-oss-120b",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "synthetic",
      "release_date": "2025-08-05"
    },
    "synthetic/hf:zai-org/GLM-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "hf:zai-org/GLM-4.5",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "synthetic",
      "release_date": "2025-07-28"
    },
    "synthetic/hf:zai-org/GLM-4.6": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "hf:zai-org/GLM-4.6",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "synthetic",
      "release_date": "2025-09-30"
    },
    "synthetic/hf:zai-org/GLM-4.7": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "hf:zai-org/GLM-4.7",
      "input_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "GLM 4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.00219,
      "provider": "synthetic",
      "release_date": "2025-12-22"
    },
    "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "togetherai",
      "release_date": "2025-07-23"
    },
    "togetherai/deepseek-ai/DeepSeek-R1": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 163839,
      "max_output_tokens": 12288,
      "mode": "chat",
      "name": "DeepSeek R1",
      "open_weights": true,
      "output_cost_per_1k": 0.007,
      "provider": "togetherai",
      "release_date": "2024-12-26"
    },
    "togetherai/deepseek-ai/DeepSeek-V3": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 12288,
      "mode": "chat",
      "name": "DeepSeek V3",
      "open_weights": true,
      "output_cost_per_1k": 0.00125,
      "provider": "togetherai",
      "release_date": "2025-01-20"
    },
    "togetherai/deepseek-ai/DeepSeek-V3-1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3-1",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 12288,
      "mode": "chat",
      "name": "DeepSeek V3.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0017,
      "provider": "togetherai",
      "release_date": "2025-08-21"
    },
    "togetherai/essentialai/Rnj-1-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "rnj",
      "id": "essentialai/Rnj-1-Instruct",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Rnj-1 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "togetherai",
      "release_date": "2025-12-05"
    },
    "togetherai/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "input_cost_per_1k": 0.00088,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Llama 3.3 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00088,
      "provider": "togetherai",
      "release_date": "2024-12-06"
    },
    "togetherai/moonshotai/Kimi-K2-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "togetherai",
      "release_date": "2025-07-14"
    },
    "togetherai/moonshotai/Kimi-K2-Thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Thinking",
      "input_cost_per_1k": 0.0012,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.004,
      "provider": "togetherai",
      "release_date": "2025-11-06"
    },
    "togetherai/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "togetherai",
      "release_date": "2025-08-05"
    },
    "togetherai/zai-org/GLM-4.6": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org/GLM-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "togetherai",
      "release_date": "2025-09-30"
    },
    "upstage/solar-mini": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "solar-mini",
      "id": "solar-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "solar-mini",
      "output_cost_per_1k": 0.00015,
      "provider": "upstage",
      "release_date": "2024-06-12"
    },
    "upstage/solar-pro2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "solar-pro",
      "id": "solar-pro2",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "solar-pro2",
      "output_cost_per_1k": 0.00025,
      "provider": "upstage",
      "release_date": "2025-05-20"
    },
    "v0/v0-1.0-md": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "v0",
      "id": "v0-1.0-md",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "v0-1.0-md",
      "output_cost_per_1k": 0.015,
      "provider": "v0",
      "release_date": "2025-05-22"
    },
    "v0/v0-1.5-lg": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "v0",
      "id": "v0-1.5-lg",
      "input_cost_per_1k": 0.015,
      "max_input_tokens": 512000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "v0-1.5-lg",
      "output_cost_per_1k": 0.075,
      "provider": "v0",
      "release_date": "2025-06-09"
    },
    "v0/v0-1.5-md": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "v0",
      "id": "v0-1.5-md",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "v0-1.5-md",
      "output_cost_per_1k": 0.015,
      "provider": "v0",
      "release_date": "2025-06-09"
    },
    "venice/claude-opus-45": {
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "claude-opus-45",
      "input_cost_per_1k": 0.006,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.03,
      "provider": "venice",
      "release_date": "2024-12-05"
    },
    "venice/deepseek-v3.2": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-v3.2",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 163840,
      "max_output_tokens": 40960,
      "mode": "chat",
      "name": "DeepSeek V3.2",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "venice",
      "release_date": "2025-12-07"
    },
    "venice/gemini-3-flash-preview": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "gemini-3-flash-preview",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 3 Flash Preview",
      "output_cost_per_1k": 0.00375,
      "provider": "venice",
      "release_date": "2025-12-13"
    },
    "venice/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.000625,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "gemini-3-pro-preview",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.015,
      "provider": "venice",
      "release_date": "2024-06-07"
    },
    "venice/google-gemma-3-27b-it": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gemma-3",
      "id": "google-gemma-3-27b-it",
      "input_cost_per_1k": 0.00012,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "mode": "chat",
      "name": "Google Gemma 3 27B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "venice",
      "release_date": "2024-04-01"
    },
    "venice/grok-41-fast": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-41-fast",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Grok 4.1 Fast",
      "output_cost_per_1k": 0.00125,
      "provider": "venice",
      "release_date": "2025-04-29"
    },
    "venice/hermes-3-llama-3.1-405b": {
      "capabilities": [
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "hermes-3-llama-3.1-405b",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Hermes 3 Llama 3.1 405b",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "venice",
      "release_date": "2024-04-01"
    },
    "venice/kimi-k2-thinking": {
      "cache_read_cost_per_1k": 0.0001875,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-thinking",
      "input_cost_per_1k": 0.00075,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0032,
      "provider": "venice",
      "release_date": "2024-06-07"
    },
    "venice/llama-3.2-3b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "llama-3.2",
      "id": "llama-3.2-3b",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama 3.2 3B",
      "open_weights": true,
      "output_cost_per_1k": 0.0006,
      "provider": "venice",
      "release_date": "2024-10-03"
    },
    "venice/llama-3.3-70b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "llama-3.3-70b",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama 3.3 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "venice",
      "release_date": "2024-12-09"
    },
    "venice/mistral-31-24b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "mistral",
      "id": "mistral-31-24b",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Venice Medium",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "venice",
      "release_date": "2025-03-18"
    },
    "venice/openai-gpt-52": {
      "cache_read_cost_per_1k": 0.000219,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-5",
      "id": "openai-gpt-52",
      "input_cost_per_1k": 0.00219,
      "knowledge_cutoff": "2025-08-31",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "GPT-5.2",
      "output_cost_per_1k": 0.0175,
      "provider": "venice",
      "release_date": "2024-12-11"
    },
    "venice/openai-gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "openai-gpt-oss",
      "id": "openai-gpt-oss-120b",
      "input_cost_per_1k": 7e-05,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "OpenAI GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "venice",
      "release_date": "2024-04-01"
    },
    "venice/qwen3-235b-a22b-instruct-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-instruct-2507",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen 3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.00075,
      "provider": "venice",
      "release_date": "2025-04-29"
    },
    "venice/qwen3-235b-a22b-thinking-2507": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-235b-a22b-thinking-2507",
      "input_cost_per_1k": 0.00045,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen 3 235B A22B Thinking 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0035,
      "provider": "venice",
      "release_date": "2025-04-29"
    },
    "venice/qwen3-4b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-4b",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Venice Small",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "venice",
      "release_date": "2025-04-29"
    },
    "venice/qwen3-coder-480b-a35b-instruct": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen3-coder-480b-a35b-instruct",
      "input_cost_per_1k": 0.00075,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen 3 Coder 480b",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "venice",
      "release_date": "2025-04-29"
    },
    "venice/qwen3-next-80b": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "qwen3",
      "id": "qwen3-next-80b",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Qwen 3 Next 80b",
      "open_weights": true,
      "output_cost_per_1k": 0.0019,
      "provider": "venice",
      "release_date": "2025-04-29"
    },
    "venice/venice-uncensored": {
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "family": "venice-uncensored",
      "id": "venice-uncensored",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Venice Uncensored 1.1",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "venice",
      "release_date": "2025-03-18"
    },
    "venice/zai-org-glm-4.6": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai-org-glm-4.6",
      "input_cost_per_1k": 0.00085,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.00275,
      "provider": "venice",
      "release_date": "2024-04-01"
    },
    "venice/zai-org-glm-4.6v": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "glm-4.6",
      "id": "zai-org-glm-4.6v",
      "input_cost_per_1k": 0.00039,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM 4.6V",
      "open_weights": true,
      "output_cost_per_1k": 0.00113,
      "provider": "venice",
      "release_date": "2024-12-10"
    },
    "venice/zai-org-glm-4.7": {
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "zai-org-glm-4.7",
      "input_cost_per_1k": 0.00085,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM 4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.00275,
      "provider": "venice",
      "release_date": "2024-04-01"
    },
    "vercel/alibaba/qwen3-coder-plus": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "alibaba/qwen3-coder-plus",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "mode": "chat",
      "name": "Qwen3 Coder Plus",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "vercel",
      "release_date": "2025-07-23"
    },
    "vercel/alibaba/qwen3-max": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "alibaba/qwen3-max",
      "input_cost_per_1k": 0.0012,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 Max",
      "output_cost_per_1k": 0.006,
      "provider": "vercel",
      "release_date": "2025-09-23"
    },
    "vercel/alibaba/qwen3-next-80b-a3b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "alibaba/qwen3-next-80b-a3b-instruct",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.002,
      "provider": "vercel",
      "release_date": "2025-09-12"
    },
    "vercel/alibaba/qwen3-next-80b-a3b-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "alibaba/qwen3-next-80b-a3b-thinking",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Qwen3 Next 80B A3B Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "vercel",
      "release_date": "2025-09-12"
    },
    "vercel/alibaba/qwen3-vl-instruct": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "alibaba/qwen3-vl-instruct",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 129024,
      "mode": "chat",
      "name": "Qwen3 VL Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0028,
      "provider": "vercel",
      "release_date": "2025-09-24"
    },
    "vercel/alibaba/qwen3-vl-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "qwen3-vl",
      "id": "alibaba/qwen3-vl-thinking",
      "input_cost_per_1k": 0.0007,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 131072,
      "max_output_tokens": 129024,
      "mode": "chat",
      "name": "Qwen3 VL Thinking",
      "open_weights": true,
      "output_cost_per_1k": 0.0084,
      "provider": "vercel",
      "release_date": "2025-09-24"
    },
    "vercel/amazon/nova-lite": {
      "cache_read_cost_per_1k": 1.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nova-lite",
      "id": "amazon/nova-lite",
      "input_cost_per_1k": 6e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Nova Lite",
      "output_cost_per_1k": 0.00024,
      "provider": "vercel",
      "release_date": "2024-12-03"
    },
    "vercel/amazon/nova-micro": {
      "cache_read_cost_per_1k": 8.75e-06,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "nova-micro",
      "id": "amazon/nova-micro",
      "input_cost_per_1k": 3.5e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Nova Micro",
      "output_cost_per_1k": 0.00014,
      "provider": "vercel",
      "release_date": "2024-12-03"
    },
    "vercel/amazon/nova-pro": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "nova-pro",
      "id": "amazon/nova-pro",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Nova Pro",
      "output_cost_per_1k": 0.0032,
      "provider": "vercel",
      "release_date": "2024-12-03"
    },
    "vercel/anthropic/claude-3-haiku": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-3-haiku",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Haiku 3",
      "output_cost_per_1k": 0.00125,
      "provider": "vercel",
      "release_date": "2024-03-13"
    },
    "vercel/anthropic/claude-3-opus": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-3-opus",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-08-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Claude Opus 3",
      "output_cost_per_1k": 0.075,
      "provider": "vercel",
      "release_date": "2024-02-29"
    },
    "vercel/anthropic/claude-3.5-haiku": {
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-3.5-haiku",
      "input_cost_per_1k": 0.0008,
      "knowledge_cutoff": "2024-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Haiku 3.5",
      "output_cost_per_1k": 0.004,
      "provider": "vercel",
      "release_date": "2024-10-22"
    },
    "vercel/anthropic/claude-3.5-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-3.5-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-04-30",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Claude Sonnet 3.5 v2",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2024-10-22"
    },
    "vercel/anthropic/claude-3.7-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-3.7-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-10-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 3.7",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-02-19"
    },
    "vercel/anthropic/claude-4-1-opus": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-4-1-opus",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "vercel",
      "release_date": "2025-05-22"
    },
    "vercel/anthropic/claude-4-opus": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-4-opus",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4",
      "output_cost_per_1k": 0.075,
      "provider": "vercel",
      "release_date": "2025-05-22"
    },
    "vercel/anthropic/claude-4-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-4-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-05-22"
    },
    "vercel/anthropic/claude-4.5-sonnet": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-4.5-sonnet",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-09-29"
    },
    "vercel/anthropic/claude-haiku-4.5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-4.5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.00125,
      "provider": "vercel",
      "release_date": "2025-10-15"
    },
    "vercel/anthropic/claude-opus-4.5": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.5",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Opus 4.5",
      "output_cost_per_1k": 0.025,
      "provider": "vercel",
      "release_date": "2025-11-24"
    },
    "vercel/deepseek/deepseek-r1": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek/deepseek-r1",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "DeepSeek-R1",
      "output_cost_per_1k": 0.0054,
      "provider": "vercel",
      "release_date": "2025-01-20"
    },
    "vercel/deepseek/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "deprecated": true,
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.00075,
      "knowledge_cutoff": "2024-07",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.00099,
      "provider": "vercel",
      "release_date": "2025-01-20"
    },
    "vercel/deepseek/deepseek-v3.1-terminus": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.1-terminus",
      "input_cost_per_1k": 0.00027,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3.1 Terminus",
      "open_weights": true,
      "output_cost_per_1k": 0.001,
      "provider": "vercel",
      "release_date": "2025-09-22"
    },
    "vercel/deepseek/deepseek-v3.2-exp": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.2-exp",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 163840,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3.2 Exp",
      "output_cost_per_1k": 0.00042,
      "provider": "vercel",
      "release_date": "2025-09-29"
    },
    "vercel/deepseek/deepseek-v3.2-exp-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek/deepseek-v3.2-exp-thinking",
      "input_cost_per_1k": 0.00028,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 163840,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek V3.2 Exp Thinking",
      "output_cost_per_1k": 0.00042,
      "provider": "vercel",
      "release_date": "2025-09-29"
    },
    "vercel/google/gemini-2.0-flash": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.0-flash",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash",
      "output_cost_per_1k": 0.0004,
      "provider": "vercel",
      "release_date": "2024-12-11"
    },
    "vercel/google/gemini-2.0-flash-lite": {
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.0-flash-lite",
      "input_cost_per_1k": 7.5e-05,
      "knowledge_cutoff": "2024-06",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Gemini 2.0 Flash Lite",
      "output_cost_per_1k": 0.0003,
      "provider": "vercel",
      "release_date": "2024-12-11"
    },
    "vercel/google/gemini-2.5-flash": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash",
      "output_cost_per_1k": 0.0025,
      "provider": "vercel",
      "release_date": "2025-03-20"
    },
    "vercel/google/gemini-2.5-flash-lite": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.5-flash-lite",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite",
      "output_cost_per_1k": 0.0004,
      "provider": "vercel",
      "release_date": "2025-06-17"
    },
    "vercel/google/gemini-2.5-flash-lite-preview-09-2025": {
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash-lite",
      "id": "google/gemini-2.5-flash-lite-preview-09-2025",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "output_cost_per_1k": 0.0004,
      "provider": "vercel",
      "release_date": "2025-09-25"
    },
    "vercel/google/gemini-2.5-flash-preview-09-2025": {
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-flash",
      "id": "google/gemini-2.5-flash-preview-09-2025",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "output_cost_per_1k": 0.0025,
      "provider": "vercel",
      "release_date": "2025-09-25"
    },
    "vercel/google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "vercel",
      "release_date": "2025-03-20"
    },
    "vercel/google/gemini-3-pro-preview": {
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-3-pro-preview",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Gemini 3 Pro Preview",
      "output_cost_per_1k": 0.012,
      "provider": "vercel",
      "release_date": "2025-11-18"
    },
    "vercel/meta/llama-3.3-70b": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-3.3",
      "id": "meta/llama-3.3-70b",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "vercel",
      "release_date": "2024-12-06"
    },
    "vercel/meta/llama-4-maverick": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-maverick",
      "id": "meta/llama-4-maverick",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "vercel",
      "release_date": "2025-04-05"
    },
    "vercel/meta/llama-4-scout": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "meta/llama-4-scout",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Llama-4-Scout-17B-16E-Instruct-FP8",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "vercel",
      "release_date": "2025-04-05"
    },
    "vercel/minimax/minimax-m2": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.00038,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax/minimax-m2",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 205000,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "MiniMax M2",
      "open_weights": true,
      "output_cost_per_1k": 0.0012,
      "provider": "vercel",
      "release_date": "2025-10-27"
    },
    "vercel/mistral/codestral": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "codestral",
      "id": "mistral/codestral",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Codestral",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "vercel",
      "release_date": "2024-05-29"
    },
    "vercel/mistral/magistral-medium": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "magistral-medium",
      "id": "mistral/magistral-medium",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Magistral Medium",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "vercel",
      "release_date": "2025-03-17"
    },
    "vercel/mistral/magistral-small": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "magistral-small",
      "id": "mistral/magistral-small",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2025-06",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Magistral Small",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "vercel",
      "release_date": "2025-03-17"
    },
    "vercel/mistral/ministral-3b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral-3b",
      "id": "mistral/ministral-3b",
      "input_cost_per_1k": 4e-05,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Ministral 3B",
      "open_weights": true,
      "output_cost_per_1k": 4e-05,
      "provider": "vercel",
      "release_date": "2024-10-01"
    },
    "vercel/mistral/ministral-8b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "ministral-8b",
      "id": "mistral/ministral-8b",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Ministral 8B",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "vercel",
      "release_date": "2024-10-01"
    },
    "vercel/mistral/mistral-large": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-large",
      "id": "mistral/mistral-large",
      "input_cost_per_1k": 0.0005,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Mistral Large",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "vercel",
      "release_date": "2024-11-01"
    },
    "vercel/mistral/mistral-small": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "mistral-small",
      "id": "mistral/mistral-small",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-03",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Mistral Small",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "vercel",
      "release_date": "2024-09-01"
    },
    "vercel/mistral/mixtral-8x22b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "mixtral-8x22b",
      "id": "mistral/mixtral-8x22b-instruct",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Mixtral 8x22B",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "vercel",
      "release_date": "2024-04-17"
    },
    "vercel/mistral/pixtral-12b": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "pixtral",
      "id": "mistral/pixtral-12b",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2024-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Pixtral 12B",
      "open_weights": true,
      "output_cost_per_1k": 0.00015,
      "provider": "vercel",
      "release_date": "2024-09-01"
    },
    "vercel/mistral/pixtral-large": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "pixtral-large",
      "id": "mistral/pixtral-large",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "Pixtral Large",
      "open_weights": true,
      "output_cost_per_1k": 0.006,
      "provider": "vercel",
      "release_date": "2024-11-01"
    },
    "vercel/moonshotai/kimi-k2": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "deprecated": true,
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.003,
      "provider": "vercel",
      "release_date": "2025-07-14"
    },
    "vercel/morph/morph-v3-fast": {
      "family": "morph-v3-fast",
      "id": "morph/morph-v3-fast",
      "input_cost_per_1k": 0.0008,
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "Morph v3 Fast",
      "output_cost_per_1k": 0.0012,
      "provider": "vercel",
      "release_date": "2024-08-15"
    },
    "vercel/morph/morph-v3-large": {
      "family": "morph-v3-large",
      "id": "morph/morph-v3-large",
      "input_cost_per_1k": 0.0009,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Morph v3 Large",
      "output_cost_per_1k": 0.0019,
      "provider": "vercel",
      "release_date": "2024-08-15"
    },
    "vercel/openai/gpt-4-turbo": {
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "gpt-4-turbo",
      "id": "openai/gpt-4-turbo",
      "input_cost_per_1k": 0.01,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "GPT-4 Turbo",
      "output_cost_per_1k": 0.03,
      "provider": "vercel",
      "release_date": "2023-11-06"
    },
    "vercel/openai/gpt-4.1": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1",
      "id": "openai/gpt-4.1",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1",
      "output_cost_per_1k": 0.008,
      "provider": "vercel",
      "release_date": "2025-04-14"
    },
    "vercel/openai/gpt-4.1-mini": {
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-mini",
      "id": "openai/gpt-4.1-mini",
      "input_cost_per_1k": 0.0004,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 mini",
      "output_cost_per_1k": 0.0016,
      "provider": "vercel",
      "release_date": "2025-04-14"
    },
    "vercel/openai/gpt-4.1-nano": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4.1-nano",
      "id": "openai/gpt-4.1-nano",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2024-04",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT-4.1 nano",
      "output_cost_per_1k": 0.0004,
      "provider": "vercel",
      "release_date": "2025-04-14"
    },
    "vercel/openai/gpt-4o": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o",
      "id": "openai/gpt-4o",
      "input_cost_per_1k": 0.0025,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o",
      "output_cost_per_1k": 0.01,
      "provider": "vercel",
      "release_date": "2024-05-13"
    },
    "vercel/openai/gpt-4o-mini": {
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "family": "gpt-4o-mini",
      "id": "openai/gpt-4o-mini",
      "input_cost_per_1k": 0.00015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GPT-4o mini",
      "output_cost_per_1k": 0.0006,
      "provider": "vercel",
      "release_date": "2024-07-18"
    },
    "vercel/openai/gpt-5": {
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "vercel",
      "release_date": "2025-08-07"
    },
    "vercel/openai/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-09-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5-Codex",
      "output_cost_per_1k": 0.01,
      "provider": "vercel",
      "release_date": "2025-09-15"
    },
    "vercel/openai/gpt-5-mini": {
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-mini",
      "id": "openai/gpt-5-mini",
      "input_cost_per_1k": 0.00025,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Mini",
      "output_cost_per_1k": 0.002,
      "provider": "vercel",
      "release_date": "2025-08-07"
    },
    "vercel/openai/gpt-5-nano": {
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "gpt-5-nano",
      "id": "openai/gpt-5-nano",
      "input_cost_per_1k": 5e-05,
      "knowledge_cutoff": "2024-05-30",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Nano",
      "output_cost_per_1k": 0.0004,
      "provider": "vercel",
      "release_date": "2025-08-07"
    },
    "vercel/openai/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-120b",
      "input_cost_per_1k": 0.0001,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0005,
      "provider": "vercel",
      "release_date": "2025-08-05"
    },
    "vercel/openai/gpt-oss-20b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "openai/gpt-oss-20b",
      "input_cost_per_1k": 7e-05,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GPT OSS 20B",
      "open_weights": true,
      "output_cost_per_1k": 0.0003,
      "provider": "vercel",
      "release_date": "2025-08-05"
    },
    "vercel/openai/o1": {
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o1",
      "id": "openai/o1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2023-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o1",
      "output_cost_per_1k": 0.06,
      "provider": "vercel",
      "release_date": "2024-12-05"
    },
    "vercel/openai/o3": {
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o3",
      "id": "openai/o3",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3",
      "output_cost_per_1k": 0.008,
      "provider": "vercel",
      "release_date": "2025-04-16"
    },
    "vercel/openai/o3-mini": {
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "family": "o3-mini",
      "id": "openai/o3-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o3-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "vercel",
      "release_date": "2024-12-20"
    },
    "vercel/openai/o4-mini": {
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "family": "o4-mini",
      "id": "openai/o4-mini",
      "input_cost_per_1k": 0.0011,
      "knowledge_cutoff": "2024-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "mode": "chat",
      "name": "o4-mini",
      "output_cost_per_1k": 0.0044,
      "provider": "vercel",
      "release_date": "2025-04-16"
    },
    "vercel/perplexity/sonar": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "sonar",
      "id": "perplexity/sonar",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Sonar",
      "output_cost_per_1k": 0.001,
      "provider": "vercel",
      "release_date": "2025-02-19"
    },
    "vercel/perplexity/sonar-pro": {
      "capabilities": [
        "temperature",
        "vision"
      ],
      "family": "sonar-pro",
      "id": "perplexity/sonar-pro",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Sonar Pro",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-02-19"
    },
    "vercel/perplexity/sonar-reasoning": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "sonar-reasoning",
      "id": "perplexity/sonar-reasoning",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Sonar Reasoning",
      "output_cost_per_1k": 0.005,
      "provider": "vercel",
      "release_date": "2025-02-19"
    },
    "vercel/perplexity/sonar-reasoning-pro": {
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "family": "sonar-reasoning",
      "id": "perplexity/sonar-reasoning-pro",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "Sonar Reasoning Pro",
      "output_cost_per_1k": 0.008,
      "provider": "vercel",
      "release_date": "2025-02-19"
    },
    "vercel/vercel/v0-1.0-md": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "v0",
      "id": "vercel/v0-1.0-md",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "v0-1.0-md",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-05-22"
    },
    "vercel/vercel/v0-1.5-md": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "v0",
      "id": "vercel/v0-1.5-md",
      "input_cost_per_1k": 0.003,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "v0-1.5-md",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-06-09"
    },
    "vercel/xai/grok-2": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-2",
      "id": "xai/grok-2",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 2",
      "output_cost_per_1k": 0.01,
      "provider": "vercel",
      "release_date": "2024-08-20"
    },
    "vercel/xai/grok-2-vision": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok-2",
      "id": "xai/grok-2-vision",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Grok 2 Vision",
      "output_cost_per_1k": 0.01,
      "provider": "vercel",
      "release_date": "2024-08-20"
    },
    "vercel/xai/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "xai/grok-3",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-3-fast": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "xai/grok-3-fast",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Fast",
      "output_cost_per_1k": 0.025,
      "provider": "vercel",
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "xai/grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "vercel",
      "reasoning_cost_per_1k": 0.0005,
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-3-mini-fast": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "xai/grok-3-mini-fast",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini Fast",
      "output_cost_per_1k": 0.004,
      "provider": "vercel",
      "reasoning_cost_per_1k": 0.004,
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "xai/grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "vercel",
      "reasoning_cost_per_1k": 0.015,
      "release_date": "2025-07-09"
    },
    "vercel/xai/grok-4-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "xai/grok-4-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "vercel",
      "release_date": "2025-09-19"
    },
    "vercel/xai/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "xai/grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "vercel",
      "release_date": "2025-09-19"
    },
    "vercel/xai/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "xai/grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "vercel",
      "release_date": "2025-08-28"
    },
    "vercel/zai/glm-4.5": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "zai/glm-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "vercel",
      "release_date": "2025-07-28"
    },
    "vercel/zai/glm-4.5-air": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "zai/glm-4.5-air",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "vercel",
      "release_date": "2025-07-28"
    },
    "vercel/zai/glm-4.5v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "zai/glm-4.5v",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-08",
      "max_input_tokens": 66000,
      "max_output_tokens": 16000,
      "mode": "chat",
      "name": "GLM 4.5V",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "vercel",
      "release_date": "2025-08-11"
    },
    "vercel/zai/glm-4.6": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "zai/glm-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 200000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "vercel",
      "release_date": "2025-09-30"
    },
    "vultr/deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1-distill-llama",
      "id": "deepseek-r1-distill-llama-70b",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 121808,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Llama 70B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "vultr",
      "release_date": "2025-01-20"
    },
    "vultr/deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen",
      "id": "deepseek-r1-distill-qwen-32b",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 121808,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "vultr",
      "release_date": "2025-01-20"
    },
    "vultr/gpt-oss-120b": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "gpt-oss",
      "id": "gpt-oss-120b",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 121808,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "GPT OSS 120B",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "vultr",
      "release_date": "2025-06-23"
    },
    "vultr/kimi-k2-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "kimi-k2-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 58904,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Kimi K2 Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "vultr",
      "release_date": "2024-07-18"
    },
    "vultr/qwen2.5-coder-32b-instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen2.5-coder",
      "id": "qwen2.5-coder-32b-instruct",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 12952,
      "max_output_tokens": 2048,
      "mode": "chat",
      "name": "Qwen2.5 Coder 32B Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0002,
      "provider": "vultr",
      "release_date": "2024-11-06"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3 235B A22B Instruct 2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "wandb",
      "release_date": "2025-04-28"
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "qwen3",
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "input_cost_per_1k": 0.0001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "open_weights": true,
      "output_cost_per_1k": 0.0001,
      "provider": "wandb",
      "release_date": "2025-07-25"
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "mode": "chat",
      "name": "Qwen3-Coder-480B-A35B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.0015,
      "provider": "wandb",
      "release_date": "2025-07-23"
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-r1",
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2025-05",
      "max_input_tokens": 161000,
      "max_output_tokens": 163840,
      "mode": "chat",
      "name": "DeepSeek-R1-0528",
      "open_weights": true,
      "output_cost_per_1k": 0.0054,
      "provider": "wandb",
      "release_date": "2025-05-28"
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "deepseek-v3",
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "input_cost_per_1k": 0.00114,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 161000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "DeepSeek-V3-0324",
      "open_weights": true,
      "output_cost_per_1k": 0.00275,
      "provider": "wandb",
      "release_date": "2025-03-24"
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.1",
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "input_cost_per_1k": 0.00022,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00022,
      "provider": "wandb",
      "release_date": "2024-07-23"
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "llama-3.3",
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "input_cost_per_1k": 0.00071,
      "knowledge_cutoff": "2023-12",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "Llama-3.3-70B-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00071,
      "provider": "wandb",
      "release_date": "2024-12-06"
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "llama-4-scout",
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "input_cost_per_1k": 0.00017,
      "knowledge_cutoff": "2024-12",
      "max_input_tokens": 64000,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00066,
      "provider": "wandb",
      "release_date": "2025-01-31"
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "phi-4",
      "id": "microsoft/Phi-4-mini-instruct",
      "input_cost_per_1k": 8e-05,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Phi-4-mini-instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.00035,
      "provider": "wandb",
      "release_date": "2024-12-11"
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/Kimi-K2-Instruct",
      "input_cost_per_1k": 0.00135,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi-K2-Instruct",
      "open_weights": true,
      "output_cost_per_1k": 0.004,
      "provider": "wandb",
      "release_date": "2025-07-14"
    },
    "xai/grok-2": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-2",
      "id": "grok-2",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 2",
      "output_cost_per_1k": 0.01,
      "provider": "xai",
      "release_date": "2024-08-20"
    },
    "xai/grok-2-1212": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-2",
      "id": "grok-2-1212",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 2 (1212)",
      "output_cost_per_1k": 0.01,
      "provider": "xai",
      "release_date": "2024-12-12"
    },
    "xai/grok-2-latest": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-2",
      "id": "grok-2-latest",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 2 Latest",
      "output_cost_per_1k": 0.01,
      "provider": "xai",
      "release_date": "2024-08-20"
    },
    "xai/grok-2-vision": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok-2",
      "id": "grok-2-vision",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Grok 2 Vision",
      "output_cost_per_1k": 0.01,
      "provider": "xai",
      "release_date": "2024-08-20"
    },
    "xai/grok-2-vision-1212": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok-2",
      "id": "grok-2-vision-1212",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Grok 2 Vision (1212)",
      "output_cost_per_1k": 0.01,
      "provider": "xai",
      "release_date": "2024-08-20"
    },
    "xai/grok-2-vision-latest": {
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok-2",
      "id": "grok-2-vision-latest",
      "input_cost_per_1k": 0.002,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Grok 2 Vision Latest",
      "output_cost_per_1k": 0.01,
      "provider": "xai",
      "release_date": "2024-08-20"
    },
    "xai/grok-3": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3",
      "output_cost_per_1k": 0.015,
      "provider": "xai",
      "release_date": "2025-02-17"
    },
    "xai/grok-3-fast": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-fast",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Fast",
      "output_cost_per_1k": 0.025,
      "provider": "xai",
      "release_date": "2025-02-17"
    },
    "xai/grok-3-fast-latest": {
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-fast-latest",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Fast Latest",
      "output_cost_per_1k": 0.025,
      "provider": "xai",
      "release_date": "2025-02-17"
    },
    "xai/grok-3-latest": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-latest",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Latest",
      "output_cost_per_1k": 0.015,
      "provider": "xai",
      "release_date": "2025-02-17"
    },
    "xai/grok-3-mini": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini",
      "output_cost_per_1k": 0.0005,
      "provider": "xai",
      "reasoning_cost_per_1k": 0.0005,
      "release_date": "2025-02-17"
    },
    "xai/grok-3-mini-fast": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini-fast",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini Fast",
      "output_cost_per_1k": 0.004,
      "provider": "xai",
      "reasoning_cost_per_1k": 0.004,
      "release_date": "2025-02-17"
    },
    "xai/grok-3-mini-fast-latest": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini-fast-latest",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini Fast Latest",
      "output_cost_per_1k": 0.004,
      "provider": "xai",
      "reasoning_cost_per_1k": 0.004,
      "release_date": "2025-02-17"
    },
    "xai/grok-3-mini-latest": {
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok-3",
      "id": "grok-3-mini-latest",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2024-11",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "mode": "chat",
      "name": "Grok 3 Mini Latest",
      "output_cost_per_1k": 0.0005,
      "provider": "xai",
      "reasoning_cost_per_1k": 0.0005,
      "release_date": "2025-02-17"
    },
    "xai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "xai",
      "reasoning_cost_per_1k": 0.015,
      "release_date": "2025-07-09"
    },
    "xai/grok-4-1-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-1-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4.1 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "xai",
      "release_date": "2025-11-19"
    },
    "xai/grok-4-1-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-1-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4.1 Fast (Non-Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "xai",
      "release_date": "2025-11-19"
    },
    "xai/grok-4-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "xai",
      "release_date": "2025-09-19"
    },
    "xai/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok",
      "id": "grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "output_cost_per_1k": 0.0005,
      "provider": "xai",
      "release_date": "2025-09-19"
    },
    "xai/grok-beta": {
      "cache_read_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "grok-beta",
      "id": "grok-beta",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Grok Beta",
      "output_cost_per_1k": 0.015,
      "provider": "xai",
      "release_date": "2024-11-01"
    },
    "xai/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2023-10",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "xai",
      "release_date": "2025-08-28"
    },
    "xai/grok-vision-beta": {
      "cache_read_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok-vision",
      "id": "grok-vision-beta",
      "input_cost_per_1k": 0.005,
      "knowledge_cutoff": "2024-08",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "mode": "chat",
      "name": "Grok Vision Beta",
      "output_cost_per_1k": 0.015,
      "provider": "xai",
      "release_date": "2024-11-01"
    },
    "xiaomi/mimo-v2-flash": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mimo-v2-flash",
      "id": "mimo-v2-flash",
      "input_cost_per_1k": 7e-05,
      "knowledge_cutoff": "2024-12-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "MiMo-V2-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.00021,
      "provider": "xiaomi",
      "release_date": "2025-12-17"
    },
    "zai/glm-4.5": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "glm-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "zai",
      "release_date": "2025-07-28"
    },
    "zai/glm-4.5-air": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "glm-4.5-air",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "zai",
      "release_date": "2025-07-28"
    },
    "zai/glm-4.5-flash": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-flash",
      "id": "glm-4.5-flash",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai",
      "release_date": "2025-07-28"
    },
    "zai/glm-4.5v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "glm-4.5v",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GLM-4.5V",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "zai",
      "release_date": "2025-08-11"
    },
    "zai/glm-4.6": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "zai",
      "release_date": "2025-09-30"
    },
    "zai/glm-4.6v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "glm-4.6v",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM-4.6V",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "zai",
      "release_date": "2025-12-08"
    },
    "zai/glm-4.7": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "glm-4.7",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "zai",
      "release_date": "2025-12-22"
    },
    "zai_coding_plan/glm-4.5": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "glm-4.5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-07-28"
    },
    "zai_coding_plan/glm-4.5-air": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "glm-4.5-air",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-07-28"
    },
    "zai_coding_plan/glm-4.5-flash": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-flash",
      "id": "glm-4.5-flash",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-07-28"
    },
    "zai_coding_plan/glm-4.5v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "glm-4.5v",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GLM-4.5V",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-08-11"
    },
    "zai_coding_plan/glm-4.6": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-09-30"
    },
    "zai_coding_plan/glm-4.6v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "glm-4.6v",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM-4.6V",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-12-08"
    },
    "zai_coding_plan/glm-4.7": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "glm-4.7",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zai_coding_plan",
      "release_date": "2025-12-22"
    },
    "zenmux/anthropic/claude-haiku-4.5": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-haiku",
      "id": "anthropic/claude-haiku-4.5",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-02-28",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Haiku 4.5",
      "output_cost_per_1k": 0.005,
      "provider": "zenmux",
      "release_date": "2025-10-15"
    },
    "zenmux/anthropic/claude-opus-4.1": {
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-opus",
      "id": "anthropic/claude-opus-4.1",
      "input_cost_per_1k": 0.015,
      "knowledge_cutoff": "2025-03-31",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Claude Opus 4.1",
      "output_cost_per_1k": 0.075,
      "provider": "zenmux",
      "release_date": "2025-08-05"
    },
    "zenmux/anthropic/claude-sonnet-4.5": {
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "claude-sonnet",
      "id": "anthropic/claude-sonnet-4.5",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-07-31",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "mode": "chat",
      "name": "Claude Sonnet 4.5",
      "output_cost_per_1k": 0.015,
      "provider": "zenmux",
      "release_date": "2025-09-29"
    },
    "zenmux/deepseek/deepseek-chat": {
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "deepseek-chat",
      "id": "deepseek/deepseek-chat",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2025-07",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "mode": "chat",
      "name": "DeepSeek-V3.2-Exp (Non-thinking Mode)",
      "open_weights": true,
      "output_cost_per_1k": 0.00168,
      "provider": "zenmux",
      "release_date": "2025-09-29"
    },
    "zenmux/google/gemini-2.5-pro": {
      "cache_read_cost_per_1k": 0.00031,
      "cache_write_cost_per_1k": 0.0045,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "gemini-pro",
      "id": "google/gemini-2.5-pro",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2025-01",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "mode": "chat",
      "name": "Gemini 2.5 Pro",
      "output_cost_per_1k": 0.01,
      "provider": "zenmux",
      "release_date": "2025-03-20"
    },
    "zenmux/inclusionai/lint-1t": {
      "cache_read_cost_per_1k": 0.000112,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "lint-1t",
      "id": "inclusionai/lint-1t",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Ling-1T",
      "open_weights": true,
      "output_cost_per_1k": 0.00224,
      "provider": "zenmux",
      "release_date": "2025-10-09"
    },
    "zenmux/inclusionai/ring-1t": {
      "cache_read_cost_per_1k": 0.000112,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "ring-1t",
      "id": "inclusionai/ring-1t",
      "input_cost_per_1k": 0.00056,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "Ring-1T",
      "open_weights": true,
      "output_cost_per_1k": 0.00224,
      "provider": "zenmux",
      "release_date": "2025-10-12"
    },
    "zenmux/kuaishou/kat-coder-pro-v1": {
      "cache_read_cost_per_1k": 0.00012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kat-coder-pro",
      "id": "kuaishou/kat-coder-pro-v1",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-01-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "KAT-Coder-Pro-V1",
      "output_cost_per_1k": 0.0024,
      "provider": "zenmux",
      "release_date": "2025-10-23"
    },
    "zenmux/minimax/minimax-m2": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "minimax",
      "id": "minimax/minimax-m2",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-10",
      "max_input_tokens": 204800,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "MiniMax M2",
      "output_cost_per_1k": 0.0012,
      "provider": "zenmux",
      "release_date": "2025-10-27"
    },
    "zenmux/moonshotai/kimi-k2-0905": {
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-0905",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2024-10",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "Kimi K2 0905",
      "output_cost_per_1k": 0.0025,
      "provider": "zenmux",
      "release_date": "2025-09-04"
    },
    "zenmux/moonshotai/kimi-k2-thinking": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-thinking",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking",
      "output_cost_per_1k": 0.0025,
      "provider": "zenmux",
      "release_date": "2025-11-06"
    },
    "zenmux/moonshotai/kimi-k2-thinking-turbo": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "kimi-k2",
      "id": "moonshotai/kimi-k2-thinking-turbo",
      "input_cost_per_1k": 0.00115,
      "knowledge_cutoff": "2025-11",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "mode": "chat",
      "name": "Kimi K2 Thinking Turbo",
      "output_cost_per_1k": 0.008,
      "provider": "zenmux",
      "release_date": "2025-11-06"
    },
    "zenmux/openai/gpt-5": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5",
      "id": "openai/gpt-5",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5",
      "output_cost_per_1k": 0.01,
      "provider": "zenmux",
      "release_date": "2025-08-07"
    },
    "zenmux/openai/gpt-5-codex": {
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "gpt-5-codex",
      "id": "openai/gpt-5-codex",
      "input_cost_per_1k": 0.00125,
      "knowledge_cutoff": "2024-10-01",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GPT-5 Codex",
      "output_cost_per_1k": 0.01,
      "provider": "zenmux",
      "release_date": "2025-09-23"
    },
    "zenmux/qwen/qwen3-coder-plus": {
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "family": "qwen3-coder",
      "id": "qwen/qwen3-coder-plus",
      "input_cost_per_1k": 0.001,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 1000000,
      "max_output_tokens": 66540,
      "mode": "chat",
      "name": "Qwen3 Coder Plus",
      "open_weights": true,
      "output_cost_per_1k": 0.005,
      "provider": "zenmux",
      "release_date": "2025-07-23"
    },
    "zenmux/x-ai/grok-4": {
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4",
      "input_cost_per_1k": 0.003,
      "knowledge_cutoff": "2025-01-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "mode": "chat",
      "name": "Grok 4",
      "output_cost_per_1k": 0.015,
      "provider": "zenmux",
      "release_date": "2025-07-09"
    },
    "zenmux/x-ai/grok-4-fast": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4-fast",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-01-01",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast",
      "output_cost_per_1k": 0.0005,
      "provider": "zenmux",
      "release_date": "2025-09-19"
    },
    "zenmux/x-ai/grok-4-fast-non-reasoning": {
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "family": "grok-4",
      "id": "x-ai/grok-4-fast-non-reasoning",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-01-01",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "mode": "chat",
      "name": "Grok 4 Fast None Reasoning",
      "output_cost_per_1k": 0.0005,
      "provider": "zenmux",
      "release_date": "2025-09-19"
    },
    "zenmux/x-ai/grok-code-fast-1": {
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "grok",
      "id": "x-ai/grok-code-fast-1",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-01-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "mode": "chat",
      "name": "Grok Code Fast 1",
      "output_cost_per_1k": 0.0015,
      "provider": "zenmux",
      "release_date": "2025-08-26"
    },
    "zenmux/xiaomi/mimo-v2-flash": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "mimo-v2-flash",
      "id": "xiaomi/mimo-v2-flash",
      "input_cost_per_1k": 7e-05,
      "knowledge_cutoff": "2024-12-01",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "name": "MiMo-V2-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.00021,
      "provider": "zenmux",
      "release_date": "2025-12-17"
    },
    "zenmux/z-ai/glm-4.5-air": {
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "z-ai/glm-4.5-air",
      "input_cost_per_1k": 0.00011,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "mode": "chat",
      "name": "GLM 4.5 Air",
      "open_weights": true,
      "output_cost_per_1k": 0.00056,
      "provider": "zenmux",
      "release_date": "2025-07-25"
    },
    "zenmux/z-ai/glm-4.6": {
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "z-ai/glm-4.6",
      "input_cost_per_1k": 0.00035,
      "knowledge_cutoff": "2025-09",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "name": "GLM 4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.00154,
      "provider": "zenmux",
      "release_date": "2025-09-30"
    },
    "zhipuai/glm-4.5": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "glm-4.5",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "zhipuai",
      "release_date": "2025-07-28"
    },
    "zhipuai/glm-4.5-air": {
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "glm-4.5-air",
      "input_cost_per_1k": 0.0002,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0011,
      "provider": "zhipuai",
      "release_date": "2025-07-28"
    },
    "zhipuai/glm-4.5-flash": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-flash",
      "id": "glm-4.5-flash",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai",
      "release_date": "2025-07-28"
    },
    "zhipuai/glm-4.5v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "glm-4.5v",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GLM-4.5V",
      "open_weights": true,
      "output_cost_per_1k": 0.0018,
      "provider": "zhipuai",
      "release_date": "2025-08-11"
    },
    "zhipuai/glm-4.6": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "zhipuai",
      "release_date": "2025-09-30"
    },
    "zhipuai/glm-4.6v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "glm-4.6v",
      "input_cost_per_1k": 0.0003,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM-4.6V",
      "open_weights": true,
      "output_cost_per_1k": 0.0009,
      "provider": "zhipuai",
      "release_date": "2025-12-08"
    },
    "zhipuai/glm-4.6v-flash": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "glm-4.6v-flash",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM-4.6V-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai",
      "release_date": "2025-12-08"
    },
    "zhipuai/glm-4.7": {
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "glm-4.7",
      "input_cost_per_1k": 0.0006,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0022,
      "provider": "zhipuai",
      "release_date": "2025-12-22"
    },
    "zhipuai_coding_plan/glm-4.5": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5",
      "id": "glm-4.5",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-07-28"
    },
    "zhipuai_coding_plan/glm-4.5-air": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-air",
      "id": "glm-4.5-air",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Air",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-07-28"
    },
    "zhipuai_coding_plan/glm-4.5-flash": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.5-flash",
      "id": "glm-4.5-flash",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "mode": "chat",
      "name": "GLM-4.5-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-07-28"
    },
    "zhipuai_coding_plan/glm-4.5v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.5v",
      "id": "glm-4.5v",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "mode": "chat",
      "name": "GLM-4.5V",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-08-11"
    },
    "zhipuai_coding_plan/glm-4.6": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.6",
      "id": "glm-4.6",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.6",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-09-30"
    },
    "zhipuai_coding_plan/glm-4.6v": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "glm-4.6v",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM-4.6V",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-12-08"
    },
    "zhipuai_coding_plan/glm-4.6v-flash": {
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "family": "glm-4.6v",
      "id": "glm-4.6v-flash",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "mode": "chat",
      "name": "GLM-4.6V-Flash",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-12-08"
    },
    "zhipuai_coding_plan/glm-4.7": {
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "family": "glm-4.7",
      "id": "glm-4.7",
      "input_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-04",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "mode": "chat",
      "name": "GLM-4.7",
      "open_weights": true,
      "output_cost_per_1k": 0.0,
      "provider": "zhipuai_coding_plan",
      "release_date": "2025-12-22"
    }
  },
  "providers": {
    "anthropic": {
      "api_endpoint": null,
      "auth": {
        "header": "x-api-key",
        "key_prefixes": [
          "sk-ant-"
        ],
        "type": "api_key"
      },
      "display_name": "Anthropic",
      "domains": [
        "api.anthropic.com"
      ],
      "features": [
        "chat",
        "vision",
        "tool_use",
        "computer_use"
      ],
      "id": "anthropic",
      "models_dev_id": null,
      "type": "cloud"
    },
    "aws_bedrock": {
      "api_endpoint": null,
      "auth": {
        "type": "aws_sig_v4"
      },
      "display_name": "AWS Bedrock",
      "domains": [
        "bedrock-runtime.*.amazonaws.com",
        "bedrock.*.amazonaws.com"
      ],
      "features": [
        "chat",
        "embedding",
        "image_generation"
      ],
      "id": "aws_bedrock",
      "models_dev_id": null,
      "type": "cloud"
    },
    "azure_openai": {
      "api_endpoint": null,
      "auth": {
        "header": "api-key",
        "type": "api_key"
      },
      "display_name": "Azure OpenAI Service",
      "domains": [
        "*.openai.azure.com"
      ],
      "features": [
        "chat",
        "completion",
        "embedding",
        "image_generation"
      ],
      "id": "azure_openai",
      "models_dev_id": null,
      "type": "cloud"
    },
    "cohere": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Cohere",
      "domains": [
        "api.cohere.ai",
        "api.cohere.com"
      ],
      "features": [
        "chat",
        "embedding",
        "rerank"
      ],
      "id": "cohere",
      "models_dev_id": null,
      "type": "cloud"
    },
    "deepseek": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "DeepSeek",
      "domains": [
        "api.deepseek.com"
      ],
      "features": [
        "chat",
        "reasoning"
      ],
      "id": "deepseek",
      "models_dev_id": null,
      "type": "cloud"
    },
    "fireworks": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Fireworks AI",
      "domains": [
        "api.fireworks.ai"
      ],
      "features": [
        "chat",
        "embedding"
      ],
      "id": "fireworks",
      "models_dev_id": null,
      "type": "cloud"
    },
    "google": {
      "api_endpoint": null,
      "auth": {
        "query_param": "key",
        "type": "api_key"
      },
      "display_name": "Google AI (Gemini)",
      "domains": [
        "generativelanguage.googleapis.com",
        "aiplatform.googleapis.com"
      ],
      "features": [
        "chat",
        "embedding",
        "vision",
        "function_calling"
      ],
      "id": "google",
      "models_dev_id": null,
      "type": "cloud"
    },
    "groq": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Groq",
      "domains": [
        "api.groq.com"
      ],
      "features": [
        "chat",
        "vision"
      ],
      "id": "groq",
      "models_dev_id": null,
      "type": "cloud"
    },
    "huggingface": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Hugging Face",
      "domains": [
        "api-inference.huggingface.co"
      ],
      "features": [
        "chat",
        "embedding"
      ],
      "id": "huggingface",
      "models_dev_id": null,
      "type": "cloud"
    },
    "lmstudio": {
      "api_endpoint": null,
      "auth": {
        "type": "none"
      },
      "display_name": "LM Studio",
      "domains": [
        "localhost:1234",
        "127.0.0.1:1234"
      ],
      "features": [
        "chat"
      ],
      "id": "lmstudio",
      "models_dev_id": null,
      "type": "local"
    },
    "mistral": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Mistral AI",
      "domains": [
        "api.mistral.ai"
      ],
      "features": [
        "chat",
        "embedding",
        "function_calling"
      ],
      "id": "mistral",
      "models_dev_id": null,
      "type": "cloud"
    },
    "ollama": {
      "api_endpoint": null,
      "auth": {
        "type": "none"
      },
      "display_name": "Ollama",
      "domains": [
        "localhost:11434",
        "127.0.0.1:11434",
        "*.local:11434"
      ],
      "features": [
        "chat",
        "embedding"
      ],
      "id": "ollama",
      "models_dev_id": null,
      "type": "local"
    },
    "openai": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "key_prefixes": [
          "sk-",
          "sk-proj-",
          "sk-svcacct-"
        ],
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "OpenAI",
      "domains": [
        "api.openai.com"
      ],
      "features": [
        "chat",
        "completion",
        "embedding",
        "image_generation",
        "audio_transcription",
        "audio_speech",
        "moderation"
      ],
      "id": "openai",
      "models_dev_id": null,
      "type": "cloud"
    },
    "perplexity": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Perplexity",
      "domains": [
        "api.perplexity.ai"
      ],
      "features": [
        "chat",
        "web_search"
      ],
      "id": "perplexity",
      "models_dev_id": null,
      "type": "cloud"
    },
    "replicate": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Token ",
        "type": "api_key"
      },
      "display_name": "Replicate",
      "domains": [
        "api.replicate.com"
      ],
      "features": [
        "chat",
        "image_generation"
      ],
      "id": "replicate",
      "models_dev_id": null,
      "type": "cloud"
    },
    "text_generation_inference": {
      "api_endpoint": null,
      "auth": {
        "type": "none"
      },
      "display_name": "Text Generation Inference (TGI)",
      "domains": [],
      "features": [
        "chat",
        "completion"
      ],
      "id": "text_generation_inference",
      "models_dev_id": null,
      "type": "self_hosted"
    },
    "together": {
      "api_endpoint": null,
      "auth": {
        "header": "Authorization",
        "prefix": "Bearer ",
        "type": "api_key"
      },
      "display_name": "Together AI",
      "domains": [
        "api.together.xyz"
      ],
      "features": [
        "chat",
        "embedding",
        "image_generation"
      ],
      "id": "together",
      "models_dev_id": null,
      "type": "cloud"
    },
    "vllm": {
      "api_endpoint": null,
      "auth": {
        "type": "api_key"
      },
      "display_name": "vLLM",
      "domains": [],
      "features": [
        "chat",
        "completion"
      ],
      "id": "vllm",
      "models_dev_id": null,
      "type": "self_hosted"
    }
  },
  "source": "oisp-spec",
  "version": "0.1"
}